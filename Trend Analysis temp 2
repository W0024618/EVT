Check below both backend and Frontend file carefully ..i have review one issue here WHich i need to fix...
When i run trend for 
From
2025-11-06
To
2025-11-06
http://localhost:8002/run?date=2025-11-06
{
  "_raw_unique_person_uids": 607,
  "aggregated_rows_total_raw": 607,
  "aggregated_unique_persons": 607,
  "end_date": "2025-11-06",
  "files": [
    "trend_pune_20251106.csv"
  ],
  "flagged_rate_percent": 2.47,
  "flagged_rows": 15,
  "rows": 607,
  "sample": [


here Flagged rows are 15 but sample display only 10 people why this issue happen..
{
  "_raw_unique_person_uids": 607,
  "aggregated_rows_total_raw": 607,
  "aggregated_unique_persons": 607,
  "end_date": "2025-11-06",
  "files": [
    "trend_pune_20251106.csv"
  ],
  "flagged_rate_percent": 2.47,
  "flagged_rows": 15,
  "rows": 607,
  "sample": [
    {
      "AnomalyScore": 1.5,
      "BreakCount": 0,
      "CardNumber": "615467",
      "CompanyName": "WU Srvcs India Private Ltd",
      "ConsecWeeksShort4hrs": 0,
      "CountSwipes": 17,
      "Date": "2025-11-06",
      "DetectedScenarios": "short_duration_<4h; repeated_short_breaks",
      "Duration": "2:19:07",
      "DurationMinutes": 139.11666666666667,
      "DurationSeconds": 8347.0,
      "EmpHistoryPresent": false,
      "EmployeeID": "312751",
      "EmployeeIdentity": "08C48C40-8339-4C88-9E33-F2F29F4D635C",
      "EmployeeName": "Ablankar, Sujit Manohar",
      "Explanation": "Ablankar, Sujit Manohar -  Short total presence (139 min) \u2014 less than 4 hours; may indicate short stay or partial-day attendance. Many short gaps between swipes \u2014 repeated short breaks pattern.",
      "FirstDirection": "InDirection",
      "FirstDoor": "APAC_IN_PUN_PODIUM_P-1 TURNSTILE 2-DOOR",
      "FirstSwipe": "2025-11-06T13:50:03",
      "HistPatternShortLongCount90": 0,
      "HistRepeatedShortBreakCount90": 33,
      "HistShortDurationCount90": 8,
      "InCount": 9,
      "IsFlagged": true,
      "LastDirection": "OutDirection",
      "LastDoor": "APAC_IN_PUN_PODIUM_P-1 TURNSTILE 1-OUT DOOR",
      "LastSwipe": "2025-11-06T16:09:10",
      "LongBreakCount": 0,
      "MaxSwipeGapSeconds": 4776,
      "MonitorFlag": false,
      "OnlyIn": 0,
      "OnlyOut": 0,
      "OutCount": 8,
      "OverlapWith": null,
      "PartitionName2": "APAC.Default",
      "PatternSequence": null,
      "PatternSequenceReadable": null,
      "PatternShortLongRepeat": false,
      "PersonnelType": "Employee",
      "PersonnelTypeName": "Employee",
      "PresentToday": true,
      "PrimaryLocation": "Pune - Business Bay",
      "Reasons": "repeated_short_breaks; short_duration_<4h",
      "RejectionCount": 0,
      "RiskLevel": "High",
      "RiskScore": 5,
      "ShortGapCount": 13,
      "SingleDoor": 0,
      "TotalBreakMinutes": 0.0,
      "UniqueDoors": 6,
      "UniqueLocations": 1,
      "ViolationDaysLast90": 7,
      "_norm_id": "08C48C40-8339-4C88-9E33-F2F29F4D635C",
      "badge_sharing_suspected": false,
      "behaviour_shift": false,
      "coffee_badging": false,
      "consecutive_absent_days": false,
      "early_arrival_before_06": false,
      "high_swipes_benign": false,
      "high_variance_duration": false,
      "late_exit_after_22": false,
      "long_gap_>=4.5h": false,
      "low_swipe_count_<=2": false,
      "multiple_location_same_day": false,
      "only_in": false,
      "only_out": false,
      "overtime_>=10h": false,
      "person_uid": "08C48C40-8339-4C88-9E33-F2F29F4D635C",
      "repeated_rejection_count": false,
      "repeated_short_breaks": true,
      "shift_inconsistency": false,
      "short_duration_<4h": true,
      "short_duration_on_high_presence_days": false,
      "shortstay_longout_repeat": false,
      "single_door": false,
      "swipe_overlap": false,
      "trending_decline": false,
      "unusually_high_swipes": false,
      "very_long_duration_>=16h": false,
      "weekend_activity": false,
      "zero_swipes": false
    },
    {
      "AnomalyScore": 1.5,
      "BreakCount": 0,
      "CardNumber": "604850",
      "CompanyName": "WU Srvcs India Private Ltd",
      "ConsecWeeksShort4hrs": 0,
      "CountSwipes": 16,
      "Date": "2025-11-06",
      "DetectedScenarios": "short_duration_<4h; repeated_short_breaks",
      "Duration": "3:59:46",
      "DurationMinutes": 239.76666666666668,
      "DurationSeconds": 14386.0,
      "EmpHistoryPresent": false,
      "EmployeeID": "321163",
      "EmployeeIdentity": "0FD439A9-8CFA-4D4F-88A1-D1B3A18244DE",
      "EmployeeName": "Khardenavis, Shruti",
      "Explanation": "Khardenavis, Shruti -  Short total presence (240 min) \u2014 less than 4 hours; may indicate short stay or partial-day attendance. Many short gaps between swipes \u2014 repeated short breaks pattern.",
      "FirstDirection": "InDirection",
      "FirstDoor": "APAC_IN_PUN_TOWER B_MAIN RECEPTION DOOR",
      "FirstSwipe": "2025-11-06T11:33:30",
      "HistPatternShortLongCount90": 0,
      "HistRepeatedShortBreakCount90": 30,
      "HistShortDurationCount90": 4,
      "InCount": 8,
      "IsFlagged": true,
      "LastDirection": "OutDirection",
      "LastDoor": "APAC_IN_PUN_TOWER B_MAIN RECEPTION DOOR",
      "LastSwipe": "2025-11-06T15:33:16",
      "LongBreakCount": 0,
      "MaxSwipeGapSeconds": 8016,
      "MonitorFlag": false,
      "OnlyIn": 0,
      "OnlyOut": 0,
      "OutCount": 8,
      "OverlapWith": null,
      "PartitionName2": "APAC.Default",
      "PatternSequence": null,
      "PatternSequenceReadable": null,
      "PatternShortLongRepeat": false,
      "PersonnelType": "Employee",
      "PersonnelTypeName": "Employee",
      "PresentToday": true,
      "PrimaryLocation": "Pune - Business Bay",
      "Reasons": "repeated_short_breaks; short_duration_<4h",
      "RejectionCount": 0,
      "RiskLevel": "Low Medium",
      "RiskScore": 2,
      "ShortGapCount": 12,
      "SingleDoor": 0,
      "TotalBreakMinutes": 0.0,
      "UniqueDoors": 3,
      "UniqueLocations": 1,
      "ViolationDaysLast90": 2,
      "_norm_id": "0FD439A9-8CFA-4D4F-88A1-D1B3A18244DE",
      "badge_sharing_suspected": false,
      "behaviour_shift": false,
      "coffee_badging": false,
      "consecutive_absent_days": false,
      "early_arrival_before_06": false,
      "high_swipes_benign": false,
      "high_variance_duration": false,
      "late_exit_after_22": false,
      "long_gap_>=4.5h": false,
      "low_swipe_count_<=2": false,
      "multiple_location_same_day": false,
      "only_in": false,
      "only_out": false,
      "overtime_>=10h": false,
      "person_uid": "0FD439A9-8CFA-4D4F-88A1-D1B3A18244DE",
      "repeated_rejection_count": false,
      "repeated_short_breaks": true,
      "shift_inconsistency": false,
      "short_duration_<4h": true,
      "short_duration_on_high_presence_days": false,
      "shortstay_longout_repeat": false,
      "single_door": false,
      "swipe_overlap": false,
      "trending_decline": false,
      "unusually_high_swipes": false,
      "very_long_duration_>=16h": false,
      "weekend_activity": false,
      "zero_swipes": false
    },
    {
      "AnomalyScore": 2.8,
      "BreakCount": 1,
      "CardNumber": "600179",
      "CompanyName": "WU Srvcs India Private Ltd",
      "ConsecWeeksShort4hrs": 0,
      "CountSwipes": 21,
      "Date": "2025-11-06",
      "DetectedScenarios": "long_gap_>=4.5h; repeated_short_breaks; shortstay_longout_repeat",
      "Duration": "9:43:33",
      "DurationMinutes": 583.55,
      "DurationSeconds": 35013.0,
      "EmpHistoryPresent": false,
      "EmployeeID": "317791",
      "EmployeeIdentity": "1A6FF41C-1515-40C7-AEBB-930B7F87E9B7",
      "EmployeeName": "Bharadwaj, Tribhuvan",
      "Explanation": "Bharadwaj, Tribhuvan -  Long gap between swipes (~4 hr 38 min). This may indicate an extended out-of-office absence. Many short gaps between swipes \u2014 repeated short breaks pattern. Repeated pattern: short in \u2192 long out-of-office \u2192 short return \u2014 may indicate leaving site for extended period between brief visits.",
      "FirstDirection": "InDirection",
      "FirstDoor": "APAC_IN_PUN_PODIUM_P-1 TURNSTILE 3-DOOR",
      "FirstSwipe": "2025-11-06T09:50:23",
      "HistPatternShortLongCount90": 0,
      "HistRepeatedShortBreakCount90": 33,
      "HistShortDurationCount90": 2,
      "InCount": 12,
      "IsFlagged": true,
      "LastDirection": "OutDirection",
      "LastDoor": "APAC_IN_PUN-PODIUM_P-1 TURNSTILE 3 -OUT DOOR",
      "LastSwipe": "2025-11-06T19:33:56",
      "LongBreakCount": 1,
      "MaxSwipeGapSeconds": 16676,
      "MonitorFlag": false,
      "OnlyIn": 0,
      "OnlyOut": 0,
      "OutCount": 9,
      "OverlapWith": null,
      "PartitionName2": "APAC.Default",
      "PatternSequence": null,
      "PatternSequenceReadable": "work (10m) -> out_of_office (278m) -> work (42m)",
      "PatternShortLongRepeat": true,
      "PersonnelType": "Employee",
      "PersonnelTypeName": "Employee",
      "PresentToday": true,
      "PrimaryLocation": "Pune - Business Bay",
      "Reasons": "long_gap_>=4.5h; repeated_short_breaks; shortstay_longout_repeat",
      "RejectionCount": 0,
      "RiskLevel": "Medium High",
      "RiskScore": 4,
      "ShortGapCount": 12,
      "SingleDoor": 0,
      "TotalBreakMinutes": 277.9,
      "UniqueDoors": 9,
      "UniqueLocations": 1,
      "ViolationDaysLast90": 1,
      "_norm_id": "1A6FF41C-1515-40C7-AEBB-930B7F87E9B7",
      "badge_sharing_suspected": false,
      "behaviour_shift": false,
      "coffee_badging": false,
      "consecutive_absent_days": false,
      "early_arrival_before_06": false,
      "high_swipes_benign": false,
      "high_variance_duration": false,
      "late_exit_after_22": false,
      "long_gap_>=4.5h": true,
      "low_swipe_count_<=2": false,
      "multiple_location_same_day": false,
      "only_in": false,
      "only_out": false,
      "overtime_>=10h": false,
      "person_uid": "1A6FF41C-1515-40C7-AEBB-930B7F87E9B7",
      "repeated_rejection_count": false,
      "repeated_short_breaks": true,
      "shift_inconsistency": false,
      "short_duration_<4h": false,
      "short_duration_on_high_presence_days": false,
      "shortstay_longout_repeat": true,
      "single_door": false,
      "swipe_overlap": false,
      "trending_decline": false,
      "unusually_high_swipes": false,
      "very_long_duration_>=16h": false,
      "weekend_activity": false,
      "zero_swipes": false
    },
    {
      "AnomalyScore": 4.05,
      "BreakCount": 0,
      "CardNumber": "234541",
      "CompanyName": "WU Srvcs India Private Ltd",
      "ConsecWeeksShort4hrs": 1,
      "CountSwipes": 2,
      "Date": "2025-11-06",
      "DetectedScenarios": "long_gap_>=4.5h; low_swipe_count_<=2; single_door; overtime_>=10h; very_long_duration_>=16h; early_arrival_before_06; late_exit_after_22",
      "Duration": "22:19:17",
      "DurationMinutes": 1339.2833333333333,
      "DurationSeconds": 80357.0,
      "EmpHistoryPresent": false,
      "EmployeeID": "317716",
      "EmployeeIdentity": "1BF8710B-5618-4A88-9EF5-BB9D812C23E5",
      "EmployeeName": "Vishwakarma, Amit Kumar",
      "Explanation": "Vishwakarma, Amit Kumar -  Long gap between swipes (~22 hr 19 min). This may indicate an extended out-of-office absence. Very few swipes on day \u2014 unusually low activity. Only a single door used during the day \u2014 possible badge-sharing or single-entry behavior. Overtime detected (>=10 hours). Very long presence (>=16 hours). First swipe earlier than 06:00. Last swipe after 22:00 (22:20:39).",
      "FirstDirection": "OutDirection",
      "FirstDoor": "APAC_IN_PUN_PODIUM_YELLOW_MAIN LIFT LOBBY-DOOR NEW",
      "FirstSwipe": "2025-11-06T00:01:22",
      "HistPatternShortLongCount90": 3,
      "HistRepeatedShortBreakCount90": 35,
      "HistShortDurationCount90": 6,
      "InCount": 1,
      "IsFlagged": true,
      "LastDirection": "InDirection",
      "LastDoor": "APAC_IN_PUN_PODIUM_YELLOW_MAIN LIFT LOBBY-DOOR NEW",
      "LastSwipe": "2025-11-06T22:20:39",
      "LongBreakCount": 0,
      "MaxSwipeGapSeconds": 80357,
      "MonitorFlag": false,
      "OnlyIn": 0,
      "OnlyOut": 0,
      "OutCount": 1,
      "OverlapWith": null,
      "PartitionName2": "APAC.Default",
      "PatternSequence": null,
      "PatternSequenceReadable": null,
      "PatternShortLongRepeat": false,
      "PersonnelType": "Employee",
      "PersonnelTypeName": "Employee",
      "PresentToday": true,
      "PrimaryLocation": "Pune - Business Bay",
      "Reasons": "early_arrival_before_06; late_exit_after_22; long_gap_>=4.5h; low_swipe_count_<=2; overtime_>=10h; single_door; very_long_duration_>=16h",
      "RejectionCount": 0,
      "RiskLevel": "High",
      "RiskScore": 5,
      "ShortGapCount": 0,
      "SingleDoor": 1,
      "TotalBreakMinutes": 0.0,
      "UniqueDoors": 1,
      "UniqueLocations": 1,
      "ViolationDaysLast90": 5,
      "_norm_id": "1BF8710B-5618-4A88-9EF5-BB9D812C23E5",
      "badge_sharing_suspected": false,
      "behaviour_shift": false,
      "coffee_badging": false,
      "consecutive_absent_days": false,
      "early_arrival_before_06": true,
      "high_swipes_benign": false,
      "high_variance_duration": false,
      "late_exit_after_22": true,
      "long_gap_>=4.5h": true,
      "low_swipe_count_<=2": true,
      "multiple_location_same_day": false,
      "only_in": false,
      "only_out": false,
      "overtime_>=10h": true,
      "person_uid": "1BF8710B-5618-4A88-9EF5-BB9D812C23E5",
      "repeated_rejection_count": false,
      "repeated_short_breaks": false,
      "shift_inconsistency": false,
      "short_duration_<4h": false,
      "short_duration_on_high_presence_days": false,
      "shortstay_longout_repeat": false,
      "single_door": true,
      "swipe_overlap": false,
      "trending_decline": false,
      "unusually_high_swipes": false,
      "very_long_duration_>=16h": true,
      "weekend_activity": false,
      "zero_swipes": false
    },
    {
      "AnomalyScore": 1.5,
      "BreakCount": 0,
      "CardNumber": "615582",
      "CompanyName": "WU Srvcs India Private Ltd",
      "ConsecWeeksShort4hrs": 0,
      "CountSwipes": 9,
      "Date": "2025-11-06",
      "DetectedScenarios": "short_duration_<4h; repeated_short_breaks",
      "Duration": "1:34:11",
      "DurationMinutes": 94.18333333333334,
      "DurationSeconds": 5651.0,
      "EmpHistoryPresent": false,
      "EmployeeID": "327004",
      "EmployeeIdentity": "29313667-533E-4C46-8627-A40EED4DC363",
      "EmployeeName": "Sagar, Mohit",
      "Explanation": "Sagar, Mohit -  Short total presence (94 min) \u2014 less than 4 hours; may indicate short stay or partial-day attendance. Many short gaps between swipes \u2014 repeated short breaks pattern.",
      "FirstDirection": "InDirection",
      "FirstDoor": "APAC_IN_PUN_PODIUM_P-1 TURNSTILE 2-DOOR",
      "FirstSwipe": "2025-11-06T11:55:22",
      "HistPatternShortLongCount90": 2,
      "HistRepeatedShortBreakCount90": 39,
      "HistShortDurationCount90": 8,
      "InCount": 5,
      "IsFlagged": true,
      "LastDirection": "OutDirection",
      "LastDoor": "APAC_IN_PUN_PODIUM_P-1 TURNSTILE 1-OUT DOOR",
      "LastSwipe": "2025-11-06T13:29:33",
      "LongBreakCount": 0,
      "MaxSwipeGapSeconds": 2066,
      "MonitorFlag": false,
      "OnlyIn": 0,
      "OnlyOut": 0,
      "OutCount": 4,
      "OverlapWith": null,
      "PartitionName2": "APAC.Default",
      "PatternSequence": null,
      "PatternSequenceReadable": null,
      "PatternShortLongRepeat": false,
      "PersonnelType": "Employee",
      "PersonnelTypeName": "Employee",
      "PresentToday": true,
      "PrimaryLocation": "Pune - Business Bay",
      "Reasons": "repeated_short_breaks; short_duration_<4h",
      "RejectionCount": 0,
      "RiskLevel": "High",
      "RiskScore": 5,
      "ShortGapCount": 5,
      "SingleDoor": 0,
      "TotalBreakMinutes": 0.0,
      "UniqueDoors": 7,
      "UniqueLocations": 1,
      "ViolationDaysLast90": 7,
      "_norm_id": "29313667-533E-4C46-8627-A40EED4DC363",
      "badge_sharing_suspected": false,
      "behaviour_shift": false,
      "coffee_badging": false,
      "consecutive_absent_days": false,
      "early_arrival_before_06": false,
      "high_swipes_benign": false,
      "high_variance_duration": false,
      "late_exit_after_22": false,
      "long_gap_>=4.5h": false,
      "low_swipe_count_<=2": false,
      "multiple_location_same_day": false,
      "only_in": false,
      "only_out": false,
      "overtime_>=10h": false,
      "person_uid": "29313667-533E-4C46-8627-A40EED4DC363",
      "repeated_rejection_count": false,
      "repeated_short_breaks": true,
      "shift_inconsistency": false,
      "short_duration_<4h": true,
      "short_duration_on_high_presence_days": false,
      "shortstay_longout_repeat": false,
      "single_door": false,
      "swipe_overlap": false,
      "trending_decline": false,
      "unusually_high_swipes": false,
      "very_long_duration_>=16h": false,
      "weekend_activity": false,
      "zero_swipes": false
    },
    {
      "AnomalyScore": 2.9,
      "BreakCount": 1,
      "CardNumber": "615897",
      "CompanyName": "WU Srvcs India Private Ltd",
      "ConsecWeeksShort4hrs": 0,
      "CountSwipes": 7,
      "Date": "2025-11-06",
      "DetectedScenarios": "long_gap_>=4.5h; overtime_>=10h; very_long_duration_>=16h; repeated_short_breaks; early_arrival_before_06",
      "Duration": "21:48:42",
      "DurationMinutes": 1308.7,
      "DurationSeconds": 78522.0,
      "EmpHistoryPresent": false,
      "EmployeeID": "325804",
      "EmployeeIdentity": "30235026-6DD1-4DCB-A614-321119EA7F44",
      "EmployeeName": "Gaddam, John Pascal",
      "Explanation": "Gaddam, John Pascal -  Long gap between swipes (~13 hr 50 min). This may indicate an extended out-of-office absence. Overtime detected (>=10 hours). Very long presence (>=16 hours). Many short gaps between swipes \u2014 repeated short breaks pattern. First swipe earlier than 06:00.",
      "FirstDirection": "OutDirection",
      "FirstDoor": "APAC_IN_PUN_PODIUM_RED_RECEPTION TO WS ENTRY 1-DOOR NEW",
      "FirstSwipe": "2025-11-06T00:08:40",
      "HistPatternShortLongCount90": 2,
      "HistRepeatedShortBreakCount90": 28,
      "HistShortDurationCount90": 5,
      "InCount": 4,
      "IsFlagged": true,
      "LastDirection": "InDirection",
      "LastDoor": "APAC_IN_PUN_PODIUM_ST2 DOOR 1 (RED)",
      "LastSwipe": "2025-11-06T21:57:22",
      "LongBreakCount": 1,
      "MaxSwipeGapSeconds": 49813,
      "MonitorFlag": false,
      "OnlyIn": 0,
      "OnlyOut": 0,
      "OutCount": 3,
      "OverlapWith": null,
      "PartitionName2": "APAC.Default",
      "PatternSequence": null,
      "PatternSequenceReadable": null,
      "PatternShortLongRepeat": false,
      "PersonnelType": "Employee",
      "PersonnelTypeName": "Employee",
      "PresentToday": true,
      "PrimaryLocation": "Pune - Business Bay",
      "Reasons": "early_arrival_before_06; long_gap_>=4.5h; overtime_>=10h; repeated_short_breaks; very_long_duration_>=16h",
      "RejectionCount": 0,
      "RiskLevel": "High",
      "RiskScore": 5,
      "ShortGapCount": 2,
      "SingleDoor": 0,
      "TotalBreakMinutes": 830.2,
      "UniqueDoors": 5,
      "UniqueLocations": 1,
      "ViolationDaysLast90": 4,
      "_norm_id": "30235026-6DD1-4DCB-A614-321119EA7F44",
      "badge_sharing_suspected": false,
      "behaviour_shift": false,
      "coffee_badging": false,
      "consecutive_absent_days": false,
      "early_arrival_before_06": true,
      "high_swipes_benign": false,
      "high_variance_duration": false,
      "late_exit_after_22": false,
      "long_gap_>=4.5h": true,
      "low_swipe_count_<=2": false,
      "multiple_location_same_day": false,
      "only_in": false,
      "only_out": false,
      "overtime_>=10h": true,
      "person_uid": "30235026-6DD1-4DCB-A614-321119EA7F44",
      "repeated_rejection_count": false,
      "repeated_short_breaks": true,
      "shift_inconsistency": false,
      "short_duration_<4h": false,
      "short_duration_on_high_presence_days": false,
      "shortstay_longout_repeat": false,
      "single_door": false,
      "swipe_overlap": false,
      "trending_decline": false,
      "unusually_high_swipes": false,
      "very_long_duration_>=16h": true,
      "weekend_activity": false,
      "zero_swipes": false
    },
    {
      "AnomalyScore": 2.5,
      "BreakCount": 0,
      "CardNumber": "609619",
      "CompanyName": "WU Srvcs India Private Ltd",
      "ConsecWeeksShort4hrs": 0,
      "CountSwipes": 35,
      "Date": "2025-11-06",
      "DetectedScenarios": "repeated_short_breaks; shortstay_longout_repeat",
      "Duration": "8:46:12",
      "DurationMinutes": 526.2,
      "DurationSeconds": 31572.0,
      "EmpHistoryPresent": false,
      "EmployeeID": "319917",
      "EmployeeIdentity": "364D903E-25C0-4E69-BDF6-6D59AF0BD5AF",
      "EmployeeName": "Mistri, Bhalchandra",
      "Explanation": "Mistri, Bhalchandra -  Many short gaps between swipes \u2014 repeated short breaks pattern. Repeated pattern: short in \u2192 long out-of-office \u2192 short return \u2014 may indicate leaving site for extended period between brief visits.",
      "FirstDirection": "InDirection",
      "FirstDoor": "APAC_IN_PUN_PODIUM_P-1 TURNSTILE 3-DOOR",
      "FirstSwipe": "2025-11-06T09:29:58",
      "HistPatternShortLongCount90": 0,
      "HistRepeatedShortBreakCount90": 20,
      "HistShortDurationCount90": 2,
      "InCount": 20,
      "IsFlagged": true,
      "LastDirection": "OutDirection",
      "LastDoor": "APAC_IN_PUN-PODIUM_P-1 TURNSTILE 3 -OUT DOOR",
      "LastSwipe": "2025-11-06T18:16:10",
      "LongBreakCount": 0,
      "MaxSwipeGapSeconds": 9039,
      "MonitorFlag": false,
      "OnlyIn": 0,
      "OnlyOut": 0,
      "OutCount": 15,
      "OverlapWith": null,
      "PartitionName2": "APAC.Default",
      "PatternSequence": null,
      "PatternSequenceReadable": "work (47m) -> out_of_office (151m) -> work (20m)",
      "PatternShortLongRepeat": true,
      "PersonnelType": "Employee",
      "PersonnelTypeName": "Employee",
      "PresentToday": true,
      "PrimaryLocation": "Pune - Business Bay",
      "Reasons": "repeated_short_breaks; shortstay_longout_repeat",
      "RejectionCount": 0,
      "RiskLevel": "Medium",
      "RiskScore": 3,
      "ShortGapCount": 21,
      "SingleDoor": 0,
      "TotalBreakMinutes": 0.0,
      "UniqueDoors": 10,
      "UniqueLocations": 1,
      "ViolationDaysLast90": 1,
      "_norm_id": "364D903E-25C0-4E69-BDF6-6D59AF0BD5AF",
      "badge_sharing_suspected": false,
      "behaviour_shift": false,
      "coffee_badging": false,
      "consecutive_absent_days": false,
      "early_arrival_before_06": false,
      "high_swipes_benign": false,
      "high_variance_duration": false,
      "late_exit_after_22": false,
      "long_gap_>=4.5h": false,
      "low_swipe_count_<=2": false,
      "multiple_location_same_day": false,
      "only_in": false,
      "only_out": false,
      "overtime_>=10h": false,
      "person_uid": "364D903E-25C0-4E69-BDF6-6D59AF0BD5AF",
      "repeated_rejection_count": false,
      "repeated_short_breaks": true,
      "shift_inconsistency": false,
      "short_duration_<4h": false,
      "short_duration_on_high_presence_days": false,
      "shortstay_longout_repeat": true,
      "single_door": false,
      "swipe_overlap": false,
      "trending_decline": false,
      "unusually_high_swipes": false,
      "very_long_duration_>=16h": false,
      "weekend_activity": false,
      "zero_swipes": false
    },
    {
      "AnomalyScore": 2.8,
      "BreakCount": 1,
      "CardNumber": "612114",
      "CompanyName": "WU Srvcs India Private Ltd",
      "ConsecWeeksShort4hrs": 0,
      "CountSwipes": 17,
      "Date": "2025-11-06",
      "DetectedScenarios": "long_gap_>=4.5h; repeated_short_breaks; shortstay_longout_repeat",
      "Duration": "9:35:25",
      "DurationMinutes": 575.4166666666666,
      "DurationSeconds": 34525.0,
      "EmpHistoryPresent": false,
      "EmployeeID": "312107",
      "EmployeeIdentity": "56B1A751-2DE2-47A1-B193-05726940CDC8",
      "EmployeeName": "Prakash, Deepak",
      "Explanation": "Prakash, Deepak -  Long gap between swipes (~4 hr 38 min). This may indicate an extended out-of-office absence. Many short gaps between swipes \u2014 repeated short breaks pattern. Repeated pattern: short in \u2192 long out-of-office \u2192 short return \u2014 may indicate leaving site for extended period between brief visits.",
      "FirstDirection": "InDirection",
      "FirstDoor": "APAC_IN_PUN_PODIUM_P-1 TURNSTILE 3-DOOR",
      "FirstSwipe": "2025-11-06T09:16:32",
      "HistPatternShortLongCount90": 1,
      "HistRepeatedShortBreakCount90": 28,
      "HistShortDurationCount90": 3,
      "InCount": 10,
      "IsFlagged": true,
      "LastDirection": "OutDirection",
      "LastDoor": "APAC_IN_PUN-PODIUM_P-1 TURNSTILE 3 -OUT DOOR",
      "LastSwipe": "2025-11-06T18:51:57",
      "LongBreakCount": 1,
      "MaxSwipeGapSeconds": 16680,
      "MonitorFlag": false,
      "OnlyIn": 0,
      "OnlyOut": 0,
      "OutCount": 7,
      "OverlapWith": null,
      "PartitionName2": "APAC.Default",
      "PatternSequence": null,
      "PatternSequenceReadable": "work (17m) -> out_of_office (278m) -> work (0m)",
      "PatternShortLongRepeat": true,
      "PersonnelType": "Employee",
      "PersonnelTypeName": "Employee",
      "PresentToday": true,
      "PrimaryLocation": "Pune - Business Bay",
      "Reasons": "long_gap_>=4.5h; repeated_short_breaks; shortstay_longout_repeat",
      "RejectionCount": 0,
      "RiskLevel": "Medium High",
      "RiskScore": 4,
      "ShortGapCount": 4,
      "SingleDoor": 0,
      "TotalBreakMinutes": 278.0,
      "UniqueDoors": 10,
      "UniqueLocations": 1,
      "ViolationDaysLast90": 2,
      "_norm_id": "56B1A751-2DE2-47A1-B193-05726940CDC8",
      "badge_sharing_suspected": false,
      "behaviour_shift": false,
      "coffee_badging": false,
      "consecutive_absent_days": false,
      "early_arrival_before_06": false,
      "high_swipes_benign": false,
      "high_variance_duration": false,
      "late_exit_after_22": false,
      "long_gap_>=4.5h": true,
      "low_swipe_count_<=2": false,
      "multiple_location_same_day": false,
      "only_in": false,
      "only_out": false,
      "overtime_>=10h": false,
      "person_uid": "56B1A751-2DE2-47A1-B193-05726940CDC8",
      "repeated_rejection_count": false,
      "repeated_short_breaks": true,
      "shift_inconsistency": false,
      "short_duration_<4h": false,
      "short_duration_on_high_presence_days": false,
      "shortstay_longout_repeat": true,
      "single_door": false,
      "swipe_overlap": false,
      "trending_decline": false,
      "unusually_high_swipes": false,
      "very_long_duration_>=16h": false,
      "weekend_activity": false,
      "zero_swipes": false
    },
    {
      "AnomalyScore": 2.5,
      "BreakCount": 1,
      "CardNumber": "609809",
      "CompanyName": "WU Srvcs India Private Ltd",
      "ConsecWeeksShort4hrs": 0,
      "CountSwipes": 22,
      "Date": "2025-11-06",
      "DetectedScenarios": "repeated_short_breaks; shortstay_longout_repeat",
      "Duration": "9:27:24",
      "DurationMinutes": 567.4,
      "DurationSeconds": 34044.0,
      "EmpHistoryPresent": false,
      "EmployeeID": "324987",
      "EmployeeIdentity": "66165D91-DBD8-4412-9D76-55D0BC835F8C",
      "EmployeeName": "Divekar, Pranav Devdatta",
      "Explanation": "Divekar, Pranav Devdatta -  Many short gaps between swipes \u2014 repeated short breaks pattern. Repeated pattern: short in \u2192 long out-of-office \u2192 short return \u2014 may indicate leaving site for extended period between brief visits.",
      "FirstDirection": "InDirection",
      "FirstDoor": "APAC_IN_PUN_TOWER B_LIFT LOBBY DOOR",
      "FirstSwipe": "2025-11-06T09:37:20",
      "HistPatternShortLongCount90": 0,
      "HistRepeatedShortBreakCount90": 32,
      "HistShortDurationCount90": 5,
      "InCount": 11,
      "IsFlagged": true,
      "LastDirection": "OutDirection",
      "LastDoor": "APAC_IN_PUN_PODIUM_P-1 TURNSTILE 4 -OUT DOOR",
      "LastSwipe": "2025-11-06T19:04:44",
      "LongBreakCount": 1,
      "MaxSwipeGapSeconds": 14857,
      "MonitorFlag": false,
      "OnlyIn": 0,
      "OnlyOut": 0,
      "OutCount": 11,
      "OverlapWith": null,
      "PartitionName2": "APAC.Default",
      "PatternSequence": null,
      "PatternSequenceReadable": "work (2m) -> out_of_office (248m) -> work (42m)",
      "PatternShortLongRepeat": true,
      "PersonnelType": "Employee",
      "PersonnelTypeName": "Employee",
      "PresentToday": true,
      "PrimaryLocation": "Pune - Business Bay",
      "Reasons": "repeated_short_breaks; shortstay_longout_repeat",
      "RejectionCount": 0,
      "RiskLevel": "Medium",
      "RiskScore": 3,
      "ShortGapCount": 13,
      "SingleDoor": 0,
      "TotalBreakMinutes": 247.6,
      "UniqueDoors": 7,
      "UniqueLocations": 1,
      "ViolationDaysLast90": 3,
      "_norm_id": "66165D91-DBD8-4412-9D76-55D0BC835F8C",
      "badge_sharing_suspected": false,
      "behaviour_shift": false,
      "coffee_badging": false,
      "consecutive_absent_days": false,
      "early_arrival_before_06": false,
      "high_swipes_benign": false,
      "high_variance_duration": false,
      "late_exit_after_22": false,
      "long_gap_>=4.5h": false,
      "low_swipe_count_<=2": false,
      "multiple_location_same_day": false,
      "only_in": false,
      "only_out": false,
      "overtime_>=10h": false,
      "person_uid": "66165D91-DBD8-4412-9D76-55D0BC835F8C",
      "repeated_rejection_count": false,
      "repeated_short_breaks": true,
      "shift_inconsistency": false,
      "short_duration_<4h": false,
      "short_duration_on_high_presence_days": false,
      "shortstay_longout_repeat": true,
      "single_door": false,
      "swipe_overlap": false,
      "trending_decline": false,
      "unusually_high_swipes": false,
      "very_long_duration_>=16h": false,
      "weekend_activity": false,
      "zero_swipes": false
    },
    {
      "AnomalyScore": 1.5,
      "BreakCount": 0,
      "CardNumber": "615558",
      "CompanyName": "WU Srvcs India Private Ltd",
      "ConsecWeeksShort4hrs": 0,
      "CountSwipes": 10,
      "Date": "2025-11-06",
      "DetectedScenarios": "short_duration_<4h; repeated_short_breaks",
      "Duration": "2:15:02",
      "DurationMinutes": 135.03333333333333,
      "DurationSeconds": 8102.0,
      "EmpHistoryPresent": false,
      "EmployeeID": "326768",
      "EmployeeIdentity": "67CDFD90-1D74-4A2F-89BE-0B750C49396E",
      "EmployeeName": "Saxena, Ankur",
      "Explanation": "Saxena, Ankur -  Short total presence (135 min) \u2014 less than 4 hours; may indicate short stay or partial-day attendance. Many short gaps between swipes \u2014 repeated short breaks pattern.",
      "FirstDirection": "InDirection",
      "FirstDoor": "APAC_IN_PUN_TOWER B_LIFT LOBBY DOOR",
      "FirstSwipe": "2025-11-06T17:50:48",
      "HistPatternShortLongCount90": 0,
      "HistRepeatedShortBreakCount90": 30,
      "HistShortDurationCount90": 6,
      "InCount": 6,
      "IsFlagged": true,
      "LastDirection": "OutDirection",
      "LastDoor": "APAC_IN_PUN_TOWER B_MAIN RECEPTION DOOR",
      "LastSwipe": "2025-11-06T20:05:50",
      "LongBreakCount": 0,
      "MaxSwipeGapSeconds": 4122,
      "MonitorFlag": false,
      "OnlyIn": 0,
      "OnlyOut": 0,
      "OutCount": 4,
      "OverlapWith": null,
      "PartitionName2": "APAC.Default",
      "PatternSequence": null,
      "PatternSequenceReadable": null,
      "PatternShortLongRepeat": false,
      "PersonnelType": "Employee",
      "PersonnelTypeName": "Employee",
      "PresentToday": true,
      "PrimaryLocation": "Pune - Business Bay",
      "Reasons": "repeated_short_breaks; short_duration_<4h",
      "RejectionCount": 0,
      "RiskLevel": "High",
      "RiskScore": 5,
      "ShortGapCount": 6,
      "SingleDoor": 0,
      "TotalBreakMinutes": 0.0,
      "UniqueDoors": 5,
      "UniqueLocations": 1,
      "ViolationDaysLast90": 4,
      "_norm_id": "67CDFD90-1D74-4A2F-89BE-0B750C49396E",
      "badge_sharing_suspected": false,
      "behaviour_shift": false,
      "coffee_badging": false,
      "consecutive_absent_days": false,
      "early_arrival_before_06": false,
      "high_swipes_benign": false,
      "high_variance_duration": false,
      "late_exit_after_22": false,
      "long_gap_>=4.5h": false,
      "low_swipe_count_<=2": false,
      "multiple_location_same_day": false,
      "only_in": false,
      "only_out": false,
      "overtime_>=10h": false,
      "person_uid": "67CDFD90-1D74-4A2F-89BE-0B750C49396E",
      "repeated_rejection_count": false,
      "repeated_short_breaks": true,
      "shift_inconsistency": false,
      "short_duration_<4h": true,
      "short_duration_on_high_presence_days": false,
      "shortstay_longout_repeat": false,
      "single_door": false,
      "swipe_overlap": false,
      "trending_decline": false,
      "unusually_high_swipes": false,
      "very_long_duration_>=16h": false,
      "weekend_activity": false,
      "zero_swipes": false
    }
  ],
  "start_date": "2025-11-06"
}




Check below APi responce carefully and fix this issue 



############################

# backend/trend_runner.py
from datetime import date, datetime, time, timedelta
from pathlib import Path
import pandas as pd
import numpy as np
import logging
import hashlib
import math
import re
import os
from collections import defaultdict

# IMPORTANT: duration_report must exist and expose run_for_date(date, regions, outdir, city)
from duration_report import run_for_date
# alias imported function so local wrapper does not shadow it
from config.door_zone import map_door_to_zone as config_map_door_to_zone, BREAK_ZONES, OUT_OF_OFFICE_ZONE

# HIST_PATH: try a few likely locations (project config, repository root, absolute path)
CANDIDATE_HISTORY = [
    Path(__file__).parent / "config" / "current_analysis.csv",
    Path(__file__).parent.parent / "config" / "current_analysis.csv",
    Path.cwd() / "current_analysis.csv",
    Path(__file__).parent / "current_analysis.csv"
]
HIST_PATH = None
for p in CANDIDATE_HISTORY:
    if p.exists():
        HIST_PATH = p
        break

if HIST_PATH is None:
    logging.warning("Historical profile file current_analysis.csv not found in candidate locations.")
    HIST_DF = pd.DataFrame()
else:
    try:
        HIST_DF = pd.read_csv(HIST_PATH)
        logging.info("Loaded historical profile from %s (rows=%d)", HIST_PATH, len(HIST_DF))
    except Exception as e:
        logging.warning("Failed to load historical profile: %s", e)
        HIST_DF = pd.DataFrame()

OUTDIR = Path("./outputs")
OUTDIR.mkdir(parents=True, exist_ok=True)
MODELS_DIR = Path("./models")
MODELS_DIR.mkdir(parents=True, exist_ok=True)
logging.basicConfig(level=logging.INFO)

# ----- small shared helpers: treat empty/placeholder tokens as None -----
_PLACEHOLDER_STRS = set(['', 'nan', 'na', 'n/a', '-', '—', '–', 'none', 'null'])

def _is_placeholder_str(s: object) -> bool:
    try:
        if s is None:
            return True
        st = str(s).strip().lower()
        return st in _PLACEHOLDER_STRS
    except Exception:
        return False


def _normalize_id_val(v):
    """
    Normalize an id-like value: strip, convert floats like '320172.0' -> '320172'
    Return None for NaN/empty/placeholder.
    """
    try:
        if pd.isna(v):
            return None
    except Exception:
        pass
    if v is None:
        return None
    s = str(v).strip()
    if s == "" or s.lower() == "nan" or _is_placeholder_str(s):
        return None
    # strip .0 if integer-like
    try:
        if '.' in s:
            f = float(s)
            if math.isfinite(f) and f.is_integer():
                return str(int(f))
    except Exception:
        pass
    return s


# prefer to avoid emp:<GUID> person_uids — only treat emp: if value looks like a human id (not GUID)
_GUID_RE = re.compile(r'^[0-9A-Fa-f]{8}-(?:[0-9A-Fa-f]{4}-){3}[0-9A-Fa-f]{12}$')

def _looks_like_guid(s: object) -> bool:
    """Return True if s looks like a GUID/UUID string."""
    if s is None:
        return False
    try:
        st = str(s).strip()
        if not st:
            return False
        return bool(_GUID_RE.match(st))
    except Exception:
        return False

def _looks_like_name(s: object) -> bool:
    """Heuristic: treat as a plausible human name if it contains letters and not a GUID."""
    if s is None:
        return False
    try:
        st = str(s).strip()
        if not st:
            return False
        # reject GUIDs and obviously numeric ids
        if _looks_like_guid(st):
            return False
        # require at least one alphabetic character
        return bool(re.search(r'[A-Za-z]', st))
    except Exception:
        return False

def _pick_first_non_guid_value(series):
    """Pick the first non-null, non-GUID, non-placeholder value from a pandas Series (as str) or None."""
    for v in series:
        if v is None:
            continue
        try:
            s = str(v).strip()
            if not s:
                continue
            if _is_placeholder_str(s):
                continue
            if _looks_like_guid(s):
                continue
            return s
        except Exception:
            continue
    return None

def _canonical_person_uid(row):
    """
    Create canonical person uid:
      - prefer EmployeeID (normalized) -> 'emp:<id>' only if it is not a GUID
      - else EmployeeIdentity -> 'uid:<val>' (GUID allowed)
      - else EmployeeName -> hash-based 'name:<shorthash>'
    """
    empid = row.get('EmployeeID', None)
    empident = row.get('EmployeeIdentity', None)
    name = row.get('EmployeeName', None)
    empid_n = _normalize_id_val(empid)
    if empid_n and not _looks_like_guid(empid_n):
        return f"emp:{empid_n}"
    empident_n = _normalize_id_val(empident)
    if empident_n:
        return f"uid:{empident_n}"
    if name and str(name).strip():
        # stable short hash of name
        h = hashlib.sha1(str(name).strip().lower().encode('utf8')).hexdigest()[:10]
        return f"name:{h}"
    return None


# small helper to extract Card from XML-like strings
_CARD_XML_RE = re.compile(r'<Card>([^<]+)</Card>', re.IGNORECASE | re.DOTALL)
def _extract_card_from_xml(txt):
    try:
        if not txt or not isinstance(txt, str):
            return None
        m = _CARD_XML_RE.search(txt)
        if m:
            return m.group(1).strip()
        # fallback: look for CHUID ... Card: pattern or Card: 12345
        m2 = re.search(r'CHUID.*?Card.*?[:=]\s*([0-9A-Za-z\-\_]+)', txt, re.IGNORECASE | re.DOTALL)
        if m2:
            return m2.group(1).strip()
    except Exception:
        pass
    return None


# explicit list of zones considered breaks (fallback local; config.door_zone imported earlier)
# If config.door_zone defines BREAK_ZONES it's used. Keep a fallback here for safety.
try:
    _BREAK_ZONES = BREAK_ZONES
    _OUT_OF_OFFICE_ZONE = OUT_OF_OFFICE_ZONE
except Exception:
    _BREAK_ZONES = set(["East Outdoor Area", "West Outdoor Area", "Assembly Area"])
    _OUT_OF_OFFICE_ZONE = "Out of office"

def map_door_to_zone(door: object, direction: object = None) -> str:
    """
    Local wrapper that delegates to config's map_door_to_zone (aliased to config_map_door_to_zone)
    with a defensive fallback if the config function fails.
    """
    try:
        # call the aliased function imported from config
        return config_map_door_to_zone(door, direction)
    except Exception:
        try:
            if door is None:
                return None
            s = str(door).strip()
            if not s:
                return None
            s_l = s.lower()
            if direction and isinstance(direction, str):
                d = direction.strip().lower()
                if "out" in d:
                    return _OUT_OF_OFFICE_ZONE
                if "in" in d:
                    return "Reception Area"
            if "out" in s_l or "exit" in s_l or ("turnstile" in s_l and "out" in s_l):
                return _OUT_OF_OFFICE_ZONE
            return "Working Area"
        except Exception:
            return None

# --- CONFIG for violation window and risk thresholds ---
VIOLATION_WINDOW_DAYS = 90  # look-back window to count violation days (adjustable)
# risk thresholds (numeric ranges) -> labels
RISK_THRESHOLDS = [
    (0.5, "Low"),
    (1.5, "Low Medium"),
    (2.5, "Medium"),
    (4.0, "Medium High"),
    (float("inf"), "High"),
]

def map_score_to_label(score: float) -> (int, str):
    """
    Map a numeric score to RiskScore (1..5) and RiskLevel label.
    Returns (risk_bucket, label)
    """
    try:
        if score is None:
            score = 0.0
        s = float(score)
    except Exception:
        s = 0.0
    bucket = 1
    label = "Low"
    for i, (threshold, lbl) in enumerate(RISK_THRESHOLDS, start=1):
        if s <= threshold:
            bucket = i
            label = lbl
            break
    return bucket, label

# ---------------- SCENARIOS (boolean functions) ----------------
def scenario_long_gap(row):
    """
    Long gap detection — updated per request to flag gaps >= 4.5 hours (4:30).
    """
    try:
        gap = int(row.get('MaxSwipeGapSeconds') or 0)
        return gap >= int(4.5 * 3600)  # 4.5 hours = 16200 seconds
    except Exception:
        return False

def scenario_short_duration(row):
    return (row.get('DurationMinutes') or 0) < 240

def scenario_coffee_badging(row):
    return (row.get('CountSwipes') or 0) >= 4 and (row.get('DurationMinutes') or 0) < 60

def scenario_low_swipe_count(row):
    return 0 < (row.get('CountSwipes') or 0) <= 2

def scenario_single_door(row):
    return (row.get('UniqueDoors') or 0) <= 1

def scenario_only_in(row):
    return int(row.get('OnlyIn', 0)) == 1

def scenario_only_out(row):
    return int(row.get('OnlyOut', 0)) == 1

def scenario_overtime(row):
    return (row.get('DurationMinutes') or 0) >= 10 * 60

def scenario_very_long_duration(row):
    return (row.get('DurationMinutes') or 0) >= 16 * 60

def scenario_zero_swipes(row):
    return int(row.get('CountSwipes', 0)) == 0

def scenario_unusually_high_swipes(row):
    """
    Flag unusually high swipes *only* when accompanied by short total duration.
    """
    cur = int(row.get('CountSwipes') or 0)
    dur = float(row.get('DurationMinutes') or 0.0)
    empid = row.get('EmployeeID')

    try:
        if not HIST_DF.empty and empid is not None and empid in HIST_DF['EmployeeID'].values:
            rec = HIST_DF[HIST_DF['EmployeeID'] == empid].iloc[0]
            median = rec.get('TotalSwipes_median', np.nan)
            if pd.notna(median) and median > 0:
                return (cur > 3 * float(median)) and (dur < 60)
    except Exception:
        pass

    try:
        if not HIST_DF.empty and 'TotalSwipes_median' in HIST_DF.columns:
            global_med = HIST_DF['TotalSwipes_median'].median()
            if pd.notna(global_med) and global_med > 0:
                return (cur > 3 * float(global_med)) and (dur < 60)
    except Exception:
        pass

    return (cur > 50) and (dur < 60)

def scenario_high_swipes_benign(row):
    cur = int(row.get('CountSwipes') or 0)
    dur = float(row.get('DurationMinutes') or 0.0)
    empid = row.get('EmployeeID')
    try:
        if not HIST_DF.empty and empid is not None and empid in HIST_DF['EmployeeID'].values:
            rec = HIST_DF[HIST_DF['EmployeeID'] == empid].iloc[0]
            median = rec.get('TotalSwipes_median', np.nan)
            if pd.notna(median) and median > 0:
                return (cur > 3 * float(median)) and (dur >= 60)
    except Exception:
        pass
    try:
        if not HIST_DF.empty and 'TotalSwipes_median' in HIST_DF.columns:
            global_med = HIST_DF['TotalSwipes_median'].median()
            if pd.notna(global_med) and global_med > 0:
                return (cur > 3 * float(global_med)) and (dur >= 60)
    except Exception:
        pass
    return (cur > 50) and (dur >= 60)


def scenario_behaviour_shift(row, hist_df=None, minutes_threshold=180):
    """
    Flag when today's first swipe time deviates from historical median by more than minutes_threshold (default 180 minutes = 3 hours).
    """
    try:
        if pd.isna(row.get('FirstSwipe')) or row.get('FirstSwipe') is None:
            return False
        first_ts = pd.to_datetime(row.get('FirstSwipe'))
        # compute minutes since midnight for today's first swipe
        today_minutes = first_ts.hour * 60 + first_ts.minute
        empid = row.get('EmployeeID')
        hist = hist_df if hist_df is not None else (HIST_DF if (HIST_DF is not None and not HIST_DF.empty) else None)
        if hist is None or hist.empty or empid is None:
            return False
        try:
            rec = hist[hist['EmployeeID'] == empid]
            if rec.empty:
                return False
            if 'FirstSwipeMinutes_median' in rec.columns:
                median_min = rec.iloc[0].get('FirstSwipeMinutes_median')
            else:
                median_min = rec.iloc[0].get('AvgFirstSwipeMins_median', None)
            if pd.isna(median_min) or median_min is None:
                return False
            diff = abs(today_minutes - float(median_min))
            return diff >= int(minutes_threshold)
        except Exception:
            return False
    except Exception:
        return False



def scenario_repeated_short_breaks(row):
    """
    Revised logic to avoid false positives from a single long out_of_office segment.
    """
    try:
        break_count = int(row.get('BreakCount') or 0)
        total_break_mins = float(row.get('TotalBreakMinutes') or 0.0)
        long_break_count = int(row.get('LongBreakCount') or 0)
        short_gap_count = int(row.get('ShortGapCount') or 0)

        if break_count >= 2:
            return True
        if short_gap_count >= 5:
            return True
        if total_break_mins >= 180 and short_gap_count >= 2:
            return True

        return False
    except Exception:
        return False


def scenario_multiple_location_same_day(row):
    return (row.get('UniqueLocations') or 0) > 1

def scenario_weekend_activity(row):
    try:
        d = pd.to_datetime(row['Date'])
        return d.weekday() >= 5
    except Exception:
        return False

def scenario_repeated_rejection_count(row):
    return (row.get('RejectionCount') or 0) >= 2

def scenario_badge_sharing_suspected(row, badge_map=None):
    card = row.get('CardNumber')
    d = row.get('Date')
    if card is None or pd.isna(card) or d is None:
        return False
    if badge_map is None:
        return False
    return badge_map.get((d, card), 0) > 1

def scenario_early_arrival_before_06(row):
    fs = row.get('FirstSwipe')
    if pd.isna(fs) or fs is None:
        return False
    try:
        t = pd.to_datetime(fs).time()
        return t < time(hour=6)
    except Exception:
        return False

def scenario_late_exit_after_22(row):
    ls = row.get('LastSwipe')
    if pd.isna(ls) or ls is None:
        return False
    try:
        t = pd.to_datetime(ls).time()
        return t >= time(hour=22)
    except Exception:
        return False

def scenario_shift_inconsistency(row):
    empid = row.get('EmployeeID')
    dur = row.get('DurationMinutes') or 0
    if HIST_DF is not None and not HIST_DF.empty and empid in HIST_DF['EmployeeID'].values:
        rec = HIST_DF[HIST_DF['EmployeeID'] == empid].iloc[0]
        med = rec.get('AvgDurationMins_median', np.nan)
        std = rec.get('AvgDurationMins_std', np.nan)
        if pd.notna(med) and pd.notna(std):
            return (dur < med - 2.5 * std) or (dur > med + 2.5 * std)
    return False

def scenario_trending_decline(row):
    empid = row.get('EmployeeID')
    if HIST_DF is None or HIST_DF.empty:
        return False
    if 'TrendingDecline' in HIST_DF.columns:
        rec = HIST_DF[HIST_DF['EmployeeID'] == empid]
        if not rec.empty:
            val = rec.iloc[0].get('TrendingDecline')
            return str(val).strip().lower() == 'yes' if pd.notna(val) else False
    return False

def scenario_consecutive_absent_days(row):
    if row.get('CountSwipes') == 0:
        empid = row.get('EmployeeID')
        if HIST_DF is not None and not HIST_DF.empty and 'ConsecAbsent3Plus' in HIST_DF.columns:
            rec = HIST_DF[HIST_DF['EmployeeID'] == empid]
            if not rec.empty:
                v = rec.iloc[0].get('ConsecAbsent3Plus')
                return str(v).strip().lower() in ('yes', 'true', '1')
        return False
    return False

def scenario_high_variance_duration(row):
    empid = row.get('EmployeeID')
    if HIST_DF is not None and not HIST_DF.empty and empid in HIST_DF['EmployeeID'].values:
        rec = HIST_DF[HIST_DF['EmployeeID'] == empid].iloc[0]
        med = rec.get('AvgDurationMins_median', np.nan)
        std = rec.get('AvgDurationMins_std', np.nan)
        if pd.notna(med) and pd.notna(std) and med > 0:
            return (std / med) > 1.0
    return False

def scenario_short_duration_on_high_presence_days(row):
    days_present = row.get('DaysPresentInWeek') or 0
    dur = row.get('DurationMinutes') or 0
    return (days_present >= 4) and (dur < 240)

def scenario_swipe_overlap(row, swipe_overlap_map=None):
    d = row.get('Date')
    uid = row.get('person_uid')
    if swipe_overlap_map is None or d is None or uid is None:
        return False
    return (d, uid) in swipe_overlap_map

# NEW scenario: the pattern described by the user
def scenario_shortstay_longout_repeat(row):
    # Uses the feature computed in compute_features: PatternShortLongRepeat
    return bool(row.get('PatternShortLongRepeat', False))


# scenario list (name, fn)
SCENARIOS = [
    ("long_gap_>=4.5h", scenario_long_gap),
    ("short_duration_<4h", scenario_short_duration),
    ("coffee_badging", scenario_coffee_badging),
    ("low_swipe_count_<=2", scenario_low_swipe_count),
    ("single_door", scenario_single_door),
    ("only_in", scenario_only_in),
    ("only_out", scenario_only_out),
    ("overtime_>=10h", scenario_overtime),
    ("very_long_duration_>=16h", scenario_very_long_duration),
    ("zero_swipes", scenario_zero_swipes),
    ("unusually_high_swipes", scenario_unusually_high_swipes),
    ("repeated_short_breaks", scenario_repeated_short_breaks),
    ("multiple_location_same_day", scenario_multiple_location_same_day),
    ("weekend_activity", scenario_weekend_activity),
    ("repeated_rejection_count", scenario_repeated_rejection_count),
    ("badge_sharing_suspected", scenario_badge_sharing_suspected),
    ("early_arrival_before_06", scenario_early_arrival_before_06),
    ("late_exit_after_22", scenario_late_exit_after_22),
    ("shift_inconsistency", scenario_shift_inconsistency),
    ("trending_decline", scenario_trending_decline),
    ("consecutive_absent_days", scenario_consecutive_absent_days),
    ("high_variance_duration", scenario_high_variance_duration),
    ("short_duration_on_high_presence_days", scenario_short_duration_on_high_presence_days),
    ("swipe_overlap", scenario_swipe_overlap),
    ("high_swipes_benign", scenario_high_swipes_benign),
    # new pattern scenario
    ("behaviour_shift", scenario_behaviour_shift),
    ("shortstay_longout_repeat", scenario_shortstay_longout_repeat)
]

# --- Human readable explanations per scenario (short and neutral) ---
def _fmt_minutes(seconds):
    try:
        m = int(round((seconds or 0) / 60.0))
        return f"{m} min" if m < 60 else f"{m//60} hr {m%60} min"
    except Exception:
        return None

SCENARIO_EXPLANATIONS = {
    "long_gap_>=4.5h": lambda r: f"Long gap between swipes (~{_fmt_minutes(r.get('MaxSwipeGapSeconds'))}). This may indicate an extended out-of-office absence.",
    "short_duration_<4h": lambda r: f"Short total presence ({int(round(r.get('DurationMinutes',0)))} min) — less than 4 hours; may indicate short stay or partial-day attendance.",
    "coffee_badging": lambda r: "Multiple quick swipes in short time (possible 'coffee' or proxy badge use).",
    "low_swipe_count_<=2": lambda r: "Very few swipes on day — unusually low activity.",
    "single_door": lambda r: "Only a single door used during the day — possible badge-sharing or single-entry behavior.",
    "only_in": lambda r: "Only 'IN' events recorded without corresponding 'OUT'.",
    "only_out": lambda r: "Only 'OUT' events recorded without prior 'IN'.",
    "overtime_>=10h": lambda r: "Overtime detected (>=10 hours).",
    "very_long_duration_>=16h": lambda r: "Very long presence (>=16 hours).",
    "zero_swipes": lambda r: "No swipes recorded on this day.",
    "unusually_high_swipes": lambda r: "Unusually high number of swipes compared to peers/history.",
    "repeated_short_breaks": lambda r: "Many short gaps between swipes — repeated short breaks pattern.",
    "multiple_location_same_day": lambda r: "Multiple locations/partitions used in same day.",
    "weekend_activity": lambda r: "Activity recorded on weekend day.",
    "repeated_rejection_count": lambda r: "Multiple rejection events recorded.",
    "badge_sharing_suspected": lambda r: "Same card used by multiple users on same day — possible badge sharing.",
    "early_arrival_before_06": lambda r: "First swipe earlier than 06:00.",
    "late_exit_after_22": lambda r: f"Last swipe after 22:00 ({(pd.to_datetime(r.get('LastSwipe')).time() if pd.notna(r.get('LastSwipe')) else 'time unknown')}).",
    "shift_inconsistency": lambda r: "Duration deviates from historical shift patterns.",
    "trending_decline": lambda r: "Employee shows trending decline in presence.",
    "consecutive_absent_days": lambda r: "Consecutive absent days observed historically.",
    "high_variance_duration": lambda r: "High variance in daily durations historically.",
    "short_duration_on_high_presence_days": lambda r: "Short duration despite normally high presence days.",
    "swipe_overlap": lambda r: "Overlap in swipe times with other persons on same door — suspicious co-located events.",
    "behaviour_shift": lambda r: "Significant change in arrival time compared to historical baseline — behaviour shift detected.",
    "shortstay_longout_repeat": lambda r: "Repeated pattern: short in → long out-of-office → short return — may indicate leaving site for extended period between brief visits."
}

def _explain_scenarios_detected(row, detected_list):
    pieces = []
    name = row.get('EmployeeName') or row.get('EmployeeID') or row.get('person_uid') or "Employee"
    prefix = f"{name} - "
    for sc in detected_list:
        sc = sc.strip()
        fn = SCENARIO_EXPLANATIONS.get(sc)
        try:
            if fn:
                # let each lambda produce a sentence
                pieces.append(fn(row))
            else:
                pieces.append(sc.replace("_", " ").replace(">=", "≥"))
        except Exception:
            pieces.append(sc)
    if not pieces:
        return None
    # Join as sentences for clarity.
    explanation = " ".join([p if p.endswith('.') else p + '.' for p in pieces])
    return prefix + " " + explanation

# --- compute_features (replaced/updated) ---
def compute_features(swipes: pd.DataFrame, durations: pd.DataFrame) -> pd.DataFrame:
    """
    Compute per person-per-date features used by scenarios.
    Returns DataFrame per (person_uid, Date) with feature columns and normalized IDs/names.
    """
    if swipes is None or swipes.empty:
        return pd.DataFrame()

    sw = swipes.copy()

    # Build lowercase->actual column map for flexible column detection
    cols_lower = {c.lower(): c for c in sw.columns}

    # detect time column
    time_candidates = ['localemessagetime', 'messagetime', 'timestamp', 'time', 'localemessagetimestamp']
    found_time_col = next((cols_lower[c] for c in time_candidates if c in cols_lower), None)
    if found_time_col:
        sw['LocaleMessageTime'] = pd.to_datetime(sw[found_time_col], errors='coerce')
        sw['Date'] = sw['LocaleMessageTime'].dt.date
    else:
        if 'Date' in sw.columns:
            sw['Date'] = pd.to_datetime(sw['Date'], errors='coerce').dt.date
        else:
            sw['Date'] = None

    # find these earlier in compute_features — prefer Int1/Text12 for EmployeeID and CHUID/Card for CardNumber
    name_candidates = ['employeename', 'objectname1', 'objectname', 'employee_name', 'name', 'object_name']
    employeeid_candidates = ['int1', 'text12', 'employeeid', 'employee_id', 'empid', 'id']
    card_candidates = ['cardnumber', 'chuid', 'card', 'card_no', 'cardnum', 'value']
    door_candidates = ['door', 'doorname', 'door_name']
    direction_candidates = ['direction', 'directionname', 'direction_name']

    name_col = next((cols_lower[c] for c in name_candidates if c in cols_lower), None)
    empid_col = next((cols_lower[c] for c in employeeid_candidates if c in cols_lower), None)
    card_col = next((cols_lower[c] for c in card_candidates if c in cols_lower), None)
    door_col = next((cols_lower[c] for c in door_candidates if c in cols_lower), None)
    dir_col = next((cols_lower[c] for c in direction_candidates if c in cols_lower), None)

    
    # --- normalise commonly used column names so downstream code can rely on them ---
    # map detected source columns to canonical names used throughout this function
    try:
        if dir_col and dir_col in sw.columns:
            sw['Direction'] = sw[dir_col]
        if door_col and door_col in sw.columns:
            sw['Door'] = sw[door_col]
        if empid_col and empid_col in sw.columns:
            sw['EmployeeID'] = sw[empid_col]
        if name_col and name_col in sw.columns:
            sw['EmployeeName'] = sw[name_col]
        if card_col and card_col in sw.columns:
            sw['CardNumber'] = sw[card_col]

        # ensure Date exists and use LocaleMessageTime if available
        if 'LocaleMessageTime' in sw.columns:
            sw['Date'] = pd.to_datetime(sw['LocaleMessageTime'], errors='coerce').dt.date
        elif 'Date' in sw.columns:
            sw['Date'] = pd.to_datetime(sw['Date'], errors='coerce').dt.date
    except Exception:
        logging.exception("Normalization of swipe columns failed.")


    # Filter personnel types: tolerant matching to avoid accidental row drops
    if 'PersonnelTypeName' in sw.columns:
        sw['PersonnelTypeName'] = sw['PersonnelTypeName'].astype(str).str.strip()
        mask = sw['PersonnelTypeName'].str.lower().str.contains(r'employee|terminated', na=False)
        logging.info("PersonnelTypeName values example: %s", list(sw['PersonnelTypeName'].dropna().unique()[:6]))
        before = len(sw)
        sw = sw[mask].copy()
        logging.info("PersonnelTypeName filter applied: before=%d after=%d", before, len(sw))
    elif 'PersonnelType' in sw.columns:
        sw['PersonnelType'] = sw['PersonnelType'].astype(str).str.strip()
        mask = sw['PersonnelType'].str.lower().str.contains(r'employee|terminated', na=False)
        before = len(sw)
        sw = sw[mask].copy()
        logging.info("PersonnelType filter applied: before=%d after=%d", before, len(sw))


    # else keep everything

    if sw.empty:
        logging.info("compute_features: no rows after PersonnelType filter")
        return pd.DataFrame()

    # ensure stable person_uid (canonical)
    if 'person_uid' not in sw.columns:
        def make_person_uid_local(r):
            # prefer canonical EmployeeID (normalized, non-GUID) then EmployeeIdentity then EmployeeName
            empid_val = None
            if empid_col and empid_col in r and pd.notna(r.get(empid_col)):
                empid_val = r.get(empid_col)
            elif 'EmployeeID' in r and pd.notna(r.get('EmployeeID')):
                empid_val = r.get('EmployeeID')

            empident_val = r.get('EmployeeIdentity') if 'EmployeeIdentity' in r else None
            name_val = None
            if name_col and name_col in r:
                name_val = r.get(name_col)
            elif 'EmployeeName' in r:
                name_val = r.get('EmployeeName')
            elif 'ObjectName1' in r:
                name_val = r.get('ObjectName1')

            return _canonical_person_uid({
                'EmployeeID': empid_val,
                'EmployeeIdentity': empident_val,
                'EmployeeName': name_val
            })
        sw['person_uid'] = sw.apply(make_person_uid_local, axis=1)

    # selection columns for aggregation: include discovered columns
    sel_cols = set(['LocaleMessageTime', 'Direction', 'Door', 'PartitionName2', 'Rejection_Type',
                    'CardNumber', 'EmployeeID', 'EmployeeName', 'ObjectName1', 'PersonnelType', 'PersonnelTypeName',
                    'EmployeeIdentity'])
    if name_col:
        sel_cols.add(name_col)
    if empid_col:
        sel_cols.add(empid_col)
    if card_col:
        sel_cols.add(card_col)
    if door_col:
        sel_cols.add(door_col)
    if dir_col:
        sel_cols.add(dir_col)
    sel_cols = [c for c in sel_cols if c in sw.columns]

    def agg_swipe_group(g):
        # g is a DataFrame for one person_uid + date
        times = sorted(g['LocaleMessageTime'].dropna().tolist()) if 'LocaleMessageTime' in g else []
        gaps = []
        short_gap_count = 0
        for i in range(1, len(times)):
            s = (times[i] - times[i-1]).total_seconds()
            gaps.append(s)
            if s <= 5*60:
                short_gap_count += 1
        max_gap = int(max(gaps)) if gaps else 0

        # Direction counts (default to column names present)
        in_count = int((g['Direction'] == 'InDirection').sum()) if 'Direction' in g.columns else 0
        out_count = int((g['Direction'] == 'OutDirection').sum()) if 'Direction' in g.columns else 0
        unique_doors = int(g['Door'].nunique()) if 'Door' in g.columns else 0
        unique_locations = int(g['PartitionName2'].nunique()) if 'PartitionName2' in g.columns else 0
        rejection_count = int(g['Rejection_Type'].notna().sum()) if 'Rejection_Type' in g.columns else 0

        # pick first non-placeholder, non-guid card number if present (prefer cardnumber/chuid)
        card_numbers = []
        # 1) direct known column
        if card_col and card_col in g.columns:
            card_numbers = list(pd.unique(g[card_col].dropna()))
        # 2) explicit 'CardNumber' output column (from SQL COALESCE)
        if not card_numbers and 'CardNumber' in g.columns:
            card_numbers = list(pd.unique(g['CardNumber'].dropna()))
        # 3) some XML-shred columns may appear as 'value' or other column names
        if not card_numbers:
            for c in g.columns:
                cl = c.lower()
                if 'value' == cl or 'xml' in cl or 'msg' in cl or 'shred' in cl:
                    try:
                        vals = list(pd.unique(g[c].dropna()))
                        if vals:
                            card_numbers.extend(vals)
                    except Exception:
                        continue
        # 4) lastly try to extract from XmlMessage fields
        if not card_numbers:
            for c in g.columns:
                cl = c.lower()
                if 'xml' in cl or 'xmlmessage' in cl or 'xml_msg' in cl or 'xmlmessage' in cl:
                    for raw in g[c].dropna().astype(str):
                        extracted = _extract_card_from_xml(raw)
                        if extracted:
                            card_numbers.append(extracted)
        # 5) final unique
        card_numbers = list(dict.fromkeys(card_numbers))  # preserve order, unique

        card_number = None
        for c in card_numbers:
            n = _normalize_id_val(c)
            # explicitly reject GUIDs as card numbers
            if n and not _looks_like_guid(n):
                card_number = n
                break

        # stable id/name from the group using discovered columns first
        employee_id = None
        employee_name = None
        employee_identity = None
        personnel_type = None

        # Employee ID: prefer Int1/Text12 then EmployeeID; DO NOT use EmployeeIdentity as EmployeeID
        # use _pick_first_non_guid_value to skip GUIDs automatically
        if empid_col and empid_col in g.columns:
            vals = g[empid_col].dropna().astype(str).map(lambda x: x.strip())
            employee_id = _pick_first_non_guid_value(vals)
            if employee_id is None and not vals.empty:
                v0 = vals.iloc[0]
                normalized = _normalize_id_val(v0)
                if normalized and not _looks_like_guid(normalized):
                    employee_id = normalized
        elif 'EmployeeID' in g.columns:
            vals = g['EmployeeID'].dropna().astype(str).map(lambda x: x.strip())
            employee_id = _pick_first_non_guid_value(vals)
            if employee_id is None and not vals.empty:
                v0 = vals.iloc[0]
                normalized = _normalize_id_val(v0)
                if normalized and not _looks_like_guid(normalized):
                    employee_id = normalized

        # If still no employee_id and PersonnelType indicates contractor -> prefer Text12 explicitly
        if (not employee_id) and 'PersonnelType' in g.columns:
            try:
                pvals = g['PersonnelType'].dropna().astype(str)
                if not pvals.empty:
                    p0 = pvals.iloc[0]
                    if str(p0).strip().lower() in ('contractor', 'terminated contractor', 'contractor '):
                        # look for text12 explicitly (case-insensitive)
                        for c in g.columns:
                            if c.lower() == 'text12':
                                vals = g[c].dropna().astype(str).map(lambda x: x.strip())
                                employee_id = _pick_first_non_guid_value(vals)
                                if employee_id:
                                    break
            except Exception:
                pass

        # Employee identity (GUID) — keep but do not promote to EmployeeID
        if 'EmployeeIdentity' in g.columns:
            vals = g['EmployeeIdentity'].dropna().astype(str).map(lambda x: x.strip())
            if not vals.empty:
                employee_identity = vals.iloc[0]

        # Employee name: pick non-GUID candidate
        candidate_name_vals = None
        if name_col and name_col in g.columns:
            candidate_name_vals = g[name_col].dropna().astype(str).map(lambda x: x.strip())
        elif 'EmployeeName' in g.columns:
            candidate_name_vals = g['EmployeeName'].dropna().astype(str).map(lambda x: x.strip())
        elif 'ObjectName1' in g.columns:
            candidate_name_vals = g['ObjectName1'].dropna().astype(str).map(lambda x: x.strip())

        if candidate_name_vals is not None and not candidate_name_vals.empty:
            employee_name = _pick_first_non_guid_value(candidate_name_vals)
            if employee_name is None:
                # accept any value that looks like a name
                for v in candidate_name_vals:
                    if _looks_like_name(v) and not _is_placeholder_str(v):
                        employee_name = str(v).strip()
                        break

        # personnel type
        if 'PersonnelTypeName' in g.columns:
            vals = g['PersonnelTypeName'].dropna()
            if not vals.empty:
                personnel_type = vals.iloc[0]
        elif 'PersonnelType' in g.columns:
            vals = g['PersonnelType'].dropna()
            if not vals.empty:
                personnel_type = vals.iloc[0]

        # First/Last swipe times
        first_swipe = None
        last_swipe = None
        if times:
            first_swipe = times[0]
            last_swipe = times[-1]

        # ----------------- NEW: break/out-of-office sequence analysis -----------------
        # Build a timeline of (time, door, direction, zone)
        timeline = []
        for _, row in g.sort_values('LocaleMessageTime').iterrows():
            t = row.get('LocaleMessageTime')
            dname = None
            if door_col and door_col in row and pd.notna(row.get(door_col)):
                dname = row.get(door_col)
            elif 'Door' in row and pd.notna(row.get('Door')):
                dname = row.get('Door')
            direction = None
            if dir_col and dir_col in row and pd.notna(row.get(dir_col)):
                direction = row.get(dir_col)
            elif 'Direction' in row and pd.notna(row.get('Direction')):
                direction = row.get('Direction')
            zone = map_door_to_zone(dname, direction)
            timeline.append((t, dname, direction, zone))

        # compress timeline into segments with labels: 'work', 'break', 'out_of_office'
        segments = []
        if timeline:
            cur_zone = None
            seg_start = timeline[0][0]
            seg_label = None
            for (t, dname, direction, zone) in timeline:
                # determine label
                if zone in _BREAK_ZONES:
                    lbl = 'break'
                elif zone == _OUT_OF_OFFICE_ZONE:
                    lbl = 'out_of_office'
                else:
                    lbl = 'work'
                if cur_zone is None:
                    cur_zone = zone
                    seg_label = lbl
                    seg_start = t
                else:
                    # if label changes, close previous segment
                    if lbl != seg_label:
                        segments.append({
                            'label': seg_label,
                            'start': seg_start,
                            'end': t,
                            'start_zone': cur_zone
                        })
                        seg_start = t
                        seg_label = lbl
                        cur_zone = zone
                    else:
                        # keep current segment (extend)
                        cur_zone = cur_zone or zone
            # close last
            if seg_label is not None:
                segments.append({
                    'label': seg_label,
                    'start': seg_start,
                    'end': timeline[-1][0],
                    'start_zone': cur_zone
                })

        # Compute break metrics: only count "real" breaks (and only if long enough)
        break_count = 0
        long_break_count = 0
        total_break_minutes = 0.0


        # thresholds (minutes)
        # Count break segments only if >= 1 hour (60 min) for break zones
        BREAK_MINUTES_THRESHOLD = 60

        # Out-of-office needs to be at least 3 hours (180 min) to be counted as a break segment
        OUT_OFFICE_COUNT_MINUTES = 180

        # Long-break flag threshold: use 120 minutes (2 hours).
        # This ensures single long break ≥ 2h will be considered significant,
        # and two breaks >= 1h each will also be detectable via BreakCount >= 2.
        LONG_BREAK_FLAG_MINUTES = 120


        for i, s in enumerate(segments):
            lbl = s.get('label')
            start = s.get('start')
            end = s.get('end')
            dur_mins = ((end - start).total_seconds() / 60.0) if (start and end) else 0.0

            if lbl == 'break':
                # only count break segments that are actually long enough (>= BREAK_MINUTES_THRESHOLD)
                if dur_mins >= BREAK_MINUTES_THRESHOLD:
                    break_count += 1
                    total_break_minutes += dur_mins
                    if dur_mins >= LONG_BREAK_FLAG_MINUTES:
                        long_break_count += 1

            elif lbl == 'out_of_office':
                # for out_of_office: treat as break only when it's between work segments
                # and satisfies out-office threshold (>= OUT_OFFICE_COUNT_MINUTES)
                prev_lbl = segments[i-1]['label'] if i > 0 else None
                next_lbl = segments[i+1]['label'] if i < len(segments)-1 else None
                # Only treat as break if it's between work segments and long enough (>= OUT_OFFICE_COUNT_MINUTES)
                if prev_lbl == 'work' and next_lbl == 'work' and dur_mins >= OUT_OFFICE_COUNT_MINUTES:
                    break_count += 1
                    total_break_minutes += dur_mins
                    if dur_mins >= LONG_BREAK_FLAG_MINUTES:
                        long_break_count += 1

        # Detect the specific pattern:
        pattern_flag = False
        pattern_sequence_readable = None
        try:
            # create simplified label list with durations
            seq = []
            for s in segments:
                dur_mins = (s['end'] - s['start']).total_seconds() / 60.0 if (s['end'] and s['start']) else 0
                seq.append((s['label'], int(round(dur_mins))))
          
           
            # look for the pattern anywhere in sequence (triplet: short work -> long out -> short work)
            for i in range(len(seq)-2):
                a = seq[i]     # first work
                b = seq[i+1]   # long out
                c = seq[i+2]   # short work
                # short work: < 60 min; long out: >= LONG_BREAK_FLAG_MINUTES; short return: < 60 min
                if (a[0] == 'work' and a[1] < 60) and \
                   (b[0] in ('out_of_office','break') and b[1] >= LONG_BREAK_FLAG_MINUTES) and \
                   (c[0] == 'work' and c[1] < 60):
                    pattern_flag = True
                    seq_fragment = [a, b, c]
                    pattern_sequence_readable = " -> ".join([f"{lbl} ({mins}m)" for lbl, mins in seq_fragment])
                    break

        except Exception:
            pattern_flag = False
            pattern_sequence_readable = None



            

        # ----------------- return aggregated metrics (including new ones) -----------------
        return pd.Series({
            'CountSwipes': int(len(g)),
            'MaxSwipeGapSeconds': max_gap,
            'ShortGapCount': int(short_gap_count),
            'InCount': in_count,
            'OutCount': out_count,
            'UniqueDoors': unique_doors,
            'UniqueLocations': unique_locations,
            'RejectionCount': rejection_count,
            'CardNumber': card_number,
            'EmployeeID': employee_id,
            'EmployeeIdentity': employee_identity,
            'EmployeeName': employee_name,
            'PersonnelType': personnel_type,
            'FirstSwipe': first_swipe,
            'LastSwipe': last_swipe,
            # new break features
            'BreakCount': int(break_count),
            'LongBreakCount': int(long_break_count),
            'TotalBreakMinutes': float(round(total_break_minutes,1)),
            'PatternShortLongRepeat': bool(pattern_flag),
            'PatternSequenceReadable': pattern_sequence_readable,
            'PatternSequence': None  # keep old field empty for compatibility
        })

    grouped = sw[['person_uid', 'Date'] + sel_cols].groupby(['person_uid', 'Date'])
    grouped = grouped.apply(agg_swipe_group).reset_index()

    dur = pd.DataFrame() if durations is None else durations.copy()
    if not dur.empty and 'Date' in dur.columns:
        dur['Date'] = pd.to_datetime(dur['Date'], errors='coerce').dt.date

    merged = pd.merge(grouped, dur, how='left', on=['person_uid', 'Date'])

    # --- START PATCH: coalesce duplicate columns produced by merge ---
    def _coalesce_merge_columns(df, bases):
        for base in bases:
            x = base + "_x"
            y = base + "_y"
            try:
                has_base = base in df.columns
                base_all_null = False
                if has_base:
                    base_all_null = df[base].isnull().all()
            except Exception:
                has_base = base in df.columns
                base_all_null = True

            if (not has_base) or base_all_null:
                if x in df.columns and y in df.columns:
                    try:
                        df[base] = df[x].combine_first(df[y])
                    except Exception:
                        try:
                            df[base] = df[x].where(df[x].notna(), df[y] if y in df.columns else None)
                        except Exception:
                            if x in df.columns:
                                df[base] = df[x]
                            elif y in df.columns:
                                df[base] = df[y]
                elif x in df.columns:
                    df[base] = df[x]
                elif y in df.columns:
                    df[base] = df[y]
    _coalesce_merge_columns(merged, [
        "EmployeeID", "Int1", "Text12", "CardNumber", "EmployeeName", "EmployeeIdentity"
    ])
    drop_cols = [c for c in merged.columns if c.endswith("_x") or c.endswith("_y")]
    if drop_cols:
        try:
            merged.drop(columns=drop_cols, inplace=True)
        except Exception:
            for c in drop_cols:
                if c in merged.columns:
                    try:
                        merged.drop(columns=[c], inplace=True)
                    except Exception:
                        pass
    # --- END PATCH ---

    # coalesce helpers (ensure column existence)
    def ensure_col(df, col, default=None):
        if col not in df.columns:
            df[col] = default

    ensure_col(merged, 'DurationSeconds', 0)
    ensure_col(merged, 'FirstSwipe', pd.NaT)
    ensure_col(merged, 'LastSwipe', pd.NaT)
    ensure_col(merged, 'CountSwipes', 0)
    ensure_col(merged, 'MaxSwipeGapSeconds', 0)
    ensure_col(merged, 'ShortGapCount', 0)
    ensure_col(merged, 'RejectionCount', 0)
    ensure_col(merged, 'UniqueLocations', 0)
    ensure_col(merged, 'UniqueDoors', 0)
    ensure_col(merged, 'CardNumber', None)
    ensure_col(merged, 'EmployeeID', None)
    ensure_col(merged, 'EmployeeName', None)
    ensure_col(merged, 'EmployeeIdentity', None)
    ensure_col(merged, 'PersonnelType', None)
    ensure_col(merged, 'BreakCount', 0)
    ensure_col(merged, 'LongBreakCount', 0)
    ensure_col(merged, 'TotalBreakMinutes', 0.0)
    ensure_col(merged, 'PatternShortLongRepeat', False)
    ensure_col(merged, 'PatternSequenceReadable', None)
    ensure_col(merged, 'PatternSequence', None)

    # If EmployeeName is missing or a GUID, try to get a better name from durations (durations typically has EmployeeName)
    if 'EmployeeName' in merged.columns:
        def choose_best_name(row):
            gname = row.get('EmployeeName')
            dname = None
            for cand in ('EmployeeName', 'employee_name', 'objectname1', 'ObjectName1'):
                if cand in row and row.get(cand) is not None:
                    dname = row.get(cand)
                    break
            if _looks_like_name(gname):
                return str(gname).strip()
            if _looks_like_name(dname):
                return str(dname).strip()
            if gname and not _looks_like_guid(gname) and not _is_placeholder_str(gname):
                return str(gname).strip()
            if dname and not _is_placeholder_str(dname):
                return str(dname).strip()
            return None
        merged['EmployeeName'] = merged.apply(choose_best_name, axis=1)
    else:
        if not dur.empty:
            def fill_name_from_dur(row):
                gname = row.get('EmployeeName')
                if _looks_like_name(gname) and not _is_placeholder_str(gname):
                    return gname
                for cand in ('EmployeeName', 'EmployeeName_y', 'EmployeeName_x'):
                    if cand in row and _looks_like_name(row[cand]) and not _is_placeholder_str(row[cand]):
                        return row[cand]
                return None
            merged['EmployeeName'] = merged.apply(fill_name_from_dur, axis=1)

    # numeric normalization for EmployeeID: ensure not GUIDs/placeholder, convert floats like '320172.0' -> '320172'
    def normalize_empid(v):
        if v is None:
            return None
        try:
            s = str(v).strip()
            if s == '' or s.lower() == 'nan' or _is_placeholder_str(s):
                return None
            if _looks_like_guid(s):
                return None
            try:
                if '.' in s:
                    f = float(s)
                    if math.isfinite(f) and f.is_integer():
                        return str(int(f))
            except Exception:
                pass
            return s
        except Exception:
            return None

    merged['EmployeeID'] = merged['EmployeeID'].apply(normalize_empid)

    # normalize card numbers: reject GUIDs and placeholder tokens
    def normalize_card(v):
        if v is None:
            return None
        try:
            s = str(v).strip()
            if s == '' or s.lower() == 'nan' or _is_placeholder_str(s):
                return None
            if _looks_like_guid(s):
                return None
            return s
        except Exception:
            return None

    merged['CardNumber'] = merged['CardNumber'].apply(normalize_card)

    # numeric normalization
    # If durations DataFrame provided DurationSeconds, use that; else fall back to computed (LastSwipe-FirstSwipe)
    if 'DurationSeconds' not in merged.columns or merged['DurationSeconds'].isnull().all():
        try:
            merged['DurationSeconds'] = (pd.to_datetime(merged['LastSwipe']) - pd.to_datetime(merged['FirstSwipe'])).dt.total_seconds().clip(lower=0).fillna(0)
        except Exception:
            merged['DurationSeconds'] = merged.get('DurationSeconds', 0)

    merged['DurationSeconds'] = pd.to_numeric(merged['DurationSeconds'], errors='coerce').fillna(0).astype(float)
    merged['DurationMinutes'] = (merged['DurationSeconds'] / 60.0).astype(float)
    merged['CountSwipes'] = merged['CountSwipes'].fillna(0).astype(int)
    merged['MaxSwipeGapSeconds'] = merged['MaxSwipeGapSeconds'].fillna(0).astype(int)
    merged['ShortGapCount'] = merged['ShortGapCount'].fillna(0).astype(int)
    merged['RejectionCount'] = merged['RejectionCount'].fillna(0).astype(int)
    merged['UniqueLocations'] = merged['UniqueLocations'].fillna(0).astype(int)
    merged['UniqueDoors'] = merged['UniqueDoors'].fillna(0).astype(int)
    merged['BreakCount'] = merged['BreakCount'].fillna(0).astype(int)
    merged['LongBreakCount'] = merged['LongBreakCount'].fillna(0).astype(int)
    merged['TotalBreakMinutes'] = merged['TotalBreakMinutes'].fillna(0.0).astype(float)
    merged['PatternShortLongRepeat'] = merged['PatternShortLongRepeat'].fillna(False).astype(bool)

    # ensure FirstSwipe/LastSwipe are datetimes
    for col in ['FirstSwipe', 'LastSwipe']:
        try:
            merged[col] = pd.to_datetime(merged[col], errors='coerce')
        except Exception:
            merged[col] = pd.NaT

    merged['OnlyIn'] = ((merged.get('InCount', 0) > 0) & (merged.get('OutCount', 0) == 0)).astype(int)
    merged['OnlyOut'] = ((merged.get('OutCount', 0) > 0) & (merged.get('InCount', 0) == 0)).astype(int)
    merged['SingleDoor'] = (merged.get('UniqueDoors', 0) <= 1).astype(int)

    # EmpHistoryPresent
    hist_map = {}
    if not HIST_DF.empty and 'EmployeeID' in HIST_DF.columns:
        hist_map = HIST_DF.set_index('EmployeeID').to_dict(orient='index')
    merged['EmpHistoryPresent'] = merged['EmployeeID'].apply(lambda x: _normalize_id_val(x) in hist_map if pd.notna(x) else False)

    # normalize string columns for safe downstream use; EmployeeName keep as readable-only
    for c in ['EmployeeID', 'CardNumber', 'EmployeeIdentity', 'PersonnelType']:
        if c in merged.columns:
            def _clean_str_val(v):
                if v is None:
                    return None
                try:
                    s = str(v).strip()
                    if s == '' or s.lower() == 'nan' or _is_placeholder_str(s):
                        return None
                    return s
                except Exception:
                    return None
            merged[c] = merged[c].apply(_clean_str_val)

    # EmployeeName: keep None if empty or GUID/placeholder; otherwise string.
    if 'EmployeeName' in merged.columns:
        merged['EmployeeName'] = merged['EmployeeName'].apply(lambda v: None if (v is None or (isinstance(v, float) and np.isnan(v)) or _looks_like_guid(v) or _is_placeholder_str(v)) else str(v).strip())

    return merged


# ---------------- SCENARIO WEIGHTS (for anomaly scoring) ----------------
WEIGHTS = {
    "long_gap_>=4.5h": 0.3,
    "short_duration_<4h": 1.0,
    "coffee_badging": 1.0,
    "low_swipe_count_<=2": 0.5,
    "single_door": 0.25,
    "only_in": 0.8,
    "only_out": 0.8,
    "overtime_>=10h": 0.2,
    "very_long_duration_>=16h": 1.5,
    "zero_swipes": 0.4,
    "unusually_high_swipes": 1.5,
    "repeated_short_breaks": 0.5,
    "multiple_location_same_day": 0.6,
    "weekend_activity": 0.6,
    "repeated_rejection_count": 0.8,
    "badge_sharing_suspected": 2.0,
    "early_arrival_before_06": 0.4,
    "late_exit_after_22": 0.4,
    "shift_inconsistency": 1.2,
    "trending_decline": 0.7,
    "consecutive_absent_days": 1.2,
    "high_variance_duration": 0.8,
    "short_duration_on_high_presence_days": 1.1,
    "swipe_overlap": 2.0,
    "high_swipes_benign": 0.1,

    # weight for new scenario
    "shortstay_longout_repeat": 2.0
}
ANOMALY_THRESHOLD = 1.5


def _read_past_trend_csvs(outdir: str, window_days: int, target_date: date):
    """
    Read existing trend_pune_*.csv in outdir and return a single DataFrame filtered to the
    window (target_date - window_days .. target_date-1).
    """
    p = Path(outdir)
    csvs = sorted(p.glob("trend_pune_*.csv"), reverse=True)
    if not csvs:
        return pd.DataFrame()
    dfs = []
    cutoff = target_date - timedelta(days=window_days)
    for fp in csvs:
        try:
            df = pd.read_csv(fp, parse_dates=['Date'])
            # keep only rows with date in (cutoff .. target_date-1)
            if 'Date' in df.columns:
                try:
                    df['Date'] = pd.to_datetime(df['Date'], errors='coerce').dt.date
                except Exception:
                    pass
                df = df[df['Date'].apply(lambda d: d is not None and d >= cutoff and d < target_date)]
            dfs.append(df)
        except Exception:
            try:
                df = pd.read_csv(fp, dtype=str)
                if 'Date' in df.columns:
                    try:
                        df['Date'] = pd.to_datetime(df['Date'], errors='coerce').dt.date
                        df = df[df['Date'].apply(lambda d: d is not None and d >= cutoff and d < target_date)]
                    except Exception:
                        pass
                dfs.append(df)
            except Exception:
                continue
    if not dfs:
        return pd.DataFrame()
    try:
        out = pd.concat(dfs, ignore_index=True)
        return out
    except Exception:
        return pd.DataFrame()


def _read_scenario_counts_by_person(outdir: str, window_days: int, target_date: date, scenario_col: str):
    """
    Return dict mapping normalized identifier -> count of days where scenario_col == True
    in the window (target_date - window_days .. target_date-1).
    Keys include normalized EmployeeID/person_uid/plain numeric tokens (same normalization as compute_violation_days_map).
    """
    df = _read_past_trend_csvs(outdir, window_days, target_date)
    if df is None or df.empty or scenario_col not in df.columns:
        return {}

    # normalize Date
    if 'Date' in df.columns:
        try:
            df['Date'] = pd.to_datetime(df['Date'], errors='coerce').dt.date
        except Exception:
            pass

    id_cols = [c for c in ('person_uid', 'EmployeeID', 'EmployeeIdentity', 'CardNumber', 'Int1', 'Text12') if c in df.columns]

    out = defaultdict(int)
    # consider only rows where scenario_col is truthy
    q = df[df[scenario_col] == True] if df[scenario_col].dtype == bool else df[df[scenario_col].astype(str).str.lower() == 'true']
    for _, r in q.iterrows():
        for col in id_cols:
            try:
                raw = r.get(col)
                if raw in (None, '', float('nan')):
                    continue
                norm = _normalize_id_val(raw)
                if norm:
                    out[str(norm)] += 1
                    # also store stripped prefix variant
                    stripped = _strip_uid_prefix(str(norm))
                    if stripped != str(norm):
                        out[str(stripped)] += 1
            except Exception:
                continue
        # fallback Int1/Text12 fields
        for fallback in ('Int1', 'Text12'):
            if fallback in r and r.get(fallback) not in (None, '', 'nan'):
                try:
                    norm = _normalize_id_val(r.get(fallback))
                    if norm:
                        out[str(norm)] += 1
                except Exception:
                    continue
    return dict(out)





def _strip_uid_prefix(s):
    """Strip common prefixes like emp:, uid:, name: if present; return original otherwise."""
    try:
        if s is None:
            return s
        st = str(s)
        for p in ('emp:', 'uid:', 'name:'):
            if st.startswith(p):
                return st[len(p):]
        return st
    except Exception:
        return s


def compute_violation_days_map(outdir: str, window_days: int, target_date: date):
    """
    Return dict: identifier_string -> count of unique dates flagged as IsFlagged True
    in the last window_days (excluding target_date).

    We build a multi-key map so historical rows flagged under different identifier columns
    (person_uid, EmployeeID, EmployeeIdentity, CardNumber) are all discoverable.
    """
    df = _read_past_trend_csvs(outdir, window_days, target_date)
    if df is None or df.empty:
        return {}

    # Make sure Date is a date object
    if 'Date' in df.columns:
        try:
            df['Date'] = pd.to_datetime(df['Date'], errors='coerce').dt.date
        except Exception:
            pass

    # Determine which column names are present that we care about
    id_cols = []
    for c in ('person_uid', 'EmployeeID', 'EmployeeIdentity', 'CardNumber'):
        if c in df.columns:
            id_cols.append(c)

    # Ensure IsFlagged exists
    if 'IsFlagged' not in df.columns:
        if 'AnomalyScore' in df.columns:
            df['IsFlagged'] = df['AnomalyScore'].apply(lambda s: float(s) >= ANOMALY_THRESHOLD if not pd.isna(s) else False)
        else:
            df['IsFlagged'] = False

    # Build mapping identifier -> set(dates)
    ident_dates = defaultdict(set)
    try:
        # iterate flagged rows only
        flagged = df[df['IsFlagged'] == True]
        for _, r in flagged.iterrows():
            d = r.get('Date')
            if d is None:
                continue
            # for each identifier column present, normalize and add date
            for col in id_cols:
                try:
                    raw = r.get(col)
                    if raw is None:
                        continue
                    norm = _normalize_id_val(raw)
                    if norm:
                        # store both the normalized token and stripped prefix variant
                        ident_dates[str(norm)].add(d)
                        stripped = _strip_uid_prefix(str(norm))
                        if stripped != str(norm):
                            ident_dates[str(stripped)].add(d)
                except Exception:
                    continue
            # also try any fallback token fields if present (older CSVs may store Int1/Text12)
            for fallback in ('Int1', 'Text12'):
                if fallback in r and r.get(fallback) not in (None, '', 'nan'):
                    try:
                        norm = _normalize_id_val(r.get(fallback))
                        if norm:
                            ident_dates[str(norm)].add(d)
                            stripped = _strip_uid_prefix(str(norm))
                            if stripped != str(norm):
                                ident_dates[str(stripped)].add(d)
                    except Exception:
                        continue
    except Exception:
        logging.exception("Error building violation days map from history.")
        # best-effort: convert what we have

    # convert sets -> counts
    out = {k: int(len(v)) for k, v in ident_dates.items()}
    return out


def run_trend_for_date(target_date: date, outdir: str = "./outputs", city='Pune', as_dict: bool = False):
    logging.info("run_trend_for_date: date=%s (city=%s)", target_date, city)
    results = run_for_date(target_date, regions=['apac'], outdir=outdir, city=city)
    apac = results.get('apac', {})
    swipes = apac.get('swipes', pd.DataFrame())
    durations = apac.get('durations', pd.DataFrame())

    # save raw swipes for evidence (full raw)
    try:
        if swipes is not None and not swipes.empty:
            sw_out = Path(outdir) / f"swipes_{city.lower().replace(' ','_')}_{target_date.strftime('%Y%m%d')}.csv"
            swipes.to_csv(sw_out, index=False)
            logging.info("Saved raw swipes to %s", sw_out)
    except Exception as e:
        logging.warning("Failed to save raw swipes: %s", e)

    # compute features
    features = compute_features(swipes, durations)
    if features.empty:
        logging.warning("run_trend_for_date: no features computed")
        if as_dict:
            return {'rows': 0, 'flagged_rows': 0, 'sample': [], 'reasons_count': {}, 'risk_counts': {}, 'aggregated_unique_persons': 0}
        return pd.DataFrame()

    # ----- New: compute historical scenario counts and weekly short-duration patterns -----
    try:
        # read scenario counts for pattern shortstay_longout_repeat
        hist_pattern_counts = _read_scenario_counts_by_person(outdir, VIOLATION_WINDOW_DAYS, target_date, 'shortstay_longout_repeat')
        # repeated_short_breaks counts
        hist_rep_breaks = _read_scenario_counts_by_person(outdir, VIOLATION_WINDOW_DAYS, target_date, 'repeated_short_breaks')
        # short_duration_<4h counts (scenario name "short_duration_<4h" exists in SCENARIOS)
        hist_short_duration = _read_scenario_counts_by_person(outdir, VIOLATION_WINDOW_DAYS, target_date, 'short_duration_<4h')

        def get_hist_count_for_row(row, hist_map):
            # check several identifiers used historically
            for k in ('EmployeeID', 'person_uid', 'EmployeeIdentity', 'CardNumber', 'Int1', 'Text12'):
                if k in row and row.get(k) not in (None, '', float('nan')):
                    try:
                        norm = _normalize_id_val(row.get(k))
                        if norm and str(norm) in hist_map:
                            return int(hist_map.get(str(norm), 0))
                        stripped = _strip_uid_prefix(str(norm)) if norm else None
                        if stripped and str(stripped) in hist_map:
                            return int(hist_map.get(str(stripped), 0))
                    except Exception:
                        continue
            return 0

        features['HistPatternShortLongCount90'] = features.apply(lambda r: get_hist_count_for_row(r, hist_pattern_counts), axis=1)
        features['HistRepeatedShortBreakCount90'] = features.apply(lambda r: get_hist_count_for_row(r, hist_rep_breaks), axis=1)
        features['HistShortDurationCount90'] = features.apply(lambda r: get_hist_count_for_row(r, hist_short_duration), axis=1)

        # escalate: if PatternShortLong repeat count >=3 -> high risk
        pat_mask = features['HistPatternShortLongCount90'].fillna(0).astype(int) >= 3
        if pat_mask.any():
            features.loc[pat_mask, 'RiskScore'] = 5
            features.loc[pat_mask, 'RiskLevel'] = 'High'
            features.loc[pat_mask, 'IsFlagged'] = True

        # repeated_short_breaks: if history > 5 -> force High (example of heavy violator)
        rep_mask = features['HistRepeatedShortBreakCount90'].fillna(0).astype(int) >= 5
        if rep_mask.any():
            features.loc[rep_mask, 'RiskScore'] = 5
            features.loc[rep_mask, 'RiskLevel'] = 'High'
            features.loc[rep_mask, 'IsFlagged'] = True

    except Exception:
        logging.exception("Failed to compute historical scenario counts.")


    # compute weekly short-duration runs and attach to features (ConsecWeeksShort4hrs)
    # try:
    #     past_df = _read_past_trend_csvs(outdir, VIOLATION_WINDOW_DAYS, target_date)
    #     week_runs = _compute_weeks_with_threshold(past_df, person_col='person_uid', date_col='Date', scenario_col='short_duration_<4h', threshold_days=3)
    #     # attach to features
    #     def get_week_run(r):
    #         # prefer EmployeeID or person_uid
    #         for k in ('person_uid', 'EmployeeID'):
    #             if k in r and r.get(k):
    #                 key = str(r.get(k))
    #                 if key in week_runs:
    #                     return int(week_runs[key])
    #         return 0
    #     features['ConsecWeeksShort4hrs'] = features.apply(get_week_run, axis=1)
    #     # escalate: 1 run -> Low-Medium note, 2+ consecutive weeks -> bump score (increase AnomalyScore)
    #     mask1 = features['ConsecWeeksShort4hrs'] >= 1
    #     mask2 = features['ConsecWeeksShort4hrs'] >= 2
    #     if mask1.any():
    #         features.loc[mask1, 'AnomalyScore'] = features.loc[mask1, 'AnomalyScore'] + 0.5
    #     if mask2.any():
    #         features.loc[mask2, 'AnomalyScore'] = features.loc[mask2, 'AnomalyScore'] + 1.0
    # except Exception:
    #     logging.exception("Failed to compute weekly short-duration runs")


    # ===== START FIX: reconcile zero CountSwipes with raw swipe files =====
    try:
        if swipes is not None and not swipes.empty and 'person_uid' in swipes.columns:
            tsw = swipes.copy()
            if 'LocaleMessageTime' in tsw.columns:
                tsw['LocaleMessageTime'] = pd.to_datetime(tsw['LocaleMessageTime'], errors='coerce')
            else:
                for cand in ('MessageUTC','MessageTime','Timestamp','timestamp'):
                    if cand in tsw.columns:
                        tsw['LocaleMessageTime'] = pd.to_datetime(tsw[cand], errors='coerce')
                        break
            if 'Date' not in tsw.columns:
                if 'LocaleMessageTime' in tsw.columns:
                    tsw['Date'] = tsw['LocaleMessageTime'].dt.date
                else:
                    for cand in ('date','Date'):
                        if cand in tsw.columns:
                            try:
                                tsw['Date'] = pd.to_datetime(tsw[cand], errors='coerce').dt.date
                            except Exception:
                                tsw['Date'] = None
                            break

            try:
                grp = tsw.dropna(subset=['person_uid', 'Date']).groupby(['person_uid', 'Date'])
                counts = grp.size().to_dict()
                firsts = grp['LocaleMessageTime'].min().to_dict()
                lasts = grp['LocaleMessageTime'].max().to_dict()
            except Exception:
                counts = {}
                firsts = {}
                lasts = {}

            def _fix_row_by_raw(idx, row):
                key = (row.get('person_uid'), row.get('Date'))
                if key in counts and (row.get('CountSwipes', 0) == 0 or pd.isna(row.get('CountSwipes'))):
                    try:
                        c = int(counts.get(key, 0))
                        features.at[idx, 'CountSwipes'] = c
                        f = firsts.get(key)
                        l = lasts.get(key)
                        if pd.notna(f) and (pd.isna(row.get('FirstSwipe')) or row.get('FirstSwipe') is None):
                            features.at[idx, 'FirstSwipe'] = pd.to_datetime(f)
                        if pd.notna(l) and (pd.isna(row.get('LastSwipe')) or row.get('LastSwipe') is None):
                            features.at[idx, 'LastSwipe'] = pd.to_datetime(l)
                        try:
                            fs = features.at[idx, 'FirstSwipe']
                            ls = features.at[idx, 'LastSwipe']
                            if pd.notna(fs) and pd.notna(ls):
                                dursec = (pd.to_datetime(ls) - pd.to_datetime(fs)).total_seconds()
                                dursec = max(0, dursec)
                                features.at[idx, 'DurationSeconds'] = float(dursec)
                                features.at[idx, 'DurationMinutes'] = float(dursec / 60.0)
                        except Exception:
                            pass
                    except Exception:
                        pass

            for ix, r in features[features['CountSwipes'].fillna(0).astype(int) == 0].iterrows():
                try:
                    _fix_row_by_raw(ix, r)
                except Exception:
                    logging.debug("Failed to reconcile row %s with raw swipes", ix)
    except Exception:
        logging.exception("Error while reconciling aggregated features with raw swipes (zero-swipe fix).")
    # ===== END FIX =====

    # Build badge map and swipe overlap maps for higher-severity scenarios
    badge_map = {}
    if 'CardNumber' in swipes.columns and 'person_uid' in swipes.columns and 'Date' in swipes.columns:
        tmp = swipes[['CardNumber', 'person_uid', 'Date']].dropna(subset=['CardNumber'])
        if not tmp.empty:
            grouped_card = tmp.groupby(['Date', 'CardNumber'])['person_uid'].nunique().reset_index(name='distinct_users')
            badge_map = {(row.Date, row.CardNumber): int(row.distinct_users) for row in grouped_card.itertuples(index=False)}

    swipe_overlap_map = {}
    overlap_window_seconds = 2
    if {'Door', 'LocaleMessageTime', 'person_uid', 'Date'}.issubset(swipes.columns):
        tmp = swipes[['Door', 'LocaleMessageTime', 'person_uid', 'Date']].dropna()
        if not tmp.empty:
            tmp = tmp.sort_values(['Door', 'LocaleMessageTime'])
            for (d, door), g in tmp.groupby(['Date', 'Door']):
                items = list(g[['LocaleMessageTime', 'person_uid']].itertuples(index=False, name=None))
                n = len(items)
                for i in range(n):
                    t_i, uid_i = items[i]
                    j = i+1
                    while j < n and (items[j][0] - t_i).total_seconds() <= overlap_window_seconds:
                        uid_j = items[j][1]
                        if uid_i != uid_j:
                            swipe_overlap_map.setdefault((d, uid_i), set()).add(uid_j)
                            swipe_overlap_map.setdefault((d, uid_j), set()).add(uid_i)
                        j += 1

    # Evaluate scenarios (use weighting to compute anomaly score)
    for name, fn in SCENARIOS:
        if name == "badge_sharing_suspected":
            features[name] = features.apply(lambda r: scenario_badge_sharing_suspected(r, badge_map=badge_map), axis=1)
        elif name == "swipe_overlap":
            features[name] = features.apply(lambda r: scenario_swipe_overlap(r, swipe_overlap_map), axis=1)
        else:
            features[name] = features.apply(lambda r, f=fn: bool(f(r)), axis=1)

    def compute_score(r):
        score = 0.0
        detected = []
        for name, _ in SCENARIOS:
            val = bool(r.get(name))
            w = WEIGHTS.get(name, 0.0)
            if val and w > 0:
                score += float(w)
                detected.append(name)
        return score, detected

    scores = features.apply(lambda r: pd.Series(compute_score(r), index=['AnomalyScore', 'DetectedScenarios']), axis=1)
    features['AnomalyScore'] = scores['AnomalyScore'].astype(float)
    features['DetectedScenarios'] = scores['DetectedScenarios'].apply(lambda x: "; ".join(x) if (isinstance(x, (list, tuple)) and len(x)>0) else None)
    features['IsFlagged'] = features['AnomalyScore'].apply(lambda s: bool(s >= ANOMALY_THRESHOLD))
    scores = features.apply(lambda r: pd.Series(compute_score(r), index=['AnomalyScore', 'DetectedScenarios']), axis=1)
    features['AnomalyScore'] = scores['AnomalyScore'].astype(float)
    features['DetectedScenarios'] = scores['DetectedScenarios'].apply(lambda x: "; ".join(x) if (isinstance(x, (list, tuple)) and len(x)>0) else None)
    features['IsFlagged'] = features['AnomalyScore'].apply(lambda s: bool(s >= ANOMALY_THRESHOLD))


  # ----- NEW: PresentToday flag, historical monitoring note, and post-score weekly adjustments -----
    try:
        # PresentToday: considered present if there were any swipes recorded
        features['PresentToday'] = features['CountSwipes'].fillna(0).astype(int) > 0

        # Compute violation days map (already computed later normally) but ensure column exists
        if 'ViolationDaysLast90' not in features.columns:
            # best-effort default to 0
            features['ViolationDaysLast90'] = 0

        # Append monitoring note for persons who have past violations and are present today.
        def _append_monitor_note(idx, row):
            try:
                vd = int(row.get('ViolationDaysLast90') or 0)
            except Exception:
                vd = 0
            if vd <= 0:
                return row.get('Explanation')  # unchanged
            if not row.get('PresentToday', False):
                return row.get('Explanation')
            # Prepare note text
            note = f"Note: Previously flagged {vd} time{'s' if vd!=1 else ''} in the last {VIOLATION_WINDOW_DAYS} days — monitor when present today."
            ex = row.get('Explanation') or ''
            if ex and not ex.strip().endswith('.'):
                ex = ex.strip() + '.'
            # Avoid duplicate note if already present
            if note in ex:
                return ex
            return (ex + ' ' + note).strip()

        features['Explanation'] = features.apply(lambda r: _append_monitor_note(r.name, r), axis=1)

        # Add MonitorFlag boolean column so UI can highlight easily
        features['MonitorFlag'] = features.apply(lambda r: (int(r.get('ViolationDaysLast90') or 0) > 0) and bool(r.get('PresentToday')), axis=1)

        # Now compute consecutive-week short-duration runs (post scoring)
        past_df = _read_past_trend_csvs(outdir, VIOLATION_WINDOW_DAYS, target_date)
        week_runs = _compute_weeks_with_threshold(past_df, person_col='person_uid', date_col='Date', scenario_col='short_duration_<4h', threshold_days=3)

        def _get_week_run_for_row(r):
            for k in ('person_uid', 'EmployeeID'):
                if k in r and r.get(k):
                    key = str(r.get(k))
                    if key in week_runs:
                        return int(week_runs[key])
                    # also try stripped prefix
                    stripped = _strip_uid_prefix(key)
                    if stripped in week_runs:
                        return int(week_runs[stripped])
            return 0

        features['ConsecWeeksShort4hrs'] = features.apply(_get_week_run_for_row, axis=1)

        # Apply anomaly score bumps now that AnomalyScore exists
        # (safe: check column presence)
        if 'AnomalyScore' not in features.columns:
            features['AnomalyScore'] = 0.0

        mask1 = features['ConsecWeeksShort4hrs'].fillna(0).astype(int) >= 1
        mask2 = features['ConsecWeeksShort4hrs'].fillna(0).astype(int) >= 2

        if mask1.any():
            features.loc[mask1, 'AnomalyScore'] = features.loc[mask1, 'AnomalyScore'].astype(float) + 0.5
        if mask2.any():
            features.loc[mask2, 'AnomalyScore'] = features.loc[mask2, 'AnomalyScore'].astype(float) + 1.0

        # Recompute IsFlagged and RiskLevel after bumping AnomalyScore
        features['IsFlagged'] = features['AnomalyScore'].apply(lambda s: bool(s >= ANOMALY_THRESHOLD))

        def _map_risk_after_bump(r):
            score = r.get('AnomalyScore') or 0.0
            bucket, label = map_score_to_label(score)
            return int(bucket), label
        rs2 = features.apply(lambda r: pd.Series(_map_risk_after_bump(r), index=['RiskScore', 'RiskLevel']), axis=1)
        features['RiskScore'] = rs2['RiskScore']
        features['RiskLevel'] = rs2['RiskLevel']

    except Exception:
        logging.exception("Failed post-scoring weekly-run / monitoring augmentation.")



    def reasons_for_row(r):
        if not bool(r.get('IsFlagged')):
            return None
        ds_raw = r.get('DetectedScenarios')
        if ds_raw:
            ds = [s.strip() for s in ds_raw.split(";") if s and s.strip()]
            # Build natural explanation sentences for the detected scenarios
            explanation = _explain_scenarios_detected(r, ds)
            # Also produce compact reasons list (code-style) in Reasons for backwards compatibility
            reasons_codes = "; ".join(ds) if ds else None
            return reasons_codes, explanation
        return None, None

    # Apply reasons_for_row to populate Reasons (codes) and Explanation (natural text)
    reason_tuples = features.apply(lambda r: pd.Series(reasons_for_row(r), index=['Reasons', 'Explanation']), axis=1)
    features['Reasons'] = reason_tuples['Reasons']
    features['Explanation'] = reason_tuples['Explanation']

    if 'OverlapWith' not in features.columns:
        def overlap_with_fn(r):
            d = r.get('Date')
            uid = r.get('person_uid')
            if (d, uid) in swipe_overlap_map:
                return ";".join(sorted(str(x) for x in swipe_overlap_map[(d, uid)]))
            return None
        features['OverlapWith'] = features.apply(overlap_with_fn, axis=1)

    # compute ViolationDays in past window (person_uid -> count) using existing trend CSVs in outdir
    try:
        violation_map = compute_violation_days_map(outdir, VIOLATION_WINDOW_DAYS, target_date)

        def map_violation_days(r):
            # Check multiple possible identifiers; normalize them the same way as history map keys
            candidates = []
            for k in ('person_uid', 'EmployeeID', 'EmployeeIdentity', 'CardNumber', 'Int1', 'Text12'):
                if k in r and r.get(k) not in (None, '', float('nan')):
                    val = r.get(k)
                    try:
                        norm = _normalize_id_val(val)
                        if norm:
                            candidates.append(str(norm))
                            stripped = _strip_uid_prefix(str(norm))
                            if stripped != str(norm):
                                candidates.append(str(stripped))
                    except Exception:
                        continue
            # try also the raw EmployeeID fallback
            for cand in candidates:
                if cand in violation_map:
                    return int(violation_map[cand])
            return 0

        features['ViolationDaysLast90'] = features.apply(map_violation_days, axis=1)
    except Exception:
        features['ViolationDaysLast90'] = 0


    # compute RiskScore (bucket) and RiskLevel label
    try:
        def map_risk(r):
            score = r.get('AnomalyScore') or 0.0
            bucket, label = map_score_to_label(score)
            return int(bucket), label
        rs = features.apply(lambda r: pd.Series(map_risk(r), index=['RiskScore', 'RiskLevel']), axis=1)
        features['RiskScore'] = rs['RiskScore']
        features['RiskLevel'] = rs['RiskLevel']
    except Exception:
        features['RiskScore'] = 1
        features['RiskLevel'] = 'Low'

    # ---- OVERRIDE: force High risk when ViolationDaysLast90 >= 4 ----
    try:
        features['ViolationDaysLast90'] = features['ViolationDaysLast90'].fillna(0).astype(int)
        high_violation_mask = features['ViolationDaysLast90'] >= 4
        if high_violation_mask.any():
            features.loc[high_violation_mask, 'RiskScore'] = 5
            features.loc[high_violation_mask, 'RiskLevel'] = 'High'
    except Exception:
        pass
    # ---------------------------------------------------------------

    # Remove suffix columns and fix duplicates
    cols_to_drop = [c for c in features.columns if c.endswith("_x") or c.endswith("_y")]
    if cols_to_drop:
        for c in cols_to_drop:
            base = c[:-2]
            if base in features.columns:
                try:
                    features.drop(columns=[c], inplace=True)
                except Exception:
                    pass
            else:
                try:
                    features.rename(columns={c: base}, inplace=True)
                except Exception:
                    pass
    features = features.loc[:, ~features.columns.duplicated()]

    # ensure booleans are native Python (avoid numpy.bool_)
    for col in [name for name, _ in SCENARIOS] + ['IsFlagged']:
        if col in features.columns:
            features[col] = features[col].astype(bool)

    # write CSV with native types
    out_csv = Path(outdir) / f"trend_pune_{target_date.strftime('%Y%m%d')}.csv"
    try:
        write_df = features.copy()
        # FirstSwipe/LastSwipe -> ISO strings
        for dtcol in ('FirstSwipe', 'LastSwipe'):
            if dtcol in write_df.columns:
                write_df[dtcol] = pd.to_datetime(write_df[dtcol], errors='coerce').dt.strftime('%Y-%m-%dT%H:%M:%S')
        # Date -> ISO date
        if 'Date' in write_df.columns:
            try:
                write_df['Date'] = pd.to_datetime(write_df['Date'], errors='coerce').dt.date
                write_df['Date'] = write_df['Date'].apply(lambda d: d.isoformat() if pd.notna(d) else None)
            except Exception:
                pass
        write_df = write_df.where(pd.notnull(write_df), None)
        write_df.to_csv(out_csv, index=False)
        logging.info("run_trend_for_date: wrote %s (rows=%d)", out_csv, len(write_df))
    except Exception as e:
        logging.exception("Failed to write trend CSV: %s", e)

  
  
  
    # If caller wants dict/json-friendly output (useful for API endpoints), prepare it:
    # if as_dict:
    #     try:
    #         # prepare a safe records list (convert datetimes to ISO strings)
    #         rec_df = features.copy()
    #         for dtcol in ('FirstSwipe', 'LastSwipe'):
    #             if dtcol in rec_df.columns:
    #                 rec_df[dtcol] = pd.to_datetime(rec_df[dtcol], errors='coerce').dt.strftime('%Y-%m-%dT%H:%M:%S')
    #         if 'Date' in rec_df.columns:
    #             try:
    #                 rec_df['Date'] = pd.to_datetime(rec_df['Date'], errors='coerce').dt.date
    #                 rec_df['Date'] = rec_df['Date'].apply(lambda d: d.isoformat() if pd.notna(d) else None)
    #             except Exception:
    #                 pass
    #         rec_df = rec_df.where(pd.notnull(rec_df), None)

    #         # total rows & flagged rows
    #         total_rows = int(len(rec_df))
    #         flagged_rows = int(rec_df['IsFlagged'].sum()) if 'IsFlagged' in rec_df.columns else 0

    #         # reasons_count: split Reasons by ';' and count occurrences
    #         reasons_count = {}
    #         if 'Reasons' in rec_df.columns:
    #             for v in rec_df['Reasons'].dropna().astype(str):
    #                 parts = [p.strip() for p in v.split(";") if p.strip()]
    #                 for p in parts:
    #                     reasons_count[p] = reasons_count.get(p, 0) + 1

    #         # risk_counts: count RiskLevel strings
    #         risk_counts = {}
    #         if 'RiskLevel' in rec_df.columns:
    #             for v in rec_df['RiskLevel'].fillna('').astype(str):
    #                 if v:
    #                     risk_counts[v] = risk_counts.get(v, 0) + 1

    #         # sample: return full flagged rows (reasonable size). If you want a preview only, API layer can trim.
    #         flagged_df = rec_df[rec_df['IsFlagged'] == True] if 'IsFlagged' in rec_df.columns else rec_df
    #         sample_records = flagged_df.to_dict(orient='records')

    #         return {
    #             'rows': total_rows,
    #             'flagged_rows': flagged_rows,
    #             'aggregated_unique_persons': total_rows,
    #             'sample': sample_records,
    #             'reasons_count': reasons_count,
    #             'risk_counts': risk_counts
    #         }
    #     except Exception:
    #         logging.exception("Failed to build dict output for run_trend_for_date")
    #         return {'rows': len(features), 'flagged_rows': int(features['IsFlagged'].sum() if 'IsFlagged' in features.columns else 0),
    #                 'sample': [], 'reasons_count': {}, 'risk_counts': {}, 'aggregated_unique_persons': len(features)}

    # If caller wants dict/json-friendly output (useful for API endpoints), prepare it:
    if as_dict:
        try:
            # prepare a safe records list (convert datetimes to ISO strings)
            rec_df = features.copy()
            for dtcol in ('FirstSwipe', 'LastSwipe'):
                if dtcol in rec_df.columns:
                    rec_df[dtcol] = pd.to_datetime(rec_df[dtcol], errors='coerce').dt.strftime('%Y-%m-%dT%H:%M:%S')
            if 'Date' in rec_df.columns:
                try:
                    rec_df['Date'] = pd.to_datetime(rec_df['Date'], errors='coerce').dt.date
                    rec_df['Date'] = rec_df['Date'].apply(lambda d: d.isoformat() if pd.notna(d) else None)
                except Exception:
                    pass
            rec_df = rec_df.where(pd.notnull(rec_df), None)

            # total rows & flagged rows (explicit and consistent)
            total_rows = int(len(rec_df))
            flagged_rows = int(rec_df['IsFlagged'].sum()) if 'IsFlagged' in rec_df.columns else 0

            # reasons_count: count reasons only among flagged rows (keeps semantics consistent with flagged_rows)
            reasons_count = {}
            flagged_df = rec_df[rec_df['IsFlagged'] == True] if 'IsFlagged' in rec_df.columns else pd.DataFrame()
            if 'Reasons' in flagged_df.columns and not flagged_df.empty:
                for v in flagged_df['Reasons'].dropna().astype(str):
                    for part in re.split(r'[;,\|]', v):
                        key = part.strip()
                        if key:
                            reasons_count[key] = reasons_count.get(key, 0) + 1

            # risk_counts: count RiskLevel only among flagged rows (so this sums to flagged_rows)
            risk_counts = {}
            if 'RiskLevel' in flagged_df.columns and not flagged_df.empty:
                for v in flagged_df['RiskLevel'].fillna('').astype(str):
                    if v:
                        risk_counts[v] = risk_counts.get(v, 0) + 1

            # sample: return flagged rows as sample (keep behaviour)
            sample_records = flagged_df.to_dict(orient='records') if not flagged_df.empty else []

            return {
                'rows': total_rows,
                'flagged_rows': flagged_rows,
                'aggregated_unique_persons': total_rows,
                'sample': sample_records,
                'reasons_count': reasons_count,
                'risk_counts': risk_counts
            }
        except Exception:
            logging.exception("Failed to build dict output for run_trend_for_date")
            return {'rows': len(features), 'flagged_rows': int(features['IsFlagged'].sum() if 'IsFlagged' in features.columns else 0),
                    'sample': [], 'reasons_count': {}, 'risk_counts': {}, 'aggregated_unique_persons': len(features)}



    # default: return DataFrame (existing behavior)
    return features


def _compute_weeks_with_threshold(df, person_col='person_uid', date_col='Date', scenario_col='short_duration_<4h', threshold_days=3, lookback_weeks=8):
    """
    Return dict person_uid -> max_consecutive_weeks meeting threshold_days for scenario_col
    df expected to include Date as date type and scenario_col boolean.
    """
    out = {}
    if df is None or df.empty or scenario_col not in df.columns:
        return out
    try:
        dd = df.copy()
        dd['Date'] = pd.to_datetime(dd[date_col], errors='coerce').dt.date
        # compute ISO year-week
        dd['year_week'] = dd['Date'].apply(lambda d: (d.isocalendar()[0], d.isocalendar()[1]) if d else (None, None))
        # Build per person-week counts
        grp = dd[dd[scenario_col] == True].groupby([person_col, 'year_week']).size().reset_index(name='cnt')
        # collect last lookback_weeks weeks values for each person
        for person, g in grp.groupby(person_col):
            # sort by year_week
            weeks = sorted([ (yw, int(cnt)) for yw, cnt in zip(g['year_week'], g['cnt']) if yw is not None ])
            # transform to list of (year, week, cnt) then determine consecutive weeks that meet threshold
            week_map = { (y,w): cnt for (y,w),cnt in zip(g['year_week'], g['cnt'])}
            # get the list of week keys sorted
            wk_keys = sorted(week_map.keys())
            # compute max consecutive runs
            max_run = 0
            cur_run = 0
            prev = None
            for y,w in wk_keys:
                cnt = week_map.get((y,w), 0)
                if cnt >= threshold_days:
                    if prev is None:
                        cur_run = 1
                    else:
                        # check consecutive week
                        # naive next-week calculation:
                        py, pw = prev
                        # increment which handles year boundary
                        from datetime import date as _date
                        try:
                            d1 = _date.fromisocalendar(py, pw, 1)
                            d2 = _date.fromisocalendar(y, w, 1)
                            diff_weeks = int((d2 - d1).days / 7)
                        except Exception:
                            diff_weeks = 1 if (y,w) != prev else 0
                        if diff_weeks == 1:
                            cur_run += 1
                        else:
                            cur_run = 1
                    prev = (y,w)
                else:
                    prev = (y,w)
                    cur_run = 0
                max_run = max(max_run, cur_run)
            out[person] = max_run
    except Exception:
        logging.exception("Failed computing weeks with threshold")
    return out

def build_90day_training(end_date: date = None, window_days: int = 90, outdir: str = "./outputs",
                         min_unique_employees: int = 100, city: str = "Pune"):
    """
    Build a per-person training CSV aggregated across the last `window_days` days.
    Output: outdir/training_person_90day.csv (or with window_days in name)
    Each row aggregates medians/means/sums for numeric metrics and creates binary labels
    for each scenario if the scenario occurred at least once in the window for that person.
    """
    if end_date is None:
        end_date = datetime.now().date()
    outdir = Path(outdir)
    outdir.mkdir(parents=True, exist_ok=True)
    logging.info("build_90day_training: end_date=%s window_days=%d", end_date, window_days)

    # read trend CSVs within window (uses existing helper)
    df = _read_past_trend_csvs(outdir=str(outdir), window_days=window_days, target_date=end_date)
    if df is None or df.empty:
        logging.warning("No trend CSVs found in %s for window ending %s", outdir, end_date)
        return None

    # ensure Date is date
    if 'Date' in df.columns:
        try:
            df['Date'] = pd.to_datetime(df['Date'], errors='coerce').dt.date
        except Exception:
            pass

    # ensure person_uid exists (fallback to EmployeeID/EmployeeIdentity)
    if 'person_uid' not in df.columns:
        def make_person_uid_local(row):
            parts = []
            for c in ('EmployeeIdentity', 'EmployeeID', 'EmployeeName'):
                v = row.get(c)
                if pd.notna(v) and str(v).strip():
                    parts.append(str(v).strip())
            return "|".join(parts) if parts else None
        df['person_uid'] = df.apply(make_person_uid_local, axis=1)

    # choose scenario columns (boolean daily indicators) existing in df
    scenario_names = [name for name, _ in SCENARIOS if name in df.columns]

    # aggregate per person_uid
    agg_funcs = {
        'CountSwipes': ['median', 'mean', 'sum'],
        'DurationMinutes': ['median', 'mean', 'sum'],
        'MaxSwipeGapSeconds': ['max', 'median'],
        'ShortGapCount': ['sum'],
        'UniqueDoors': ['median'],
        'UniqueLocations': ['median'],
        'RejectionCount': ['sum']
    }

    # ensure numeric columns exist
    for col in ['CountSwipes', 'DurationMinutes', 'MaxSwipeGapSeconds', 'ShortGapCount', 'UniqueDoors', 'UniqueLocations', 'RejectionCount']:
        if col not in df.columns:
            df[col] = 0

    group_cols = ['person_uid']
    grp = df.groupby(group_cols, sort=False)

    person_rows = []
    unique_persons = set()

    for person, g in grp:
        row = {}
        row['person_uid'] = person
        row['EmployeeID'] = next((v for v in g.get('EmployeeID', []) if pd.notna(v) and not _is_placeholder_str(v)), None)
        row['EmployeeName'] = next((v for v in g.get('EmployeeName', []) if pd.notna(v) and not _is_placeholder_str(v)), None)
        row['days_present'] = int(g.shape[0])
        row['HistPatternShortLongCount90'] = int(g.get('HistPatternShortLongCount90', pd.Series([0])).sum()) if 'HistPatternShortLongCount90' in g else 0
        row['HistRepeatedShortBreakCount90'] = int(g.get('HistRepeatedShortBreakCount90', pd.Series([0])).sum()) if 'HistRepeatedShortBreakCount90' in g else 0
        row['HistShortDurationCount90'] = int(g.get('HistShortDurationCount90', pd.Series([0])).sum()) if 'HistShortDurationCount90' in g else 0



        # numeric aggregates
        for col, funcs in agg_funcs.items():
            if col in g.columns:
                for f in funcs:
                    key = f"{col}_{f}"
                    try:
                        val = getattr(g[col], f)()
                        row[key] = float(val) if pd.notna(val) else None
                    except Exception:
                        row[key] = None
            else:
                for f in funcs:
                    row[f"{col}_{f}"] = None

        # scenario labels: if scenario column exists in daily rows, label = sum > 0
        for s in scenario_names:
            try:
                s_count = int(g[s].astype(int).sum()) if s in g.columns else 0
            except Exception:
                s_count = int((g[s].sum()) if s in g.columns else 0)
            row[f"{s}_days"] = s_count
            row[f"{s}_label"] = int(s_count > 0)

        person_rows.append(row)
        unique_persons.add(person)

        # early stop if dataset large
        if len(unique_persons) >= min_unique_employees:
            logging.info("Reached min unique employees=%d; stopping early", min_unique_employees)
            break

    if not person_rows:
        logging.warning("No aggregated person rows were created.")
        return None

    training_df = pd.DataFrame(person_rows)
    out_name = f"training_person_{window_days}day_{end_date.strftime('%Y%m%d')}.csv"
    out_path = outdir / out_name
    training_df.to_csv(out_path, index=False)
    logging.info("Saved 90-day training CSV to %s (rows=%d)", out_path, len(training_df))
    return out_path


# ---------------- training dataset builder (restored) ----------------
def build_monthly_training(end_date: date = None, months: int = 3, min_unique_employees: int = 1000,
                           outdir: str = "./outputs", city: str = "Pune"):
    if end_date is None:
        end_date = datetime.now().date()
    logging.info("build_monthly_training: end_date=%s months=%d min_unique=%d", end_date, months, min_unique_employees)
    outdir = Path(outdir)
    month_windows = []
    cur = end_date.replace(day=1)
    for _ in range(months):
        start = cur
        next_month = (cur.replace(day=28) + timedelta(days=4)).replace(day=1)
        last = next_month - timedelta(days=1)
        month_windows.append((start, last))
        cur = (start - timedelta(days=1)).replace(day=1)

    person_month_rows = []
    unique_persons = set()

    for start, last in month_windows:
        d = start
        month_dfs = []
        while d <= last:
            csv_path = outdir / f"trend_pune_{d.strftime('%Y%m%d')}.csv"
            if csv_path.exists():
                try:
                    df = pd.read_csv(csv_path)
                    month_dfs.append(df)
                except Exception:
                    try:
                        df = pd.read_csv(csv_path, dtype=str)
                        month_dfs.append(df)
                    except Exception as e:
                        logging.warning("Failed reading %s: %s", csv_path, e)
            else:
                # generate the daily trend if missing
                logging.info("Monthly builder: trend CSV missing for %s — generating by running run_trend_for_date", d.isoformat())
                try:
                    run_trend_for_date(d, outdir=str(outdir), city=city)
                    # attempt to read after generating
                    if csv_path.exists():
                        try:
                            df = pd.read_csv(csv_path)
                            month_dfs.append(df)
                        except Exception:
                            try:
                                df = pd.read_csv(csv_path, dtype=str)
                                month_dfs.append(df)
                            except Exception as e:
                                logging.warning("Failed reading %s after generation: %s", csv_path, e)
                except Exception as e:
                    logging.warning("Failed to generate trend for %s: %s", d, e)
            d = d + timedelta(days=1)

        if not month_dfs:
            logging.info("No daily trend CSVs found for month %s - %s", start.isoformat(), last.isoformat())
            continue

        month_df = pd.concat(month_dfs, ignore_index=True)
        # ensure person_uid exists
        if 'person_uid' not in month_df.columns:
            def make_person_uid(row):
                parts = []
                for c in ('EmployeeIdentity', 'EmployeeID', 'EmployeeName'):
                    v = row.get(c)
                    if pd.notna(v) and str(v).strip():
                        parts.append(str(v).strip())
                return "|".join(parts) if parts else None
            month_df['person_uid'] = month_df.apply(make_person_uid, axis=1)

        # convert boolean columns to int for aggregation if necessary
        for name, _ in SCENARIOS:
            if name in month_df.columns:
                month_df[name] = month_df[name].astype(int)

        agg_funcs = {
            'CountSwipes': ['median', 'mean', 'sum'],
            'DurationMinutes': ['median', 'mean', 'sum'],
            'MaxSwipeGapSeconds': ['max', 'median'],
            'ShortGapCount': ['sum'],
            'UniqueDoors': ['median'],
            'UniqueLocations': ['median'],
            'RejectionCount': ['sum']
        }
        scenario_cols = [name for name,_ in SCENARIOS if name in month_df.columns]
        group_cols = ['person_uid']
        grp = month_df.groupby(group_cols)

        for person, g in grp:
            row = {}
            row['person_uid'] = person
            row['EmployeeID'] = next((v for v in g.get('EmployeeID', []) if pd.notna(v) and not _is_placeholder_str(v)), None)
            row['EmployeeName'] = next((v for v in g.get('EmployeeName', []) if pd.notna(v) and not _is_placeholder_str(v)), None)
            row['MonthStart'] = start.isoformat()
            row['MonthEnd'] = last.isoformat()
            for col, funcs in agg_funcs.items():
                if col in g.columns:
                    for f in funcs:
                        key = f"{col}_{f}"
                        try:
                            val = getattr(g[col], f)()
                            row[key] = float(val) if pd.notna(val) else None
                        except Exception:
                            row[key] = None
                else:
                    for f in funcs:
                        row[f"{col}_{f}"] = None
            for s in scenario_cols:
                row[f"{s}_days"] = int(g[s].sum())
                row[f"{s}_label"] = int(g[s].sum() > 0)
            row['days_present'] = int(g.shape[0])
            person_month_rows.append(row)
            unique_persons.add(person)

        if len(unique_persons) >= min_unique_employees:
            logging.info("Reached min unique employees=%d, stopping aggregation early", min_unique_employees)
            break

    if not person_month_rows:
        logging.warning("No person-month rows created (no data).")
        return None

    training_df = pd.DataFrame(person_month_rows)
    train_out = outdir / "training_person_month.csv"
    training_df.to_csv(train_out, index=False)
    logging.info("Saved training CSV to %s (rows=%d unique_persons=%d)", train_out, len(training_df), len(unique_persons))
    return train_out


if __name__ == "__main__":
    today = datetime.now().date()
    df = run_trend_for_date(today)
    print("Completed; rows:", len(df) if df is not None else 0)











<!doctype html>
<html>

<head>
  <meta charset="utf-8" />
  <title>Behaviour Analysis — Dashboard</title>
  <meta name="viewport" content="width=device-width,initial-scale=1" />
  <!-- React + ReactDOM + Babel (quick prototyping) -->
  <script crossorigin src="https://unpkg.com/react@18/umd/react.development.js"></script>
  <script crossorigin src="https://unpkg.com/react-dom@18/umd/react-dom.development.js"></script>
  <script crossorigin src="https://unpkg.com/babel-standalone@6.26.0/babel.min.js"></script>

  <!-- Chart.js -->
  <script src="https://cdn.jsdelivr.net/npm/chart.js"></script>

  <!-- Flatpickr (high-quality calendar) -->
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/flatpickr/dist/flatpickr.min.css">
  <script src="https://cdn.jsdelivr.net/npm/flatpickr"></script>

  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap-icons@1.11.1/font/bootstrap-icons.css">
  <!-- (styles omitted here for brevity — use your existing styles) -->

  <link rel="stylesheet" href="style.css">


</head>

<body>

</head>


<body>
  <div id="root"></div>

  <script type="text/babel">
    (function () {
      const { useState, useEffect, useRef } = React;

      // CHANGE THIS IF YOUR API HOST DIFFERS
      const API_BASE = "http://localhost:8002";

      // Colour mapping requested by user
      const RISK_COLORS = {
        "Low": "#10b981",
        "Low Medium": "#86efac",
        "Medium": "#facc15",
        "Medium High": "#fb923c",
        "High": "#ef4444"
      };

      const RISK_LABELS = ["Low", "Low Medium", "Medium", "Medium High", "High"];

      const SCENARIO_EXPLANATIONS = {
        "long_gap_>=4.5h": "Long gap between swipes (>= 4.5 hours) — could indicate extended out-of-office break.",
        "short_duration_<4h": "Short total duration in office (< 4 hours).",
        "coffee_badging": "Frequent short badge cycles (>=4) with short duration — possible 'coffee badging'.",
        "low_swipe_count_<=2": "Low swipe count (<=2) for the day.",
        "single_door": "All swipes used the same door — single-door behavior.",
        "only_in": "Only IN swipe(s) recorded for the day.",
        "only_out": "Only OUT swipe(s) recorded for the day.",
        "overtime_>=10h": "Long duration (>=10 hours) — overtime.",
        "very_long_duration_>=16h": "Very long duration (>=16 hours) — suspiciously long presence.",
        "unusually_high_swipes": "Unusually high number of swipes versus historical median.",
        "repeated_short_breaks": "Multiple short breaks within the day.",
        "multiple_location_same_day": "Swipes recorded at multiple locations same day.",
        "weekend_activity": "Activity recorded on weekend.",
        "repeated_rejection_count": "Several card rejections.",
        "badge_sharing_suspected": "Badge sharing suspected (same card used by multiple persons on same day).",
        "early_arrival_before_06": "First swipe before 06:00.",
        "late_exit_after_22": "Last swipe after 22:00.",
        "shift_inconsistency": "Duration inconsistent with historical shift patterns.",
        "trending_decline": "Historical trending decline flagged.",
        "consecutive_absent_days": "Marked absent for consecutive days historically.",
        "high_variance_duration": "High variance in durations historically.",
        "short_duration_on_high_presence_days": "Short duration even though employee usually attends many days.",
        "swipe_overlap": "Simultaneous swipe(s) near the same time with other uid(s) (possible tailgating or collusion).",
        "shortstay_longout_repeat": "Pattern: short stay, long out-of-office, short return (repeat)."
      };

      function pad(n) { return n.toString().padStart(2, '0'); }
      function formatDateISO(d) {
        if (!d) return "";
        const dt = (d instanceof Date) ? d : new Date(d);
        return dt.getFullYear() + "-" + pad(dt.getMonth() + 1) + "-" + pad(dt.getDate());
      }
      function datesBetween(start, end) {
        var out = [];
        var cur = new Date(start);
        while (cur <= end) {
          out.push(new Date(cur));
          cur.setDate(cur.getDate() + 1);
        }
        return out;
      }
      function safeDateDisplay(val) {
        if (!val && val !== 0) return "";
        try {
          var d = (val instanceof Date) ? val : new Date(val);
          if (isNaN(d.getTime())) return String(val);
          return d.toLocaleString();
        } catch (e) {
          return String(val);
        }
      }
      function sanitizeName(row) {
        return row.EmployeeName || row.EmployeeName_x || row.EmployeeName_y || row.person_uid || "";
      }
      function downloadCSV(rows, filename) {
        if (!rows || !rows.length) { alert("No rows to export"); return; }
        var cols = Object.keys(rows[0]);
        var lines = [cols.join(",")];
        rows.forEach(function (r) {
          var row = cols.map(function (c) {
            var v = (r[c] === undefined || r[c] === null) ? "" : String(r[c]).replace(/\n/g, ' ');
            return JSON.stringify(v);
          }).join(",");
          lines.push(row);
        });
        var blob = new Blob([lines.join("\n")], { type: 'text/csv' });
        var url = URL.createObjectURL(blob);
        var a = document.createElement('a'); a.href = url; a.download = filename || 'export.csv'; a.click(); URL.revokeObjectURL(url);
      }

      // convert seconds -> "HH:mm:ss"
      function formatSecondsToHmsJS(seconds) {
        if (seconds === null || seconds === undefined || seconds === '') return "-";
        const n = Number(seconds);
        if (isNaN(n) || !isFinite(n)) return "-";
        const s = Math.max(0, Math.floor(n));
        const hh = Math.floor(s / 3600);
        const mm = Math.floor((s % 3600) / 60);
        const ss = s % 60;
        return pad(hh) + ":" + pad(mm) + ":" + pad(ss);
      }

      function App() {
        var yesterday = new Date();
        yesterday.setDate(yesterday.getDate() - 1);

        const [dateFrom, setDateFrom] = useState(formatDateISO(yesterday));
        const [dateTo, setDateTo] = useState(formatDateISO(new Date()));
        const [loading, setLoading] = useState(false);
        const [summary, setSummary] = useState({ rows: 0, flagged_rows: 0, files: [], end_date: null });
        const [rows, setRows] = useState([]);
        const [reasonsCount, setReasonsCount] = useState({});
        const [riskCounts, setRiskCounts] = useState({ "Low": 0, "Low Medium": 0, "Medium": 0, "Medium High": 0, "High": 0 });
        const [filterText, setFilterText] = useState("");
        const [page, setPage] = useState(1);
        const [selectedReason, setSelectedReason] = useState("");
        const [reasonFilterText, setReasonFilterText] = useState("");
        const [modalRow, setModalRow] = useState(null);
        const [modalDetails, setModalDetails] = useState(null);
        const [modalLoading, setModalLoading] = useState(false);
        const [selectedRiskFilter, setSelectedRiskFilter] = useState("");
        const pageSize = 25;
        const chartRef = useRef(null);
        const chartInst = useRef(null);

        // flatpickr refs
        const fromRef = useRef(null);
        const toRef = useRef(null);
        const fromFp = useRef(null);
        const toFp = useRef(null);

        // Chat state
        const [chatOpen, setChatOpen] = useState(false);
        const [chatMessages, setChatMessages] = useState([]); // {who: 'user'|'bot', text, evidence:[]}
        const [chatInput, setChatInput] = useState("");
        const [chatLoading, setChatLoading] = useState(false);

        useEffect(function () {
          if (window.flatpickr && fromRef.current && toRef.current) {
            try { if (fromFp.current) fromFp.current.destroy(); } catch (e) { }
            try { if (toFp.current) toFp.current.destroy(); } catch (e) { }
            fromFp.current = window.flatpickr(fromRef.current, {
              dateFormat: "Y-m-d",
              defaultDate: dateFrom,
              allowInput: true,
              onChange: function (selectedDates, str) {
                if (selectedDates && selectedDates.length) {
                  const iso = formatDateISO(selectedDates[0]);
                  setDateFrom(iso);
                  try { if (toFp.current) toFp.current.set('minDate', iso); } catch (e) { }
                  if (dateTo && new Date(iso) > new Date(dateTo)) {
                    setDateTo(iso);
                    try { if (toFp.current) toFp.current.setDate(iso, true); } catch (e) { }
                  }
                }
              }
            });
            toFp.current = window.flatpickr(toRef.current, {
              dateFormat: "Y-m-d",
              defaultDate: dateTo,
              allowInput: true,
              onChange: function (selectedDates, str) {
                if (selectedDates && selectedDates.length) {
                  const iso = formatDateISO(selectedDates[0]);
                  setDateTo(iso);
                  try { if (fromFp.current) fromFp.current.set('maxDate', iso); } catch (e) { }
                  if (dateFrom && new Date(iso) < new Date(dateFrom)) {
                    setDateFrom(iso);
                    try { if (fromFp.current) fromFp.current.setDate(iso, true); } catch (e) { }
                  }
                }
              }
            });
            try { if (fromFp.current) fromFp.current.set('maxDate', dateTo); if (toFp.current) toFp.current.set('minDate', dateFrom); } catch (e) { }
          }
          loadLatest();
          return function () { try { if (fromFp.current) fromFp.current.destroy(); } catch (e) { } try { if (toFp.current) toFp.current.destroy(); } catch (e) { } };
          // eslint-disable-next-line
        }, []);

        useEffect(function () {
          try { if (fromFp.current && dateFrom) fromFp.current.setDate(dateFrom, false); } catch (e) { }
          try { if (toFp.current && dateTo) toFp.current.setDate(dateTo, false); } catch (e) { }
          try { if (fromFp.current) fromFp.current.set('maxDate', dateTo); } catch (e) { }
          try { if (toFp.current) toFp.current.set('minDate', dateFrom); } catch (e) { }
        }, [dateFrom, dateTo]);

        async function runForRange() {
          setLoading(true);
          setRows([]);
          setSummary({ rows: 0, flagged_rows: 0, files: [], end_date: null });
          setReasonsCount({});
          setRiskCounts({ "Low": 0, "Low Medium": 0, "Medium": 0, "Medium High": 0, "High": 0 });
          try {
            const start = encodeURIComponent(dateFrom);
            const end = encodeURIComponent(dateTo);
            let url = API_BASE + "/run?start=" + start + "&end=" + end + "&full=true";
            let r = await fetch(url, { method: 'GET' });
            if (!r.ok) { const txt = await r.text(); throw new Error("API returned " + r.status + ": " + txt); }
            let js = await r.json();

            const totalRows = (typeof js.aggregated_unique_persons === 'number') ? js.aggregated_unique_persons
                             : (typeof js.rows === 'number') ? js.rows : 0;
            const totalFlagged = (typeof js.flagged_rows === 'number') ? js.flagged_rows : 0;
            const files = js.files || [];

            const sample = Array.isArray(js.sample) ? js.sample : [];

            setRows(sample);
            setSummary({ rows: totalRows, flagged_rows: totalFlagged, files: files, end_date: formatDateISO(new Date(dateTo)) });

            if (js.reasons_count && Object.keys(js.reasons_count).length > 0) {
              setReasonsCount(js.reasons_count);
            } else {
              computeReasonsAndRisks(sample);
            }
            if (js.risk_counts && Object.keys(js.risk_counts).length > 0) {
              const all = { "Low":0,"Low Medium":0,"Medium":0,"Medium High":0,"High":0 };
              Object.keys(js.risk_counts).forEach(k => { all[k] = js.risk_counts[k]; });
              setRiskCounts(all);
            } else {
              computeReasonsAndRisks(sample);
            }

            setPage(1);
          } catch (err) {
            alert("Error: " + err.message);
            console.error(err);
          } finally {
            setLoading(false);
          }
        }

        function pushChatMessage(msg) {
          setChatMessages(prev => [...prev, msg]);
          setTimeout(() => {
            const el = document.querySelector('.chat-body');
            if (el) el.scrollTop = el.scrollHeight;
          }, 50);
        }

        // single computeReasonsAndRisks (kept once)
        function computeReasonsAndRisks(dataRows) {
          var counts = {};
          var rcounts = { "Low": 0, "Low Medium": 0, "Medium": 0, "Medium High": 0, "High": 0 };
          (dataRows || []).forEach(function (r) {
            if (r.Reasons) {
              var parts = String(r.Reasons).split(";").map(function (s) { return s.trim(); }).filter(Boolean);
              parts.forEach(function (p) { counts[p] = (counts[p] || 0) + 1; });
            }
            var rl = getRiskLabelForRow(r);
            if (rl && rcounts[rl] !== undefined) {
              rcounts[rl] += 1;
            } else if (rl && rcounts[rl] === undefined) {
              rcounts[rl] = (rcounts[rl] || 0) + 1;
            } else {
              rcounts["Low"] += 1;
            }
          });
          setReasonsCount(counts);
          setRiskCounts(rcounts);
        }


        async function loadLatest() {
  setLoading(true);
  try {
    // compute yesterday in YYYY-MM-DD
    var d = new Date();
    d.setDate(d.getDate() - 1);
    var yesterday = formatDateISO(d);

    // set the date inputs to yesterday (so UI reflects the selection)
    setDateFrom(yesterday);
    setDateTo(yesterday);

    // call the run endpoint for yesterday only (start == end == yesterday)
    const start = encodeURIComponent(yesterday);
    const end = encodeURIComponent(yesterday);
    let url = API_BASE + "/run?start=" + start + "&end=" + end + "&full=true";
    let r = await fetch(url, { method: 'GET' });
    if (!r.ok) { const txt = await r.text(); throw new Error("API returned " + r.status + ": " + txt); }
    let js = await r.json();

    const totalRows = (typeof js.aggregated_unique_persons === 'number') ? js.aggregated_unique_persons
                     : (typeof js.rows === 'number') ? js.rows : 0;
    const totalFlagged = (typeof js.flagged_rows === 'number') ? js.flagged_rows : 0;
    const files = js.files || [];

    const sample = Array.isArray(js.sample) ? js.sample : [];

    setRows(sample);
    setSummary({ rows: totalRows, flagged_rows: totalFlagged, files: files, end_date: yesterday });

    if (js.reasons_count && Object.keys(js.reasons_count).length > 0) {
      setReasonsCount(js.reasons_count);
    } else {
      computeReasonsAndRisks(sample);
    }
    if (js.risk_counts && Object.keys(js.risk_counts).length > 0) {
      const all = { "Low":0,"Low Medium":0,"Medium":0,"Medium High":0,"High":0 };
      Object.keys(js.risk_counts).forEach(k => { all[k] = js.risk_counts[k]; });
      setRiskCounts(all);
    } else {
      computeReasonsAndRisks(sample);
    }

    setPage(1);
  } catch (err) {
    alert("Error: " + err.message);
    console.error(err);
  } finally {
    setLoading(false);
  }
}

        function getRiskLabelForRow(r) {
          if (!r) return null;
          var rl = r.RiskLevel || r.Risk || null;
          if (rl) return String(rl);
          if (r.RiskScore !== undefined && r.RiskScore !== null) {
            const mapNum = { 1: "Low", 2: "Low Medium", 3: "Medium", 4: "Medium High", 5: "High" };
            return mapNum[String(r.RiskScore)] || null;
          }
          return null;
        }

        // chart build function
        function buildChart(rcounts) {
          var labels = RISK_LABELS;
          var values = labels.map(l => rcounts && rcounts[l] ? rcounts[l] : 0);
          var colors = labels.map(l => {
            if (selectedRiskFilter) {
              return (l === selectedRiskFilter) ? RISK_COLORS[l] : '#e6edf3';
            } else {
              return RISK_COLORS[l] || '#cccccc';
            }
          });

          var ctx = chartRef.current && chartRef.current.getContext ? chartRef.current.getContext('2d') : null;
          if (!ctx) return;
          try { if (chartInst.current) chartInst.current.destroy(); } catch (e) { }

          chartInst.current = new Chart(ctx, {
            type: 'line',
            data: {
              labels: labels,
              datasets: [{
                label: 'Flagged by Risk Level',
                data: values,
                borderColor: '#2563eb',
                backgroundColor: 'rgba(37,99,235,0.2)',
                fill: true,
                tension: 0.3,
                pointBackgroundColor: colors,
                pointRadius: 5,
                pointHoverRadius: 7
              }]
            },
            options: {
              responsive: true,
              maintainAspectRatio: false,
              plugins: {
                legend: { display: false },
                tooltip: {
                  callbacks: {
                    label: function (context) {
                      return context.parsed.y + ' cases';
                    }
                  }
                }
              },
              onClick: function (evt, elements) {
                if (elements && elements.length > 0) {
                  var idx = elements[0].index;
                  var label = this.data.labels[idx];
                  handleRiskBarClick(label);
                }
              },
              scales: {
                y: { beginAtZero: true, ticks: { precision: 0 } }
              }
            }
          });

        }

        useEffect(function () {
          buildChart(riskCounts);
        }, [riskCounts, selectedRiskFilter]);

        // filtering & pagination helpers (includes risk filter + sorting)
        var filtered = (rows || []).filter(function (r) {
          var hay = (sanitizeName(r) + " " + (r.EmployeeID || "") + " " + (r.CardNumber || "") + " " + (r.Reasons || "")).toLowerCase();
          var textOk = !filterText || hay.indexOf(filterText.toLowerCase()) !== -1;
          var reasonOk = !selectedReason || (r.Reasons && ((";" + String(r.Reasons) + ";").indexOf(selectedReason) !== -1));
          var riskOk = true;
          if (selectedRiskFilter) {
            var rl = getRiskLabelForRow(r);
            if (!rl) { riskOk = false; }
            else riskOk = (String(rl) === String(selectedRiskFilter));
          }
          return textOk && reasonOk && riskOk;
        })
        .sort(function(a, b) {
          var va = Number(a.ViolationDaysLast90);
          var vb = Number(b.ViolationDaysLast90);
          if (isNaN(va)) va = 0;
          if (isNaN(vb)) vb = 0;
          if (vb !== va) return vb - va;
          return (sanitizeName(a) || "").localeCompare(sanitizeName(b) || "");
        });

        var totalPages = Math.max(1, Math.ceil(filtered.length / pageSize));
        var pageRows = filtered.slice((page - 1) * pageSize, page * pageSize);

        function exportFiltered() { downloadCSV(filtered, "trend_filtered_export.csv"); }

        function onReasonClick(reason) {
          if (!reason) { setSelectedReason(""); return; }
          if (selectedReason === reason) setSelectedReason(""); else setSelectedReason(reason);
          setPage(1);
        }

        async function openEvidence(row) {
          setModalRow(row);
          setModalDetails(null);
          setModalLoading(true);
          try {
            const q = encodeURIComponent(row.EmployeeID || row.person_uid || "");
            const resp = await fetch(API_BASE + "/record?employee_id=" + q);
            if (!resp.ok) { const txt = await resp.text(); throw new Error("record failed: " + resp.status + " - " + txt); }
            const js = await resp.json();
            const details = { aggregated_rows: js.aggregated_rows || [], raw_swipe_files: js.raw_swipe_files || [], raw_swipes: js.raw_swipes || [] };
            setModalDetails(details);
          } catch (e) {
            alert("Failed loading details: " + e.message);
            console.error(e);
          } finally { setModalLoading(false); }
        }

        function closeModal() { setModalRow(null); setModalDetails(null); }

        var rowsCount = (summary && typeof summary.rows === 'number') ? summary.rows : (rows ? rows.length : 0);
        var flaggedCount = (summary && typeof summary.flagged_rows === 'number') ? summary.flagged_rows : (rows ? rows.filter(function (r) { return !!r.Reasons; }).length : 0);
        var flaggedPct = rowsCount ? Math.round((flaggedCount * 100) / (rowsCount || 1)) : 0;

        function renderOverlapCell(r) {
          var ov = r.OverlapWith || r.swipe_overlap || r.overlap_with || null;
          if (ov && typeof ov === 'string') {
            var parts = ov.split(";").map(function (s) { return s.trim(); }).filter(Boolean);
            if (parts.length === 0) return <span className="muted">—</span>;
            return <span className="pill" title={ov}>{parts.length} overlap</span>;
          }
          return <span className="muted">—</span>;
        }

        function renderReasonChips(reasonText) {
          if (!reasonText) return <span className="muted">—</span>;
          const parts = String(reasonText).split(";").map(s => s.trim()).filter(Boolean);
          return parts.map((p, idx) => (<span key={idx} className="pill" title={SCENARIO_EXPLANATIONS[p] || p}>{p}</span>));
        }

        function renderReasonExplanations(reasonText) {
          if (!reasonText) return <div className="muted">No flags</div>;
          const parts = String(reasonText).split(";").map(s => s.trim()).filter(Boolean);
          return (
            <div>
              {parts.map((p, idx) => (
                <div key={idx} className="why-item" style={{ marginBottom: 8 }}>
                  <b>{p}</b>
                  <div className="small">{SCENARIO_EXPLANATIONS[p] || "No explanation available."}</div>
                </div>
              ))}
            </div>
          );
        }

        async function sendChat(qText, opts={top_k:5}) {
          if (!qText || !qText.toString().trim()) return;
          const text = qText.toString().trim();
          pushChatMessage({who:'user', text});
          setChatInput("");
          setChatLoading(true);
          try {
            const payload = Object.assign({q: text}, opts);
            const resp = await fetch(API_BASE + "/chatbot/query", {
              method: 'POST',
              headers: { 'Content-Type': 'application/json' },
              body: JSON.stringify(payload)
            });
            if (!resp.ok) {
              const t = await resp.text().catch(()=>'');
              throw new Error("Server: " + resp.status + " " + t);
            }
            const js = await resp.json();
            const answer = js.answer || js.answer_text || js.result || "No answer returned.";
            const evidence = Array.isArray(js.evidence) ? js.evidence : (js.evidence ? [js.evidence] : []);
            pushChatMessage({who:'bot', text: answer, evidence});
          } catch (err) {
            pushChatMessage({who:'bot', text: "Error: " + err.message, evidence: []});
            console.error("chat error", err);
          } finally {
            setChatLoading(false);
            setTimeout(() => {
              const el = document.querySelector('.chat-body');
              if (el) el.scrollTop = el.scrollHeight;
            }, 80);
          }
        }

        const QUICK_PROMPTS = [
          "Who is high risk today",
          "Who is low risk today",
          "Show me 320172 last 90 days",
          "Trend details for today — top reasons",
          "Explain repeated_short_breaks"
        ];
        function useQuickPrompt(q) {
          setChatOpen(true);
          sendChat(q);
        }

        function renderSwipeTimeline(details, modalRow) {
          if (!details || !details.raw_swipes || details.raw_swipes.length === 0) {
            return <div className="muted">No raw swipe evidence available (person not flagged or raw file missing).</div>;
          }
          const all = details.raw_swipes.slice().map(r => {
            const obj = Object.assign({}, r);
            try {
              if (obj.Date && obj.Time) { obj.__ts = new Date(obj.Date + "T" + obj.Time); }
              else if (obj.Date && obj.Time === undefined && obj.LocaleMessageTime) { obj.__ts = new Date(obj.LocaleMessageTime); }
              else if (obj.LocaleMessageTime) { obj.__ts = new Date(obj.LocaleMessageTime); }
              else { obj.__ts = null; }
            } catch (e) { obj.__ts = null; }
            let gap = null;
            if (obj.SwipeGapSeconds !== undefined && obj.SwipeGapSeconds !== null) { gap = Number(obj.SwipeGapSeconds); if (isNaN(gap)) gap = null; }
            else if (obj.SwipeGap) {
              try { const parts = String(obj.SwipeGap).split(':').map(p => Number(p)); if (parts.length === 3) gap = parts[0] * 3600 + parts[1] * 60 + parts[2]; } catch (e) { gap = null; }
            }
            obj.__gap = gap;
            obj.__zone_l = String((obj.Zone || '')).toLowerCase();
            return obj;
          }).sort((a, b) => {
            if (a.__ts && b.__ts) return a.__ts - b.__ts;
            if (a.__ts) return -1;
            if (b.__ts) return 1;
            return 0;
          });

          const flags = new Array(all.length).fill({}).map(() => ({ dayStart: false, outReturn: false }));
          for (let i = 0; i < all.length; i++) {
            const cur = all[i]; const prev = all[i - 1];
            try {
              const curDate = cur.Date ? cur.Date.slice(0, 10) : (cur.__ts ? cur.__ts.toISOString().slice(0, 10) : null);
              const prevDate = prev ? (prev.Date ? prev.Date.slice(0, 10) : (prev.__ts ? prev.__ts.toISOString().slice(0, 10) : null)) : null;
              if (!prev || prevDate !== curDate) { flags[i].dayStart = true; }
            } catch (e) { }
          }
          const OUT_RETURN_GAP_SECONDS = 60 * 60;
          for (let i = 0; i < all.length - 1; i++) {
            const a = all[i], b = all[i + 1];
            const aZone = a.__zone_l || ''; const bZone = b.__zone_l || ''; const bGap = b.__gap || 0;
            if (aZone.includes('out of office') || aZone.includes('out_of_office') || aZone.includes('out of')) {
              if (!bZone.includes('out of office') && (bGap >= OUT_RETURN_GAP_SECONDS || bGap === null && aZone.includes('out'))) {
                flags[i].outReturn = true; flags[i + 1].outReturn = true;
              }
            }
          }

          return (
            <div className="table-scroll">
              <table className="evidence-table" role="table" aria-label="Swipe timeline">
                <thead>
                  <tr>
                    <th>Employee Name</th>
                    <th>Employee ID</th>
                    <th>Card</th>
                    <th>Date</th>
                    <th>Time</th>
                    <th>SwipeGap</th>
                    <th>Door</th>
                    <th>Direction</th>
                    <th>Zone</th>
                    <th>Note</th>
                  </tr>
                </thead>
                <tbody>
                  {all.map((rObj, idx) => {
                    const r = rObj || {};
                    const g = r.__gap;
                    const gapFormatted = (r.SwipeGap && String(r.SwipeGap).trim()) ? String(r.SwipeGap) : (g !== null && g !== undefined) ? formatSecondsToHmsJS(g) : "-";
                    const cls = [];
                    if (flags[idx].dayStart) cls.push('row-day-start');
                    if (flags[idx].outReturn) cls.push('row-out-return');
                    if (g && g >= OUT_RETURN_GAP_SECONDS) cls.push('highlight-long-duration');
                    return (
                      <tr key={idx} className={cls.join(' ')}>
                        <td className="small">{r.EmployeeName || '-'}</td>
                        <td className="small">{r.EmployeeID || '-'}</td>
                        <td className="small">{r.CardNumber || r.Card || '-'}</td>
                        <td className="small">{r.Date || '-'}</td>
                        <td className="small">{r.Time || (r.__ts ? r.__ts.toTimeString().slice(0, 8) : '-')}</td>
                        <td className="small">{gapFormatted}</td>
                        <td className="small" style={{ minWidth: 160 }}>{r.Door || '-'}</td>
                        <td className="small">{r.Direction || '-'}</td>
                        <td className="small">{r.Zone || '-'}</td>
                        <td className="small">{r.Note || '-'}{r._source ? <span className="muted"> ({r._source})</span> : null}</td>
                      </tr>
                    );
                  })
                  }
                </tbody>
              </table>
            </div>
          );
        }

        function handleRiskBarClick(label) {
          if (!label) return;
          if (selectedRiskFilter === label) {
            setSelectedRiskFilter("");
          } else {
            setSelectedRiskFilter(label);
          }
          setPage(1);
        }

        function clearRiskFilter() {
          setSelectedRiskFilter("");
        }

        // ---- RETURN: place chat FAB / chat modal INSIDE the returned JSX ----
        return (
          <div className="container" aria-live="polite">
            {loading && (
              <div className="spinner-overlay" role="status" aria-label="Loading">
                <div className="spinner-box">
                  <div className="spinner" />
                  <div style={{ fontWeight: 700 }}>Loading…</div>
                </div>
              </div>
            )}

            <div className="topbar" role="banner">
              <div className="wu-brand" aria-hidden={false}>
                <div className="wu-logo">WU</div>
                <div className="title-block">
                  <h1>Western Union — Trend Analysis</h1>
                  <p>Pune</p>
                </div>
              </div>

              <div className="header-actions" role="region" aria-label="controls">
                <div className="control">
                  <label className="small" htmlFor="fromDate">From</label>
                  <input id="fromDate" ref={fromRef} className="date-input" type="text" placeholder="YYYY-MM-DD" />
                </div>

                <div className="control">
                  <label className="small" htmlFor="toDate">To</label>
                  <input id="toDate" ref={toRef} className="date-input" type="text" placeholder="YYYY-MM-DD" />
                </div>

                <button className="btn-primary" onClick={runForRange} disabled={loading}>Run</button>
                <button className="btn-ghost" onClick={loadLatest} disabled={loading}>Load latest</button>
              </div>
            </div>

            {/* cards, main content, table etc. (keep your implementation as-is) */}
            <div className="card-shell">
              <div className="cards" aria-hidden={loading}>
                <div className="card" title="Rows analysed">
                  <div className="card-content">
                    <div className="card-text">
                      <h3>{(rowsCount !== undefined && rowsCount !== null) ? rowsCount.toLocaleString() : 0}</h3>
                      <p>Rows analysed</p>
                    </div>
                  </div>
                </div>
                <div className="card card-flagged" title="Flagged rows">
                  <div className="card-content">
                    <div className="card-text">
                      <h3>{(flaggedCount !== undefined && flaggedCount !== null) ? flaggedCount.toLocaleString() : 0}</h3>
                      <p>Flagged rows</p>
                    </div>
                  </div>
                </div>
                <div className="card card-rate" title="Flagged rate">
                  <div className="card-content">
                    <div className="card-text">
                      <h3>{flaggedPct}%</h3>
                      <p>Flagged rate</p>
                    </div>
                  </div>
                </div>
              </div>

              <div className="main">
                <div className="left">
                  <div className="chart-wrap" aria-label="Risk level chart">
                    <canvas ref={chartRef}></canvas>
                  </div>

                  <div style={{ display: 'flex', alignItems: 'center', gap: 8, marginTop: 6 }}>
                    <input placeholder="Search name, employee id, card or reason..." value={filterText} onChange={function (e) { setFilterText(e.target.value); setPage(1); }} style={{ flex: 1, padding: 10, borderRadius: 6, border: '1px solid #e6edf3' }} />
                    <div className="muted">Showing {filtered.length} / {rows.length} rows</div>
                    <button className="small-button" onClick={exportFiltered}>Export filtered</button>
                    {selectedRiskFilter ? <button className="small-button" onClick={clearRiskFilter}>Clear risk filter</button> : null}
                  </div>

                  <div style={{ marginTop: 10 }} className="table-scroll" role="region" aria-label="results table">
                    <table>
                      <thead>
                        <tr>
                          <th>Employee</th>
                          <th className="small">ID</th>
                          <th className="small">Card</th>
                          <th className="small">Date</th>
                          <th className="small">Duration</th>
                          <th className="small">ViolationDaysLast90</th>
                          <th className="small">Reasons</th>
                          <th className="small">Evidence</th>
                        </tr>
                      </thead>
                      <tbody>
                        {pageRows.map(function (r, idx) {
                          var empName = sanitizeName(r);
                          var displayDate = safeDateDisplay(r.Date || r.FirstSwipe || r.LastSwipe);
                          var durText = r.Duration || (r.DurationMinutes ? Math.round(r.DurationMinutes) + " min" : "");
                          var flagged = r.Reasons && String(r.Reasons).trim();
                          return (
                            <tr key={idx} className={flagged ? "flagged-row" : ""}>
                              <td className="row-click" onClick={function () { openEvidence(r); }}>{empName || <span className="muted">—</span>}</td>
                              <td className="small">{r.EmployeeID || ""}</td>
                              <td className="small">{r.CardNumber || ""}</td>
                              <td className="small">{displayDate}</td>
                              <td className="small">{durText}</td>
                              <td className="small">
                                {(r.ViolationDaysLast90 !== undefined && r.ViolationDaysLast90 !== null && r.ViolationDaysLast90 !== "")
                                  ? (Number(r.ViolationDaysLast90).toString())
                                  : ((r.ViolationDaysLast_90 !== undefined && r.ViolationDaysLast_90 !== null) ? String(r.ViolationDaysLast_90) : "")
                                }
                              </td>
                              <td className="small">{renderReasonChips(r.Reasons)}</td>
                              <td className="small">
                                <button className="evidence-btn" onClick={function () { openEvidence(r); }}>Evidence</button>
                              </td>
                            </tr>
                          );
                        })}
                      </tbody>
                    </table>
                  </div>

                  <div style={{ display: 'flex', gap: 8, alignItems: 'center', marginTop: 10 }}>
                    <button onClick={function () { setPage(function (p) { return Math.max(1, p - 1); }); }} disabled={page <= 1}>Prev</button>
                    <div className="muted">Page {page} / {totalPages}</div>
                    <button onClick={function () { setPage(function (p) { return Math.min(totalPages, p + 1); }); }} disabled={page >= totalPages}>Next</button>
                  </div>
                </div>

                <aside className="right" aria-label="side panel">
                  <div className="sidebar-section">
                    <strong>Risk filters</strong>
                    <div className="small muted" style={{ marginTop: 6 }}>Click a risk to filter. Chart click also toggles filter.</div>

                    <div className="risk-filter-list" style={{ marginTop: 8 }}>
                      {RISK_LABELS.map((lab) => {
                        const cnt = (riskCounts && riskCounts[lab]) ? riskCounts[lab] : 0;
                        const active = selectedRiskFilter === lab;
                        return (
                          <div key={lab} role="button" tabIndex={0} aria-pressed={active} className={"risk-chip " + (active ? "active" : "")} onClick={function () { handleRiskBarClick(lab); }} onKeyDown={function (e) { if (e.key === 'Enter' || e.key === ' ') { handleRiskBarClick(lab); } }}>
                            <div style={{ width: 10, height: 10, borderRadius: 999, background: RISK_COLORS[lab], boxShadow: '0 2px 6px rgba(0,0,0,0.08)' }}></div>
                            <div style={{ fontSize: 13 }}>{lab} <span className="muted" style={{ marginLeft: 6 }}>({cnt})</span></div>
                          </div>
                        );
                      })}
                    </div>

                    <div style={{ marginTop: 8 }}>
                      <button className="small-button" onClick={clearRiskFilter}>Clear risk filter</button>
                    </div>
                  </div>

                  <div className="sidebar-section" style={{ marginTop: 12 }}>
                    <strong>Top reasons summary</strong>
                    <div className="small muted" style={{ marginTop: 6 }}>Click a reason to filter the table by that reason. Click again to clear.</div>

                    <div style={{ marginTop: 8, display: 'flex', gap: 8 }}>
                      <input placeholder="Filter reason list..." value={reasonFilterText} onChange={function (e) { setReasonFilterText(e.target.value); }} style={{ flex: 1, padding: '6px 8px', borderRadius: 6, border: '1px solid #e2e8f0' }} />
                      <button className="small-button" onClick={function () { setSelectedReason(''); setReasonFilterText(''); }}>Clear</button>
                    </div>

                    <div style={{ marginTop: 8, maxHeight: 320, overflow: 'auto' }}>
                      {Object.keys(reasonsCount).length === 0 && <div className="muted">No flags found</div>}
                      {Object.entries(reasonsCount).sort(function (a, b) { return b[1] - a[1]; }).filter(function (kv) {
                        var name = kv[0];
                        if (!reasonFilterText) return true;
                        return name.toLowerCase().indexOf(reasonFilterText.toLowerCase()) !== -1;
                      }).slice(0, 50).map(function (kv) {
                        var name = kv[0], count = kv[1];
                        var active = selectedReason === name;
                        return (
                          <div key={name} style={{ display: 'flex', alignItems: 'center', justifyContent: 'space-between', gap: 8, marginBottom: 6 }}>
                            <button className={"chip " + (active ? "active" : "")} style={{ textAlign: 'left', flex: 1 }} onClick={function () { onReasonClick(name); }}>
                              {name}
                            </button>
                            <div style={{ minWidth: 48, textAlign: 'right' }} className="small"><b>{count}</b></div>
                          </div>
                        );
                      })}
                    </div>
                  </div>
                </aside>
              </div>
            </div>

            {modalRow &&
              <div className="modal" onClick={closeModal}>
                <div className="modal-inner" onClick={function (e) { e.stopPropagation(); }}>
                  {/* modal contents (unchanged) */}
                  <div className="modal-header">
                    <div className="header-content">
                      <div className="header-icon">
                        <i className="bi bi-clipboard2-data-fill"></i>
                      </div>
                      <div className="header-text">
                        <h3>Details — Evidence</h3>
                        <div className="header-subtitle small">Evidence & explanation for selected row</div>
                      </div>
                    </div>
                    <button className="close-btn" onClick={closeModal}>
                      <i className="bi bi-x-lg"></i>
                      Close
                    </button>
                  </div>
                  <div className="modal-body">
                    {modalLoading && (
                      <div className="loading-state">
                        <div className="loading-spinner"></div>
                        <span>Loading evidence…</span>
                      </div>
                    )}
                    <div className="modal-top" role="region" aria-label="evidence summary">
                      {/* ... modal body contents as in original ... */}
                      <div className="image-section">
                        <div className="image-container">
                          <div className="multi-color-border">
                            <div className="color-ring color-1"></div>
                            <div className="color-ring color-2"></div>
                            <div className="color-ring color-3"></div>
                            <div className="color-ring color-4"></div>
                            <div className="image-content">
                              {(modalDetails && modalDetails.aggregated_rows && modalDetails.aggregated_rows.length > 0) ? (
                                (() => {
                                  const md = modalDetails.aggregated_rows[0];
                                  if (md && md.imageUrl) {
                                    return (
                                      <img
                                        className="modal-image"
                                        src={API_BASE + md.imageUrl}
                                        alt="Employee"
                                        onError={(e) => {
                                          e.target.style.display = 'none';
                                          e.target.nextSibling.style.display = 'flex';
                                        }}
                                      />
                                    );
                                  } else {
                                    return <div className="modal-image-placeholder">No image</div>;
                                  }
                                })()
                              ) : (
                                <div className="modal-image-placeholder">
                                  <i className="bi bi-person-square"></i>
                                  <span>No image</span>
                                </div>
                              )}
                            </div>
                          </div>
                        </div>
                      </div>

                      {/* rest of modal columns (kept same) */}
                      <div className="modal-details">
                        <div className="details-header">
                          <div className="emp-info">
                            <div className="emp-name">
                              {sanitizeName(modalRow) || "—"}
                              <span
                                className="risk-badge"
                                style={{
                                  marginLeft: "12px",
                                  background:
                                    RISK_COLORS[modalRow.RiskLevel] ||
                                    RISK_COLORS[getRiskLabelForRow(modalRow)] ||
                                    RISK_COLORS["Low"],
                                }}
                              >
                                {modalRow.RiskLevel ||
                                  (modalRow.RiskScore ? "Score " + modalRow.RiskScore : "Low")}
                              </span>
                            </div>
                            <div className="emp-badge">
                              <i className="bi bi-person-badge"></i>
                              ID: {modalRow.EmployeeID || "—"}
                            </div>
                          </div>
                        </div>
                        <div className="details-grid">
                          <div className="detail-item">
                            <div className="detail-icon">
                              <i className="bi bi-credit-card"></i>
                            </div>
                            <div className="detail-content">
                              <label>Card Number</label>
                              <span>{modalRow.CardNumber || "—"}</span>
                            </div>
                          </div>
                          <div className="detail-item">
                            <div className="detail-icon">
                              <i className="bi bi-envelope"></i>
                            </div>
                            <div className="detail-content">
                              <label>Email</label>
                              <span>
                                {(modalDetails && modalDetails.aggregated_rows && modalDetails.aggregated_rows[0] && modalDetails.aggregated_rows[0].EmployeeEmail)
                                  ? modalDetails.aggregated_rows[0].EmployeeEmail
                                  : <span className="muted">—</span>}
                              </span>
                            </div>
                          </div>
                          <div className="detail-item">
                            <div className="detail-icon">
                              <i className="bi bi-calendar-date"></i>
                            </div>
                            <div className="detail-content">
                              <label>Date</label>
                              <span>{safeDateDisplay(modalRow.Date || modalRow.FirstSwipe)}</span>
                            </div>
                          </div>
                          <div className="detail-item">
                            <div className="detail-icon">
                              <i className="bi bi-clock"></i>
                            </div>
                            <div className="detail-content">
                              <label>Duration</label>
                              <span className="duration-badge">
                                {modalRow.Duration || (modalRow.DurationMinutes ? Math.round(modalRow.DurationMinutes) + " min" : "—")}
                              </span>
                            </div>
                            <div style={{ marginTop: 8, textAlign: 'right' }}>
                              <div className="muted">Violation days (90d)</div>
                              <div style={{ fontWeight: 700 }}>
                                {(modalRow.ViolationDaysLast90 !== undefined && modalRow.ViolationDaysLast90 !== null)
                                  ? modalRow.ViolationDaysLast90
                                  : 0}
                              </div>
                            </div>
                          </div>
                        </div>
                      </div>

                      <div className="modal-reasons">
                        <div className="explanation-section" style={{ marginTop: 12 }}>
                          <div style={{ fontWeight: 700 }}>Explanation</div>
                          <div style={{
                            marginTop: 8,
                            maxHeight: 160,
                            overflow: 'auto',
                            background: '#fff',
                            border: '1px solid #eef2f7',
                            padding: 8,
                            borderRadius: 6
                          }}>
                            {modalRow.Explanation
                              ? <div style={{ whiteSpace: 'pre-wrap' }}>{modalRow.Explanation}</div>
                              : <div className="muted">No explanation provided.</div>}
                          </div>
                        </div>
                        <div className="reasons-section">
                          <div className="section-title">
                            <i className="bi bi-list-check"></i>
                            Reasons Flagged
                          </div>
                          <div className="reasons-list">
                            {renderReasonChips(modalRow.Reasons)}
                          </div>
                        </div>
                      </div>
                    </div>

                    <div className="evidence-section">
                      <div className="section-header">
                        <i className="bi bi-folder2-open"></i>
                        <h4>Available Evidence Files</h4>
                      </div>
                      <div className="files-container">
                        {modalDetails && modalDetails.raw_swipe_files && modalDetails.raw_swipe_files.length > 0 ? (
                          <div className="files-list">
                            {modalDetails.raw_swipe_files.map((f, i) => (
                              <div key={i} className="file-item">
                                <i className="bi bi-file-earmark-text"></i>
                                <span className="file-name">{f}</span>
                                <button
                                  className="download-btn"
                                  onClick={function () { window.location = API_BASE + "/swipes/" + encodeURIComponent(f); }}
                                >
                                  <i className="bi bi-download"></i>
                                  Download
                                </button>
                              </div>
                            ))}
                          </div>
                        ) : (
                          <div className="no-files">
                            <i className="bi bi-folder-x"></i>
                            <span>No raw swipe files found for this person/date.</span>
                          </div>
                        )}
                      </div>
                    </div>

                    <div className="timeline-section">
                      <div className="section-header">
                        <i className="bi bi-clock-history"></i>
                        <h4>Swipe Timeline</h4>
                        <span className="subtitle">Filtered for this person/date</span>
                      </div>
                      <div className="timeline-content">
                        {modalDetails ? renderSwipeTimeline(modalDetails, modalRow) : (
                          <div className="loading-timeline">
                            <i className="bi bi-hourglass-split"></i>
                            <span>Evidence not loaded yet.</span>
                          </div>
                        )}
                      </div>
                    </div>

                    <div className="raw-json-section">
                      <label className="toggle-label">
                        <input
                          type="checkbox"
                          id="showraw"
                          onChange={function (e) {
                            const el = document.getElementById('rawpayload');
                            if (el) el.style.display = e.target.checked ? 'block' : 'none';
                          }}
                        />
                        <span className="toggle-slider"></span>
                        <span className="toggle-text">
                          <i className="bi bi-code-slash"></i>
                          Show raw aggregated JSON
                        </span>
                      </label>
                      <div id="rawpayload" className="raw-json">
                        <pre>{JSON.stringify(modalRow, null, 2)}</pre>
                      </div>
                    </div>
                  </div>
                </div>
              </div>
            }

            {/* ===== CHAT FAB & CHAT MODAL: now INSIDE the component RETURN (no more stray JSX outside) ===== */}
            <button className="chat-fab" title="Ask Trend Details (Ask Me )" onClick={() => setChatOpen(true)} aria-label="Open chat">
               
              <span className="meta-icon"><img src="chat-bot.png" alt=""/></span>
            </button>

            {chatOpen && (
              <div className="chat-modal" role="dialog" aria-modal="true" aria-label="Trend Chatbot">
                <div className="chat-header">
                  <div style={{display:'flex', alignItems:'center', gap:8}}>
                    <div style={{width:36,height:36, borderRadius:8, background:'#', display:'flex', alignItems:'center', justifyContent:'center', color:'#2563eb', fontWeight:800}}><img src="chat-bot.png" alt=""  style={{width:36,height:36, }}/></div>
                    <div>
                      <div className="title">Ask me — Trend Details</div>
                      <div style={{fontSize:12, opacity:0.85}}>Ask trend & risk questions</div>
                    </div>
                  </div>
                  <div style={{marginLeft:'auto'}}>
                    <button className="small-button bot-close" onClick={() => { setChatOpen(false); }}>Close</button>
                  </div>
                </div>

                <div className="chat-body">
                  {chatMessages.length === 0 && (
                    <div style={{color:'#64748b', fontSize:13}}>
                      Hi — ask about trends (e.g. "Who is high risk today"). Use the quick prompts below.
                    </div>
                  )}
                  {chatMessages.map((m, i) => (
                    <div key={i} style={{display:'block'}}>
                      <div className={"chat-bubble " + (m.who === 'user' ? 'user' : 'bot')}>
                        {m.text}
                        {m.who === 'bot' && m.evidence && m.evidence.length > 0 && (
                          <div className="chat-evidence">
                            <strong>Evidence</strong>
                            <div style={{marginTop:6}}>{m.evidence.slice(0,5).map((e,j)=>(<div key={j}>{typeof e === 'string' ? e : JSON.stringify(e)}</div>))}</div>
                          </div>
                        )}
                      </div>
                    </div>
                  ))}

                  {chatLoading && <div className="chat-loading" style={{marginTop:6}}>Thinking…</div>}
                  <div style={{marginTop:8}} className="quick-prompts" aria-hidden={chatLoading}>
                    {QUICK_PROMPTS.map((q,idx)=>(
                      <button key={idx} onClick={()=>useQuickPrompt(q)} disabled={chatLoading}>{q}</button>
                    ))}
                  </div>
                </div>

                <div className="chat-input-row">
                  <input
                    className="chat-input"
                    placeholder="Type a question, e.g. 'Who is high risk today'…"
                    value={chatInput}
                    onChange={(e)=>setChatInput(e.target.value)}
                    onKeyDown={(e)=>{ if (e.key === 'Enter' && !e.shiftKey) { e.preventDefault(); sendChat(chatInput); } }}
                  />
                  <button className="chat-send-btn" onClick={()=>sendChat(chatInput)} disabled={chatLoading}>Send</button>
                </div>
              </div>
            )}

          </div>
        );
      }

      const root = ReactDOM.createRoot(document.getElementById('root'));
      root.render(React.createElement(App));
    })();
  </script>
</body>
</html>




