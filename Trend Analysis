(.venv) PS C:\Users\W0024618\Desktop\Trend Analysis\backend> python scripts/generate_90_days.py
>>
Traceback (most recent call last):
  File "C:\Users\W0024618\Desktop\Trend Analysis\backend\scripts\generate_90_days.py", line 3, in <module>
    from trend_runner import run_trend_for_date
ModuleNotFoundError: No module named 'trend_runner'
(.venv) PS C:\Users\W0024618\Desktop\Trend Analysis\backend> python ml_training.py --input outputs/training_person_90day_20251105.csv --models_dir models --features "CountSwipes_median,CountSwipes_mean,CountSwipes_sum,DurationMinutes_median,DurationMinutes_mean,DurationMinutes_sum,MaxSwipeGapSeconds_max,MaxSwipeGapSeconds_median,ShortGapCount_sum,UniqueDoors_median,UniqueLocations_median,RejectionCount_sum,days_present"
>>
>>
Traceback (most recent call last):
  File "C:\Users\W0024618\Desktop\Trend Analysis\backend\ml_training.py", line 100, in <module>
    main(input_csv, models_dir, feature_cols)
    ~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\W0024618\Desktop\Trend Analysis\backend\ml_training.py", line 72, in main
    raise FileNotFoundError(f"input CSV not found: {input_csv}")
FileNotFoundError: input CSV not found: outputs\training_person_90day_20251105.csv
(.venv) PS C:\Users\W0024618\Desktop\Trend Analysis\backend> pip install scikit-learn joblib
>>
Requirement already satisfied: scikit-learn in c:\users\w0024618\desktop\trend analysis\backend\.venv\lib\site-packages (1.7.2)
Requirement already satisfied: joblib in c:\users\w0024618\desktop\trend analysis\backend\.venv\lib\site-packages (1.5.2)
Requirement already satisfied: numpy>=1.22.0 in c:\users\w0024618\desktop\trend analysis\backend\.venv\lib\site-packages (from scikit-learn) (2.3.4)
Requirement already satisfied: scipy>=1.8.0 in c:\users\w0024618\desktop\trend analysis\backend\.venv\lib\site-packages (from scikit-learn) (1.16.2)
Requirement already satisfied: threadpoolctl>=3.1.0 in c:\users\w0024618\desktop\trend analysis\backend\.venv\lib\site-packages (from scikit-learn) (3.6.0)
(.venv) PS C:\Users\W0024618\Desktop\Trend Analysis\backend> python ml_training.py --input outputs/training_person_90day_20251105.csv --models_dir models --features "CountSwipes_median,CountSwipes_mean,CountSwipes_sum,DurationMinutes_median,DurationMinutes_mean,DurationMinutes_sum,MaxSwipeGapSeconds_max,MaxSwipeGapSeconds_median,ShortGapCount_sum,UniqueDoors_median,UniqueLocations_median,RejectionCount_sum,days_present"
>>
Traceback (most recent call last):
  File "C:\Users\W0024618\Desktop\Trend Analysis\backend\ml_training.py", line 100, in <module>
    main(input_csv, models_dir, feature_cols)
    ~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\W0024618\Desktop\Trend Analysis\backend\ml_training.py", line 72, in main
    raise FileNotFoundError(f"input CSV not found: {input_csv}")
FileNotFoundError: input CSV not found: outputs\training_person_90day_20251105.csv
(.venv) PS C:\Users\W0024618\Desktop\Trend Analysis\backend> 





# scripts/build_90day_training.py
from datetime import date
from pathlib import Path
import sys
import argparse

# defensive sys.path tweak so imports work even if script is invoked from anywhere
HERE = Path(__file__).resolve()
PROJECT_ROOT = HERE.parent.parent  # backend/
if str(PROJECT_ROOT) not in sys.path:
    sys.path.insert(0, str(PROJECT_ROOT))

from trend_runner import build_90day_training

def main(end_date_str=None, outdir="./outputs", window_days=90, min_unique_employees=1000, city="Pune"):
    if end_date_str:
        end_date = date.fromisoformat(end_date_str)
    else:
        end_date = date.today()
    out_path = build_90day_training(end_date=end_date, window_days=window_days, outdir=outdir,
                                   min_unique_employees=min_unique_employees, city=city)
    if out_path:
        print("Training CSV created:", out_path)
    else:
        print("Training CSV not created. Check logs and ensure trend CSVs exist in", outdir)

if __name__ == "__main__":
    p = argparse.ArgumentParser()
    p.add_argument("--end", help="end date (YYYY-MM-DD). default = today", default=None)
    p.add_argument("--outdir", help="outputs dir", default="./outputs")
    p.add_argument("--min_unique_employees", type=int, default=1000)
    p.add_argument("--window", type=int, default=90)
    p.add_argument("--city", default="Pune")
    args = p.parse_args()
    main(end_date_str=args.end, outdir=args.outdir, window_days=args.window,
         min_unique_employees=args.min_unique_employees, city=args.city)












# scripts/generate_90_days.py
from datetime import date, timedelta
from pathlib import Path
import sys

# Ensure backend project root is on sys.path so "import trend_runner" works
HERE = Path(__file__).resolve()
PROJECT_ROOT = HERE.parent.parent  # backend/
if str(PROJECT_ROOT) not in sys.path:
    sys.path.insert(0, str(PROJECT_ROOT))

from trend_runner import run_trend_for_date

OUTDIR = "./outputs"
CITY = "Pune"

end = date.today()
start = end - timedelta(days=89)  # inclusive 90 days

d = start
while d <= end:
    try:
        print("Processing", d.isoformat())
        run_trend_for_date(d, outdir=OUTDIR, city=CITY)
    except Exception as e:
        print("Failed for", d.isoformat(), e)
    d = d + timedelta(days=1)











# C:\Users\W0024618\Desktop\Trend Analysis\backend\ml_training.py
"""
Train one binary classifier per scenario using the training CSV produced by trend_runner.build_monthly_training.
Usage:
    python ml_training.py --input outputs/training_person_month.csv --models_dir models/
Outputs:
    models/<scenario>.joblib
Requirements:
    scikit-learn, joblib, pandas, numpy
"""
import argparse
from pathlib import Path
import pandas as pd
import numpy as np
import logging

logging.basicConfig(level=logging.INFO)

try:
    from sklearn.ensemble import RandomForestClassifier
    from sklearn.model_selection import train_test_split
    from sklearn.metrics import classification_report
    import joblib
except Exception as e:
    logging.error("Required ML packages missing: %s", e)
    logging.error("Install scikit-learn and joblib: pip install scikit-learn joblib")
    raise

DEFAULT_FEATURE_COLS = [
    'CountSwipes_median', 'CountSwipes_mean', 'CountSwipes_sum',
    'DurationMinutes_median', 'DurationMinutes_mean', 'DurationMinutes_sum',
    'MaxSwipeGapSeconds_max', 'MaxSwipeGapSeconds_median',
    'ShortGapCount_sum', 'UniqueDoors_median', 'UniqueLocations_median', 'RejectionCount_sum',
    'days_present'
]

def auto_detect_scenarios(df):
    scenario_labels = [c for c in df.columns if c.endswith('_label')]
    scenarios = [c[:-6] for c in scenario_labels]
    return scenarios

def prepare_features(df, features=None):
    if features is None:
        features = DEFAULT_FEATURE_COLS
    # ensure columns exist, fill missing with 0/median
    X = df.copy()
    for f in features:
        if f not in X.columns:
            X[f] = 0.0
    X = X[features].fillna(0.0)
    return X

def train_one(df, scenario, features):
    label_col = f"{scenario}_label"
    if label_col not in df.columns:
        logging.warning("Label %s not in dataframe, skipping", label_col)
        return None
    y = df[label_col].astype(int)
    if y.sum() == 0:
        logging.warning("No positive examples for %s; skipping model training", scenario)
        return None
    X = prepare_features(df, features)
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)
    clf = RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1)
    clf.fit(X_train, y_train)
    y_pred = clf.predict(X_test)
    logging.info("Classification report for %s:\n%s", scenario, classification_report(y_test, y_pred, zero_division=0))
    return clf

def main(input_csv: Path, models_dir: Path, feature_cols=None):
    if not input_csv.exists():
        raise FileNotFoundError(f"input CSV not found: {input_csv}")
    df = pd.read_csv(input_csv)
    scenarios = auto_detect_scenarios(df)
    if not scenarios:
        logging.error("No scenarios ( *_label ) columns found in %s", input_csv)
        return
    models_dir.mkdir(parents=True, exist_ok=True)
    for s in scenarios:
        logging.info("Training for scenario: %s", s)
        clf = train_one(df, s, feature_cols)
        if clf is not None:
            outp = models_dir / f"{s}.joblib"
            joblib.dump({"model": clf, "features": (feature_cols or DEFAULT_FEATURE_COLS)}, outp)
            logging.info("Saved model to %s", outp)
        else:
            logging.info("Skipped training for %s", s)

if __name__ == "__main__":
    parser = argparse.ArgumentParser()
    parser.add_argument("--input", required=True, help="training CSV (person-month) created by /train endpoint")
    parser.add_argument("--models_dir", default="models", help="folder to save models")
    parser.add_argument("--features", default=None, help="comma separated feature columns (optional)")
    args = parser.parse_args()

    input_csv = Path(args.input)
    models_dir = Path(args.models_dir)
    feature_cols = args.features.split(",") if args.features else None

    main(input_csv, models_dir, feature_cols)













