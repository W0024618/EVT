I have Upadte 3 File Duration . app.py and index.Html we got error from app.py and Add above snippet in index.html file and share me fully updated files carefully dont make 
unnecessary changes carefully...


INFO:werkzeug: * Restarting with stat
  File "C:\Users\W0024618\Desktop\Trend Analysis\backend\app.py", line 1429
    if tcol and tcol in filtered.columns:
IndentationError: unexpected indent
(.venv) PS C:\Users\W0024618\Desktop\Trend Analysis\backend> 


#C:\Users\W0024618\Desktop\Trend Analysis\backend\app.py

from flask import Flask, jsonify, request, send_from_directory
from datetime import datetime, timedelta, date
from pathlib import Path
import logging
import pandas as pd
import numpy as np
import joblib
import math
import re
import io

from trend_runner import run_trend_for_date, build_monthly_training, OUTDIR
from config.door_zone import map_door_to_zone, BREAK_ZONES, OUT_OF_OFFICE_ZONE

MODELS_DIR = Path(__file__).parent / "models"
_loaded_models = {}

def load_model(name):
    if name in _loaded_models:
        return _loaded_models[name]
    p = MODELS_DIR / f"{name}.joblib"
    if not p.exists():
        return None
    data = joblib.load(p)
    _loaded_models[name] = data
    return data

# Try to enable CORS
try:
    from flask_cors import CORS
    has_cors = True
except Exception:
    CORS = None
    has_cors = False

app = Flask(__name__, static_folder=None)
if has_cors:
    CORS(app)
else:
    logging.warning("flask_cors not available; continuing without CORS.")

logging.basicConfig(level=logging.INFO)

BASE_DIR = Path(__file__).parent.resolve()
DEFAULT_OUTDIR = BASE_DIR / "outputs"
DEFAULT_OUTDIR.mkdir(parents=True, exist_ok=True)


from flask import send_file
try:
    # optional import; used for styling
    from openpyxl import load_workbook
    from openpyxl.styles import Font, Alignment, Border, Side
    OPENPYXL_AVAILABLE = True
except Exception:
    OPENPYXL_AVAILABLE = False



def _to_python_scalar(x):
    """
    Convert numpy/pandas scalar types to built-in Python types and
    convert NaN-like values to None so JSON is safe.
    """
    try:
        import pandas as _pd
        if isinstance(x, _pd.Timestamp):
            return x.to_pydatetime().isoformat()
    except Exception:
        pass

    try:
        import numpy as _np
        if isinstance(x, _np.generic):
            v = x.item()
            if isinstance(v, float) and _np.isnan(v):
                return None
            return v
    except Exception:
        pass

    try:
        if isinstance(x, float) and math.isnan(x):
            return None
    except Exception:
        pass

    if isinstance(x, (datetime,)):
        return x.isoformat()
    if isinstance(x, (bool, int, str, type(None), float)):
        # convert floats NaN handled above
        return x
    try:
        # fallback to string
        return str(x)
    except Exception:
        return None


_uuid_like_re = re.compile(r'^[0-9a-fA-F]{8}\-[0-9a-fA-F]{4}\-[0-9a-fA-F]{4}\-[0-9a-fA-F]{4}\-[0-9a-fA-F]{12}$')

def _looks_like_guid(s):
    try:
        if not s or not isinstance(s, str):
            return False
        s = s.strip()
        return bool(_uuid_like_re.match(s)) or s.startswith('name:') or s.startswith('emp:') or s.startswith('uid:')
    except Exception:
        return False


# Helper: format seconds to HH:MM:SS
def format_seconds_to_hms(seconds):
    try:
        if seconds is None:
            return None
        # guard against floats and NaN
        s = int(float(seconds))
        if s < 0:
            s = 0
        hh = s // 3600
        mm = (s % 3600) // 60
        ss = s % 60
        return f"{hh:02d}:{mm:02d}:{ss:02d}"
    except Exception:
        return None


# Placeholder tokens (keep consistent with trend_runner expectations)
_PLACEHOLDER_STRS = set(['', 'nan', 'na', 'n/a', '-', '—', '–', 'none', 'null'])

def _is_placeholder_str(s: object) -> bool:
    try:
        if s is None:
            return True
        st = str(s).strip().lower()
        return st in _PLACEHOLDER_STRS
    except Exception:
        return False


_CARD_XML_RE = re.compile(r'<Card>([^<]+)</Card>', re.IGNORECASE | re.DOTALL)
def _extract_card_from_xml_text(txt):
    try:
        if not txt or not isinstance(txt, str):
            return None
        m = _CARD_XML_RE.search(txt)
        if m:
            return m.group(1).strip()
        m2 = re.search(r'CHUID.*?Card.*?[:=]\s*([0-9A-Za-z\-\_]+)', txt, re.IGNORECASE | re.DOTALL)
        if m2:
            return m2.group(1).strip()
    except Exception:
        pass
    return None


def _resolve_field_from_record(record: dict, candidate_tokens: list):
    """
    Search a single row `record` (dict) for likely columns listed in candidate_tokens.
    Return first non-placeholder value found (converted to Python scalar), else None.
    """
    if record is None:
        return None

    # 1) exact key matches (case-sensitive & common casing)
    for key in candidate_tokens:
        if key in record:
            v = record.get(key)
            if v is None:
                continue
            if isinstance(v, float) and math.isnan(v):
                continue
            sval = str(v).strip()
            if sval and not _is_placeholder_str(sval):
                return _to_python_scalar(v)

    # 2) case-insensitive contains match
    lower_keys = {k.lower(): k for k in record.keys()}
    for tok in candidate_tokens:
        tok_l = tok.lower()
        for lk, orig_key in lower_keys.items():
            if tok_l in lk:
                v = record.get(orig_key)
                if v is None:
                    continue
                if isinstance(v, float) and math.isnan(v):
                    continue
                sval = str(v).strip()
                if sval and not _is_placeholder_str(sval):
                    return _to_python_scalar(v)

    # 3) xml / value parsing fallback for CardNumber
    card_like = any(tok.lower() in ('cardnumber', 'chuid', 'card') for tok in candidate_tokens)
    if card_like:
        for lk, orig_key in lower_keys.items():
            if 'xml' in lk or 'xmlmessage' in lk or 'xml_msg' in lk or 'msg' in lk or 'value' == lk:
                v = record.get(orig_key)
                if v is None:
                    continue
                try:
                    txt = str(v)
                    extracted = _extract_card_from_xml_text(txt)
                    if extracted and not _is_placeholder_str(extracted):
                        return _to_python_scalar(extracted)
                except Exception:
                    continue

    # 4) final fallback: first non-placeholder value
    for k, v in record.items():
        if v is None:
            continue
        if isinstance(v, float) and math.isnan(v):
            continue
        sval = str(v).strip()
        if sval and not _is_placeholder_str(sval):
            return _to_python_scalar(v)

    return None


def _clean_sample_df(df: pd.DataFrame, max_rows: int = 10):
    """
    Clean a dataframe for JSON output (convert NaN -> None, pandas types -> native, format datetimes).
    """
    if df is None or df.empty:
        return []
    df = df.copy()

    # remove duplicate suffix columns
    cols_to_fix = [c for c in df.columns if c.endswith('_x') or c.endswith('_y')]
    for c in cols_to_fix:
        base = c[:-2]
        if base in df.columns:
            try:
                df.drop(columns=[c], inplace=True)
            except Exception:
                pass
        else:
            try:
                df.rename(columns={c: base}, inplace=True)
            except Exception:
                pass

    # Date normalization
    if 'Date' in df.columns:
        try:
            df['Date'] = pd.to_datetime(df['Date'], errors='coerce').dt.date
            df['Date'] = df['Date'].apply(lambda d: d.isoformat() if pd.notna(d) else None)
        except Exception:
            pass

    # Datetime columns to ISO strings
    for dtcol in ('FirstSwipe', 'LastSwipe', 'LocaleMessageTime'):
        if dtcol in df.columns:
            try:
                df[dtcol] = pd.to_datetime(df[dtcol], errors='coerce')
                df[dtcol] = df[dtcol].apply(lambda t: t.to_pydatetime().isoformat() if pd.notna(t) else None)
            except Exception:
                try:
                    df[dtcol] = df[dtcol].astype(str).replace('NaT', None)
                except Exception:
                    pass

    # Replace NaN/inf -> None
    df = df.where(pd.notnull(df), None)

    # Convert records to safe Python types
    rows = df.head(max_rows).to_dict(orient='records')
    cleaned = []
    for r in rows:
        out = {}
        for k, v in r.items():
            out[k] = _to_python_scalar(v)

        # Typical fields
        emp_name = out.get('EmployeeName')
        emp_id = out.get('EmployeeID') or out.get('EmployeeIdentity')
        person_uid = out.get('person_uid')

        # ----- Schema-aware fallback resolution -----
        if not emp_id:
            emp_tokens = ['Int1', 'Text12', 'EmployeeID', 'empid', 'id']
            resolved_emp = _resolve_field_from_record(r, emp_tokens)
            if resolved_emp is not None:
                try:
                    s = str(resolved_emp).strip()
                    # remove trailing .0 for floats
                    if '.' in s:
                        f = float(s)
                        if math.isfinite(f) and f.is_integer():
                            s = str(int(f))
                    if _looks_like_guid(s):
                        out['EmployeeID'] = None
                        emp_id = None
                    else:
                        out['EmployeeID'] = s
                        emp_id = s
                except Exception:
                    if _looks_like_guid(resolved_emp):
                        out['EmployeeID'] = None
                        emp_id = None
                    else:
                        out['EmployeeID'] = resolved_emp
                        emp_id = resolved_emp

        # Prefer Credential.CardNumber / CHUID / Card as CardNumber when missing — reject GUIDs/placeholders
        if out.get('CardNumber') in (None, '', 'nan'):
            card_tokens = ['CardNumber', 'CHUID', 'Card', 'card_no', 'cardnum']
            resolved_card = _resolve_field_from_record(r, card_tokens)
            if resolved_card is not None:
                try:
                    cs = str(resolved_card).strip()
                    if _looks_like_guid(cs) or _is_placeholder_str(cs):
                        out['CardNumber'] = None
                    else:
                        out['CardNumber'] = cs
                except Exception:
                    out['CardNumber'] = None

        # final safety: ensure EmployeeID/CardNumber are not GUID-like tokens
        if 'EmployeeID' in out and isinstance(out['EmployeeID'], str) and _looks_like_guid(out['EmployeeID']):
            out['EmployeeID'] = None
        if 'CardNumber' in out and isinstance(out['CardNumber'], str) and _looks_like_guid(out['CardNumber']):
            out['CardNumber'] = None

        # If EmployeeName empty or looks like a GUID, prefer EmployeeID (human id) over GUIDs
        if (emp_name in (None, '', 'nan')) or (isinstance(emp_name, str) and _looks_like_guid(emp_name)):
            if emp_id not in (None, '', 'nan') and not _looks_like_guid(emp_id):
                out['EmployeeName'] = str(emp_id)
            else:
                out['EmployeeName'] = None

        cleaned.append(out)
    return cleaned


@app.route('/')
def root():
    return "Trend Analysis API — Pune test"


@app.route('/run', methods=['GET', 'POST'])
def run_trend():
    params = {}
    if request.method == 'GET':
        params = request.args.to_dict()
    else:
        if request.is_json:
            params = request.json or {}

    date_str = params.get('date')
    start_str = params.get('start')
    end_str = params.get('end')

    dates = []
    try:
        if date_str:
            dt = datetime.strptime(date_str, "%Y-%m-%d").date()
            dates = [dt]
        elif start_str and end_str:
            s = datetime.strptime(start_str, "%Y-%m-%d").date()
            e = datetime.strptime(end_str, "%Y-%m-%d").date()
            if e < s:
                return jsonify({"error":"end must be >= start"}), 400
            cur = s
            while cur <= e:
                dates.append(cur)
                cur = cur + timedelta(days=1)
        else:
            # default: include yesterday and today so previous-day evidence gets generated by default
            today = datetime.now().date()
            yesterday = today - timedelta(days=1)
            dates = [yesterday, today]
    except Exception as e:
        return jsonify({"error": f"Invalid date format: {e}"}), 400

    combined_rows = []
    files = []
    samples = []

    for d in dates:
        try:
            df = run_trend_for_date(d, outdir=str(DEFAULT_OUTDIR))
        except Exception as e:
            logging.exception("run_trend_for_date failed for %s", d)
            return jsonify({"error": f"runner failed for {d}: {e}"}), 500

        csv_path = DEFAULT_OUTDIR / f"trend_pune_{d.strftime('%Y%m%d')}.csv"
        if csv_path.exists():
            files.append(csv_path.name)

        if df is None or df.empty:
            continue

        # Ensure IsFlagged exists; Reasons only when flagged
        if 'IsFlagged' not in df.columns:
            df['IsFlagged'] = False
        if 'Reasons' not in df.columns:
            df['Reasons'] = None

        # Prefer sample of flagged rows (makes QA easier); else generic sample
        flagged = df[df['IsFlagged'] == True]
        sample_df = flagged.head(10) if not flagged.empty else df.head(10)
        samples.extend(_clean_sample_df(sample_df, max_rows=10))

        combined_rows.append(df)

    combined_df = pd.concat(combined_rows, ignore_index=True) if combined_rows else pd.DataFrame()

    # Determine best identifier column to count unique persons (priority)
    id_candidates = ['person_uid', 'EmployeeID', 'EmployeeIdentity', 'Int1']
    id_col = next((c for c in id_candidates if c in combined_df.columns), None)

    def _norm_id_val(v):
        try:
            if pd.isna(v):
                return None
        except Exception:
            pass
        if v is None:
            return None
        s = str(v).strip()
        if s == '' or s.lower() == 'nan':
            return None
        # convert floats like "320172.0" -> "320172"
        try:
            if '.' in s:
                f = float(s)
                if math.isfinite(f) and f.is_integer():
                    s = str(int(f))
        except Exception:
            pass
        return s

    if id_col is None or combined_df.empty:
        analysis_count = int(len(combined_df))
        flagged_count = int(combined_df['IsFlagged'].sum()) if 'IsFlagged' in combined_df.columns else 0
    else:
        # if Int1 exists in combined_df, prefer it when normalizing ids
        ids_series = combined_df[id_col].apply(_norm_id_val)
        unique_ids = set([x for x in ids_series.unique() if x])
        analysis_count = int(len(unique_ids))

        # flagged unique persons (using IsFlagged)
        if 'IsFlagged' in combined_df.columns:
            flagged_series = combined_df.loc[combined_df['IsFlagged'] == True, id_col].apply(_norm_id_val)
            flagged_unique = set([x for x in flagged_series.unique() if x])
            flagged_count = int(len(flagged_unique))
        else:
            flagged_count = 0

    resp = {
        "start_date": dates[0].isoformat() if dates else None,
        "end_date": dates[-1].isoformat() if dates else None,
        "files": files,
        # legacy totals
        "aggregated_rows_total": int(len(combined_df)),
        # new semantics (distinct persons)
        "rows": int(analysis_count),
        "flagged_rows": int(flagged_count),
        "sample": samples[:20]
    }
    return jsonify(resp)


@app.route('/latest', methods=['GET'])
def latest_results():
    p = Path(DEFAULT_OUTDIR)
    csvs = sorted(p.glob("trend_pune_*.csv"), reverse=True)
    if not csvs:
        return jsonify({"error": "no outputs found"}), 404
    latest = csvs[0]
    try:
        df = pd.read_csv(latest)
    except Exception:
        df = pd.read_csv(latest, dtype=str)
    sample = _clean_sample_df(df, max_rows=5)
    return jsonify({
        "file": latest.name,
        "rows": int(len(df)),
        "sample": sample
    })


# @app.route('/record', methods=['GET'])
# def get_record():
#     """
#     /record?employee_id=... or /record?person_uid=...
#     Returns matching aggregated trend rows and filtered raw swipe rows (only for flagged persons).
#     Updated: read ALL trend CSVs (not just the latest), so previous days are included.
#     Also add Zone and SwipeGap (seconds) to raw_swipes returned as evidence.
#     """
#     q = request.args.get('employee_id') or request.args.get('person_uid')
#     p = Path(DEFAULT_OUTDIR)
#     csvs = sorted(p.glob("trend_pune_*.csv"), reverse=True)
#     if not csvs:
#         return jsonify({'aggregated_rows': [], 'raw_swipe_files': [], 'raw_swipes': []}), 200

#     # Read all CSVs (concat) so /record will search previous days too
#     df_list = []
#     for fp in csvs:
#         try:
#             tmp = pd.read_csv(fp, parse_dates=['FirstSwipe','LastSwipe'], infer_datetime_format=True)
#         except Exception:
#             try:
#                 tmp = pd.read_csv(fp, dtype=str)
#             except Exception:
#                 continue
#         df_list.append(tmp)
#     if not df_list:
#         return jsonify({'aggregated_rows': [], 'raw_swipe_files': [], 'raw_swipes': []}), 200
#     df = pd.concat(df_list, ignore_index=True)

#     if q is None:
#         cleaned = _clean_sample_df(df, max_rows=10)
#         return jsonify({'aggregated_rows': cleaned, 'raw_swipe_files': [], 'raw_swipes': []}), 200

#     q_str = str(q).strip()

#     def normalize_series(s):
#         if s is None:
#             return pd.Series([None]*len(df))
#         s = s.fillna('').astype(str).str.strip()
#         def _norm_val(v):
#             if not v:
#                 return ''
#             try:
#                 if '.' in v:
#                     fv = float(v)
#                     if math.isfinite(fv) and fv.is_integer():
#                         return str(int(fv))
#             except Exception:
#                 pass
#             return v
#         return s.map(_norm_val)

#     found_mask = pd.Series(False, index=df.index)

#     if 'EmployeeID' in df.columns:
#         emp_series = normalize_series(df['EmployeeID'])
#         found_mask = found_mask | (emp_series == q_str)

#     if 'person_uid' in df.columns:
#         uid_series = normalize_series(df['person_uid'])
#         found_mask = found_mask | (uid_series == q_str)

#     # also check Int1 (Personnel.Int1) if present in CSV
#     if 'Int1' in df.columns and not found_mask.any():
#         int1_series = normalize_series(df['Int1'])
#         found_mask = found_mask | (int1_series == q_str)

#     if not found_mask.any():
#         # try numeric equivalence
#         try:
#             q_numeric = float(q_str)
#             if 'EmployeeID' in df.columns:
#                 emp_numeric = pd.to_numeric(df['EmployeeID'], errors='coerce')
#                 found_mask = found_mask | (emp_numeric == q_numeric)
#             if 'Int1' in df.columns and not found_mask.any():
#                 int_numeric = pd.to_numeric(df['Int1'], errors='coerce')
#                 found_mask = found_mask | (int_numeric == q_numeric)
#         except Exception:
#             pass

#     matched = df[found_mask]
#     if matched.empty:
#         return jsonify({'aggregated_rows': [], 'raw_swipe_files': [], 'raw_swipes': []}), 200

#     cleaned_matched = _clean_sample_df(matched, max_rows=len(matched))

#     # Resolve raw swipe file names by Date (collect all dates present in matched rows)
#     raw_files = set()
#     date_vals = set()
#     if 'Date' in matched.columns:
#         try:
#             dates_parsed = pd.to_datetime(matched['Date'], errors='coerce').dropna().dt.date.unique()
#             for d in dates_parsed:
#                 date_vals.add(str(d.isoformat()))
#         except Exception:
#             pass

#     if not date_vals:
#         for col in ('FirstSwipe', 'LastSwipe'):
#             if col in matched.columns:
#                 try:
#                     vals = pd.to_datetime(matched[col], errors='coerce').dropna().dt.date.unique()
#                     for d in vals:
#                         date_vals.add(str(d.isoformat()))
#                 except Exception:
#                     pass

#     # build filtered raw swipe rows ONLY for flagged persons
#     raw_swipes_out = []
#     # pick first matched row to decide identifiers to filter raw swipes
#     for idx, agg_row in matched.iterrows():
#         # gather the identifying values
#         person_uid = agg_row.get('person_uid') if 'person_uid' in agg_row else None
#         empid = agg_row.get('EmployeeID') if 'EmployeeID' in agg_row else None
#         # also check Int1 in aggregated row if present
#         if (not empid) and 'Int1' in agg_row:
#             empid = agg_row.get('Int1')
#         card = agg_row.get('CardNumber') if 'CardNumber' in agg_row else None

#         # determine date string(s) to look for raw files using Date / FirstSwipe / LastSwipe
#         dates_for_row = set()
#         if 'Date' in agg_row and pd.notna(agg_row['Date']):
#             try:
#                 d = pd.to_datetime(agg_row['Date']).date()
#                 dates_for_row.add(d.isoformat())
#             except Exception:
#                 pass
#         for col in ('FirstSwipe','LastSwipe'):
#             if col in agg_row and pd.notna(agg_row[col]):
#                 try:
#                     d = pd.to_datetime(agg_row[col]).date()
#                     dates_for_row.add(d.isoformat())
#                 except Exception:
#                     pass

#         # only fetch raw swipe evidence when this aggregated row is flagged
#         is_flagged = bool(agg_row.get('IsFlagged', False))
#         if not is_flagged:
#             continue

#         for d in dates_for_row:
#             try:
#                 dd = d[:10]  # 'YYYY-MM-DD'
#                 target = dd.replace('-', '')
#                 # find any swipes_*_{YYYYMMDD}.csv file(s) in outputs
#                 candidates = list(Path(DEFAULT_OUTDIR).glob(f"swipes_*_{target}.csv"))
#                 if not candidates:
#                     # nothing found for that date
#                     continue

#                 # Process each matching candidate file individually
#                 for fp in candidates:
#                     raw_name = fp.name
#                     raw_files.add(raw_name)
#                     # read the raw swipe CSV (try to parse datetimes if possible)
#                     try:
#                         raw_df = pd.read_csv(fp, parse_dates=['LocaleMessageTime'], infer_datetime_format=True)
#                     except Exception:
#                         try:
#                             raw_df = pd.read_csv(fp, dtype=str)
#                         except Exception:
#                             continue

#                     # normalize columns names to lowercase for searching
#                     cols_lower = {c.lower(): c for c in raw_df.columns}

#                     # candidate column names (schema-aware)
#                     tcol = cols_lower.get('localemessagetime') or cols_lower.get('messagetime') or cols_lower.get('timestamp') or cols_lower.get('time') or None
#                     emp_col = cols_lower.get('int1') or cols_lower.get('employeeid') or cols_lower.get('employeeidentity') or cols_lower.get('employee_id') or None
#                     name_col = cols_lower.get('employeename') or cols_lower.get('objectname1') or cols_lower.get('employee_name') or None
#                     card_col = cols_lower.get('cardnumber') or cols_lower.get('card') or cols_lower.get('chuid') or cols_lower.get('value') or None
#                     door_col = cols_lower.get('door') or cols_lower.get('doorname') or cols_lower.get('door_name') or None
#                     dir_col = cols_lower.get('direction') or cols_lower.get('directionname') or cols_lower.get('direction_name') or None
#                     note_col = cols_lower.get('rejection_type') or cols_lower.get('note') or cols_lower.get('source') or None

#                     # build filter mask: match person_uid OR empid OR card (whichever present)
#                     mask = pd.Series(False, index=raw_df.index)
#                     if person_uid is not None and 'person_uid' in raw_df.columns:
#                         mask = mask | (raw_df['person_uid'].astype(str).str.strip() == str(person_uid).strip())
#                     if emp_col:
#                         if empid is not None:
#                             # compare after stripping (normalize numeric float .0)
#                             try:
#                                 cmp_val = str(empid).strip()
#                                 if '.' in cmp_val:
#                                     fv = float(cmp_val)
#                                     if math.isfinite(fv) and fv.is_integer():
#                                         cmp_val = str(int(fv))
#                             except Exception:
#                                 cmp_val = str(empid).strip()
#                             mask = mask | (raw_df[emp_col].astype(str).str.strip() == cmp_val)
#                     if card_col and card is not None:
#                         mask = mask | (raw_df[card_col].astype(str).str.strip() == str(card).strip())

#                     # Also attempt to match by EmployeeName if agg has name and no other match
#                     if (not mask.any()) and name_col and 'EmployeeName' in agg_row and pd.notna(agg_row.get('EmployeeName')):
#                         mask = mask | (raw_df[name_col].astype(str).str.strip() == str(agg_row.get('EmployeeName')).strip())

#                     # Also filter by date: ensure the timestamp's date equals dd
#                     if tcol and tcol in raw_df.columns:
#                         try:
#                             raw_df[tcol] = pd.to_datetime(raw_df[tcol], errors='coerce')
#                             mask = mask & (raw_df[tcol].dt.date == pd.to_datetime(dd).date())
#                         except Exception:
#                             pass

#                     filtered = raw_df[mask].copy()
#                     if filtered.empty:
#                         # additional attempt: try matching where card is embedded inside xml/value fields
#                         if card is not None:
#                             for c in raw_df.columns:
#                                 cl = c.lower()
#                                 if 'xml' in cl or 'msg' in cl or 'value' == cl:
#                                     try:
#                                         vals = raw_df[c].dropna().astype(str)
#                                         match_mask = vals.apply(lambda x: (_extract_card_from_xml_text(x) == str(card).strip()))
#                                         if match_mask.any():
#                                             idxs = match_mask.index[match_mask]
#                                             filtered = raw_df.loc[idxs].copy()
#                                             break
#                                     except Exception:
#                                         continue
#                         if filtered.empty:
#                             continue

#                     # --- NEW: compute Zone and SwipeGapSeconds for filtered person/date ---
#                     try:
#                         # ensure timestamp col exists and is datetime
#                         if tcol and tcol in filtered.columns:
#                             filtered[tcol] = pd.to_datetime(filtered[tcol], errors='coerce')
#                         else:
#                             # try common names
#                             if 'localemessagetime' in filtered.columns:
#                                 filtered['localemessagetime'] = pd.to_datetime(filtered['localemessagetime'], errors='coerce')
#                                 tcol = 'localemessagetime'
#                     except Exception:
#                         pass

#                     # sort by timestamp for this person's filtered rows
#                     if tcol and tcol in filtered.columns:
#                         filtered = filtered.sort_values(by=tcol)
#                         # compute gap in seconds relative to previous row for this person/date
#                         try:
#                             filtered['_prev_ts'] = filtered[tcol].shift(1)
#                             filtered['_swipe_gap_seconds'] = (filtered[tcol] - filtered['_prev_ts']).dt.total_seconds().fillna(0).astype(float)
#                         except Exception:
#                             filtered['_swipe_gap_seconds'] = 0.0
#                     else:
#                         filtered['_swipe_gap_seconds'] = 0.0

#                     # compute zone per row using map_door_to_zone — IMPORTANT: per-row direction used
#                     try:
#                         if door_col and door_col in filtered.columns:
#                             if dir_col and dir_col in filtered.columns:
#                                 filtered['_zone'] = filtered.apply(lambda rr: map_door_to_zone(rr.get(door_col), rr.get(dir_col)), axis=1)
#                             else:
#                                 filtered['_zone'] = filtered[door_col].apply(lambda dv: map_door_to_zone(dv, None))
#                         else:
#                             # fallback: try PartitionName2 -> treat as Working Area / use PartitionName2 as hint
#                             if 'PartitionName2' in filtered.columns:
#                                 filtered['_zone'] = filtered['PartitionName2'].fillna('').astype(str).apply(lambda x: x if x else None)
#                             else:
#                                 filtered['_zone'] = None
#                     except Exception:
#                         filtered['_zone'] = None

#                     # Convert filtered rows into the standardized output structure requested by frontend
#                     for _, r in filtered.iterrows():
#                         out = {}
#                         # EmployeeName
#                         if name_col and name_col in raw_df.columns:
#                             out['EmployeeName'] = _to_python_scalar(r.get(name_col))
#                         else:
#                             out['EmployeeName'] = _to_python_scalar(agg_row.get('EmployeeName') or agg_row.get('person_uid'))

#                         # EmployeeID: prefer Int1 in raw file, then EmployeeID, then fallback to aggregated value
#                         emp_val = None
#                         if 'int1' in cols_lower and cols_lower.get('int1') in raw_df.columns:
#                             emp_val = _to_python_scalar(r.get(cols_lower.get('int1')))
#                         elif emp_col and emp_col in raw_df.columns:
#                             emp_val = _to_python_scalar(r.get(emp_col))
#                         else:
#                             possible_emp = None
#                             for cand in ('Int1','Text12','EmployeeID','EmployeeIdentity','empid','id'):
#                                 if cand.lower() in cols_lower:
#                                     possible_emp = _to_python_scalar(r.get(cols_lower[cand.lower()]))
#                                     if possible_emp not in (None, '', 'nan'):
#                                         break
#                             emp_val = possible_emp if possible_emp not in (None, '', 'nan') else _to_python_scalar(agg_row.get('EmployeeID'))

#                         # Normalize employee value and reject GUIDs
#                         if emp_val is not None:
#                             try:
#                                 s = str(emp_val).strip()
#                                 if '.' in s:
#                                     f = float(s)
#                                     if math.isfinite(f) and f.is_integer():
#                                         s = str(int(f))
#                                 if _looks_like_guid(s) or _is_placeholder_str(s):
#                                     emp_val = None
#                                 else:
#                                     emp_val = s
#                             except Exception:
#                                 if _looks_like_guid(emp_val):
#                                     emp_val = None
#                         out['EmployeeID'] = emp_val

#                         # CardNumber: prefer CardNumber in raw file, then CHUID/Card, value, then aggregated value (and xml extraction)
#                         card_val = None
#                         if 'cardnumber' in cols_lower and cols_lower.get('cardnumber') in raw_df.columns:
#                             card_val = _to_python_scalar(r.get(cols_lower.get('cardnumber')))
#                         elif card_col and card_col in raw_df.columns:
#                             card_val = _to_python_scalar(r.get(card_col))
#                         else:
#                             possible_card = None
#                             for cand in ('CardNumber','CHUID','Card','card_no','cardnum','value','xmlmessage'):
#                                 if cand.lower() in cols_lower:
#                                     possible_card = _to_python_scalar(r.get(cols_lower[cand.lower()]))
#                                     if possible_card not in (None, '', 'nan'):
#                                         break
#                             if possible_card in (None, '', 'nan'):
#                                 for c in raw_df.columns:
#                                     cl = c.lower()
#                                     if 'xml' in cl or 'msg' in cl or 'value' == cl:
#                                         try:
#                                             txt = r.get(c)
#                                             extracted = _extract_card_from_xml_text(str(txt)) if txt is not None else None
#                                             if extracted:
#                                                 possible_card = extracted
#                                                 break
#                                         except Exception:
#                                             continue
#                             card_val = possible_card if possible_card not in (None, '', 'nan') else _to_python_scalar(agg_row.get('CardNumber'))

#                         # Normalize card and reject GUIDs/placeholders
#                         if card_val is not None:
#                             try:
#                                 cs = str(card_val).strip()
#                                 if _looks_like_guid(cs) or _is_placeholder_str(cs):
#                                     card_val = None
#                                 else:
#                                     card_val = cs
#                             except Exception:
#                                 card_val = None
#                         out['CardNumber'] = card_val

#                         # Date and Time
#                         if tcol and tcol in raw_df.columns:
#                             ts = r.get(tcol)
#                             try:
#                                 ts_py = pd.to_datetime(ts)
#                                 out['Date'] = ts_py.date().isoformat()
#                                 out['Time'] = ts_py.time().isoformat()
#                             except Exception:
#                                 txt = str(r.get(tcol))
#                                 out['Date'] = txt[:10]
#                                 out['Time'] = txt[11:19] if len(txt) >= 19 else txt
#                         else:
#                             out['Date'] = d
#                             out['Time'] = None

#                         # Door
#                         if door_col and door_col in raw_df.columns:
#                             out['Door'] = _to_python_scalar(r.get(door_col))
#                         else:
#                             out['Door'] = None

#                         # Direction
#                         if dir_col and dir_col in raw_df.columns:
#                             out['Direction'] = _to_python_scalar(r.get(dir_col))
#                         else:
#                             out['Direction'] = _to_python_scalar(r.get('Direction')) if 'Direction' in r else None

#                         # Note (rejection / source)
#                         if note_col and note_col in raw_df.columns:
#                             out['Note'] = _to_python_scalar(r.get(note_col))
#                         else:
#                             out['Note'] = None

#                         # Zone and SwipeGapSeconds (new fields)
#                         try:
#                             out['Zone'] = _to_python_scalar(r.get('_zone')) if '_zone' in r else map_door_to_zone(out['Door'], out['Direction'])
#                         except Exception:
#                             out['Zone'] = None
#                         try:
#                             gap = r.get('_swipe_gap_seconds') if '_swipe_gap_seconds' in r else None
#                             out['SwipeGapSeconds'] = float(gap) if gap is not None else None
#                             out['SwipeGap'] = format_seconds_to_hms(out['SwipeGapSeconds'])
#                         except Exception:
#                             out['SwipeGapSeconds'] = None
#                             out['SwipeGap'] = None

#                         out['_source'] = raw_name
#                         raw_swipes_out.append(out)
#             except Exception as e:
#                 logging.exception("Error processing raw swipe file for date %s: %s", d, e)
#                 continue

#     return jsonify({
#         "aggregated_rows": cleaned_matched,
#         "raw_swipe_files": sorted(list(raw_files)),
#         "raw_swipes": raw_swipes_out
#     }), 200


@app.route('/record', methods=['GET'])
def get_record():
    """
    /record?employee_id=... or /record?person_uid=...
    Returns matching aggregated trend rows and filtered raw swipe rows (only for flagged persons).
    Updated: read ALL trend CSVs (not just the latest), so previous days are included.
    Also add Zone and SwipeGap (seconds) to raw_swipes returned as evidence.

    New behaviour:
      - By default, raw_swipes are returned only for aggregated rows where IsFlagged == True
      - Set include_unflagged=1 (or true/yes) to also fetch evidence for unflagged aggregated rows.
      - If an aggregated row has no Date/FirstSwipe/LastSwipe, we fall back to scanning all swipes files.
    """
    q = request.args.get('employee_id') or request.args.get('person_uid')
    include_unflagged = str(request.args.get('include_unflagged', '')).lower() in ('1', 'true', 'yes')

    p = Path(DEFAULT_OUTDIR)
    csvs = sorted(p.glob("trend_pune_*.csv"), reverse=True)
    if not csvs:
        return jsonify({'aggregated_rows': [], 'raw_swipe_files': [], 'raw_swipes': []}), 200

    # Read all CSVs (concat) so /record will search previous days too
    df_list = []
    for fp in csvs:
        try:
            tmp = pd.read_csv(fp, parse_dates=['FirstSwipe','LastSwipe'], infer_datetime_format=True)
        except Exception:
            try:
                tmp = pd.read_csv(fp, dtype=str)
            except Exception:
                continue
        df_list.append(tmp)
    if not df_list:
        return jsonify({'aggregated_rows': [], 'raw_swipe_files': [], 'raw_swipes': []}), 200
    df = pd.concat(df_list, ignore_index=True)

    if q is None:
        cleaned = _clean_sample_df(df, max_rows=10)
        return jsonify({'aggregated_rows': cleaned, 'raw_swipe_files': [], 'raw_swipes': []}), 200

    q_str = str(q).strip()

    def normalize_series(s):
        if s is None:
            return pd.Series([''] * len(df))
        s = s.fillna('').astype(str).str.strip()
        def _norm_val(v):
            if not v:
                return ''
            try:
                if '.' in v:
                    fv = float(v)
                    if math.isfinite(fv) and fv.is_integer():
                        return str(int(fv))
            except Exception:
                pass
            return v
        return s.map(_norm_val)

    found_mask = pd.Series(False, index=df.index)

    if 'EmployeeID' in df.columns:
        emp_series = normalize_series(df['EmployeeID'])
        found_mask = found_mask | (emp_series == q_str)

    if 'person_uid' in df.columns:
        uid_series = normalize_series(df['person_uid'])
        found_mask = found_mask | (uid_series == q_str)

    # also check Int1 (Personnel.Int1) if present in CSV
    if 'Int1' in df.columns and not found_mask.any():
        int1_series = normalize_series(df['Int1'])
        found_mask = found_mask | (int1_series == q_str)

    if not found_mask.any():
        # try numeric equivalence
        try:
            q_numeric = float(q_str)
            if 'EmployeeID' in df.columns:
                emp_numeric = pd.to_numeric(df['EmployeeID'], errors='coerce')
                found_mask = found_mask | (emp_numeric == q_numeric)
            if 'Int1' in df.columns and not found_mask.any():
                int_numeric = pd.to_numeric(df['Int1'], errors='coerce')
                found_mask = found_mask | (int_numeric == q_numeric)
        except Exception:
            pass

    matched = df[found_mask]
    if matched.empty:
        return jsonify({'aggregated_rows': [], 'raw_swipe_files': [], 'raw_swipes': []}), 200

    cleaned_matched = _clean_sample_df(matched, max_rows=len(matched))

    # Resolve raw swipe file names by Date (collect all dates present in matched rows)
    raw_files = set()
    raw_swipes_out = []

    # Helper to add and dedupe swipe rows
    seen_swipe_keys = set()
    def _append_swipe(out_row, source_name):
        # create a dedupe key (date,time,door,direction,card)
        key = (
            out_row.get('Date') or '',
            out_row.get('Time') or '',
            (out_row.get('Door') or '').strip(),
            (out_row.get('Direction') or '').strip(),
            (out_row.get('CardNumber') or out_row.get('Card') or '').strip()
        )
        if key in seen_swipe_keys:
            return
        seen_swipe_keys.add(key)
        out_row['_source'] = source_name
        raw_swipes_out.append(out_row)

    # iterate matched aggregated rows and search raw swipe files
    for idx, agg_row in matched.iterrows():
        person_uid = agg_row.get('person_uid') if 'person_uid' in agg_row else None
        empid = agg_row.get('EmployeeID') if 'EmployeeID' in agg_row else None
        if (not empid) and 'Int1' in agg_row:
            empid = agg_row.get('Int1')
        card = agg_row.get('CardNumber') if 'CardNumber' in agg_row else None

        # build dates_for_row from Date / FirstSwipe / LastSwipe
        dates_for_row = set()
        if 'Date' in agg_row and pd.notna(agg_row['Date']):
            try:
                d = pd.to_datetime(agg_row['Date']).date()
                dates_for_row.add(d.isoformat())
            except Exception:
                pass
        for col in ('FirstSwipe','LastSwipe'):
            if col in agg_row and pd.notna(agg_row[col]):
                try:
                    d = pd.to_datetime(agg_row[col]).date()
                    dates_for_row.add(d.isoformat())
                except Exception:
                    pass

        # If aggregated row is not flagged and include_unflagged is False, skip fetching raw evidence
        is_flagged = bool(agg_row.get('IsFlagged', False))
        if (not is_flagged) and (not include_unflagged):
            continue

        # If no dates found, fallback to scanning all swipes files (so we don't miss evidence)
        dates_to_scan = dates_for_row or {None}

        for d in dates_to_scan:
            try:
                if d is None:
                    # scan all swipes files
                    candidates = list(Path(DEFAULT_OUTDIR).glob(f"swipes_*.csv"))
                else:
                    dd = d[:10]  # 'YYYY-MM-DD'
                    target = dd.replace('-', '')
                    candidates = list(Path(DEFAULT_OUTDIR).glob(f"swipes_*_{target}.csv"))

                if not candidates:
                    continue

                for fp in candidates:
                    raw_name = fp.name
                    raw_files.add(raw_name)
                    try:
                        raw_df = pd.read_csv(fp, parse_dates=['LocaleMessageTime'], infer_datetime_format=True)
                    except Exception:
                        try:
                            raw_df = pd.read_csv(fp, dtype=str)
                        except Exception:
                            continue

                    cols_lower = {c.lower(): c for c in raw_df.columns}
                    tcol = cols_lower.get('localemessagetime') or cols_lower.get('messagetime') or cols_lower.get('timestamp') or cols_lower.get('time') or None
                    emp_col = cols_lower.get('int1') or cols_lower.get('employeeid') or cols_lower.get('employeeidentity') or cols_lower.get('employee_id') or None
                    name_col = cols_lower.get('employeename') or cols_lower.get('objectname1') or cols_lower.get('employee_name') or None
                    card_col = cols_lower.get('cardnumber') or cols_lower.get('card') or cols_lower.get('chuid') or cols_lower.get('value') or None
                    door_col = cols_lower.get('door') or cols_lower.get('doorname') or cols_lower.get('door_name') or None
                    dir_col = cols_lower.get('direction') or cols_lower.get('directionname') or cols_lower.get('direction_name') or None
                    note_col = cols_lower.get('rejection_type') or cols_lower.get('note') or cols_lower.get('source') or None

                    # build filter mask
                    mask = pd.Series(False, index=raw_df.index)
                    if person_uid is not None and 'person_uid' in raw_df.columns:
                        mask = mask | (raw_df['person_uid'].astype(str).str.strip() == str(person_uid).strip())
                    if emp_col:
                        if empid is not None:
                            try:
                                cmp_val = str(empid).strip()
                                if '.' in cmp_val:
                                    fv = float(cmp_val)
                                    if math.isfinite(fv) and fv.is_integer():
                                        cmp_val = str(int(fv))
                            except Exception:
                                cmp_val = str(empid).strip()
                            mask = mask | (raw_df[emp_col].astype(str).str.strip() == cmp_val)
                    if card_col and card is not None:
                        mask = mask | (raw_df[card_col].astype(str).str.strip() == str(card).strip())

                    if (not mask.any()) and name_col and 'EmployeeName' in agg_row and pd.notna(agg_row.get('EmployeeName')):
                        mask = mask | (raw_df[name_col].astype(str).str.strip() == str(agg_row.get('EmployeeName')).strip())

                    # filter by date if possible
                    if d is not None and tcol and tcol in raw_df.columns:
                        try:
                            raw_df[tcol] = pd.to_datetime(raw_df[tcol], errors='coerce')
                            mask = mask & (raw_df[tcol].dt.date == pd.to_datetime(d).date())
                        except Exception:
                            pass

                    filtered = raw_df[mask].copy()
                    if filtered.empty:
                        # xml value fallback for embedded card values
                        if card is not None:
                            for ccol in raw_df.columns:
                                cl = ccol.lower()
                                if 'xml' in cl or 'msg' in cl or 'value' == cl:
                                    try:
                                        vals = raw_df[ccol].dropna().astype(str)
                                        match_mask = vals.apply(lambda x: (_extract_card_from_xml_text(x) == str(card).strip()))
                                        if match_mask.any():
                                            idxs = match_mask.index[match_mask]
                                            filtered = raw_df.loc[idxs].copy()
                                            break
                                    except Exception:
                                        continue
                        if filtered.empty:
                            continue

                    # enrich filtered rows and append to output (deduped)
                    try:
                        if tcol and tcol in filtered.columns:
                            filtered[tcol] = pd.to_datetime(filtered[tcol], errors='coerce')
                        else:
                            if 'localemessagetime' in filtered.columns:
                                filtered['localemessagetime'] = pd.to_datetime(filtered['localemessagetime'], errors='coerce')
                                tcol = 'localemessagetime'
                    except Exception:
                        pass

                    if tcol and tcol in filtered.columns:
                        filtered = filtered.sort_values(by=tcol)
                        filtered['_prev_ts'] = filtered[tcol].shift(1)
                        try:
                            filtered['_swipe_gap_seconds'] = (filtered[tcol] - filtered['_prev_ts']).dt.total_seconds().fillna(0).astype(float)
                        except Exception:
                            filtered['_swipe_gap_seconds'] = 0.0
                    else:
                        filtered['_swipe_gap_seconds'] = 0.0

                    try:
                        if door_col and door_col in filtered.columns:
                            if dir_col and dir_col in filtered.columns:
                                filtered['_zone'] = filtered.apply(lambda rr: map_door_to_zone(rr.get(door_col), rr.get(dir_col)), axis=1)
                            else:
                                filtered['_zone'] = filtered[door_col].apply(lambda dv: map_door_to_zone(dv, None))
                        else:
                            if 'PartitionName2' in filtered.columns:
                                filtered['_zone'] = filtered['PartitionName2'].fillna('').astype(str).apply(lambda x: x if x else None)
                            else:
                                filtered['_zone'] = None
                    except Exception:
                        filtered['_zone'] = None

                    # normalize and append
                    for _, r in filtered.iterrows():
                        out = {}
                        out['EmployeeName'] = _to_python_scalar(r.get(name_col)) if name_col and name_col in raw_df.columns else _to_python_scalar(agg_row.get('EmployeeName') or agg_row.get('person_uid'))

                        # EmployeeID
                        emp_val = None
                        if 'int1' in cols_lower and cols_lower.get('int1') in raw_df.columns:
                            emp_val = _to_python_scalar(r.get(cols_lower.get('int1')))
                        elif emp_col and emp_col in raw_df.columns:
                            emp_val = _to_python_scalar(r.get(emp_col))
                        else:
                            possible_emp = None
                            for cand in ('Int1','Text12','EmployeeID','EmployeeIdentity','empid','id'):
                                if cand.lower() in cols_lower:
                                    possible_emp = _to_python_scalar(r.get(cols_lower[cand.lower()]))
                                    if possible_emp not in (None, '', 'nan'):
                                        break
                            emp_val = possible_emp if possible_emp not in (None, '', 'nan') else _to_python_scalar(agg_row.get('EmployeeID'))

                        if emp_val is not None:
                            try:
                                s = str(emp_val).strip()
                                if '.' in s:
                                    f = float(s)
                                    if math.isfinite(f) and f.is_integer():
                                        s = str(int(f))
                                if _looks_like_guid(s) or _is_placeholder_str(s):
                                    emp_val = None
                                else:
                                    emp_val = s
                            except Exception:
                                if _looks_like_guid(emp_val):
                                    emp_val = None
                        out['EmployeeID'] = emp_val

                        # CardNumber
                        card_val = None
                        if 'cardnumber' in cols_lower and cols_lower.get('cardnumber') in raw_df.columns:
                            card_val = _to_python_scalar(r.get(cols_lower.get('cardnumber')))
                        elif card_col and card_col in raw_df.columns:
                            card_val = _to_python_scalar(r.get(card_col))
                        else:
                            possible_card = None
                            for cand in ('CardNumber','CHUID','Card','card_no','cardnum','value','xmlmessage'):
                                if cand.lower() in cols_lower:
                                    possible_card = _to_python_scalar(r.get(cols_lower[cand.lower()]))
                                    if possible_card not in (None, '', 'nan'):
                                        break
                            if possible_card in (None, '', 'nan'):
                                for ccc in raw_df.columns:
                                    cl = ccc.lower()
                                    if 'xml' in cl or 'msg' in cl or 'value' == cl:
                                        try:
                                            txt = r.get(ccc)
                                            extracted = _extract_card_from_xml_text(str(txt)) if txt is not None else None
                                            if extracted:
                                                possible_card = extracted
                                                break
                                        except Exception:
                                            continue
                            card_val = possible_card if possible_card not in (None, '', 'nan') else _to_python_scalar(agg_row.get('CardNumber'))

                        if card_val is not None:
                            try:
                                cs = str(card_val).strip()
                                if _looks_like_guid(cs) or _is_placeholder_str(cs):
                                    card_val = None
                                else:
                                    card_val = cs
                            except Exception:
                                card_val = None
                        out['CardNumber'] = card_val

                        # timestamp -> Date/Time
                        if tcol and tcol in raw_df.columns:
                            ts = r.get(tcol)
                            try:
                                ts_py = pd.to_datetime(ts)
                                out['Date'] = ts_py.date().isoformat()
                                out['Time'] = ts_py.time().isoformat()
                            except Exception:
                                txt = str(r.get(tcol))
                                out['Date'] = txt[:10]
                                out['Time'] = txt[11:19] if len(txt) >= 19 else txt
                        else:
                            out['Date'] = d if d is not None else None
                            out['Time'] = None

                        out['Door'] = _to_python_scalar(r.get(door_col)) if (door_col and door_col in filtered.columns) else None
                        out['Direction'] = _to_python_scalar(r.get(dir_col)) if (dir_col and dir_col in filtered.columns) else _to_python_scalar(r.get('Direction')) if 'Direction' in r else None
                        out['Note'] = _to_python_scalar(r.get(note_col)) if (note_col and note_col in filtered.columns) else None

                        try:
                            out['Zone'] = _to_python_scalar(r.get('_zone')) if '_zone' in r else map_door_to_zone(out['Door'], out['Direction'])
                        except Exception:
                            out['Zone'] = None
                        try:
                            gap = r.get('_swipe_gap_seconds') if '_swipe_gap_seconds' in r else None
                            out['SwipeGapSeconds'] = float(gap) if gap is not None else None
                            out['SwipeGap'] = format_seconds_to_hms(out['SwipeGapSeconds'])
                        except Exception:
                            out['SwipeGapSeconds'] = None
                            out['SwipeGap'] = None

                        _append_swipe(out, raw_name)
            except Exception as e:
                logging.exception("Error processing raw swipe file for date %s: %s", d, e)
                continue

    return jsonify({
        "aggregated_rows": cleaned_matched,
        "raw_swipe_files": sorted(list(raw_files)),
        "raw_swipes": raw_swipes_out
    }), 200



@app.route('/record/export', methods=['GET'])
def export_record_excel():
    """
    /record/export?employee_id=...&date=YYYY-MM-DD  OR /record/export?person_uid=...&date=YYYY-MM-DD
    Produces an Excel file (xlsx) filtered for the requested employee and date (if provided).
    Two sheets:
      - "Details — Evidence": EmployeeName, EmployeeID, Door, Direction, Zone, Date, LocaleMessageTime, SwipeGapSeconds, PartitionName2, _source_file
      - "Swipe timeline": Employee Name, Employee ID, Card, Date, Time, SwipeGapSeconds, Door, Direction, Zone, Note
    """
    q = request.args.get('employee_id') or request.args.get('person_uid')
    date_str = request.args.get('date')  # optional 'YYYY-MM-DD' (single date)
    if not q:
        return jsonify({"error":"employee_id or person_uid is required"}), 400

    # Determine list of raw swipe files to scan. If date provided, restrict to that date only.
    files_to_scan = []
    p = Path(DEFAULT_OUTDIR)
    if date_str:
        try:
            dd = pd.to_datetime(date_str).date()
            target = dd.strftime("%Y%m%d")
            candidates = list(p.glob(f"swipes_*_{target}.csv"))
            files_to_scan = candidates
        except Exception:
            return jsonify({"error":"invalid date format, expected YYYY-MM-DD"}), 400
    else:
        # scan all swipes files (most recent first)
        files_to_scan = sorted(p.glob("swipes_*.csv"), reverse=True)

    if not files_to_scan:
        return jsonify({"error":"no raw swipe files found for requested date / outputs"}), 404

    all_rows = []
    for fp in files_to_scan:
        try:
            raw_df = pd.read_csv(fp, dtype=str, parse_dates=['LocaleMessageTime'], infer_datetime_format=True)
        except Exception:
            try:
                raw_df = pd.read_csv(fp, dtype=str)
            except Exception:
                continue

        # normalize column names
        cols_lower = {c.lower(): c for c in raw_df.columns}
        # pick possible columns
        tcol = cols_lower.get('localemessagetime') or cols_lower.get('messagetime') or cols_lower.get('timestamp') or cols_lower.get('time') or None
        emp_col = cols_lower.get('int1') or cols_lower.get('employeeid') or cols_lower.get('employeeidentity') or cols_lower.get('employee_id') or None
        name_col = cols_lower.get('employeename') or cols_lower.get('objectname1') or cols_lower.get('employee_name') or None
        card_col = cols_lower.get('cardnumber') or cols_lower.get('card') or cols_lower.get('chuid') or cols_lower.get('value') or None
        door_col = cols_lower.get('door') or cols_lower.get('doorname') or cols_lower.get('door_name') or None
        dir_col = cols_lower.get('direction') or cols_lower.get('directionname') or cols_lower.get('direction_name') or None
        note_col = cols_lower.get('rejection_type') or cols_lower.get('note') or cols_lower.get('source') or None
        person_uid_col = cols_lower.get('person_uid')

        # build mask matching requested q: try person_uid, emp_col, card, name
        mask = pd.Series(False, index=raw_df.index)
        if person_uid_col and person_uid_col in raw_df.columns:
            mask = mask | (raw_df[person_uid_col].astype(str).str.strip() == str(q).strip())
        if emp_col and emp_col in raw_df.columns:
            mask = mask | (raw_df[emp_col].astype(str).str.strip() == str(q).strip())
        # try matching numeric equivalence
        if not mask.any() and emp_col and emp_col in raw_df.columns:
            try:
                q_numeric = float(q)
                emp_numeric = pd.to_numeric(raw_df[emp_col], errors='coerce')
                mask = mask | (emp_numeric == q_numeric)
            except Exception:
                pass
        # also try name match if nothing matched
        if not mask.any() and name_col and name_col in raw_df.columns:
            mask = mask | (raw_df[name_col].astype(str).str.strip().str.lower() == str(q).strip().lower())

        if not mask.any():
            # nothing to include from this file
            continue

        filtered = raw_df[mask].copy()
        if filtered.empty:
            continue

        # ensure timestamp col exists and parsed
        if tcol and tcol in filtered.columns:
            try:
                filtered[tcol] = pd.to_datetime(filtered[tcol], errors='coerce')
            except Exception:
                pass

        # compute swipe gaps (seconds)
        if tcol and tcol in filtered.columns:
            filtered = filtered.sort_values(by=tcol)
            filtered['_prev_ts'] = filtered[tcol].shift(1)
            try:
                filtered['_swipe_gap_seconds'] = (filtered[tcol] - filtered['_prev_ts']).dt.total_seconds().fillna(0).astype(float)
            except Exception:
                filtered['_swipe_gap_seconds'] = 0.0
        else:
            filtered['_swipe_gap_seconds'] = 0.0


         # after card normalization (or near other fields)
# Email & ManagerEmail
try:
    # prefer column present in raw file, else fall back to aggregated value
    if 'emailaddress' in cols_lower and cols_lower.get('emailaddress') in filtered.columns:
        out['EmailAddress'] = _to_python_scalar(r.get(cols_lower.get('emailaddress')))
    else:
        out['EmailAddress'] = _to_python_scalar(agg_row.get('EmailAddress'))

    if 'manageremail' in cols_lower and cols_lower.get('manageremail') in filtered.columns:
        out['ManagerEmail'] = _to_python_scalar(r.get(cols_lower.get('manageremail')))
    else:
        out['ManagerEmail'] = _to_python_scalar(agg_row.get('ManagerEmail'))

    # Portrait: prefer raw file value if present, else aggregated value
    if 'primaryportrait' in cols_lower and cols_lower.get('primaryportrait') in filtered.columns:
        out['PrimaryPortrait'] = _to_python_scalar(r.get(cols_lower.get('primaryportrait')))
    else:
        out['PrimaryPortrait'] = _to_python_scalar(agg_row.get('PrimaryPortrait'))
except Exception:
    out['EmailAddress'] = out.get('EmailAddress', None)
    out['ManagerEmail'] = out.get('ManagerEmail', None)
    out['PrimaryPortrait'] = out.get('PrimaryPortrait', None)
   

        # compute zone per row (use door+direction if available)
        try:
            if door_col and door_col in filtered.columns:
                if dir_col and dir_col in filtered.columns:
                    filtered['_zone'] = filtered.apply(lambda rr: map_door_to_zone(rr.get(door_col), rr.get(dir_col)), axis=1)
                else:
                    filtered['_zone'] = filtered[door_col].apply(lambda dv: map_door_to_zone(dv, None))
            else:
                filtered['_zone'] = filtered.get('PartitionName2', None)
        except Exception:
            filtered['_zone'] = None

        # normalize columns into common shape and append rows
        for _, r in filtered.iterrows():
            row = {}
            row['EmployeeName'] = _to_python_scalar(r.get(name_col)) if (name_col and name_col in filtered.columns) else None
            # EmployeeID attempts: Int1/Text12/EmployeeID
            emp_val = None
            if emp_col and emp_col in filtered.columns:
                emp_val = _to_python_scalar(r.get(emp_col))
            else:
                # fallbacks
                for cand in ('int1','text12','employeeid','employee_identity','employeeidentity'):
                    if cand in cols_lower and cols_lower[cand] in filtered.columns:
                        emp_val = _to_python_scalar(r.get(cols_lower[cand]))
                        if emp_val:
                            break
            row['EmployeeID'] = emp_val
            row['Card'] = _to_python_scalar(r.get(card_col)) if (card_col and card_col in filtered.columns) else None





            # Date and Time
            if tcol and tcol in filtered.columns:
                ts = r.get(tcol)
                try:
                    ts_py = pd.to_datetime(ts)
                    row['Date'] = ts_py.date().isoformat()
                    row['Time'] = ts_py.time().isoformat()
                    row['LocaleMessageTime'] = ts_py.isoformat()
                except Exception:
                    txt = str(r.get(tcol))
                    row['Date'] = txt[:10]
                    row['Time'] = txt[11:19] if len(txt) >= 19 else None
                    row['LocaleMessageTime'] = txt
            else:
                row['Date'] = None
                row['Time'] = None
                row['LocaleMessageTime'] = None

            row['SwipeGapSeconds'] = float(r.get('_swipe_gap_seconds')) if '_swipe_gap_seconds' in r else 0.0
            row['SwipeGap'] = format_seconds_to_hms(row['SwipeGapSeconds'])

            row['Door'] = _to_python_scalar(r.get(door_col)) if (door_col and door_col in filtered.columns) else None
            row['Direction'] = _to_python_scalar(r.get(dir_col)) if (dir_col and dir_col in filtered.columns) else None
            row['Note'] = _to_python_scalar(r.get(note_col)) if (note_col and note_col in filtered.columns) else None

            # Zone (computed above)
            try:
                zone_val = r.get('_zone') if '_zone' in r else None
                if zone_val is None:
                    # fallback from door/direction
                    zone_val = map_door_to_zone(row['Door'], row['Direction'])
                row['Zone'] = _to_python_scalar(zone_val)
            except Exception:
                row['Zone'] = None

            row['PartitionName2'] = _to_python_scalar(r.get('PartitionName2')) if 'PartitionName2' in filtered.columns else None
            row['_source_file'] = fp.name
            all_rows.append(row)



            

    if not all_rows:
        return jsonify({"error":"no swipe rows matched the requested employee/date"}), 404

    df_out = pd.DataFrame(all_rows)

    # Build two sheets as requested (with exact requested column order)
    details_cols = ['EmployeeName','EmployeeID','Door','Direction','Zone','Date','LocaleMessageTime','SwipeGapSeconds','PartitionName2','_source_file']
    timeline_cols = ['EmployeeName','EmployeeID','Card','Date','Time','SwipeGapSeconds','Door','Direction','Zone','Note','_source_file']

    details_df = df_out[[c for c in details_cols if c in df_out.columns]].copy()
    timeline_df = df_out[[c for c in timeline_cols if c in df_out.columns]].copy()

    # Create excel in-memory
    output = io.BytesIO()
    try:
        with pd.ExcelWriter(output, engine='openpyxl') as writer:
            details_df.to_excel(writer, sheet_name='Details — Evidence', index=False)
            timeline_df.to_excel(writer, sheet_name='Swipe timeline', index=False)
            writer.save()
            output.seek(0)
    except Exception as e:
        logging.exception("Failed to create Excel: %s", e)
        return jsonify({"error":"failed to create excel"}), 500

    # If openpyxl available, apply formatting (bold header, center align, borders)
    if OPENPYXL_AVAILABLE:
        try:
            wb = load_workbook(output)
            thin = Side(border_style="thin", color="000000")
            thick = Side(border_style="medium", color="000000")
            for ws in wb.worksheets:
                # header styling
                header = ws[1]
                for cell in header:
                    cell.font = Font(bold=True)
                    cell.alignment = Alignment(horizontal="center", vertical="center")
                    cell.border = Border(top=thick, left=thick, right=thick, bottom=thick)
                # data rows: center & thin border
                for row in ws.iter_rows(min_row=2, max_row=ws.max_row, min_col=1, max_col=ws.max_column):
                    for cell in row:
                        cell.alignment = Alignment(horizontal="center", vertical="center")
                        cell.border = Border(top=thin, left=thin, right=thin, bottom=thin)
                # autosize columns (best-effort)
                for col in ws.columns:
                    max_len = 0
                    col_letter = col[0].column_letter
                    for cell in col:
                        try:
                            v = str(cell.value) if cell.value is not None else ""
                        except Exception:
                            v = ""
                        if len(v) > max_len:
                            max_len = len(v)
                    # limit column width
                    width = min(max(10, max_len + 2), 50)
                    ws.column_dimensions[col_letter].width = width
            # write back to bytes
            out2 = io.BytesIO()
            wb.save(out2)
            out2.seek(0)
            return send_file(out2, as_attachment=True,
                             download_name=f"evidence_{str(q).replace(' ','_')}_{date_str or 'all'}.xlsx",
                             mimetype="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet")
        except Exception:
            logging.exception("Excel styling failed, returning raw file")
            output.seek(0)
            return send_file(output, as_attachment=True,
                             download_name=f"evidence_{str(q).replace(' ','_')}_{date_str or 'all'}.xlsx",
                             mimetype="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet")
    else:
        # fallback: return raw excel binary without styling
        output.seek(0)
        return send_file(output, as_attachment=True,
                         download_name=f"evidence_{str(q).replace(' ','_')}_{date_str or 'all'}.xlsx",
                         mimetype="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet")


@app.route('/swipes/<filename>', methods=['GET'])
def download_swipes(filename):
    """
    Serve raw swipe CSVs from outputs/ (filename should be the file name only).
    """
    fp = DEFAULT_OUTDIR / filename
    if not fp.exists():
        return jsonify({"error":"file not found"}), 404
    # send file
    return send_from_directory(str(DEFAULT_OUTDIR), filename, as_attachment=True)


@app.route('/train', methods=['GET'])
def build_training_endpoint():
    end_date_str = request.args.get('end_date')
    months = int(request.args.get('months') or 3)
    min_unique = int(request.args.get('min_unique') or 1000)
    try:
        if end_date_str:
            end_date = datetime.strptime(end_date_str, "%Y-%m-%d").date()
        else:
            end_date = datetime.now().date()
    except Exception as e:
        return jsonify({"error": f"invalid end_date: {e}"}), 400

    try:
        csv_path = build_monthly_training(end_date=end_date, months=months, min_unique_employees=min_unique, outdir=str(DEFAULT_OUTDIR))
        if csv_path is None:
            return jsonify({"error":"no training CSV produced (no data)"}), 500
        return jsonify({"training_csv": str(csv_path)})
    except Exception as e:
        logging.exception("build_monthly_training failed")
        return jsonify({"error": str(e)}), 500


if __name__ == "__main__":
    app.run(host="0.0.0.0", port=8002, debug=True)









Now add below 2 Updates in index.html file and share me fully updated file carefully....



// --- place just before return(...) or inside App() so helper available ---
function getPortraitSrc(modalRow, modalDetails){
  try{
    var val = (modalRow && (modalRow.PrimaryPortrait || modalRow.primaryportrait))
          || (modalDetails && modalDetails.raw_swipes && modalDetails.raw_swipes.length && (modalDetails.raw_swipes[0].PrimaryPortrait || modalDetails.raw_swipes[0].primaryportrait))
          || null;
    if(!val) return null;
    val = String(val);
    val = val.trim();

    if(val === "") return null;
    // already a data: URI
    if(val.startsWith('data:')) return val;
    // http/https link
    if(val.startsWith('http://') || val.startsWith('https://')) return val;
    // If value looks like python bytes literal "b'...'" strip b'' wrapper
    if(val.startsWith(\"b'\") || val.startsWith('b\"')){
      val = val.replace(/^b['\"]|['\"]$/g, '');
    }
    // remove whitespace/newlines
    var candidate = val.replace(/\\s+/g,'');
    // base64 heuristic: only base64 chars and fairly long
    var base64_re = /^[A-Za-z0-9+/=]+$/;
    if(candidate.length > 100 && base64_re.test(candidate)){
      // assume jpeg by default (works for many portraits). If you need PNG change to image/png.
      return 'data:image/jpeg;base64,' + candidate;
    }
    // otherwise cannot interpret
    return null;
  }catch(e){
    return null;
  }
}









<div style={{marginTop:8, display:'flex', gap:12, alignItems:'flex-start'}}>
  {/* Left: portrait */}
  <div style={{width:120, minWidth:120}}>
    { (function(){
        const src = getPortraitSrc(modalRow, modalDetails);
        if(src){
          return <img src={src} alt="employee" style={{width:100, height:100, objectFit:'cover', borderRadius:6, border:'1px solid #e6edf3'}} />;
        }
        return (<div style={{width:100, height:100, background:'#f1f5f9', borderRadius:6, display:'flex', alignItems:'center', justifyContent:'center', border:'1px solid #e6edf3'}}><span className="muted">No image</span></div>);
    })() }
  </div>

  {/* Right: details */}
  <div style={{flex:1}}>
    <div><strong>Name:</strong> { sanitizeName(modalRow) } </div>
    <div><strong>EmployeeID:</strong> { modalRow.EmployeeID || "—" } </div>
    <div><strong>Card:</strong> { modalRow.CardNumber || modalRow.Card || "—" } </div>
    <div style={{marginTop:8}}><strong>Date:</strong> { safeDateDisplay(modalRow.Date || modalRow.FirstSwipe) } </div>
    <div><strong>Duration:</strong> { modalRow.Duration || (modalRow.DurationMinutes ? Math.round(modalRow.DurationMinutes) + " min" : "—") } </div>
    <div style={{marginTop:6}}><strong>Reasons:</strong> { renderReasonChips(modalRow.Reasons) } </div>

    <div style={{marginTop:8}}>
      <div><strong>Email:</strong> { modalRow.EmailAddress || (modalDetails && modalDetails.raw_swipes && modalDetails.raw_swipes[0] && (modalDetails.raw_swipes[0].EmailAddress || modalDetails.raw_swipes[0].emailaddress)) || "—" }</div>
      <div><strong>Manager Email:</strong> { modalRow.ManagerEmail || (modalDetails && modalDetails.raw_swipes && modalDetails.raw_swipes[0] && (modalDetails.raw_swipes[0].ManagerEmail || modalDetails.raw_swipes[0].manageremail)) || "—" }</div>
    </div>
  </div>
</div>







<!doctype html>
<html>
  <head>
    <meta charset="utf-8" />
    <title>Trend Analysis — Dashboard</title>
    <meta name="viewport" content="width=device-width,initial-scale=1" />
    <!-- React + ReactDOM + Babel (quick prototyping) -->
    <script crossorigin src="https://unpkg.com/react@18/umd/react.development.js"></script>
    <script crossorigin src="https://unpkg.com/react-dom@18/umd/react-dom.development.js"></script>
    <script crossorigin src="https://unpkg.com/babel-standalone@6.26.0/babel.min.js"></script>

    <!-- Chart.js -->
    <script src="https://cdn.jsdelivr.net/npm/chart.js"></script>

    <!-- Flatpickr (high-quality calendar) -->
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/flatpickr/dist/flatpickr.min.css">
    <script src="https://cdn.jsdelivr.net/npm/flatpickr"></script>

    <style>
      /* ---------- Global ---------- */
      :root{
        --wu-yellow: #ffd400;
        --wu-black: #0a0a0a;
        --card-bg: #ffffff;
        --muted: #64748b;
        --accent: #2563eb;
      }

      html,body { height:100%; }
      body { font-family: Inter, Roboto, Arial, sans-serif; margin: 0; padding: 0; background:#f6f7fb; color:#1f2937; -webkit-font-smoothing:antialiased; -moz-osx-font-smoothing:grayscale; }
      .container { max-width:1250px; margin:12px auto; padding:0; }

      /* ---------- Header (Western Union look) ---------- */
      .topbar {
        display:flex;
        align-items:center;
        justify-content:space-between;
        background: linear-gradient(90deg, #111 0%, #000 30%);
        color:var(--wu-yellow);
        padding: 12px 16px;
        border-radius: 8px 8px 0 0;
        box-shadow: 0 8px 24px rgba(2,6,23,0.18);
        gap:12px;
        flex-wrap:wrap; /* allow wrapping for responsiveness */
      }
      .wu-brand {
        display:flex;
        gap:12px;
        align-items:center;
        min-width:0;
      }
      .wu-logo {
        width:54px; height:34px; background:var(--wu-yellow); color:#000; display:flex; align-items:center; justify-content:center; font-weight:700; border-radius:4px; box-shadow: inset 0 -2px 0 rgba(0,0,0,0.08);
        font-family: "Helvetica Neue", Arial, sans-serif;
        flex-shrink:0;
      }
      .title-block { line-height:1; min-width:0; }
      .title-block h1 { margin:0; font-size:18px; color:var(--wu-yellow); white-space:nowrap; overflow:hidden; text-overflow:ellipsis; max-width:260px; }
      .title-block p { margin:0; color:#e6e6e6; font-size:13px; }

      .header-actions { display:flex; gap:8px; align-items:center; margin-left:auto; flex-wrap:wrap; }
      .header-actions .control { display:flex; align-items:center; gap:6px; }
      .header-actions .control label { color:#e7e7e7; font-size:13px; margin-right:4px; white-space:nowrap; }
      .date-input { padding:8px 10px; border-radius:6px; border:1px solid rgba(255,255,255,0.12); background:transparent; color:#fff; min-width:130px; }
      .header-actions button { padding:8px 12px; border-radius:6px; border:0; font-weight:600; cursor:pointer; }
      .btn-primary { background:var(--wu-yellow); color:var(--wu-black); }
      .btn-ghost { background:transparent; color:#fff; border:1px solid rgba(255,255,255,0.12); }

      /* ---------- Main card area ---------- */
      .card-shell { background:var(--card-bg); padding:10px 14px 14px 14px; border-radius:0 0 8px 8px; box-shadow:0 6px 18px rgba(16,24,40,0.04); margin-top:4px; } /* reduced gap */
      .cards { display:flex; gap:10px; margin:6px 0 10px 0; padding:6px 0; align-items:stretch; }
      .card {
        flex:1;
        background:linear-gradient(180deg,#fff,#fbfdff);
        padding:12px 12px;
        border-radius:8px;
        text-align:center;
        border: 2px solid rgba(255,212,66,0.16);
        box-shadow: 0 6px 18px rgba(16,24,40,0.04);
        min-width:120px;
      }
      .card h3 { margin:4px 0; font-size:20px; color:#0f172a; }
      .card p { margin:0; color:var(--muted); font-weight:600; }

      .main { display:flex; gap:14px; margin-top:6px; padding-bottom:18px; }
      .left { flex:2; background:transparent; padding-right:6px; }
      .right { flex:1; min-width:260px; }

      .controls { display:flex; gap:8px; align-items:center; flex-wrap:wrap; }
      .date-input::-webkit-calendar-picker-indicator { display:none; } /* hide native indicator to avoid confusion */

      /* ---------- Chart ---------- */
      .chart-wrap { background:#fff; padding:10px; border-radius:8px; box-shadow: inset 0 0 0 1px #f1f5f9; height:260px; margin-bottom:10px; }

      /* ---------- Table ---------- */
      table { width:100%; border-collapse:collapse; margin-top:8px; background:#fff; border-radius:6px; overflow:hidden; box-shadow:0 4px 20px rgba(2,6,23,0.03); }
      thead th {
        padding:10px 8px; font-weight:700; font-size:13px;
        background: linear-gradient(90deg,#fff,#fbfbfb);
        border-bottom:3px solid #e2e8f0;
        text-align:left;
      }
      tbody td { padding:8px; border-bottom:1px solid #f1f5f9; font-size:13px; color:#0f172a; vertical-align:middle; }
      .small { font-size:12px; color:var(--muted); }
      .row-click { cursor:pointer; color:#0f172a; }
      .flagged-row { background: linear-gradient(90deg,#fff8f0,#fff); }

      /* ---------- Chips & reasons ---------- */
      .pill { display:inline-block; padding:6px 10px; border-radius:999px; background:#f1f9ff; color:#064e76; font-size:12px; cursor:pointer; margin:2px; border:1px solid #e6f2ff; }
      .chip { display:inline-block; padding:6px 10px; border-radius:999px; background:#eef2ff; color:#034f84; font-size:13px; cursor:pointer; margin:3px; border:1px solid transparent; }
      .chip.active { background:#ffd; border-color:#f7c948; box-shadow:0 2px 6px rgba(39,39,56,0.06); }

      /* ---------- Evidence modal ---------- */
      .modal { position:fixed; left:0; right:0; top:0; bottom:0; display:flex; align-items:center; justify-content:center; z-index:1000; background: rgba(3,6,23,0.35); }
      .modal-inner { width:960px; max-width:96%; max-height:88%; overflow:auto; background:#fff; border-radius:8px; padding:14px; box-shadow:0 10px 40px rgba(2,6,23,0.3); border: 1px solid #e6edf3; }
      .modal-header { display:flex; align-items:center; justify-content:space-between; padding:12px; border-radius:6px; background: linear-gradient(90deg, var(--wu-yellow), #ffd966); color: #080808; margin:-14px -14px 6px -14px; }
      .modal-header h3 { margin:0; color:#000; font-size:16px; }
      .close-btn { background:#ef4444; color:#fff; border-radius:6px; padding:6px 10px; border:0; cursor:pointer; }

      .explain { background:#f8fafc; padding:10px; border-radius:8px; margin-top:8px; }

      /* ---------- Evidence table styles & highlight classes ---------- */
      .evidence-table { width:100%; border-collapse:collapse; margin-top:8px; }
      .evidence-table th, .evidence-table td { padding:8px 10px; border:1px solid #e6edf3; font-size:13px; text-align:left; vertical-align:middle; }
      .gap-flag { background:#fff5f0; color:#9a3412; padding:4px 6px; border-radius:6px; display:inline-block; margin-left:8px; font-weight:600; }

      /* Highlights requested by user */
      .row-day-start { background: linear-gradient(90deg,#eefbe8,#f7ffef); }       /* light green */
      .row-out-return { background: linear-gradient(90deg,#fff0f0,#fff6f6); }     /* light red */
      .row-out { background: linear-gradient(90deg,#fff7ed,#fffdf8); }            /* warm */
      .highlight-long-duration { outline: 2px solid rgba(239,68,68,0.12); }

      /* Loading overlay */
      .spinner-overlay {
        position: fixed;
        inset: 0;
        background: rgba(255,255,255,0.65);
        z-index: 2000;
        display:flex;
        align-items:center;
        justify-content:center;
        backdrop-filter: blur(2px);
      }
      .spinner-box {
        display:flex;
        gap:12px;
        align-items:center;
        background:#fff;
        padding:14px 18px;
        border-radius:10px;
        box-shadow: 0 10px 30px rgba(2,6,23,0.15);
        border: 1px solid #e6edf3;
      }
      .spinner {
        width:28px; height:28px; border-radius:50%; border:4px solid #e6e6e6; border-top-color:var(--accent); animation: spin 1s linear infinite;
      }
      @keyframes spin { 100% { transform: rotate(360deg); } }

      /* Small UI niceties */
      .muted { color:var(--muted); font-size:13px; }
      .evidence-btn { padding:7px 10px; background:#0ea5a4; color:#fff; border-radius:6px; border:0; cursor:pointer; }
      .small-button { padding:6px 8px; font-size:12px; border-radius:6px; border:1px solid #e2e8f0; background:transparent; cursor:pointer; }

      /* Make table horizontally scrollable on small screens */
      .table-scroll { overflow:auto; max-width:100%; }

      /* ---------- Responsive ---------- */
      @media (max-width: 900px) {
        .main { flex-direction: column; }
        .right { min-width:unset; width:100%; margin-top:12px; }
        .cards { flex-direction:row; gap:8px; }
        .chart-wrap { height:200px; }
        .header-actions { justify-content:flex-end; gap:8px; }
        .title-block h1 { max-width:200px; }
      }
      @media (max-width: 560px) {
        .topbar { padding:10px; }
        .wu-brand { width:100%; justify-content:flex-start; }
        .header-actions { width:100%; justify-content:flex-start; gap:8px; margin-top:8px; }
        .cards { flex-direction:column; }
        .card { width:100%; }
        .header-actions .date-input { width:140px; }
        .header-actions button { padding:8px 10px; }
      }


/* Smaller calendar input size */
.date-input {
  padding: 4px 6px;             /* reduce height */
  font-size: 12px;              /* smaller text */
  border-radius: 4px;           /* slightly rounded */
  min-width: 110px;             /* narrower input */
  background: #ffd700;          /* yellow-golden background */
  color: #000;                  /* dark text for contrast */
  border: 1px solid #b89f00;    /* subtle border */
}

/* Adjust Flatpickr calendar popup size */
.flatpickr-calendar {
  font-size: 12px;              /* smaller calendar text */
  transform: scale(0.9);        /* shrink entire calendar block */
  transform-origin: top left;
}


    </style>
  </head>
  <body>
    <div id="root"></div>

    <script type="text/babel">
      (function(){
        const { useState, useEffect, useRef } = React;

        // CHANGE THIS IF YOUR API HOST DIFFERS
        const API_BASE = "http://10.199.45.239:8002";

        // Threshold used to detect "long out then return" pattern (seconds)
        const OUT_RETURN_GAP_SECONDS = 60 * 60; // 1 hour (tweak if you want)

        const SCENARIO_EXPLANATIONS = {
          "long_gap_>=90min": "Long gap between swipes (>= 90 minutes) — could indicate long out-of-office break.",
          "short_duration_<4h": "Short total duration in office (< 4 hours).",
          "coffee_badging": "Frequent short badge cycles (>=4) with short duration — possible 'coffee badging'.",
          "low_swipe_count_<=2": "Low swipe count (<=2) for the day.",
          "single_door": "All swipes used the same door — single-door behavior.",
          "only_in": "Only IN swipe(s) recorded for the day.",
          "only_out": "Only OUT swipe(s) recorded for the day.",
          "overtime_>=10h": "Long duration (>=10 hours) — overtime.",
          "very_long_duration_>=16h": "Very long duration (>=16 hours) — suspiciously long presence.",
          "zero_swipes": "No swipes recorded.",
          "unusually_high_swipes": "Unusually high number of swipes versus historical median.",
          "repeated_short_breaks": "Multiple short breaks within the day.",
          "multiple_location_same_day": "Swipes recorded at multiple locations same day.",
          "weekend_activity": "Activity recorded on weekend.",
          "repeated_rejection_count": "Several card rejections.",
          "badge_sharing_suspected": "Badge sharing suspected (same card used by multiple persons on same day).",
          "early_arrival_before_06": "First swipe before 06:00.",
          "late_exit_after_22": "Last swipe after 22:00.",
          "shift_inconsistency": "Duration inconsistent with historical shift patterns.",
          "trending_decline": "Historical trending decline flagged.",
          "consecutive_absent_days": "Marked absent for consecutive days historically.",
          "high_variance_duration": "High variance in durations historically.",
          "short_duration_on_high_presence_days": "Short duration even though employee usually attends many days.",
          "swipe_overlap": "Simultaneous swipe(s) near the same time with other uid(s) (possible tailgating or collusion).",
          "shortstay_longout_repeat": "Pattern: short stay, long out-of-office, short return (repeat)."
        };

        function pad(n){ return n.toString().padStart(2,'0'); }
        function formatDateISO(d){
          if(!d) return "";
          const dt = (d instanceof Date) ? d : new Date(d);
          return dt.getFullYear() + "-" + pad(dt.getMonth()+1) + "-" + pad(dt.getDate());
        }
        function datesBetween(start, end){
          var out = [];
          var cur = new Date(start);
          while(cur <= end){
            out.push(new Date(cur));
            cur.setDate(cur.getDate()+1);
          }
          return out;
        }
        function safeDateDisplay(val){
          if(!val && val !== 0) return "";
          try {
            var d = (val instanceof Date) ? val : new Date(val);
            if(isNaN(d.getTime())) return String(val);
            return d.toLocaleString();
          } catch(e) {
            return String(val);
          }
        }
        function sanitizeName(row){
          return row.EmployeeName || row.EmployeeName_x || row.EmployeeName_y || row.person_uid || "";
        }
        function downloadCSV(rows, filename){
          if(!rows || !rows.length) { alert("No rows to export"); return; }
          var cols = Object.keys(rows[0]);
          var lines = [cols.join(",")];
          rows.forEach(function(r){
            var row = cols.map(function(c){
              var v = (r[c] === undefined || r[c] === null) ? "" : String(r[c]).replace(/\n/g,' ');
              return JSON.stringify(v);
            }).join(",");
            lines.push(row);
          });
          var blob = new Blob([lines.join("\n")], {type:'text/csv'});
          var url = URL.createObjectURL(blob);
          var a = document.createElement('a'); a.href = url; a.download = filename || 'export.csv'; a.click(); URL.revokeObjectURL(url);
        }

        // convert seconds -> "HH:mm:ss"
        function formatSecondsToHmsJS(seconds){
          if (seconds === null || seconds === undefined || seconds === '') return "-";
          const n = Number(seconds);
          if (isNaN(n) || !isFinite(n)) return "-";
          const s = Math.max(0, Math.floor(n));
          const hh = Math.floor(s / 3600);
          const mm = Math.floor((s % 3600) / 60);
          const ss = s % 60;
          return pad(hh) + ":" + pad(mm) + ":" + pad(ss);
        }

        function App(){
          var yesterday = new Date();
          yesterday.setDate(yesterday.getDate()-1);

          const [dateFrom, setDateFrom] = useState(formatDateISO(yesterday));
          const [dateTo, setDateTo] = useState(formatDateISO(new Date()));
          const [loading, setLoading] = useState(false);
          const [summary, setSummary] = useState({rows:0, flagged_rows:0, files:[], end_date:null});
          const [rows, setRows] = useState([]);
          const [reasonsCount, setReasonsCount] = useState({});
          const [filterText, setFilterText] = useState("");
          const [page, setPage] = useState(1);
          const [selectedReason, setSelectedReason] = useState("");
          const [reasonFilterText, setReasonFilterText] = useState("");
          const [modalRow, setModalRow] = useState(null);
          const [modalDetails, setModalDetails] = useState(null); // {aggregated_rows, raw_swipes, raw_swipe_files}
          const [modalLoading, setModalLoading] = useState(false);
          const pageSize = 25;
          const chartRef = useRef(null);
          const chartInst = useRef(null);

          // flatpickr refs
          const fromRef = useRef(null);
          const toRef = useRef(null);
          const fromFp = useRef(null);
          const toFp = useRef(null);

          useEffect(function(){
            // initialize flatpickr instances after component mounts
            if(window.flatpickr && fromRef.current && toRef.current){
              // destroy if existing
              try { if(fromFp.current) fromFp.current.destroy(); } catch(e){}
              try { if(toFp.current) toFp.current.destroy(); } catch(e){}

              fromFp.current = window.flatpickr(fromRef.current, {
                dateFormat: "Y-m-d",
                defaultDate: dateFrom,
                allowInput: true,
                onChange: function(selectedDates, str){
                  if(selectedDates && selectedDates.length){
                    const iso = formatDateISO(selectedDates[0]);
                    setDateFrom(iso);
                    // set min on To
                    try { if(toFp.current) toFp.current.set('minDate', iso); } catch(e){}
                    // if From > To, adjust To
                    if(dateTo && new Date(iso) > new Date(dateTo)){
                      setDateTo(iso);
                      try{ if(toFp.current) toFp.current.setDate(iso, true); }catch(e){}
                    }
                  }
                }
              });

              toFp.current = window.flatpickr(toRef.current, {
                dateFormat: "Y-m-d",
                defaultDate: dateTo,
                allowInput: true,
                onChange: function(selectedDates, str){
                  if(selectedDates && selectedDates.length){
                    const iso = formatDateISO(selectedDates[0]);
                    setDateTo(iso);
                    // set max on From
                    try { if(fromFp.current) fromFp.current.set('maxDate', iso); } catch(e){}
                    if(dateFrom && new Date(iso) < new Date(dateFrom)){
                      setDateFrom(iso);
                      try{ if(fromFp.current) fromFp.current.setDate(iso, true); }catch(e){}
                    }
                  }
                }
              });

              // ensure min/max initial sync
              try {
                if(fromFp.current) fromFp.current.set('maxDate', dateTo);
                if(toFp.current) toFp.current.set('minDate', dateFrom);
              } catch(e){}
            }

            // load latest initially
            loadLatest();

            // cleanup on unmount
            return function(){
              try{ if(fromFp.current) fromFp.current.destroy(); } catch(e){}
              try{ if(toFp.current) toFp.current.destroy(); } catch(e){}
            };
            // eslint-disable-next-line
          }, []);

          // keep flatpickr updated when dateFrom/dateTo change externally
          useEffect(function(){
            try { if(fromFp.current && dateFrom) fromFp.current.setDate(dateFrom, false); } catch(e){}
            try { if(toFp.current && dateTo) toFp.current.setDate(dateTo, false); } catch(e){}
            try { if(fromFp.current) fromFp.current.set('maxDate', dateTo); } catch(e){}
            try { if(toFp.current) toFp.current.set('minDate', dateFrom); } catch(e){}
          }, [dateFrom, dateTo]);

          async function runForRange(){
            setLoading(true);
            setRows([]);
            setSummary({rows:0, flagged_rows:0, files:[], end_date:null});
            setReasonsCount({});
            try {
              var start = new Date(dateFrom);
              var end = new Date(dateTo);
              var dateList = datesBetween(start, end).map(d => formatDateISO(d));
              var accRows = [];
              var totalRows = 0, totalFlagged = 0, files = [];
              for(var i=0;i<dateList.length;i++){
                var d = dateList[i];
                var url = API_BASE + "/run?date=" + d;
                var r = await fetch(url, { method:'GET' });
                if(!r.ok){
                  var txt = await r.text();
                  throw new Error("API returned " + r.status + ": " + txt);
                }
                var js = await r.json();
                var sample = js.sample || [];
                if(Array.isArray(sample) && sample.length) accRows = accRows.concat(sample);
                if(typeof js.rows === 'number') totalRows += js.rows; else totalRows += (Array.isArray(sample) ? sample.length : 0);
                totalFlagged += (js.flagged_rows || 0);
                if(js.files) files = files.concat(js.files);
              }
              setRows(accRows);
              setSummary({rows: totalRows, flagged_rows: totalFlagged, files: files, end_date: formatDateISO(new Date(dateTo))});
              computeReasons(accRows);
              setPage(1);
            } catch(err){
              alert("Error: " + err.message);
              console.error(err);
            } finally {
              setLoading(false);
            }
          }

          async function loadLatest(){
            setLoading(true);
            try{
              var r = await fetch(API_BASE + "/latest");
              if(!r.ok) throw new Error("latest failed: " + r.status);
              var js = await r.json();
              var sample = js.sample || [];
              if(!Array.isArray(sample)) sample = [];
              setRows(sample);
              setSummary({rows: (js.rows || sample.length || 0), flagged_rows: (sample.filter(function(x){ return !!x.Reasons; }).length || 0), files:[js.file]});
              computeReasons(sample);
              setPage(1);
            } catch(err){
              alert("Error: " + err.message + (err.message === 'latest failed: 0' ? " (check backend/CORS)" : ""));
              console.error(err);
            } finally {
              setLoading(false);
            }
          }

          function computeReasons(dataRows){
            var counts = {};
            (dataRows || []).forEach(function(r){
              if(!r.Reasons) return;
              var parts = String(r.Reasons).split(";").map(function(s){ return s.trim(); }).filter(Boolean);
              parts.forEach(function(p){ counts[p] = (counts[p] || 0) + 1; });
            });
            setReasonsCount(counts);
            buildChart(counts);
          }

          function buildChart(counts){
            var labels = Object.keys(counts).sort(function(a,b){ return counts[b] - counts[a]; });
            var values = labels.map(function(l){ return counts[l]; });
            var ctx = chartRef.current && chartRef.current.getContext ? chartRef.current.getContext('2d') : null;
            if(!ctx) return;
            try { if(chartInst.current) chartInst.current.destroy(); } catch(e){}
            chartInst.current = new Chart(ctx, {
              type:'bar',
              data:{ labels: labels, datasets:[{ label:'Events', data: values, backgroundColor: labels.map(()=> 'rgba(37,99,235,0.85)') }] },
              options:{ responsive:true, maintainAspectRatio:false, plugins:{ legend:{ display:false } }, scales:{ y:{ beginAtZero:true } } }
            });
          }

          // filtering & pagination
          var filtered = (rows || []).filter(function(r){
            var hay = (sanitizeName(r) + " " + (r.EmployeeID||"") + " " + (r.CardNumber||"") + " " + (r.Reasons||"")).toLowerCase();
            var textOk = !filterText || hay.indexOf(filterText.toLowerCase()) !== -1;
            var reasonOk = !selectedReason || (r.Reasons && ((";" + String(r.Reasons) + ";").indexOf(selectedReason) !== -1));
            return textOk && reasonOk;
          });
          var totalPages = Math.max(1, Math.ceil(filtered.length / pageSize));
          var pageRows = filtered.slice((page-1)*pageSize, page*pageSize);

          function exportFiltered(){
            downloadCSV(filtered, "trend_filtered_export.csv");
          }

          function onReasonClick(reason){
            if(!reason) { setSelectedReason(""); return; }
            if(selectedReason === reason) setSelectedReason(""); else setSelectedReason(reason);
            setPage(1);
          }

          // open evidence modal (explicit Evidence button)
          async function openEvidence(row){
            setModalRow(row);
            setModalDetails(null);
            setModalLoading(true);
            try {
              const q = encodeURIComponent(row.EmployeeID || row.person_uid || "");
              const resp = await fetch(API_BASE + "/record?employee_id=" + q);
              if(!resp.ok){
                const txt = await resp.text();
                throw new Error("record failed: " + resp.status + " - " + txt);
              }
              const js = await resp.json();
              const details = { aggregated_rows: js.aggregated_rows || [], raw_swipe_files: js.raw_swipe_files || [], raw_swipes: js.raw_swipes || [] };
              setModalDetails(details);
            } catch(e){
              alert("Failed loading details: " + e.message);
              console.error(e);
            } finally {
              setModalLoading(false);
            }
          }

          function closeModal(){ setModalRow(null); setModalDetails(null); }

          // convenience counts for cards
          var rowsCount = (summary && typeof summary.rows === 'number') ? summary.rows : (rows ? rows.length : 0);
          var flaggedCount = (summary && typeof summary.flagged_rows === 'number') ? summary.flagged_rows : (rows ? rows.filter(function(r){ return !!r.Reasons; }).length : 0);
          var flaggedPct = rowsCount ? Math.round((flaggedCount*100)/(rowsCount||1)) : 0;

          function renderOverlapCell(r){
            var ov = r.OverlapWith || r.swipe_overlap || r.overlap_with || null;
            if(ov && typeof ov === 'string'){
              var parts = ov.split(";").map(function(s){ return s.trim(); }).filter(Boolean);
              if(parts.length === 0) return <span className="muted">—</span>;
              return <span className="pill" title={ov}>{parts.length} overlap</span>;
            }
            return <span className="muted">—</span>;
          }

          function renderReasonChips(reasonText){
            if(!reasonText) return <span className="muted">—</span>;
            const parts = String(reasonText).split(";").map(s=>s.trim()).filter(Boolean);
            return parts.map((p,idx)=>(<span key={idx} className="pill" title={SCENARIO_EXPLANATIONS[p] || p}>{p}</span>));
          }

          function renderReasonExplanations(reasonText){
            if(!reasonText) return <div className="muted">No flags</div>;
            const parts = String(reasonText).split(";").map(s=>s.trim()).filter(Boolean);
            return (
              <div>
                {parts.map((p,idx)=>(
                  <div key={idx} style={{marginBottom:6}}>
                    <b>{p}</b> — <span className="small">{ SCENARIO_EXPLANATIONS[p] || "No explanation available." }</span>
                  </div>
                ))}
              </div>
            );
          }

          // render timeline with requested highlights:
          function renderSwipeTimeline(details, modalRow){
            if(!details || !details.raw_swipes || details.raw_swipes.length === 0){
              return <div className="muted">No raw swipe evidence available (person not flagged or raw file missing).</div>;
            }
            // copy & parse
            const all = details.raw_swipes.slice().map(r => {
              const obj = Object.assign({}, r);
              try {
                if(obj.Date && obj.Time){
                  obj.__ts = new Date(obj.Date + "T" + obj.Time);
                } else if(obj.Date && obj.Time === undefined && obj.LocaleMessageTime){
                  obj.__ts = new Date(obj.LocaleMessageTime);
                } else if(obj.LocaleMessageTime){
                  obj.__ts = new Date(obj.LocaleMessageTime);
                } else {
                  obj.__ts = null;
                }
              } catch(e){
                obj.__ts = null;
              }
              let gap = null;
              if(obj.SwipeGapSeconds !== undefined && obj.SwipeGapSeconds !== null){
                gap = Number(obj.SwipeGapSeconds);
                if(isNaN(gap)) gap = null;
              } else if(obj.SwipeGap){
                try {
                  const parts = String(obj.SwipeGap).split(':').map(p=>Number(p));
                  if(parts.length===3) gap = parts[0]*3600 + parts[1]*60 + parts[2];
                } catch(e){ gap = null; }
              }
              obj.__gap = gap;
              obj.__zone_l = String((obj.Zone || '')).toLowerCase();
              return obj;
            }).sort((a,b) => {
              if(a.__ts && b.__ts) return a.__ts - b.__ts;
              if(a.__ts) return -1;
              if(b.__ts) return 1;
              return 0;
            });

            const flags = new Array(all.length).fill({}).map(()=>({dayStart:false, outReturn:false}));
            for(let i=0;i<all.length;i++){
              const cur = all[i];
              const prev = all[i-1];
              try {
                const curDate = cur.Date ? cur.Date.slice(0,10) : (cur.__ts ? cur.__ts.toISOString().slice(0,10) : null);
                const prevDate = prev ? (prev.Date ? prev.Date.slice(0,10) : (prev.__ts ? prev.__ts.toISOString().slice(0,10) : null)) : null;
                if(!prev || prevDate !== curDate){
                  flags[i].dayStart = true;
                }
              } catch(e){}
            }
            for(let i=0;i<all.length-1;i++){
              const a = all[i], b = all[i+1];
              const aZone = a.__zone_l || '';
              const bZone = b.__zone_l || '';
              const bGap = b.__gap || 0;
              if(aZone.includes('out of office') || aZone.includes('out_of_office') || aZone.includes('out of') ){
                if(!bZone.includes('out of office') && (bGap >= OUT_RETURN_GAP_SECONDS || bGap === null && aZone.includes('out'))){
                  flags[i].outReturn = true;
                  flags[i+1].outReturn = true;
                }
              }
            }

            return (
              <div className="table-scroll">
                <table className="evidence-table" role="table" aria-label="Swipe timeline">
                  <thead>
                    <tr>
                      <th>Employee Name</th>
                      <th>Employee ID</th>
                      <th>Card</th>
                      <th>Date</th>
                      <th>Time</th>
                      <th>SwipeGap</th>
                      <th>Door</th>
                      <th>Direction</th>
                      <th>Zone</th>
                      <th>Note</th>
                    </tr>
                  </thead>
                  <tbody>
                    { all.map((rObj, idx) => {
                        const r = rObj || {};
                        const g = r.__gap;
                        const gapFormatted = (r.SwipeGap && String(r.SwipeGap).trim()) ? String(r.SwipeGap) :
                                              (g !== null && g !== undefined) ? formatSecondsToHmsJS(g) : "-";
                        const cls = [];
                        if(flags[idx].dayStart) cls.push('row-day-start');
                        if(flags[idx].outReturn) cls.push('row-out-return');
                        if(g && g >= OUT_RETURN_GAP_SECONDS) cls.push('highlight-long-duration');




                        
                        return (
                          <tr key={idx} className={cls.join(' ')}>
                            <td className="small">{ r.EmployeeName || '-' }</td>
                            <td className="small">{ r.EmployeeID || '-' }</td>
                            <td className="small">{ r.CardNumber || r.Card || '-' }</td>
                            <td className="small">{ r.Date || '-' }</td>
                            <td className="small">{ r.Time || (r.__ts ? r.__ts.toTimeString().slice(0,8) : '-') }</td>
                            <td className="small">{ gapFormatted }</td>
                            <td className="small" style={{minWidth:160}}>{ r.Door || '-' }</td>
                            <td className="small">{ r.Direction || '-' }</td>
                            <td className="small">{ r.Zone || '-' }</td>
                            <td className="small">{ r.Note || '-' }{ r._source ? <span className="muted"> ({r._source})</span> : null }</td>
                          </tr>
                        );
                      })
                    }
                  </tbody>
                </table>
              </div>
            );
          }

          return (
            <div className="container" aria-live="polite">
              {/* Loading overlay */}
              { loading && (
                <div className="spinner-overlay" role="status" aria-label="Loading">
                  <div className="spinner-box">
                    <div className="spinner" />
                    <div style={{fontWeight:700}}>Loading…</div>
                  </div>
                </div>
              ) }

              <div className="topbar" role="banner">
                <div className="wu-brand" aria-hidden={false}>
                  <div className="wu-logo">WU</div>
                  <div className="title-block">
                    <h1>Western Union — Trend Analysis</h1>
                    <p>Pune</p>
                  </div>
                </div>

                <div className="header-actions" role="region" aria-label="controls">
                  <div className="control">
                    <label className="small" htmlFor="fromDate">From</label>
                    <input id="fromDate" ref={fromRef} className="date-input" type="text" placeholder="YYYY-MM-DD" />
                  </div>

                  <div className="control">
                    <label className="small" htmlFor="toDate">To</label>
                    <input id="toDate" ref={toRef} className="date-input" type="text" placeholder="YYYY-MM-DD" />
                  </div>

                  <button className="btn-primary" onClick={runForRange} disabled={loading}>Run</button>
                  <button className="btn-ghost" onClick={loadLatest} disabled={loading}>Load latest</button>
                </div>
              </div>

              <div className="card-shell">
                <div className="cards" aria-hidden={loading}>
                  <div className="card" title="Rows analysed">
                    <h3>{ (rowsCount !== undefined && rowsCount !== null) ? rowsCount : 0 }</h3>
                    <p>Rows analysed</p>
                  </div>
                  <div className="card" title="Flagged rows">
                    <h3>{ (flaggedCount !== undefined && flaggedCount !== null) ? flaggedCount : 0 }</h3>
                    <p>Flagged rows</p>
                  </div>
                  <div className="card" title="Flagged rate">
                    <h3>{ flaggedPct }%</h3>
                    <p>Flagged rate</p>
                  </div>
                </div>

                <div className="main">
                  <div className="left">
                    <div className="chart-wrap">
                      <canvas ref={chartRef}></canvas>
                    </div>

                    <div style={{display:'flex',alignItems:'center',gap:8, marginTop:6}}>
                      <input placeholder="Search name, employee id, card or reason..." value={filterText} onChange={function(e){ setFilterText(e.target.value); setPage(1); }} style={{flex:1,padding:10,borderRadius:6,border:'1px solid #e6edf3'}} />
                      <div className="muted">Showing { filtered.length } / { rows.length } rows</div>
                      <button className="small-button" onClick={exportFiltered}>Export filtered</button>
                    </div>

                    <div style={{marginTop:10}} className="table-scroll" role="region" aria-label="results table">
                      <table>
                        <thead>
                          <tr>
                            <th>Employee</th>
                            <th className="small">ID</th>
                            <th className="small">Card</th>
                            <th className="small">Date</th>
                            <th className="small">Duration</th>
                            <th className="small">Reasons</th>
                            <th className="small">Overlap</th>
                            <th className="small">Evidence</th>
                          </tr>
                        </thead>
                        <tbody>
                          { pageRows.map(function(r, idx){
                              var empName = sanitizeName(r);
                              var displayDate = safeDateDisplay(r.Date || r.FirstSwipe || r.LastSwipe);
                              var durText = r.Duration || (r.DurationMinutes ? Math.round(r.DurationMinutes) + " min" : "");
                              var flagged = r.Reasons && String(r.Reasons).trim();

                              return (
                                <tr key={idx} className={ flagged ? "flagged-row" : "" }>
                                  <td className="row-click" onClick={function(){ openEvidence(r); }}>{ empName || <span className="muted">—</span> }</td>
                                  <td className="small">{ r.EmployeeID || "" }</td>
                                  <td className="small">{ r.CardNumber || "" }</td>
                                  <td className="small">{ displayDate }</td>
                                  <td className="small">{ durText }</td>
                                  <td className="small">{ renderReasonChips(r.Reasons) }</td>
                                  <td className="small">{ renderOverlapCell(r) }</td>
                                  <td className="small">
                                    <button className="evidence-btn" onClick={function(){ openEvidence(r); }}>Evidence</button>
                                  </td>
                                </tr>
                            );
                          }) }
                        </tbody>
                      </table>
                    </div>

                    <div style={{display:'flex', gap:8, alignItems:'center', marginTop:10}}>
                      <button onClick={function(){ setPage(function(p){ return Math.max(1,p-1); }); }} disabled={page<=1}>Prev</button>
                      <div className="muted">Page { page } / { totalPages }</div>
                      <button onClick={function(){ setPage(function(p){ return Math.min(totalPages,p+1); }); }} disabled={page>=totalPages}>Next</button>
                    </div>
                  </div>

                  <aside className="right" aria-label="side panel">
                    <div style={{marginBottom:12}}>
                      <strong>Files:</strong>
                      <div className="muted" style={{marginTop:6}}>{ (summary.files || []).join(", ") }</div>
                    </div>

                    <div style={{marginBottom:12}}>
                      <strong>Top reasons summary</strong>
                      <div className="small muted" style={{marginTop:6}}>Click a reason to filter the table by that reason. Click again to clear.</div>

                      <div style={{marginTop:8, display:'flex', gap:8}}>
                        <input placeholder="Filter reason list..." value={reasonFilterText} onChange={function(e){ setReasonFilterText(e.target.value); }} style={{flex:1, padding:'6px 8px', borderRadius:6, border:'1px solid #e2e8f0'}} />
                        <button className="small-button" onClick={function(){ setSelectedReason(''); setReasonFilterText(''); }}>Clear</button>
                      </div>

                      <div style={{marginTop:8, maxHeight:320, overflow:'auto'}}>
                        { Object.keys(reasonsCount).length === 0 && <div className="muted">No flags found</div> }
                        { Object.entries(reasonsCount).sort(function(a,b){ return b[1]-a[1]; }).filter(function(kv){
                            var name = kv[0];
                            if(!reasonFilterText) return true;
                            return name.toLowerCase().indexOf(reasonFilterText.toLowerCase()) !== -1;
                          }).slice(0, 50).map(function(kv){
                            var name = kv[0], count = kv[1];
                            var active = selectedReason === name;
                            return (
                              <div key={name} style={{display:'flex', alignItems:'center', justifyContent:'space-between', gap:8, marginBottom:6}}>
                                <button className={ "chip " + (active ? "active" : "") } style={{textAlign:'left', flex:1}} onClick={function(){ onReasonClick(name); }}>
                                  {name}
                                </button>
                                <div style={{minWidth:48, textAlign:'right'}} className="small"><b>{count}</b></div>
                              </div>
                            );
                          }) }
                      </div>
                    </div>
                  </aside>
                </div>
              </div>

              { modalRow &&
                <div className="modal" onClick={closeModal}>
                  <div className="modal-inner" onClick={function(e){ e.stopPropagation(); }}>
                    <div className="modal-header">
                      <h3>Details — Evidence</h3>
                      <button className="close-btn" onClick={closeModal}>Close</button>
                    </div>

                    { modalLoading && <div className="muted">Loading evidence…</div> }

                    <div style={{marginTop:8, display:'grid', gridTemplateColumns:'1fr 1fr', gap:12}}>
                      <div>
                        <div><strong>Name:</strong> { sanitizeName(modalRow) } </div>
                        <div><strong>EmployeeID:</strong> { modalRow.EmployeeID || "—" } </div>
                        <div><strong>Card:</strong> { modalRow.CardNumber || "—" } </div>
                      </div>
                      <div>
                        <div><strong>Date:</strong> { safeDateDisplay(modalRow.Date || modalRow.FirstSwipe) } </div>
                        <div><strong>Duration:</strong> { modalRow.Duration || (modalRow.DurationMinutes ? Math.round(modalRow.DurationMinutes) + " min" : "—") } </div>
                        <div><strong>Reasons:</strong> { renderReasonChips(modalRow.Reasons) } </div>
                      </div>
                    </div>

                    <div className="explain">
                      <strong>Why highlighted</strong>
                      <div style={{marginTop:6}}>
                        { renderReasonExplanations(modalRow.Reasons) }
                      </div>
                    </div>

                    <hr/>

                    <h4>Available evidence files</h4>
                    <div style={{marginTop:8}}>
                      { modalDetails && modalDetails.raw_swipe_files && modalDetails.raw_swipe_files.length > 0
                        ? <div>
                            <ul>
                              { modalDetails.raw_swipe_files.map((f,i)=>(
                                <li key={i}><b>{f}</b> — <button onClick={function(){ window.location = API_BASE + "/swipes/" + encodeURIComponent(f); }}>Download</button></li>
                              )) }
                            </ul>
                          </div>
                        : <div className="muted">No raw swipe files found for this person/date.</div>
                      }
                    </div>

                    <div style={{marginTop:12}}>
                      <strong>Swipe timeline (filtered for this person/date)</strong>
                      <div style={{marginTop:8}}>
                        { modalDetails ? renderSwipeTimeline(modalDetails, modalRow) : <div className="muted">Evidence not loaded yet.</div> }
                      </div>
                    </div>

                    <hr/>
                    <div style={{marginTop:8}}>
                      <label><input type="checkbox" id="showraw" onChange={function(e){
                        const el = document.getElementById('rawpayload');
                        if(el) el.style.display = e.target.checked ? 'block' : 'none';
                      }} /> Show raw aggregated JSON</label>
                      <div id="rawpayload" style={{display:'none', marginTop:8}}><pre>{ JSON.stringify(modalRow, null, 2) }</pre></div>
                    </div>

                  </div>
                </div>
              }
            </div>
          );
        }

        const root = ReactDOM.createRoot(document.getElementById('root'));
        root.render(React.createElement(App));
      })();
    </script>
  </body>
</html>












