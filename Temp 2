"""
Compare CCURE profiles/stats with local ActiveEmployee & ActiveContractor sheets.
Added: compute_visit_averages() - a focused function that strictly returns
the percentage of active employees and contractors who visited today,
aggregating live data across region_clients endpoints and using ccure stats.
"""

import os
import re
import uuid
import traceback
from datetime import datetime
from typing import List, Dict, Any, Optional

import pandas as pd
import numpy as np
import requests
import logging

from db import SessionLocal
from models import ActiveEmployee, ActiveContractor
from settings import OUTPUT_DIR  # ensure OUTPUT_DIR exists in your settings

logger = logging.getLogger("ccure_compare_service")
logger.setLevel(logging.INFO)
if not logger.handlers:
    ch = logging.StreamHandler()
    ch.setFormatter(logging.Formatter("%(asctime)s %(levelname)s %(name)s: %(message)s"))
    logger.addHandler(ch)

# ---------- Normalizers -------------------------------------------------------

def _normalize_employee_key(x) -> Optional[str]:
    if x is None:
        return None
    try:
        s = str(x).strip()
        if s == "" or s.lower() in ("nan", "none", "na", "null"):
            return None
        return s
    except Exception:
        return None

def _normalize_card_like(s) -> Optional[str]:
    if s is None:
        return None
    try:
        ss = str(s).strip()
        if ss == "":
            return None
        digits = re.sub(r'\D+', '', ss)  # keep digits only
        if digits == "":
            return None
        normalized = digits.lstrip('0') or digits
        return normalized
    except Exception:
        return None

def _normalize_name(s) -> Optional[str]:
    if s is None:
        return None
    try:
        t = str(s).strip().lower()
        t = re.sub(r'[^\w\s]', '', t)  # remove punctuation
        t = re.sub(r'\s+', ' ', t).strip()
        return t if t else None
    except Exception:
        return None

# ---------- CCURE client wrappers (best-effort) -------------------------------

def _fetch_ccure_stats() -> Optional[Dict[str, Any]]:
    """Return ccure_client.get_global_stats() result or None if unavailable/error."""
    try:
        import ccure_client
        if hasattr(ccure_client, "get_global_stats"):
            return ccure_client.get_global_stats()
    except Exception:
        logger.debug("ccure_client.get_global_stats not available", exc_info=True)
        return None
    return None

def _fetch_ccure_stats_totals_fallback():
    """
    If get_global_stats() is not available / incomplete, try to fetch /api/stats totals
    using ccure_client.fetch_stats_page(detail).
    Returns dict with integer totals or None values.
    """
    out = {"ActiveEmployees": None, "ActiveContractors": None, "ActiveProfiles": None}
    try:
        import ccure_client
        # try each detail: 'ActiveEmployees', 'ActiveContractors' etc.
        for key in ("ActiveEmployees", "ActiveContractors", "ActiveProfiles"):
            try:
                resp = None
                if hasattr(ccure_client, "fetch_stats_page"):
                    resp = ccure_client.fetch_stats_page(key, page=1, limit=1)
                # If API returns dict with 'total' key -> use it
                if isinstance(resp, dict) and "total" in resp:
                    out[key] = int(resp.get("total") or 0)
            except Exception:
                continue
    except Exception:
        logger.debug("ccure_client.fetch_stats_page not available", exc_info=True)
    return out

# ---------- Helpers for live-summary fetching --------------------------------

def _fetch_live_totals_from_region_clients(timeout=6):
    """
    Use region_clients.endpoints to fetch per-region live-summary(s).
    Returns tuple (employee_total:int or None, contractor_total:int or None, sites_queried:int)
    This function is defensive: fails per-region but continues.
    """
    emp_total = 0
    contr_total = 0
    sites = 0
    try:
        import region_clients
        endpoints = getattr(region_clients, "endpoints", None)
        if not isinstance(endpoints, dict):
            # if region_clients doesn't expose endpoints, bail
            return None, None, 0
    except Exception as e:
        logger.debug("region_clients import failed in _fetch_live_totals_from_region_clients", exc_info=True)
        return None, None, 0

    for region, url in endpoints.items():
        try:
            r = requests.get(url, timeout=timeout)
            r.raise_for_status()
            data = r.json()
            # prefer 'today' if present, else fallback to 'realtime' aggregated Employee/Contractor
            if isinstance(data, dict):
                if "today" in data and isinstance(data["today"], dict):
                    t = data["today"]
                    e = int(t.get("Employee") or 0)
                    c = int(t.get("Contractor") or 0)
                    emp_total += e
                    contr_total += c
                elif "realtime" in data and isinstance(data["realtime"], dict):
                    # sum Employee/Contractor across realtime partitions
                    for site in data["realtime"].values():
                        try:
                            emp_total += int(site.get("Employee") or 0)
                            contr_total += int(site.get("Contractor") or 0)
                        except Exception:
                            pass
                else:
                    # fallback: try 'total' top-level
                    if "total" in data:
                        try:
                            tot = int(data.get("total") or 0)
                            # if only total available, we cannot split employee/contractor; add to employee by default? No.
                            # We'll add to total as employee (conservative) is not acceptable; so skip.
                            pass
                        except Exception:
                            pass
            sites += 1
        except Exception as e:
            logger.warning(f"[compute_visit_averages] cannot fetch live-summary from {region}@{url}: {e}")
            continue

    if sites == 0:
        return None, None, 0
    return emp_total, contr_total, sites

# ---------- JSON sanitizer --------------------------------------------------

def _sanitize_for_json(value):
    """
    Convert pandas/numpy/datetime values to plain Python types for JSON.
    """
    try:
        import pandas as _pd
        import numpy as _np
    except Exception:
        _pd = None
        _np = None

    # None or pandas NA
    try:
        if value is None:
            return None
        if _pd is not None and _pd.isna(value):
            return None
    except Exception:
        pass

    # numpy numeric types
    if _np is not None:
        if isinstance(value, (_np.integer,)):
            return int(value)
        if isinstance(value, (_np.floating,)):
            v = float(value)
            if not _np.isfinite(v):
                return None
            return v
        if isinstance(value, (_np.bool_, bool)):
            return bool(value)

    # pandas Timestamp
    try:
        if _pd is not None and isinstance(value, _pd.Timestamp):
            try:
                return value.isoformat()
            except Exception:
                return str(value)
    except Exception:
        pass

    # datetime
    try:
        import datetime as _dt
        if isinstance(value, _dt.datetime):
            try:
                return value.isoformat()
            except Exception:
                return str(value)
    except Exception:
        pass

    # dict/list -> recurse
    if isinstance(value, dict):
        return {str(k): _sanitize_for_json(v) for k, v in value.items()}
    if isinstance(value, (list, tuple, set)):
        return [_sanitize_for_json(v) for v in value]

    # primitives
    if isinstance(value, (str, int, float, bool)):
        try:
            if isinstance(value, float):
                if _np is not None and not _np.isfinite(value):
                    return None
                if value != value:
                    return None
            return value
        except Exception:
            return None

    try:
        return str(value)
    except Exception:
        return None

# ---------- Compute visit averages -------------------------------------------

def compute_visit_averages(timeout=6) -> Dict[str, Any]:
    """
    Strictly compute averages:
      - Uses CCURE stats for ActiveEmployees and ActiveContractors (best-effort)
      - Aggregates live 'today' Employee/Contractor counts across all region_clients endpoints
      - Returns JSON-safe dict:
          {
            "live_today": {"employee": int, "contractor": int, "total": int},
            "ccure_active": {"active_employees": int|None, "active_contractors": int|None},
            "averages": {"employee_pct": float|None, "contractor_pct": float|None, "overall_pct": float|None},
            "sites_queried": int,
            "notes": "...optional..."
          }
    If denominators are missing or zero, percentages are returned as None.
    """
    notes = []
    # 1) fetch ccure stats
    ccure_stats = _fetch_ccure_stats()
    active_emps = None
    active_contracts = None
    if isinstance(ccure_stats, dict):
        try:
            if "ActiveEmployees" in ccure_stats:
                v = ccure_stats.get("ActiveEmployees")
                active_emps = int(v) if v not in (None, "") else None
            if "ActiveContractors" in ccure_stats:
                v = ccure_stats.get("ActiveContractors")
                active_contracts = int(v) if v not in (None, "") else None
            # Some APIs name these differently; attempt alternatives
            if active_emps is None and "ActiveEmployeesCount" in ccure_stats:
                try:
                    active_emps = int(ccure_stats.get("ActiveEmployeesCount"))
                except Exception:
                    pass
            if active_contracts is None and "ActiveContractorsCount" in ccure_stats:
                try:
                    active_contracts = int(ccure_stats.get("ActiveContractorsCount"))
                except Exception:
                    pass
        except Exception:
            logger.exception("Error coercing ccure_stats totals")
    # fallback to per-detail /api/stats totals if get_global_stats returned None or missing keys
    if active_emps is None or active_contracts is None:
        try:
            fallback = _fetch_ccure_stats_totals_fallback()
            if active_emps is None:
                active_emps = int(fallback.get("ActiveEmployees")) if fallback.get("ActiveEmployees") not in (None, "") else None
            if active_contracts is None:
                active_contracts = int(fallback.get("ActiveContractors")) if fallback.get("ActiveContractors") not in (None, "") else None
        except Exception:
            logger.debug("ccure stats fallback failed", exc_info=True)

    # 2) fetch live totals across region_clients endpoints
    live_emp = None
    live_con = None
    sites = 0
    try:
        emp_total, contr_total, sites = _fetch_live_totals_from_region_clients(timeout=timeout)
        if emp_total is not None:
            live_emp = int(emp_total)
        if contr_total is not None:
            live_con = int(contr_total)
    except Exception:
        logger.exception("Failed to fetch live totals")

    # If live_emp/live_con none but a default single endpoint exists (try common EMEA endpoint)
    if (live_emp is None or live_con is None) and sites == 0:
        # try a last-resort direct call (use your default occupancy host)
        try:
            url = "http://10.199.22.57:3007/api/occupancy/live-summary"
            r = requests.get(url, timeout=timeout)
            r.raise_for_status()
            data = r.json()
            if isinstance(data, dict) and "today" in data and isinstance(data["today"], dict):
                t = data["today"]
                live_emp = int(t.get("Employee") or 0)
                live_con = int(t.get("Contractor") or 0)
                sites = 1
                notes.append("Used default single occupancy endpoint fallback.")
        except Exception:
            logger.debug("fallback direct occupancy call failed", exc_info=True)

    # 3) compute percentages safely
    def safe_pct(numer, denom):
        try:
            if denom and denom > 0:
                return round((numer / denom) * 100.0, 6)
        except Exception:
            pass
        return None

    total_live = None
    if live_emp is not None and live_con is not None:
        total_live = int(live_emp + live_con)

    emp_pct = None
    contr_pct = None
    overall_pct = None
    if live_emp is not None and active_emps not in (None, 0):
        emp_pct = safe_pct(live_emp, active_emps)
    if live_con is not None and active_contracts not in (None, 0):
        contr_pct = safe_pct(live_con, active_contracts)
    if total_live is not None and ( (active_emps or 0) + (active_contracts or 0) ) > 0:
        overall_pct = safe_pct(total_live, ( (active_emps or 0) + (active_contracts or 0) ))

    result = {
        "live_today": {
            "employee": _sanitize_for_json(live_emp),
            "contractor": _sanitize_for_json(live_con),
            "total": _sanitize_for_json(total_live)
        },
        "ccure_active": {
            "active_employees": _sanitize_for_json(active_emps),
            "active_contractors": _sanitize_for_json(active_contracts)
        },
        "averages": {
            "employee_pct": _sanitize_for_json(emp_pct),
            "contractor_pct": _sanitize_for_json(contr_pct),
            "overall_pct": _sanitize_for_json(overall_pct)
        },
        "sites_queried": int(sites or 0),
        "notes": None
    }

    if not (active_emps or active_contracts):
        result["notes"] = "CCURE active counts unavailable; percentages may be None."
    if sites == 0:
        if result["notes"]:
            result["notes"] += " No live-summary endpoints returned data."
        else:
            result["notes"] = "No live-summary endpoints returned data."

    return _sanitize_for_json(result)

# ---------------------------------------------------------------------------
# The remainder of your previous compare_ccure_vs_sheets implementation
# is preserved below (unchanged). I'm keeping it as-is so other functionality
# continues to work. You already had a long implementation; to avoid duplication
# in this reply I will keep that implementation intact in your project.
# If you want me to apply the same "sanitization / small refactors" to the compare
# function I can do that next — just say so.
# ---------------------------------------------------------------------------

# NOTE: If you want the compute_visit_averages incorporated into the main
# compare_ccure_vs_sheets payload, you can call compute_visit_averages() from
# there and add its result into the response under "visit_averages".
#
# End of file.











Ok good now I to calculate average 
Using Active employees and Active contractors 
Details with comparing 
Daily live -summary API 

Initially fetch 

http://10.199.22.57:5001/api/stats?details=ActiveEmployees&page=1&limit=50

{
  "total": 8635,
  "page": 1,
  "limit": 50,
  "data": [
    {
      "id": 2097197204,
      "EmpName": "., Anushka",
      "EmployeeID": "319473",
      "PersonnelType": "Employee",
      "Manager_Name": "Rawat, Mayank",
      "Manager_WU_ID": "0",
      "Profile_Disabled": false,
      "Total_Cards": 1,
      "Active_Cards": 1,
      "Employee_Status": "Active",
      "imageUrl": "/api/employees/2097197204/image"
    },
    {
      "id": 2097203526,
      "EmpName": "., Diwakar",
      "EmployeeID": "324002",
      "PersonnelType": "Employee",
      "Manager_Name": "Charkha, Bhakti",
      "Manager_WU_ID": "0",
      "Profile_Disabled": false,
      "Total_Cards": 1,
      "Active_Cards": 1,
      "Employee_Status": "Active",
      "imageUrl": "/api/employees/2097203526/image"
    },




http://10.199.22.57:5001/api/stats?details=ActiveContractors&page=1&limit=50


{
  "total": 664,
  "page": 1,
  "limit": 50,
  "data": [
    {
      "id": 2097209941,
      "EmpName": "Abdalla, Meira",
      "EmployeeID": "W0026455",
      "PersonnelType": "Contractor",
      "Manager_Name": "Luis Rodriguez ",
      "Manager_WU_ID": "0",
      "Profile_Disabled": false,
      "Total_Cards": 2,
      "Active_Cards": 2,
      "Employee_Status": "Active",
      "imageUrl": "/api/employees/2097209941/image"
    },
    {
      "id": 2097202322,
      "EmpName": "Acosta, Victor",
      "EmployeeID": "W0013788",
      "PersonnelType": "Contractor",
      "Manager_Name": "Annie Vassallo",
      "Manager_WU_ID": "315081",
      "Profile_Disabled": false,
      "Total_Cards": 2,
      "Active_Cards": 1,
      "Employee_Status": "Active",
      "imageUrl": "/api/employees/2097202322/image"
    },





Using this API 
Monitor each Employee and Contractor Swipe from 

http://10.199.22.57:3007/api/occupancy/live-summary

{
  "success": true,
  "today": {
    "total": 329,
    "Employee": 309,
    "Contractor": 20
  },
  "realtime": {
    "LT.Vilnius": {
      "total": 156,
      "Employee": 147,
      "Contractor": 9,
      "floors": {
        "1st Floor": 26,
        "8th Floor": 22,
        "6th Floor": 18,
        "3rd Floor": 7,
        "9th Floor": 19,
        "7th Floor": 14,
        "5th Floor": 12,
        "2nd Floor": 11,
        "10th Floor": 20,
        "4th Floor": 7
      }
    },
    "MA.Casablanca": {
      "total": 8,
      "Employee": 7,
      "Contractor": 1,
      "floors": {
        "7th Floor": 8
      }
    },
    "AUT.Vienna": {
      "total": 21,
      "Employee": 19,
      "Contractor": 2,
      "floors": {
        "11th Floor": 21
      }
    },
    "IE.Dublin": {
      "total": 5,
      "Employee": 5,
      "Contractor": 0,
      "floors": {
        "Dublin": 5
      }
    },
    "UK.London": {
      "total": 11,
      "Employee": 11,
      "Contractor": 0,
      "floors": {
        "London": 11
      }
    },
    "ES.Madrid": {
      "total": 20,
      "Employee": 19,
      "Contractor": 1,
      "floors": {
        "Madrid": 20
      }
    },
    "DU.Abu Dhab": {
      "total": 12,
      "Employee": 11,
      "Contractor": 1,
      "floors": {
        "Dubai": 12
      }
    },
    "RU.Moscow": {
      "total": 5,
      "Employee": 4,
      "Contractor": 1,
      "floors": {
        "Moscow": 5
      }
    }
  },
  "details": [
    {
      "LocaleMessageTime": "2025-08-22T06:29:08.000Z",
      "Dateonly": "2025-08-22",
      "Swipe_Time": "06:29:08",
      "EmployeeID": "86142356",
      "PersonGUID": "EF662CB7-25AF-4D49-8B3D-7C7D843CFE5A",
      "ObjectName1": "Valiunas, Sigitas",
      "Door": "EMEA_LT_VNO_GAMA_1st Flr_Security Room",
      "PersonnelType": "Contractor",
      "CardNumber": "615409",
      "Text5": "Vilnius - Technopolis",
      "PartitionName2": "LT.Vilnius",
      "AdmitCode": "Admit",
      "Direction": "InDirection",
      "Floor": "1st Floor"
    },
    {
      "LocaleMessageTime": "2025-08-22T11:24:16.000Z",
      "Dateonly": "2025-08-22",
      "Swipe_Time": "11:24:16",
      "EmployeeID": "314280",
      "PersonGUID": "DBFBDBF8-CDEA-4224-97CF-56AE9D5A078F",
      "ObjectName1": "Jaraminas, Egidijus",
      "Door": "EMEA_LT_VNO_GAMA_8th Flr_Main Entrance",
      "PersonnelType": "Employee",
      "CardNumber": "619283",
      "Text5": "Vilnius - Gama Business Center",
      "PartitionName2": "LT.Vilnius",
      "AdmitCode": "Admit",
      "Direction": "InDirection",
      "Floor": "8th Floor"
    },
    {
      "LocaleMessageTime": "2025-08-22T12:22:29.000Z",
      "Dateonly": "2025-08-22",
      "Swipe_Time": "12:22:29",
      "EmployeeID": "W0024344",
      "PersonGUID": "8C17E9D2-8327-4B75-8B2C-E105DBA74850",
      "ObjectName1": "Sablinskaja, Helena",
      "Door": "EMEA_LT_VNO_GAMA_6th Flr_Main Entrance",
      "PersonnelType": "Contractor",
      "CardNumber": "615345",
      "Text5": "Vilnius - Technopolis",
      "PartitionName2": "LT.Vilnius",
      "AdmitCode": "Admit",
      "Direction": "InDirection",
      "Floor": "6th Floor"
    },
    {
      "LocaleMessageTime": "2025-08-22T11:57:40.000Z",
      "Dateonly": "2025-08-22",
      "Swipe_Time": "11:57:40",
      "EmployeeID": "W0021570",
      "PersonGUID": "13273C3C-FBB1-4A1C-94D4-EE5C858728A4",
      "ObjectName1": "Laseviciene, Stasele",
      "Door": "EMEA_LT_VNO_GAMA_EMEA_3rd Flr Stairway",
      "PersonnelType": "Contractor",
      "CardNumber": "615333",
      "Text5": "Vilnius - Technopolis",
      "PartitionName2": "LT.Vilnius",
      "AdmitCode": "Admit",
      "Direction": "InDirection",
      "Floor": "3rd Floor"
    },


With all Live Summary API and 

Cpmraing all Live Summary API with Active Employee and Contractor 
calculate AVerage of ACtive Employee & Contractor Visited today 

so Which file need to Upadte ..

initailly strickly Calculate only Average ...



# region_clients.py
import requests
from requests.exceptions import RequestException

# Edit endpoints if your hosts/ports differ
endpoints = {
    "namer": "http://10.199.22.57:3006/api/occupancy/live-summary",
    "emea":  "http://10.199.22.57:3007/api/occupancy/live-summary",
    "laca":  "http://10.199.22.57:4000/api/occupancy/live-summary",
    "apac":  "http://10.199.22.57:3008/api/occupancy/live-summary"
}

def fetch_all_regions():
    """Return list of dicts: [{region: name, count: N}, ...]"""
    results = []
    for region, url in endpoints.items():
        try:
            r = requests.get(url, timeout=6)
            r.raise_for_status()
            data = r.json()
            realtime = data.get("realtime", {}) if isinstance(data, dict) else {}
            total = 0
            for site in realtime.values():
                try:
                    total += int(site.get("total", 0))
                except Exception:
                    pass
            results.append({"region": region, "count": total})
        except RequestException as e:
            # log to console for now
            print(f"[region_clients] error fetching {region} @ {url}: {e}")
            results.append({"region": region, "count": None})
    return results

def fetch_all_details():
    """
    Return flattened 'details' list across all regions (tagged with '__region').
    Returns an empty list if none available.
    """
    all_details = []
    for region, url in endpoints.items():
        try:
            r = requests.get(url, timeout=6)
            r.raise_for_status()
            data = r.json()
            details = data.get("details", []) if isinstance(data, dict) else []
            for d in details:
                d2 = dict(d)
                d2["__region"] = region
                all_details.append(d2)
        except RequestException as e:
            print(f"[region_clients] warning: cannot fetch details from {region}@{url}: {e}")
            continue
        except Exception as e:
            print(f"[region_clients] unexpected error for {region}: {e}")
            continue
    return all_details







# app.py
from fastapi import FastAPI, UploadFile, File, HTTPException, Request, Query
from fastapi.responses import JSONResponse, FileResponse
import shutil, uuid, json
from settings import UPLOAD_DIR, OUTPUT_DIR
from pathlib import Path
import logging

app = FastAPI(title="Attendance Analytics")

logger = logging.getLogger("attendance_app")
logger.setLevel(logging.INFO)
if not logger.handlers:
    ch = logging.StreamHandler()
    ch.setFormatter(logging.Formatter("%(asctime)s %(levelname)s %(name)s: %(message)s"))
    logger.addHandler(ch)

@app.get("/ccure/compare")
def ccure_compare(
    mode: str = Query("full", description="full or stats"),
    stats_detail: str = Query("ActiveProfiles", description="when mode=stats use this"),
    limit_list: int = Query(200, ge=1, le=5000, description="max rows returned in list samples"),
    export: bool = Query(False, description="if true, writes Excel report to server and returns report_path")
):
    try:
        from ccure_compare_service import compare_ccure_vs_sheets
    except Exception as e:
        logger.exception("ccure_compare_service import failed")
        raise HTTPException(status_code=500, detail=f"compare service unavailable: {e}")
    # run compare (the function itself is defensive)
    res = compare_ccure_vs_sheets(mode=mode, stats_detail=stats_detail, limit_list=limit_list, export=export)
    # Ensure result is a dict for JSONResponse
    if not isinstance(res, dict):
        return JSONResponse({"error": "compare service returned unexpected result"}, status_code=500)
    return JSONResponse(res)



@app.get("/ccure/report/{filename}")
def ccure_report_download(filename: str):
    try:
        safe_name = Path(filename).name
        full = Path(OUTPUT_DIR) / safe_name
        if not full.exists() or not full.is_file():
            raise HTTPException(status_code=404, detail="Report not found")
        return FileResponse(
            str(full),
            media_type="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
            filename=safe_name
        )
    except HTTPException:
        raise
    except Exception as e:
        logger.exception("Failed to serve report")
        raise HTTPException(status_code=500, detail=f"Failed to serve report: {e}")


@app.post("/upload/active-employees")
async def upload_active_employees(file: UploadFile = File(...)):
    if not file.filename.endswith(('.xls', '.xlsx')):
        raise HTTPException(400, "Please upload an Excel file")
    dest = Path(UPLOAD_DIR) / f"{uuid.uuid4().hex}_{file.filename}"
    with open(dest, "wb") as buffer:
        shutil.copyfileobj(file.file, buffer)
    try:
        from ingest_excel import ingest_employee_excel
    except Exception as e:
        logger.exception("ingest_excel import failed")
        raise HTTPException(status_code=500, detail=f"ingest_excel import failed: {e}")
    ingest_employee_excel(dest)
    return {"status":"ok", "path": str(dest)}

@app.post("/upload/active-contractors")
async def upload_active_contractors(file: UploadFile = File(...)):
    if not file.filename.endswith(('.xls', '.xlsx')):
        raise HTTPException(400, "Please upload an Excel file")
    dest = Path(UPLOAD_DIR) / f"{uuid.uuid4().hex}_{file.filename}"
    with open(dest, "wb") as buffer:
        shutil.copyfileobj(file.file, buffer)
    try:
        from ingest_excel import ingest_contractor_excel
    except Exception as e:
        logger.exception("ingest_excel import failed")
        raise HTTPException(status_code=500, detail=f"ingest_excel import failed: {e}")
    ingest_contractor_excel(dest)
    return {"status":"ok", "path": str(dest)}

# Keep other endpoints unchanged (ingest/fetch-all, reports/daily)...
# (If you want, I can paste the rest verbatim — I left them as before to minimize changes.)


@app.post("/ingest/live-details")
async def ingest_live(request: Request):
    """
    Accepts:
      - Raw JSON array in body (preferred)
      - JSON object with {"details": [...]} in body
      - multipart/form-data where a form field 'details' contains a JSON string
    """
    details = None
    # Try direct JSON
    try:
        body = await request.json()
        if isinstance(body, dict) and 'details' in body:
            details = body['details']
        else:
            details = body
    except Exception:
        # not JSON, try form
        try:
            form = await request.form()
            if 'details' in form:
                raw = form['details']
                if isinstance(raw, str):
                    details = json.loads(raw)
                else:
                    try:
                        details = json.loads((await raw.read()).decode('utf-8'))
                    except Exception:
                        details = list(form.getlist('details'))
            else:
                # attempt first field
                first = None
                for v in form.values():
                    first = v
                    break
                if isinstance(first, str):
                    details = json.loads(first)
                else:
                    raise HTTPException(status_code=400, detail="No JSON payload found")
        except Exception as e:
            raise HTTPException(status_code=400, detail=f"Could not parse request body as JSON or form: {e}")

    if not isinstance(details, (list, tuple)):
        raise HTTPException(status_code=400, detail="Expected top-level array (JSON list) of detail objects")

    try:
        from compare_service import ingest_live_details_list
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"compare_service import failed: {e}")

    try:
        res = ingest_live_details_list(details)
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Failed to ingest details: {e}")

    if isinstance(res, dict):
        return {"status": "ok", **res}
    return {"status": "ok", "inserted": len(details)}


@app.get("/ingest/fetch-all")
def fetch_all_and_ingest():
    try:
        import region_clients
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"region_clients unavailable: {e}")

    details = region_clients.fetch_all_details()
    if not isinstance(details, list):
        raise HTTPException(status_code=500, detail="Unexpected data from region_clients.fetch_all_details")

    try:
        from compare_service import ingest_live_details_list
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"compare_service import failed: {e}")

    res = ingest_live_details_list(details)
    if isinstance(res, dict):
        return {"status":"ok", **res}
    return {"status":"ok", "inserted": len(details)}


@app.get("/reports/daily/{yyyymmdd}")
def daily_report(yyyymmdd: str):
    import datetime
    try:
        dt = datetime.datetime.strptime(yyyymmdd, "%Y%m%d").date()
    except Exception:
        raise HTTPException(status_code=400, detail="Date must be in YYYYMMDD format")

    try:
        from compare_service import compute_daily_attendance, compare_with_active
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"compare_service import failed: {e}")

    # compute attendance summary (will build attendance_summary rows)
    compute_daily_attendance(dt)

    # compare vs active and CCURE
    summary = compare_with_active(dt)
    return JSONResponse(summary)


# additional endpoints to fetch CCure stats directly (optional)
@app.get("/ccure/stats")
def ccure_stats():
    try:
        import ccure_client
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"ccure_client import failed: {e}")
    try:
        stats = ccure_client.get_global_stats()
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"ccure_client.get_global_stats failed: {e}")
    return stats






# ccure_compare_service.py
"""
Compare CCURE profiles/stats with local ActiveEmployee & ActiveContractor sheets.

This version:
 - Prefers ccure_client /api/stats totals when available.
 - When 'mode=full' fetches CCURE profiles and compares only CCURE active employees
   and CCURE active contractors against the ActiveEmployee/ActiveContractor sheets.
 - Returns only the CCURE-but-missing-in-sheet samples (separated by employee/contractor).
"""

import os
import re
import uuid
import traceback
from datetime import datetime
from typing import List, Dict, Any, Optional

import pandas as pd
import numpy as np

from db import SessionLocal
from models import ActiveEmployee, ActiveContractor
from settings import OUTPUT_DIR  # ensure OUTPUT_DIR exists in your settings

# ---------- Normalizers -------------------------------------------------------

def _normalize_employee_key(x) -> Optional[str]:
    if x is None:
        return None
    try:
        s = str(x).strip()
        if s == "" or s.lower() in ("nan", "none", "na", "null"):
            return None
        return s
    except Exception:
        return None

def _normalize_card_like(s) -> Optional[str]:
    if s is None:
        return None
    try:
        ss = str(s).strip()
        if ss == "":
            return None
        digits = re.sub(r'\D+', '', ss)  # keep digits only
        if digits == "":
            return None
        normalized = digits.lstrip('0') or digits
        return normalized
    except Exception:
        return None

def _normalize_name(s) -> Optional[str]:
    if s is None:
        return None
    try:
        t = str(s).strip().lower()
        t = re.sub(r'[^\w\s]', '', t)  # remove punctuation
        t = re.sub(r'\s+', ' ', t).strip()
        return t if t else None
    except Exception:
        return None

# ---------- CCURE client wrappers (best-effort) -------------------------------

def _fetch_ccure_stats() -> Optional[Dict[str, Any]]:
    """Return ccure_client.get_global_stats() result or None if unavailable/error."""
    try:
        import ccure_client
        if hasattr(ccure_client, "get_global_stats"):
            return ccure_client.get_global_stats()
    except Exception:
        return None
    return None

def _fetch_ccure_profiles(mode: str = "full", limit: int = 1000) -> List[Dict[str, Any]]:
    """
    Try to fetch full CCURE profiles (if ccure_client exposes such an API).
    Returns list of dicts (possibly empty).
    """
    try:
        import ccure_client
        # Preferred method names (some integrations differ)
        for fn in ("get_profiles", "fetch_profiles", "get_all_profiles", "fetch_all_employees_full", "fetch_all_employees"):
            if hasattr(ccure_client, fn):
                try:
                    method = getattr(ccure_client, fn)
                    # some methods accept (limit, mode) others accept none; try both safely
                    try:
                        return method(limit=limit, mode=mode) or []
                    except TypeError:
                        try:
                            return method() or []
                        except Exception:
                            continue
                except Exception:
                    continue
    except Exception:
        return []
    return []

# ---------- Helpers ----------------------------------------------------------

def _extract_card_from_raw(raw: Any) -> Optional[str]:
    """If raw is dict-like, scan common card keys and numeric-looking values."""
    if not isinstance(raw, dict):
        return None
    keys = [
        "CardNumber","card_number","Card","Card No","CardNo","Badge","BadgeNo",
        "IPassID","iPass ID","IPASSID","Badge Number"
    ]
    for k in keys:
        v = raw.get(k)
        if v:
            c = _normalize_card_like(v)
            if c:
                return c
    # fallback: scan values for numeric string candidates
    for v in raw.values():
        try:
            c = _normalize_card_like(v)
            if c and 3 <= len(c) <= 12:
                return c
        except Exception:
            continue
    return None

def _build_sheet_df(session) -> pd.DataFrame:
    """Return dataframe of active people (employees + contractors) with normalized keys."""
    act_rows = session.query(ActiveEmployee).all()
    contr_rows = session.query(ActiveContractor).all()

    recs = []
    for e in act_rows:
        empid = _normalize_employee_key(e.employee_id)
        raw_card = _extract_card_from_raw(e.raw_row or {}) if hasattr(e, 'raw_row') else None
        recs.append({
            "source": "employee_sheet",
            "employee_id": empid,
            "full_name": e.full_name,
            "full_name_norm": _normalize_name(e.full_name),
            "card_number": raw_card,
            "card_number_norm": _normalize_card_like(raw_card),
            "location_city": e.location_city,
            "status": e.current_status,
            "raw_row": e.raw_row
        })
    for c in contr_rows:
        wsid = _normalize_employee_key(getattr(c, "worker_system_id", None))
        ipass = _normalize_employee_key(getattr(c, "ipass_id", None))
        primary = wsid or ipass
        raw_card = _extract_card_from_raw(c.raw_row or {}) if hasattr(c, 'raw_row') else None
        recs.append({
            "source": "contractor_sheet",
            "employee_id": primary,
            "full_name": c.full_name,
            "full_name_norm": _normalize_name(c.full_name),
            "card_number": raw_card,
            "card_number_norm": _normalize_card_like(raw_card),
            "location_city": getattr(c, "location", None),
            "status": getattr(c, "status", None),
            "raw_row": c.raw_row
        })
    df = pd.DataFrame(recs)
    if df.empty:
        df = pd.DataFrame(columns=[
            "source","employee_id","full_name","full_name_norm","card_number","card_number_norm","location_city","status","raw_row"
        ])
    # Normalize / sanitize columns
    for col in ["employee_id","card_number","full_name","full_name_norm","card_number_norm"]:
        if col not in df.columns:
            df[col] = None
        else:
            df[col] = df[col].astype(object).where(pd.notna(df[col]), None)
    return df

def _build_ccure_df(profiles: List[Dict[str, Any]]) -> pd.DataFrame:
    """
    Convert a list of CCURE profile dicts into a normalized DataFrame.
    We try to extract employee id, full name, card number, partition/location and personnel type/status.
    """
    rows = []
    for p in profiles:
        emp_keys = ["EmployeeID", "employee_id", "Employee Id", "BadgeId", "Badge", "Worker System Id", "Worker System ID"]
        name_keys = ["FullName", "full_name", "Name", "ObjectName1"]
        card_keys = ["CardNumber","card_number","BadgeNo","Badge","IPassID","iPass ID","card"]
        loc_keys = ["PartitionName","Partition","Region","Location","Site","Location City"]
        personnel_keys = ["PersonnelType", "Personnel Type", "PersonType"]
        status_keys = ["Employee_Status", "Employee Status", "Status", "EmployeeStatus"]

        emp = None
        for k in emp_keys:
            if isinstance(p, dict) and k in p and p.get(k):
                emp = p.get(k)
                break
        name = None
        for k in name_keys:
            if isinstance(p, dict) and k in p and p.get(k):
                name = p.get(k)
                break
        card = None
        for k in card_keys:
            if isinstance(p, dict) and k in p and p.get(k):
                card = p.get(k)
                break
        loc = None
        for k in loc_keys:
            if isinstance(p, dict) and k in p and p.get(k):
                loc = p.get(k)
                break
        personnel = None
        for k in personnel_keys:
            if isinstance(p, dict) and k in p and p.get(k):
                personnel = p.get(k)
                break
        status = None
        for k in status_keys:
            if isinstance(p, dict) and k in p and p.get(k):
                status = p.get(k)
                break

        rows.append({
            "ccure_raw": p,
            "employee_id": _normalize_employee_key(emp),
            "full_name": name,
            "full_name_norm": _normalize_name(name),
            "card_number": _normalize_card_like(card),
            "location_city": loc,
            "personnel_type": (str(personnel).strip() if personnel is not None else None),
            "employee_status": (str(status).strip() if status is not None else None)
        })
    df = pd.DataFrame(rows)
    if df.empty:
        df = pd.DataFrame(columns=["ccure_raw","employee_id","full_name","full_name_norm","card_number","location_city","personnel_type","employee_status"])
    # sanitize text columns
    for col in ["employee_id", "full_name", "full_name_norm", "card_number", "location_city", "personnel_type", "employee_status"]:
        if col in df.columns:
            df[col] = df[col].astype(object).where(pd.notna(df[col]), None)
    return df

# ---------- JSON sanitizer --------------------------------------------------

def _sanitize_for_json(value):
    """
    Recursively convert pandas/numpy types to plain Python types suitable for json.dumps:
      - numpy.nan / pandas NaN -> None
      - numpy integer -> int
      - numpy float -> float (if finite) else None
      - pandas Timestamp/datetime -> isoformat str
      - dict/list -> recursively sanitize
    """
    try:
        import pandas as _pd
        import numpy as _np
    except Exception:
        _pd = None
        _np = None

    # primitives / pandas/numpy NA
    try:
        if value is None:
            return None
        if _pd is not None and _pd.isna(value):
            return None
    except Exception:
        pass

    # numpy types
    if _np is not None:
        if isinstance(value, (_np.integer,)):
            return int(value)
        if isinstance(value, (_np.floating,)):
            v = float(value)
            if not _np.isfinite(v):
                return None
            return v
        if isinstance(value, (_np.bool_, bool)):
            return bool(value)

    # pandas scalars
    try:
        import pandas as _pd
        if isinstance(value, _pd.Timestamp):
            try:
                return value.isoformat()
            except Exception:
                return str(value)
        if isinstance(value, _pd.Timedelta):
            return str(value)
    except Exception:
        pass

    # datetime
    try:
        import datetime as _dt
        if isinstance(value, _dt.datetime):
            try:
                return value.isoformat()
            except Exception:
                return str(value)
    except Exception:
        pass

    # dict
    if isinstance(value, dict):
        out = {}
        for k, v in value.items():
            try:
                key = str(k)
            except Exception:
                key = repr(k)
            out[key] = _sanitize_for_json(v)
        return out

    # list/tuple/set
    if isinstance(value, (list, tuple, set)):
        return [_sanitize_for_json(v) for v in value]

    # fallback primitives
    if isinstance(value, (str, int, float, bool)):
        try:
            if isinstance(value, float):
                if _np is not None and not _np.isfinite(value):
                    return None
                if value != value:  # NaN check
                    return None
            return value
        except Exception:
            return None

    # fallback: convert to string
    try:
        return str(value)
    except Exception:
        return None

# ---------- Comparison core --------------------------------------------------

def compare_ccure_vs_sheets(mode: str = "full", stats_detail: str = "ActiveProfiles", limit_list: int = 200, export: bool = False) -> Dict[str, Any]:
    """
    Compare CCURE (stats / profiles) with local sheets.
    New behaviour:
     - When mode=full: fetch CCURE profiles and build lists of active employees and active contractors.
       Compare those CCURE active lists against your ActiveEmployee + ActiveContractor sheets and return
       only the CCURE entries that are missing from the sheet (samples).
     - When profiles are unavailable, function still returns ccure stats (if available) and an explanatory note.
    """
    try:
        session = SessionLocal()
    except Exception as e:
        return {"error": f"DB session failed: {e}", "trace": traceback.format_exc()}

    try:
        sheet_df = _build_sheet_df(session)
        sheet_count = int(len(sheet_df))
        sheet_emp_count = int(sheet_df[sheet_df['source'] == 'employee_sheet'].shape[0])
        sheet_contractor_count = int(sheet_df[sheet_df['source'] == 'contractor_sheet'].shape[0])
    except Exception as e:
        session.close()
        return {"error": f"Failed to read sheets from DB: {e}", "trace": traceback.format_exc()}

    # fetch ccure stats & profiles (best-effort)
    ccure_stats = _fetch_ccure_stats()
    cc_profiles = []
    if mode == "full":
        try:
            cc_profiles = _fetch_ccure_profiles(mode=mode, limit=5000)
            if not isinstance(cc_profiles, list):
                cc_profiles = []
        except Exception:
            cc_profiles = []
    else:
        # still try to fetch profiles as a best-effort, but it's optional
        try:
            cc_profiles = _fetch_ccure_profiles(mode=mode, limit=2000)
            if not isinstance(cc_profiles, list):
                cc_profiles = []
        except Exception:
            cc_profiles = []

    cc_df = _build_ccure_df(cc_profiles)
    cc_count = int(len(cc_df))

    # Create sets from sheet for matching
    sheet_emp_ids = set([_normalize_employee_key(x) for x in sheet_df['employee_id'].dropna().tolist() if _normalize_employee_key(x)])
    sheet_card_ids = set([_normalize_card_like(x) for x in sheet_df['card_number'].dropna().tolist() if _normalize_card_like(x)])
    sheet_names = set([_normalize_name(x) for x in sheet_df['full_name'].dropna().tolist() if _normalize_name(x)])

    # matching helper (match ccure row to sheet employee_id if any)
    def _match_cc_row_to_sheet(row) -> Optional[str]:
        """Return matched sheet employee_id or None."""
        empid = row.get('employee_id')
        if empid and empid in sheet_emp_ids:
            return empid
        card = row.get('card_number')
        if card and card in sheet_card_ids:
            match = sheet_df[sheet_df['card_number_norm'] == card]
            if not match.empty:
                return match.iloc[0].get('employee_id')
        name_norm = row.get('full_name_norm')
        if name_norm and name_norm in sheet_names:
            match = sheet_df[sheet_df['full_name_norm'] == name_norm]
            if not match.empty:
                return match.iloc[0].get('employee_id')
        return None

    # Filter ccure for active employees & contractors (when data available)
    def _is_active_employee(row):
        st = row.get('employee_status') or ""
        ptype = row.get('personnel_type') or ""
        try:
            return (str(st).strip().lower() == "active") and str(ptype).strip().lower().startswith("employee")
        except Exception:
            return False

    def _is_active_contractor(row):
        st = row.get('employee_status') or ""
        ptype = row.get('personnel_type') or ""
        try:
            return (str(st).strip().lower() == "active") and str(ptype).strip().lower().startswith("contractor")
        except Exception:
            return False

    # If ccure profiles don't include personnel_type/status, we can attempt heuristic:
    # If employee_id looks numeric and name present -> consider as employee by default only when ccure_stats suggests employees.
    cc_emp_df = pd.DataFrame()
    cc_contractor_df = pd.DataFrame()
    if not cc_df.empty:
        # prefer explicit flags when present
        has_personnel = 'personnel_type' in cc_df.columns and 'employee_status' in cc_df.columns
        if has_personnel:
            cc_emp_df = cc_df[cc_df.apply(_is_active_employee, axis=1)].copy()
            cc_contractor_df = cc_df[cc_df.apply(_is_active_contractor, axis=1)].copy()
        else:
            # fallback: try to use 'PersonnelType' present in raw dict if available
            def _fallback_detect_employee(r):
                raw = r.get('ccure_raw') or {}
                if isinstance(raw, dict):
                    p = raw.get('PersonnelType') or raw.get('Personnel Type') or raw.get('PersonnelTypeName')
                    st = raw.get('Employee_Status') or raw.get('Status') or raw.get('Employee Status')
                    if p and st:
                        try:
                            return (str(st).strip().lower() == "active") and str(p).strip().lower().startswith("employee")
                        except Exception:
                            pass
                return False
            try:
                cc_emp_df = cc_df[cc_df.apply(_fallback_detect_employee, axis=1)].copy()
                cc_contractor_df = cc_df[cc_df.apply(lambda r: (r.get('ccure_raw') and (r['ccure_raw'].get('PersonnelType') or "").strip().lower().startswith("contractor")), axis=1)].copy()
            except Exception:
                cc_emp_df = pd.DataFrame()
                cc_contractor_df = pd.DataFrame()

    # Now compute missing lists: CCURE active employees/contractors that have no match in sheet
    in_ccure_emps_not_in_sheet = []
    in_ccure_contractors_not_in_sheet = []

    if not cc_emp_df.empty:
        for _, r in cc_emp_df.iterrows():
            try:
                matched = _match_cc_row_to_sheet(r)
                if not matched:
                    in_ccure_emps_not_in_sheet.append({
                        "employee_id": r.get('employee_id') if r.get('employee_id') is not None else None,
                        "full_name": r.get('full_name') if r.get('full_name') is not None else None,
                        "card_number": r.get('card_number') if r.get('card_number') is not None else None,
                        "location_city": r.get('location_city') if r.get('location_city') is not None else None,
                        "ccure_raw": r.get('ccure_raw')
                    })
            except Exception:
                continue

    if not cc_contractor_df.empty:
        for _, r in cc_contractor_df.iterrows():
            try:
                matched = _match_cc_row_to_sheet(r)
                if not matched:
                    in_ccure_contractors_not_in_sheet.append({
                        "employee_id": r.get('employee_id') if r.get('employee_id') is not None else None,
                        "full_name": r.get('full_name') if r.get('full_name') is not None else None,
                        "card_number": r.get('card_number') if r.get('card_number') is not None else None,
                        "location_city": r.get('location_city') if r.get('location_city') is not None else None,
                        "ccure_raw": r.get('ccure_raw')
                    })
            except Exception:
                continue

    # Limit samples
    emp_missing_sample = in_ccure_emps_not_in_sheet[:limit_list]
    contr_missing_sample = in_ccure_contractors_not_in_sheet[:limit_list]

    # counts: prefer ccure_stats if present, else derived counts from profiles
    cc_active_emps = None
    cc_active_contractors = None
    if isinstance(ccure_stats, dict):
        try:
            cc_active_emps = int(ccure_stats.get('ActiveEmployees')) if ccure_stats.get('ActiveEmployees') not in (None, "") else None
        except Exception:
            try:
                cc_active_emps = int(ccure_stats.get('ActiveEmployeesCount')) if ccure_stats.get('ActiveEmployeesCount') not in (None, "") else None
            except Exception:
                cc_active_emps = None
        try:
            cc_active_contractors = int(ccure_stats.get('ActiveContractors')) if ccure_stats.get('ActiveContractors') not in (None, "") else None
        except Exception:
            try:
                cc_active_contractors = int(ccure_stats.get('ActiveContractorsCount')) if ccure_stats.get('ActiveContractorsCount') not in (None, "") else None
            except Exception:
                cc_active_contractors = None

    # If API stats not available, derive from fetched profiles
    derived_cc_emp_count = int(len(cc_emp_df)) if not cc_emp_df.empty else 0
    derived_cc_contr_count = int(len(cc_contractor_df)) if not cc_contractor_df.empty else 0

    if cc_active_emps is None and derived_cc_emp_count:
        cc_active_emps = derived_cc_emp_count
    if cc_active_contractors is None and derived_cc_contr_count:
        cc_active_contractors = derived_cc_contr_count

    response = {
        "ccure": ccure_stats,
        "ccure_profile_count": int(cc_count) if isinstance(cc_count, int) else None,
        "sheet_counts": {
            "employees": sheet_emp_count,
            "contractors": sheet_contractor_count,
            "total_profiles": sheet_count
        },
        "ccure_active_counts": {
            "active_employees_reported": cc_active_emps,
            "active_contractors_reported": cc_active_contractors,
            "derived_active_employees_from_profiles": derived_cc_emp_count,
            "derived_active_contractors_from_profiles": derived_cc_contr_count
        },
        "differences": {
            # delta = ccure_active - sheet_count (only meaningful if ccure stats available)
            "delta_employees": (cc_active_emps - sheet_emp_count) if (isinstance(cc_active_emps, int) and isinstance(sheet_emp_count, int)) else None,
            "delta_contractors": (cc_active_contractors - sheet_contractor_count) if (isinstance(cc_active_contractors, int) and isinstance(sheet_contractor_count, int)) else None
        },
        "samples": {
            # only CCURE-but-missing-in-sheet samples are returned (user requested)
            "in_ccure_employees_not_in_sheet": emp_missing_sample,
            "in_ccure_contractors_not_in_sheet": contr_missing_sample
        },
        "report_path": None,
        "notes": None
    }

    # If profiles were not available but ccure_stats present, set a helpful note
    if (not cc_profiles or not cc_df.shape[0]) and isinstance(ccure_stats, dict):
        response["notes"] = "CCURE profiles were not returned by profile endpoint; only stats were available. Missing-name samples require profile access."

    # Optional export to Excel: write sheet_df, cc_df, and both sample lists
    if export:
        try:
            os.makedirs(OUTPUT_DIR, exist_ok=True)
            fname = f"ccure_compare_{datetime.utcnow().strftime('%Y%m%d_%H%M%S')}_{uuid.uuid4().hex[:6]}.xlsx"
            path = os.path.join(OUTPUT_DIR, fname)
            with pd.ExcelWriter(path, engine="openpyxl") as writer:
                try:
                    sheet_df.to_excel(writer, sheet_name="sheet_all", index=False)
                except Exception:
                    pd.DataFrame(sheet_df).to_excel(writer, sheet_name="sheet_all", index=False)
                try:
                    cc_df.to_excel(writer, sheet_name="ccure_all", index=False)
                except Exception:
                    pd.DataFrame(cc_df).to_excel(writer, sheet_name="ccure_all", index=False)
                pd.DataFrame(emp_missing_sample).to_excel(writer, sheet_name="in_ccure_emps_not_in_sheet", index=False)
                pd.DataFrame(contr_missing_sample).to_excel(writer, sheet_name="in_ccure_contractors_not_in_sheet", index=False)
                summary_df = pd.DataFrame([{
                    "sheet_employees": sheet_emp_count,
                    "sheet_contractors": sheet_contractor_count,
                    "sheet_total": sheet_count,
                    "ccure_profiles": cc_count,
                    "ccure_active_employees_reported": cc_active_emps,
                    "ccure_active_contractors_reported": cc_active_contractors,
                    "in_ccure_emps_not_in_sheet": len(in_ccure_emps_not_in_sheet),
                    "in_ccure_contractors_not_in_sheet": len(in_ccure_contractors_not_in_sheet)
                }])
                summary_df.to_excel(writer, sheet_name="summary", index=False)
            response["report_path"] = path
        except Exception as e:
            response["export_error"] = str(e)
            response["export_trace"] = traceback.format_exc()

    # Always sanitize everything before returning (remove NaN, numpy types, timestamps, etc.)
    sanitized_response = _sanitize_for_json(response)

    session.close()
    return sanitized_response

# ---------- helpers to convert pandas / values to native ---------------------

def _to_native(value):
    """Return JSON-serializable primitive (str/int/None) for pandas values."""
    if value is None:
        return None
    try:
        if pd.isna(value):
            return None
    except Exception:
        pass
    try:
        if isinstance(value, (int, float, str, bool)):
            # guard nan/inf
            if isinstance(value, float) and not np.isfinite(value):
                return None
            return value
        if hasattr(value, "isoformat"):
            try:
                return value.isoformat()
            except Exception:
                return str(value)
    except Exception:
        return str(value)
    return str(value)







