# --- cleanup duplicate suffixed columns before saving ---
# drop any duplicate suffixed columns like Name_x/Name_y keeping the coalesced canonical name (if present)
cols_to_drop = [c for c in features.columns if c.endswith("_x") or c.endswith("_y")]
if cols_to_drop:
    # prefer non-suffixed version if exists; otherwise keep _x as canonical
    for c in cols_to_drop:
        base = c[:-2]
        if base in features.columns:
            # we already have base, drop the suffixed column
            features.drop(columns=[c], inplace=True)
        else:
            # rename suffixed column to base (prefer _x over _y if both present)
            if c.endswith("_x"):
                features.rename(columns={c: base}, inplace=True)
            else:
                # if _y exists and _x does not, rename _y -> base
                features.rename(columns={c: base}, inplace=True)
# lastly drop any remaining duplicates of the same base (keep first)
features = features.loc[:, ~features.columns.duplicated()]
features.to_csv(out_csv, index=False)










@app.route('/record', methods=['GET'])
def get_record():
    q = request.args.get('employee_id') or request.args.get('person_uid')
    p = Path(DEFAULT_OUTDIR)
    csvs = sorted(p.glob("trend_pune_*.csv"), reverse=True)
    if not csvs:
        return jsonify({'error':'no outputs'}), 404
    df = pd.read_csv(csvs[0], parse_dates=['FirstSwipe','LastSwipe'])
    if q is None:
        return jsonify(df.head(10).to_dict(orient='records'))
    mask = (df['EmployeeID'].astype(str) == str(q)) | (df['person_uid'].astype(str) == str(q))
    rows = df[mask]
    if rows.empty:
        return jsonify({'error':'not found'}), 404
    return jsonify(rows.to_dict(orient='records'))

















Check each file outPut Carefully and Review we are getting correct ot not also explain me each API Responce carefully why we got True or False here 

http://10.199.46.101:8002/run?date=2025-10-24

{
  "date": "2025-10-24",
  "flagged_rows": 296,
  "rows": 297
}




http://10.199.46.101:8002/latest


{
  "file": "trend_pune_20251024.csv",
  "rows": 297,
  "sample": [
    {
      "CardNumber": 620138,
      "CardNumber_x": 620138,
      "CardNumber_y": 620138,
      "CompanyName": "WU Technology Engineering Services Private Limited",
      "CountSwipes": 20,
      "CountSwipes_x": 20,
      "CountSwipes_y": 20,
      "Date": "2025-10-24",
      "Duration": "7:56:25",
      "DurationMinutes": 476.4166666666667,
      "DurationSeconds": 28585.0,
      "EmpHistoryPresent": false,
      "EmployeeID": "329651",
      "EmployeeID_x": "329651",
      "EmployeeID_y": "329651",
      "EmployeeIdentity": "011A2336-D0A9-466F-A5E9-647785757F03",
      "EmployeeName": NaN,
      "EmployeeName_x": NaN,
      "EmployeeName_y": "Basu, Somdev",
      "FirstDirection": "InDirection",
      "FirstDoor": "APAC_IN_PUN_PODIUM_P-1 TURNSTILE 1-DOOR",
      "FirstSwipe": "2025-10-24 09:32:09",
      "InCount": 11,
      "LastDirection": "OutDirection",
      "LastDoor": "APAC_IN_PUN_PODIUM_P-1 TURNSTILE 1-OUT DOOR",
      "LastSwipe": "2025-10-24 17:28:34",
      "MaxSwipeGapSeconds": 11632,
      "OnlyIn": 0,
      "OnlyOut": 0,
      "OutCount": 9,
      "PartitionName2": "APAC.Default",
      "PersonnelType": NaN,
      "PersonnelTypeName": "Employee",
      "PrimaryLocation": "Pune - Business Bay",
      "Reasons": "long_gap_>=90min; repeated_short_breaks",
      "RejectionCount": 0,
      "ShortGapCount": 10,
      "SingleDoor": 0,
      "UniqueDoors": 10,
      "UniqueLocations": 1,
      "badge_sharing_suspected": false,
      "coffee_badging": false,
      "consecutive_absent_days": false,
      "early_arrival_before_06": false,
      "high_variance_duration": false,
      "late_exit_after_22": false,
      "long_gap_>=90min": true,
      "low_swipe_count_<=2": false,
      "multiple_location_same_day": false,
      "only_in": false,
      "only_out": false,
      "overtime_>=10h": false,
      "person_uid": "011A2336-D0A9-466F-A5E9-647785757F03",
      "repeated_rejection_count": false,
      "repeated_short_breaks": true,
      "shift_inconsistency": false,
      "short_duration_<4h": false,
      "short_duration_on_high_presence_days": false,
      "single_door": false,
      "trending_decline": false,
      "unusually_high_swipes": false,
      "very_long_duration_>=16h": false,
      "weekend_activity": false,
      "zero_swipes": false
    },
    {
      "CardNumber": 410335,
      "CardNumber_x": 410335,
      "CardNumber_y": 410335,
      "CompanyName": "Poona Security India Pvt. Ltd",
      "CountSwipes": 74,
      "CountSwipes_x": 74,
      "CountSwipes_y": 74,
      "Date": "2025-10-24",
      "Duration": "8:28:16",
      "DurationMinutes": 508.26666666666665,
      "DurationSeconds": 30496.0,
      "EmpHistoryPresent": false,
      "EmployeeID": NaN,
      "EmployeeID_x": NaN,
      "EmployeeID_y": NaN,
      "EmployeeIdentity": "021FD806-2EED-4393-A91A-E6B6D320C608",
      "EmployeeName": NaN,
      "EmployeeName_x": NaN,
      "EmployeeName_y": "Gondavale, Nana",
      "FirstDirection": "InDirection",
      "FirstDoor": "APAC_IN_PUN_PODIUM_P-1 TURNSTILE 4-DOOR",
      "FirstSwipe": "2025-10-24 06:41:01",
      "InCount": 41,
      "LastDirection": "OutDirection",
      "LastDoor": "APAC_IN_PUN_PODIUM_P-1 TURNSTILE 4 -OUT DOOR",
      "LastSwipe": "2025-10-24 15:09:17",
      "MaxSwipeGapSeconds": 3821,
      "OnlyIn": 0,
      "OnlyOut": 0,
      "OutCount": 33,
      "PartitionName2": "APAC.Default",
      "PersonnelType": NaN,
      "PersonnelTypeName": "Property Management",
      "PrimaryLocation": "Business Bay - Pune",
      "Reasons": "unusually_high_swipes; repeated_short_breaks",
      "RejectionCount": 0,
      "ShortGapCount": 50,
      "SingleDoor": 0,
      "UniqueDoors": 15,
      "UniqueLocations": 1,
      "badge_sharing_suspected": false,
      "coffee_badging": false,
      "consecutive_absent_days": false,
      "early_arrival_before_06": false,
      "high_variance_duration": false,
      "late_exit_after_22": false,
      "long_gap_>=90min": false,
      "low_swipe_count_<=2": false,
      "multiple_location_same_day": false,
      "only_in": false,
      "only_out": false,
      "overtime_>=10h": false,
      "person_uid": "021FD806-2EED-4393-A91A-E6B6D320C608",
      "repeated_rejection_count": false,
      "repeated_short_breaks": true,
      "shift_inconsistency": false,
      "short_duration_<4h": false,
      "short_duration_on_high_presence_days": false,
      "single_door": false,
      "trending_decline": false,
      "unusually_high_swipes": true,
      "very_long_duration_>=16h": false,
      "weekend_activity": false,
      "zero_swipes": false
    },
    {
      "CardNumber": 410966,
      "CardNumber_x": 410966,
      "CardNumber_y": 410966,
      "CompanyName": "WU Srvcs India Private Ltd",
      "CountSwipes": 26,
      "CountSwipes_x": 26,
      "CountSwipes_y": 26,
      "Date": "2025-10-24",
      "Duration": "8:07:25",
      "DurationMinutes": 487.4166666666667,
      "DurationSeconds": 29245.0,
      "EmpHistoryPresent": false,
      "EmployeeID": "311119",
      "EmployeeID_x": "311119",
      "EmployeeID_y": "311119",
      "EmployeeIdentity": "044D7244-709F-4DB8-B55A-1CE324B42A89",
      "EmployeeName": NaN,
      "EmployeeName_x": NaN,
      "EmployeeName_y": "Sawarkar, Sneha",
      "FirstDirection": "InDirection",
      "FirstDoor": "APAC_IN_PUN_PODIUM_P-1 TURNSTILE 3-DOOR",
      "FirstSwipe": "2025-10-24 08:45:36",
      "InCount": 13,
      "LastDirection": "OutDirection",
      "LastDoor": "APAC_IN_PUN_PODIUM_P-1 TURNSTILE 4 -OUT DOOR",
      "LastSwipe": "2025-10-24 16:53:01",
      "MaxSwipeGapSeconds": 4424,
      "OnlyIn": 0,
      "OnlyOut": 0,
      "OutCount": 13,
      "PartitionName2": "APAC.Default",
      "PersonnelType": NaN,
      "PersonnelTypeName": "Employee",
      "PrimaryLocation": "Pune - Business Bay",
      "Reasons": "repeated_short_breaks",
      "RejectionCount": 0,
      "ShortGapCount": 11,
      "SingleDoor": 0,
      "UniqueDoors": 9,
      "UniqueLocations": 1,
      "badge_sharing_suspected": false,
      "coffee_badging": false,
      "consecutive_absent_days": false,
      "early_arrival_before_06": false,
      "high_variance_duration": false,
      "late_exit_after_22": false,
      "long_gap_>=90min": false,
      "low_swipe_count_<=2": false,
      "multiple_location_same_day": false,
      "only_in": false,
      "only_out": false,
      "overtime_>=10h": false,
      "person_uid": "044D7244-709F-4DB8-B55A-1CE324B42A89",
      "repeated_rejection_count": false,
      "repeated_short_breaks": true,
      "shift_inconsistency": false,
      "short_duration_<4h": false,
      "short_duration_on_high_presence_days": false,
      "single_door": false,
      "trending_decline": false,
      "unusually_high_swipes": false,
      "very_long_duration_>=16h": false,
      "weekend_activity": false,
      "zero_swipes": false
    },
    {
      "CardNumber": 612223,
      "CardNumber_x": 612223,
      "CardNumber_y": 612223,
      "CompanyName": "WU Srvcs India Private Ltd",
      "CountSwipes": 22,
      "CountSwipes_x": 22,
      "CountSwipes_y": 22,
      "Date": "2025-10-24",
      "Duration": "8:03:10",
      "DurationMinutes": 483.1666666666667,
      "DurationSeconds": 28990.0,
      "EmpHistoryPresent": false,
      "EmployeeID": "324229",
      "EmployeeID_x": "324229",
      "EmployeeID_y": "324229",
      "EmployeeIdentity": "0590FBCD-5D5F-4B87-A89E-115F3C285AF5",
      "EmployeeName": NaN,
      "EmployeeName_x": NaN,
      "EmployeeName_y": "Kute, Piyush",
      "FirstDirection": "InDirection",
      "FirstDoor": "APAC_IN_PUN_PODIUM_P-1 TURNSTILE 2-DOOR",
      "FirstSwipe": "2025-10-24 07:57:02",
      "InCount": 14,
      "LastDirection": "OutDirection",
      "LastDoor": "APAC_IN_PUN_PODIUM_P-1 TURNSTILE 1-OUT DOOR",
      "LastSwipe": "2025-10-24 16:00:12",
      "MaxSwipeGapSeconds": 8508,
      "OnlyIn": 0,
      "OnlyOut": 0,
      "OutCount": 8,
      "PartitionName2": "APAC.Default",
      "PersonnelType": NaN,
      "PersonnelTypeName": "Employee",
      "PrimaryLocation": "Pune - Business Bay",
      "Reasons": "long_gap_>=90min; repeated_short_breaks",
      "RejectionCount": 0,
      "ShortGapCount": 13,
      "SingleDoor": 0,
      "UniqueDoors": 6,
      "UniqueLocations": 1,
      "badge_sharing_suspected": false,
      "coffee_badging": false,
      "consecutive_absent_days": false,
      "early_arrival_before_06": false,
      "high_variance_duration": false,
      "late_exit_after_22": false,
      "long_gap_>=90min": true,
      "low_swipe_count_<=2": false,
      "multiple_location_same_day": false,
      "only_in": false,
      "only_out": false,
      "overtime_>=10h": false,
      "person_uid": "0590FBCD-5D5F-4B87-A89E-115F3C285AF5",
      "repeated_rejection_count": false,
      "repeated_short_breaks": true,
      "shift_inconsistency": false,
      "short_duration_<4h": false,
      "short_duration_on_high_presence_days": false,
      "single_door": false,
      "trending_decline": false,
      "unusually_high_swipes": false,
      "very_long_duration_>=16h": false,
      "weekend_activity": false,
      "zero_swipes": false
    },
    {
      "CardNumber": 615669,
      "CardNumber_x": 615669,
      "CardNumber_y": 615669,
      "CompanyName": "WU Srvcs India Private Ltd",
      "CountSwipes": 18,
      "CountSwipes_x": 18,
      "CountSwipes_y": 18,
      "Date": "2025-10-24",
      "Duration": "8:13:59",
      "DurationMinutes": 493.98333333333335,
      "DurationSeconds": 29639.0,
      "EmpHistoryPresent": false,
      "EmployeeID": "327355",
      "EmployeeID_x": "327355",
      "EmployeeID_y": "327355",
      "EmployeeIdentity": "05A910F8-7B27-4491-A5FC-33A391162966",
      "EmployeeName": NaN,
      "EmployeeName_x": NaN,
      "EmployeeName_y": "Thirumala, Rajesh",
      "FirstDirection": "InDirection",
      "FirstDoor": "APAC_IN_PUN_TOWER B_MAIN RECEPTION DOOR",
      "FirstSwipe": "2025-10-24 09:51:54",
      "InCount": 9,
      "LastDirection": "OutDirection",
      "LastDoor": "APAC_IN_PUN_TOWER B_MAIN RECEPTION DOOR",
      "LastSwipe": "2025-10-24 18:05:53",
      "MaxSwipeGapSeconds": 11821,
      "OnlyIn": 0,
      "OnlyOut": 0,
      "OutCount": 9,
      "PartitionName2": "APAC.Default",
      "PersonnelType": NaN,
      "PersonnelTypeName": "Employee",
      "PrimaryLocation": "Pune - Business Bay",
      "Reasons": "long_gap_>=90min; repeated_short_breaks",
      "RejectionCount": 0,
      "ShortGapCount": 12,
      "SingleDoor": 0,
      "UniqueDoors": 3,
      "UniqueLocations": 1,
      "badge_sharing_suspected": false,
      "coffee_badging": false,
      "consecutive_absent_days": false,
      "early_arrival_before_06": false,
      "high_variance_duration": false,
      "late_exit_after_22": false,
      "long_gap_>=90min": true,
      "low_swipe_count_<=2": false,
      "multiple_location_same_day": false,
      "only_in": false,
      "only_out": false,
      "overtime_>=10h": false,
      "person_uid": "05A910F8-7B27-4491-A5FC-33A391162966",
      "repeated_rejection_count": false,
      "repeated_short_breaks": true,
      "shift_inconsistency": false,
      "short_duration_<4h": false,
      "short_duration_on_high_presence_days": false,
      "single_door": false,
      "trending_decline": false,
      "unusually_high_swipes": false,
      "very_long_duration_>=16h": false,
      "weekend_activity": false,
      "zero_swipes": false
    }
  ]
}






# backend/trend_runner.py
from datetime import date, datetime, time
from pathlib import Path
import pandas as pd
import numpy as np
import logging

# IMPORTANT: import duration_report as a top-level module (file in same folder).
from duration_report import run_for_date

# try to load historical profile (current_analysis.csv) if present
HIST_PATH = Path(__file__).parent / "current_analysis.csv"
if HIST_PATH.exists():
    try:
        HIST_DF = pd.read_csv(HIST_PATH)
        logging.info("Loaded historical profile from %s (rows=%d)", HIST_PATH, len(HIST_DF))
    except Exception as e:
        logging.warning("Failed to load historical profile: %s", e)
        HIST_DF = pd.DataFrame()
else:
    logging.warning("Historical profile file current_analysis.csv not found; history-based scenarios will fallback.")
    HIST_DF = pd.DataFrame()

OUTDIR = Path("./outputs")
OUTDIR.mkdir(parents=True, exist_ok=True)
logging.basicConfig(level=logging.INFO)


def compute_features(swipes: pd.DataFrame, durations: pd.DataFrame) -> pd.DataFrame:
    """
    Compute per person-per-date features used by scenarios.
    """
    if swipes is None or swipes.empty:
        return pd.DataFrame()

    sw = swipes.copy()
    sw['LocaleMessageTime'] = pd.to_datetime(sw['LocaleMessageTime'], errors='coerce')
    sw['Date'] = sw['LocaleMessageTime'].dt.date

    # create person_uid if missing (same logic as duration_report)
    if 'person_uid' not in sw.columns:
        def make_person_uid(row):
            parts = []
            for c in ('EmployeeIdentity', 'EmployeeID', 'EmployeeName'):
                v = row.get(c)
                if pd.notna(v) and str(v).strip():
                    parts.append(str(v).strip())
            return "|".join(parts) if parts else None
        sw['person_uid'] = sw.apply(make_person_uid, axis=1)

    # columns we will use for aggregation (choose those present to avoid apply warnings)
    sel_cols = [c for c in [
        'LocaleMessageTime', 'Direction', 'Door', 'PartitionName2', 'Rejection_Type',
        'CardNumber', 'EmployeeID', 'ObjectName1', 'PersonnelType'
    ] if c in sw.columns]

    # aggregator for each person/date
    def agg_swipe_group(g):
        times = sorted(g['LocaleMessageTime'].dropna().tolist())
        gaps = []
        short_gap_count = 0
        for i in range(1, len(times)):
            s = (times[i] - times[i-1]).total_seconds()
            gaps.append(s)
            if s <= 5*60:
                short_gap_count += 1
        max_gap = int(max(gaps)) if gaps else 0
        in_count = int((g.get('Direction') == 'InDirection').sum()) if 'Direction' in g.columns else 0
        out_count = int((g.get('Direction') == 'OutDirection').sum()) if 'Direction' in g.columns else 0
        unique_doors = int(g['Door'].nunique()) if 'Door' in g.columns else 0
        unique_locations = int(g['PartitionName2'].nunique()) if 'PartitionName2' in g.columns else 0
        rejection_count = int(g['Rejection_Type'].notna().sum()) if 'Rejection_Type' in g.columns else 0
        card_numbers = list(pd.unique(g['CardNumber'].dropna())) if 'CardNumber' in g.columns else []
        card_number = card_numbers[0] if card_numbers else None

        employee_id = None
        employee_name = None
        personnel_type = None
        if 'EmployeeID' in g.columns:
            vals = g['EmployeeID'].dropna()
            employee_id = vals.iloc[0] if not vals.empty else None
        if 'ObjectName1' in g.columns:
            vals = g['ObjectName1'].dropna()
            employee_name = vals.iloc[0] if not vals.empty else None
        if 'PersonnelType' in g.columns:
            vals = g['PersonnelType'].dropna()
            personnel_type = vals.iloc[0] if not vals.empty else None

        return pd.Series({
            'CountSwipes': int(len(g)),
            'MaxSwipeGapSeconds': max_gap,
            'ShortGapCount': int(short_gap_count),
            'InCount': in_count,
            'OutCount': out_count,
            'UniqueDoors': unique_doors,
            'UniqueLocations': unique_locations,
            'RejectionCount': rejection_count,
            'CardNumber': card_number,
            'EmployeeID': employee_id,
            'EmployeeName': employee_name,
            'PersonnelType': personnel_type
        })

    # Use only the selected columns in the groupby to avoid the FutureWarning
    gb = sw[['person_uid', 'Date'] + sel_cols].groupby(['person_uid', 'Date'])
    grouped = gb.apply(agg_swipe_group).reset_index()

    # normalize durations side
    dur = pd.DataFrame() if durations is None else durations.copy()
    if not dur.empty and 'Date' in dur.columns:
        dur['Date'] = pd.to_datetime(dur['Date']).dt.date

    merged = pd.merge(grouped, dur, how='left', on=['person_uid', 'Date'])

    # helper to coalesce possible _x/_y duplicates created by merge
    def coalesce_col(df, base, default=0):
        if base in df.columns:
            return
        a = base + '_x'
        b = base + '_y'
        if a in df.columns:
            df[base] = df[a]
        elif b in df.columns:
            df[base] = df[b]
        else:
            # create column with default scalar or series
            df[base] = default

    # coalesce likely duplicated fields coming from durations
    for col in ['CountSwipes', 'DurationSeconds', 'FirstSwipe', 'LastSwipe', 'CardNumber', 'EmployeeID', 'EmployeeName', 'PersonnelType']:
        coalesce_col(merged, col, default=np.nan if 'Swipe' in col else 0)

    # ensure types and fill defaults
    merged['DurationSeconds'] = merged.get('DurationSeconds', 0).fillna(0).astype(float)
    merged['DurationMinutes'] = (merged['DurationSeconds'] / 60.0).astype(float)
    merged['CountSwipes'] = merged['CountSwipes'].fillna(0).astype(int)
    merged['MaxSwipeGapSeconds'] = merged.get('MaxSwipeGapSeconds', 0).fillna(0).astype(int)
    merged['ShortGapCount'] = merged.get('ShortGapCount', 0).fillna(0).astype(int)
    merged['RejectionCount'] = merged.get('RejectionCount', 0).fillna(0).astype(int)
    merged['UniqueLocations'] = merged.get('UniqueLocations', 0).fillna(0).astype(int)
    merged['UniqueDoors'] = merged.get('UniqueDoors', 0).fillna(0).astype(int)

    # ensure FirstSwipe/LastSwipe exist (they come from durations) and are datetime
    for col in ['FirstSwipe', 'LastSwipe']:
        if col not in merged.columns:
            merged[col] = pd.NaT
        else:
            merged[col] = pd.to_datetime(merged[col], errors='coerce')

    # easy boolean flags
    merged['OnlyIn'] = ((merged.get('InCount', 0) > 0) & (merged.get('OutCount', 0) == 0)).astype(int)
    merged['OnlyOut'] = ((merged.get('OutCount', 0) > 0) & (merged.get('InCount', 0) == 0)).astype(int)
    merged['SingleDoor'] = (merged.get('UniqueDoors', 0) <= 1).astype(int)

    # helper: map historical medians/stds for lookups (if available)
    hist_map = {}
    if not HIST_DF.empty and 'EmployeeID' in HIST_DF.columns:
        hist_map = HIST_DF.set_index('EmployeeID').to_dict(orient='index')

    merged['EmpHistoryPresent'] = merged['EmployeeID'].apply(lambda x: x in hist_map if pd.notna(x) else False)

    return merged


# ----------------- Scenarios -----------------
def scenario_long_gap(row):
    return (row.get('MaxSwipeGapSeconds') or 0) >= 90 * 60

def scenario_short_duration(row):
    return (row.get('DurationMinutes') or 0) < 240

def scenario_coffee_badging(row):
    return (row.get('CountSwipes') or 0) >= 4 and (row.get('DurationMinutes') or 0) < 60

def scenario_low_swipe_count(row):
    return (row.get('CountSwipes') or 0) <= 2 and (row.get('CountSwipes') or 0) > 0

def scenario_single_door(row):
    return (row.get('UniqueDoors') or 0) <= 1

def scenario_only_in(row):
    return int(row.get('OnlyIn', 0)) == 1

def scenario_only_out(row):
    return int(row.get('OnlyOut', 0)) == 1

def scenario_overtime(row):
    return (row.get('DurationMinutes') or 0) >= 10 * 60

def scenario_very_long_duration(row):
    return (row.get('DurationMinutes') or 0) >= 16 * 60

def scenario_zero_swipes(row):
    return int(row.get('CountSwipes', 0)) == 0

def scenario_unusually_high_swipes(row):
    cur = row.get('CountSwipes') or 0
    empid = row.get('EmployeeID')
    if HIST_DF is not None and not HIST_DF.empty and empid in HIST_DF['EmployeeID'].values:
        try:
            rec = HIST_DF[HIST_DF['EmployeeID'] == empid].iloc[0]
            median = float(rec.get('TotalSwipes_median', np.nan))
            if np.isfinite(median) and median > 0:
                return cur > 3 * median
        except Exception:
            pass
    if 'TotalSwipes_median' in HIST_DF.columns and not HIST_DF.empty:
        global_med = HIST_DF['TotalSwipes_median'].median()
        if pd.notna(global_med) and global_med > 0:
            return cur > 3 * global_med
    return cur > 50

def scenario_repeated_short_breaks(row):
    return (row.get('ShortGapCount') or 0) >= 3

def scenario_multiple_location_same_day(row):
    return (row.get('UniqueLocations') or 0) > 1

def scenario_weekend_activity(row):
    try:
        d = pd.to_datetime(row['Date'])
        return d.weekday() >= 5
    except Exception:
        return False

def scenario_repeated_rejection_count(row):
    return (row.get('RejectionCount') or 0) >= 2

def scenario_badge_sharing_suspected(row, full_df=None):
    return False  # resolved later in run_trend_for_date

def scenario_early_arrival_before_06(row):
    fs = row.get('FirstSwipe')
    if pd.isna(fs) or fs is None:
        return False
    try:
        t = pd.to_datetime(fs).time()
        return t < time(hour=6)
    except Exception:
        return False

def scenario_late_exit_after_22(row):
    ls = row.get('LastSwipe')
    if pd.isna(ls) or ls is None:
        return False
    try:
        t = pd.to_datetime(ls).time()
        return t >= time(hour=22)
    except Exception:
        return False

def scenario_shift_inconsistency(row):
    empid = row.get('EmployeeID')
    dur = row.get('DurationMinutes') or 0
    if HIST_DF is not None and not HIST_DF.empty and empid in HIST_DF['EmployeeID'].values:
        rec = HIST_DF[HIST_DF['EmployeeID'] == empid].iloc[0]
        med = rec.get('AvgDurationMins_median', np.nan)
        std = rec.get('AvgDurationMins_std', np.nan)
        if pd.notna(med) and pd.notna(std):
            return (dur < med - 2.5 * std) or (dur > med + 2.5 * std)
    return False

def scenario_trending_decline(row):
    empid = row.get('EmployeeID')
    if HIST_DF is None or HIST_DF.empty:
        return False
    if 'TrendingDecline' in HIST_DF.columns:
        rec = HIST_DF[HIST_DF['EmployeeID'] == empid]
        if not rec.empty:
            val = rec.iloc[0].get('TrendingDecline')
            return str(val).strip().lower() == 'yes' if pd.notna(val) else False
    return False

def scenario_consecutive_absent_days(row):
    if row.get('CountSwipes') == 0:
        empid = row.get('EmployeeID')
        if HIST_DF is not None and not HIST_DF.empty and 'ConsecAbsent3Plus' in HIST_DF.columns:
            rec = HIST_DF[HIST_DF['EmployeeID'] == empid]
            if not rec.empty:
                v = rec.iloc[0].get('ConsecAbsent3Plus')
                return str(v).strip().lower() in ('yes', 'true', '1')
        return False
    return False

def scenario_high_variance_duration(row):
    empid = row.get('EmployeeID')
    if HIST_DF is not None and not HIST_DF.empty and empid in HIST_DF['EmployeeID'].values:
        rec = HIST_DF[HIST_DF['EmployeeID'] == empid].iloc[0]
        med = rec.get('AvgDurationMins_median', np.nan)
        std = rec.get('AvgDurationMins_std', np.nan)
        if pd.notna(med) and pd.notna(std) and med > 0:
            return (std / med) > 1.0
    return False

def scenario_short_duration_on_high_presence_days(row):
    days_present = row.get('DaysPresentInWeek') or 0
    dur = row.get('DurationMinutes') or 0
    return (days_present >= 4) and (dur < 240)


SCENARIOS = [
    ("long_gap_>=90min", scenario_long_gap),
    ("short_duration_<4h", scenario_short_duration),
    ("coffee_badging", scenario_coffee_badging),
    ("low_swipe_count_<=2", scenario_low_swipe_count),
    ("single_door", scenario_single_door),
    ("only_in", scenario_only_in),
    ("only_out", scenario_only_out),
    ("overtime_>=10h", scenario_overtime),
    ("very_long_duration_>=16h", scenario_very_long_duration),
    ("zero_swipes", scenario_zero_swipes),
    ("unusually_high_swipes", scenario_unusually_high_swipes),
    ("repeated_short_breaks", scenario_repeated_short_breaks),
    ("multiple_location_same_day", scenario_multiple_location_same_day),
    ("weekend_activity", scenario_weekend_activity),
    ("repeated_rejection_count", scenario_repeated_rejection_count),
    ("badge_sharing_suspected", scenario_badge_sharing_suspected),
    ("early_arrival_before_06", scenario_early_arrival_before_06),
    ("late_exit_after_22", scenario_late_exit_after_22),
    ("shift_inconsistency", scenario_shift_inconsistency),
    ("trending_decline", scenario_trending_decline),
    ("consecutive_absent_days", scenario_consecutive_absent_days),
    ("high_variance_duration", scenario_high_variance_duration),
    ("short_duration_on_high_presence_days", scenario_short_duration_on_high_presence_days)
]


def run_trend_for_date(target_date: date, outdir: str = "./outputs"):
    logging.info("run_trend_for_date: date=%s (Pune test)", target_date)
    results = run_for_date(target_date, regions=['apac'], outdir=outdir, city='Pune')
    apac = results.get('apac', {})
    swipes = apac.get('swipes', pd.DataFrame())
    durations = apac.get('durations', pd.DataFrame())

    features = compute_features(swipes, durations)
    if features.empty:
        logging.warning("run_trend_for_date: no features computed")
        return pd.DataFrame()

    # Build badge map (Date, CardNumber) => distinct person count
    badge_map = {}
    if 'CardNumber' in swipes.columns and 'person_uid' in swipes.columns and 'Date' in swipes.columns:
        tmp = swipes[['CardNumber', 'person_uid', 'Date']].dropna(subset=['CardNumber'])
        if not tmp.empty:
            grouped_card = tmp.groupby(['Date', 'CardNumber'])['person_uid'].nunique().reset_index(name='distinct_users')
            badge_map = {(row.Date, row.CardNumber): row.distinct_users for row in grouped_card.itertuples(index=False)}

    # Apply scenarios
    for name, fn in SCENARIOS:
        if name == "badge_sharing_suspected":
            def badge_fn(r):
                card = r.get('CardNumber')
                d = r.get('Date')
                if pd.isna(card) or card is None:
                    return False
                key = (d, card)
                return badge_map.get(key, 0) > 1
            features[name] = features.apply(badge_fn, axis=1)
        else:
            features[name] = features.apply(lambda r, f=fn: bool(f(r)), axis=1)

    # Create reason text
    def reasons_for_row(r):
        reasons = [name for name, _ in SCENARIOS if bool(r.get(name))]
        return "; ".join(reasons) if reasons else None

    features['Reasons'] = features.apply(reasons_for_row, axis=1)

    out_csv = Path(outdir) / f"trend_pune_{target_date.strftime('%Y%m%d')}.csv"
    features.to_csv(out_csv, index=False)
    logging.info("run_trend_for_date: wrote %s (rows=%d)", out_csv, len(features))
    return features


if __name__ == "__main__":
    today = datetime.now().date()
    df = run_trend_for_date(today)
    print("Completed; rows:", len(df))













