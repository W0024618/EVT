# backend/app.py
from flask import Flask, jsonify, request, send_from_directory, jsonify, send_file
from datetime import datetime, timedelta, date
from pathlib import Path
import logging
import pandas as pd
import numpy as np
import joblib
import math
import re
import io
import base64
import os
import difflib
from io import BytesIO
from flask import send_file  # add if not present
from pathlib import Path
from typing import Optional, List, Dict, Any
from duration_report import REGION_CONFIG
from datetime import date, timedelta, datetime
from flask import jsonify, request
import logging
logging.basicConfig(level=logging.INFO)


from employeeimage import get_person_image_bytes, get_personnel_info
from config.door_zone import map_door_to_zone, BREAK_ZONES, OUT_OF_OFFICE_ZONE


from trend_runner import run_trend_for_date, build_monthly_training


from io import BytesIO
# try to import imghdr (may be missing in some minimal Python builds)
try:
    import imghdr as _imghdr
except Exception:
    _imghdr = None

def _guess_image_kind(data_bytes):
    """Return image kind like 'jpeg', 'png', 'gif', 'webp' or None."""
    # 1) try imghdr if available
    try:
        if _imghdr:
            k = _imghdr.what(None, h=data_bytes)
            if k:
                return k
    except Exception:
        pass

    # 2) try Pillow if installed
    try:
        from io import BytesIO as _BytesIO
        from PIL import Image as _Image
        bio = _BytesIO(data_bytes)
        img = _Image.open(bio)
        fmt = getattr(img, 'format', None)
        if fmt:
            return fmt.lower()
    except Exception:
        pass

    # 3) last-resort: quick magic-bytes sniff for common formats
    try:
        header = data_bytes[:12]
        if header.startswith(b'\xff\xd8\xff'):
            return 'jpeg'
        if header.startswith(b'\x89PNG\r\n\x1a\n'):
            return 'png'
        if header[:6] in (b'GIF87a', b'GIF89a'):
            return 'gif'
        if header.startswith(b'RIFF') and header[8:12] == b'WEBP':
            return 'webp'
    except Exception:
        pass

    return None


# import helpers that exist in your employeeimage.py
try:
    from employeeimage import get_person_image_bytes, get_personnel_info
except Exception:
    # if module missing, define fallbacks so app still runs
    def get_person_image_bytes(pid):
        return None
    def get_personnel_info(pid):
        return {}


# create Flask app early (must exist before any @app.route usage)
from flask import Flask
try:
    from flask_cors import CORS
    _HAS_CORS = True
except Exception:
    CORS = None
    _HAS_CORS = False

app = Flask(__name__, static_folder=None)
if _HAS_CORS:
    CORS(app)
else:
    logging.warning("flask_cors not available; continuing without CORS.")



def _safe_read_csv(fp):
    try:
        return pd.read_csv(fp, parse_dates=['LocaleMessageTime'], low_memory=False)
    except Exception:
        try:
            return pd.read_csv(fp, low_memory=False)
        except Exception:
            return pd.DataFrame()

#path 
BASE_DIR = Path(__file__).parent.resolve()
DEFAULT_OUTDIR = BASE_DIR / "outputs"
DEFAULT_OUTDIR.mkdir(parents=True, exist_ok=True)

OUTDIR = DEFAULT_OUTDIR

OVERRIDES_FILE = DEFAULT_OUTDIR / "overrides.csv"


def _load_overrides():
    if not OVERRIDES_FILE.exists():
        return {}
    try:
        df = pd.read_csv(OVERRIDES_FILE, dtype=str)
        out = {}
        for _, r in df.iterrows():
            emp = str(r.get('EmployeeID') or r.get('person_uid') or '').strip()
            if not emp:
                continue
            out[emp] = {
                'level': str(r.get('OverrideLevel') or '').strip(),
                'reason': str(r.get('Reason') or '').strip(),
                'ts': str(r.get('Timestamp') or '').strip()
            }
        return out
    except Exception:
        logging.exception("Failed reading overrides file")
        return {}

def _save_override(employee_key, level, reason):
    now = datetime.now().isoformat()
    row = {'EmployeeID': employee_key, 'OverrideLevel': level, 'Reason': reason or '', 'Timestamp': now}
    try:
        if OVERRIDES_FILE.exists():
            df = pd.read_csv(OVERRIDES_FILE, dtype=str)
            # pandas.DataFrame.append is deprecated -> use concat
            df = pd.concat([df, pd.DataFrame([row])], ignore_index=True)
        else:
            df = pd.DataFrame([row])
        df.to_csv(OVERRIDES_FILE, index=False)
        return True
    except Exception:
        logging.exception("Failed to save override")
        return False

def _slug_city(s):
    """
    Convert a city/site string into a safe slug: lowercase, alphanumeric+hyphen
    """
    if not s:
        return ''
    # Remove special chars, spaces to hyphens, lower
    slug = re.sub(r'[^\w\s-]', '', str(s)).strip().lower()
    slug = re.sub(r'[\s_]+', '-', slug)
    return slug



_acvscore_backoff = {"ts": None, "failed": False}
_ACVSCORE_BACKOFF_SECONDS = 20


# ODBC driver (keep existing env-based driver)
ODBC_DRIVER = os.getenv("ODBC_DRIVER", "ODBC Driver 17 for SQL Server")

MODELS_DIR = Path(__file__).parent / "models"
_loaded_models = {}

def load_model(name):
    if name in _loaded_models:
        return _loaded_models[name]
    p = MODELS_DIR / f"{name}.joblib"
    if not p.exists():
        return None
    data = joblib.load(p)
    _loaded_models[name] = data
    return data







# send_file is needed for Excel responses
from flask import send_file
try:
    # optional import; used for styling
    from openpyxl import load_workbook
    from openpyxl.styles import Font, Alignment, Border, Side
    OPENPYXL_AVAILABLE = True
except Exception:
    OPENPYXL_AVAILABLE = False

def _to_python_scalar(x):
    """
    Convert numpy/pandas scalar types to built-in Python types and
    convert NaN-like values to None so JSON is safe.
    """
    try:
        import pandas as _pd
        if isinstance(x, _pd.Timestamp):
            return x.to_pydatetime().isoformat()
    except Exception:
        pass

    try:
        import numpy as _np
        if isinstance(x, _np.generic):
            v = x.item()
            if isinstance(v, float) and _np.isnan(v):
                return None
            return v
    except Exception:
        pass

    try:
        if isinstance(x, float) and math.isnan(x):
            return None
    except Exception:
        pass

    if isinstance(x, (datetime,)):
        return x.isoformat()
    if isinstance(x, (bool, int, str, type(None), float)):
        # convert floats NaN handled above
        return x
    try:
        # fallback to string
        return str(x)
    except Exception:
        return None


_uuid_like_re = re.compile(r'^[0-9a-fA-F]{8}\-[0-9a-fA-F]{4}\-[0-9a-fA-F]{4}\-[0-9a-fA-F]{4}\-[0-9a-fA-F]{12}$')

def _looks_like_guid(s):
    try:
        if not s or not isinstance(s, str):
            return False
        s = s.strip()
        return bool(_uuid_like_re.match(s)) or s.startswith('name:') or s.startswith('emp:') or s.startswith('uid:')
    except Exception:
        return False


# Helper: format seconds to HH:MM:SS
def format_seconds_to_hms(seconds):
    try:
        if seconds is None:
            return None
        # guard against floats and NaN
        s = int(float(seconds))
        if s < 0:
            s = 0
        hh = s // 3600
        mm = (s % 3600) // 60
        ss = s % 60
        return f"{hh:02d}:{mm:02d}:{ss:02d}"
    except Exception:
        return None


# Placeholder tokens (keep consistent with trend_runner expectations)
_PLACEHOLDER_STRS = set(['', 'nan', 'na', 'n/a', '-', '—', '–', 'none', 'null'])

def _is_placeholder_str(s: object) -> bool:
    try:
        if s is None:
            return True
        st = str(s).strip().lower()
        return st in _PLACEHOLDER_STRS
    except Exception:
        return False


_CARD_XML_RE = re.compile(r'<Card>([^<]+)</Card>', re.IGNORECASE | re.DOTALL)
def _extract_card_from_xml_text(txt):
    try:
        if not txt or not isinstance(txt, str):
            return None
        m = _CARD_XML_RE.search(txt)
        if m:
            return m.group(1).strip()
        m2 = re.search(r'CHUID.*?Card.*?[:=]\s*([0-9A-Za-z\-\_]+)', txt, re.IGNORECASE | re.DOTALL)
        if m2:
            return m2.group(1).strip()
    except Exception:
        pass
    return None


def _resolve_field_from_record(record: dict, candidate_tokens: list):
    """
    Search a single row `record` (dict) for likely columns listed in candidate_tokens.
    Return first non-placeholder value found (converted to Python scalar), else None.
    """
    if record is None:
        return None

    # 1) exact key matches (case-sensitive & common casing)
    for key in candidate_tokens:
        if key in record:
            v = record.get(key)
            if v is None:
                continue
            if isinstance(v, float) and math.isnan(v):
                continue
            sval = str(v).strip()
            if sval and not _is_placeholder_str(sval):
                return _to_python_scalar(v)

    # 2) case-insensitive contains match
    lower_keys = {k.lower(): k for k in record.keys()}
    for tok in candidate_tokens:
        tok_l = tok.lower()
        for lk, orig_key in lower_keys.items():
            if tok_l in lk:
                v = record.get(orig_key)
                if v is None:
                    continue
                if isinstance(v, float) and math.isnan(v):
                    continue
                sval = str(v).strip()
                if sval and not _is_placeholder_str(sval):
                    return _to_python_scalar(v)

    # 3) xml / value parsing fallback for CardNumber
    card_like = any(tok.lower() in ('cardnumber', 'chuid', 'card') for tok in candidate_tokens)
    if card_like:
        for lk, orig_key in lower_keys.items():
            if 'xml' in lk or 'xmlmessage' in lk or 'xml_msg' in lk or 'msg' in lk or 'value' == lk:
                v = record.get(orig_key)
                if v is None:
                    continue
                try:
                    txt = str(v)
                    extracted = _extract_card_from_xml_text(txt)
                    if extracted and not _is_placeholder_str(extracted):
                        return _to_python_scalar(extracted)
                except Exception:
                    continue

    # 4) final fallback: first non-placeholder value
    for k, v in record.items():
        if v is None:
            continue
        if isinstance(v, float) and math.isnan(v):
            continue
        sval = str(v).strip()
        if sval and not _is_placeholder_str(sval):
            return _to_python_scalar(v)

    return None


def _clean_sample_df(df: pd.DataFrame, max_rows: int = 10):
    """
    Clean a dataframe for JSON output (convert NaN -> None, pandas types -> native, format datetimes).
    """
    if df is None or df.empty:
        return []
    df = df.copy()

    # remove duplicate suffix columns
    cols_to_fix = [c for c in df.columns if c.endswith('_x') or c.endswith('_y')]
    for c in cols_to_fix:
        base = c[:-2]
        if base in df.columns:
            try:
                df.drop(columns=[c], inplace=True)
            except Exception:
                pass
        else:
            try:
                df.rename(columns={c: base}, inplace=True)
            except Exception:
                pass

    # Date normalization
    if 'Date' in df.columns:
        try:
            df['Date'] = pd.to_datetime(df['Date'], errors='coerce').dt.date
            df['Date'] = df['Date'].apply(lambda d: d.isoformat() if pd.notna(d) else None)
        except Exception:
            pass

    # Datetime columns to ISO strings
    for dtcol in ('FirstSwipe', 'LastSwipe', 'LocaleMessageTime'):
        if dtcol in df.columns:
            try:
                df[dtcol] = pd.to_datetime(df[dtcol], errors='coerce')
                df[dtcol] = df[dtcol].apply(lambda t: t.to_pydatetime().isoformat() if pd.notna(t) else None)
            except Exception:
                try:
                    df[dtcol] = df[dtcol].astype(str).replace('NaT', None)
                except Exception:
                    pass

    # Replace NaN/inf -> None
    df = df.where(pd.notnull(df), None)

    # Convert records to safe Python types
    rows = df.head(max_rows).to_dict(orient='records')
    cleaned = []
    for r in rows:
        out = {}
        for k, v in r.items():
            out[k] = _to_python_scalar(v)

        # Typical fields
        emp_name = out.get('EmployeeName')
        emp_id = out.get('EmployeeID') or out.get('EmployeeIdentity')
        person_uid = out.get('person_uid')

        # ----- Schema-aware fallback resolution -----
        if not emp_id:
            emp_tokens = ['Int1', 'Text12', 'EmployeeID', 'empid', 'id']
            resolved_emp = _resolve_field_from_record(r, emp_tokens)
            if resolved_emp is not None:
                try:
                    s = str(resolved_emp).strip()
                    # remove trailing .0 for floats
                    if '.' in s:
                        f = float(s)
                        if math.isfinite(f) and f.is_integer():
                            s = str(int(f))
                    if _looks_like_guid(s):
                        out['EmployeeID'] = None
                        emp_id = None
                    else:
                        out['EmployeeID'] = s
                        emp_id = s
                except Exception:
                    if _looks_like_guid(resolved_emp):
                        out['EmployeeID'] = None
                        emp_id = None
                    else:
                        out['EmployeeID'] = resolved_emp
                        emp_id = resolved_emp

        # Prefer Credential.CardNumber / CHUID / Card as CardNumber when missing — reject GUIDs/placeholders
        if out.get('CardNumber') in (None, '', 'nan'):
            card_tokens = ['CardNumber', 'CHUID', 'Card', 'card_no', 'cardnum']
            resolved_card = _resolve_field_from_record(r, card_tokens)
            if resolved_card is not None:
                try:
                    cs = str(resolved_card).strip()
                    if _looks_like_guid(cs) or _is_placeholder_str(cs):
                        out['CardNumber'] = None
                    else:
                        out['CardNumber'] = cs
                except Exception:
                    out['CardNumber'] = None

        # final safety: ensure EmployeeID/CardNumber are not GUID-like tokens
        if 'EmployeeID' in out and isinstance(out['EmployeeID'], str) and _looks_like_guid(out['EmployeeID']):
            out['EmployeeID'] = None
        if 'CardNumber' in out and isinstance(out['CardNumber'], str) and _looks_like_guid(out['CardNumber']):
            out['CardNumber'] = None

        # If EmployeeName empty or looks like a GUID, prefer EmployeeID (human id) over GUIDs
        if (emp_name in (None, '', 'nan')) or (isinstance(emp_name, str) and _looks_like_guid(emp_name)):
            if emp_id not in (None, '', 'nan') and not _looks_like_guid(emp_id):
                out['EmployeeName'] = str(emp_id)
            else:
                out['EmployeeName'] = None

        cleaned.append(out)
    return cleaned

# ----- Helpers added to match commented (Pune) file functionality but multi-city-aware -----

def _replace_placeholder_strings(obj):
    """
    If obj is a DataFrame, replace known placeholder strings with None (NaN).
    If obj is a scalar/string, return None for placeholder strings else return obj.
    """
    if obj is None:
        return obj
    try:
        if isinstance(obj, pd.DataFrame):
            df = obj.copy()
            for col in df.columns:
                try:
                    # Replace placeholder strings (case-insensitive)
                    df[col] = df[col].apply(lambda x: None if _is_placeholder_str(x) else x)
                except Exception:
                    continue
            return df
        else:
            # scalar
            return None if _is_placeholder_str(obj) else obj
    except Exception:
        return obj

def _normalize_id_local(v):
    """
    Normalize an identifier for robust matching/counting:
    - treat NaN/None/empty as None
    - strip and convert float-like integers to integer strings
    """
    try:
        if pd.isna(v):
            return None
    except Exception:
        pass
    if v is None:
        return None
    s = str(v).strip()
    if s == '' or s.lower() == 'nan':
        return None
    try:
        if '.' in s:
            fv = float(s)
            if math.isfinite(fv) and fv.is_integer():
                s = str(int(fv))
    except Exception:
        pass
    return s




def _find_swipe_files(outdir: Path, date_obj: Optional[date] = None, city_slug: Optional[str] = None, include_shifted: bool = True):
    """
    Robust swipe-file discovery.
    - If include_shifted is False, files with 'shift' in the filename (e.g. _shifted) are excluded.
    - Supports various filename patterns; if date_obj is None returns recent swipe-like files.
    - Returns list of Path objects sorted by mtime (newest first).
    """
    p = Path(outdir)
    files_set = set()
    try:
        city_slug_l = (city_slug or "").lower().strip()

        def add_glob(pattern):
            try:
                for fp in p.glob(pattern):
                    if fp.is_file():
                        files_set.add(fp)
            except Exception:
                pass

        if date_obj is None:
            add_glob("*_swipes_*.csv")
            add_glob("swipes_*.csv")
            add_glob("*swipes*.csv")
            add_glob("*_swipes.csv")
            add_glob("*swipe*.csv")
            if city_slug_l:
                add_glob(f"*{city_slug_l}*_swipes_*.csv")
                add_glob(f"*{city_slug_l}*swipes*.csv")
                add_glob(f"*{city_slug_l}*.csv")
        else:
            target = date_obj.strftime("%Y%m%d")
            patterns = [
                f"*_{target}.csv",
                f"*_swipes_{target}.csv",
                f"swipes*_{target}.csv",
                f"swipes_{target}.csv",
                f"*swipes*_{target}.csv",
                f"*{city_slug_l}*_{target}.csv",
                f"*{city_slug_l}*swipes*_{target}.csv",
                f"*{city_slug_l}_{target}.csv"
            ]
            for pat in patterns:
                add_glob(pat)

        # fallback: any CSV containing 'swipe'/'swipes' in the name
        try:
            for fp in p.iterdir():
                if not fp.is_file():
                    continue
                name = fp.name.lower()
                if ('_swipe' in name) or ('swipe' in name and name.endswith('.csv')):
                    files_set.add(fp)
        except Exception:
            pass

    except Exception:
        logging.exception("Error while searching for swipe files in %s", outdir)

    # Filter out shifted files if requested
    files = sorted(list(files_set), key=lambda f: f.stat().st_mtime if f.exists() else 0, reverse=True)
    if not include_shifted:
        files = [f for f in files if 'shift' not in f.name.lower()]

    return files


# -----------------------
# Routes
# -----------------------




@app.route('/')
def root():
    return "Trend Analysis API — Multi-city"

@app.route('/employee/<path:pid>/image', methods=['GET'])
@app.route('/api/employees/<path:pid>/image', methods=['GET'])
def serve_employee_image(pid):
    """
    Try to return image bytes for pid using employeeimage.get_person_image_bytes.
    Fallbacks:
      - try stripped prefix (emp:, uid:, name:)
      - try resolving pid -> Personnel.ObjectID / GUID using get_personnel_info()
    If none found -> 404 JSON.
    """
    try:
        b = None
        # attempt with raw pid and stripped prefix
        logging.info("serve_employee_image: requested pid=%s", pid)
        b = get_person_image_bytes(pid)
        if not b:
            # try stripping common prefixes if present
            try:
                if ':' in pid:
                    _, rest = pid.split(':', 1)
                    logging.debug("serve_employee_image: trying stripped pid=%s", rest.strip())
                    b = get_person_image_bytes(rest.strip())
            except Exception:
                pass

        # NEW: if still not found, try to resolve pid via personnel lookup (EmployeeID -> ObjectID)
        if not b:
            try:
                logging.debug("serve_employee_image: attempt personnel resolution for pid=%s", pid)
                pinfo = get_personnel_info(pid) or {}
                # prefer ObjectID, then GUID
                obj = pinfo.get("ObjectID")
                guid = pinfo.get("GUID")
                tried = []
                if obj is not None:
                    obj_s = str(obj).strip()
                    tried.append(obj_s)
                    logging.debug("serve_employee_image: trying image with resolved ObjectID=%s", obj_s)
                    b = get_person_image_bytes(obj_s)
                if not b and guid:
                    guid_s = str(guid).strip()
                    tried.append(guid_s)
                    logging.debug("serve_employee_image: trying image with resolved GUID=%s", guid_s)
                    b = get_person_image_bytes(guid_s)
                if b:
                    logging.info("serve_employee_image: resolved pid=%s -> used parent id(s)=%s to fetch image", pid, tried)
            except Exception:
                logging.exception("serve_employee_image: personnel resolution attempt failed for pid=%s", pid)

        if not b:
            logging.warning("serve_employee_image: no image found for pid=%s", pid)
            return jsonify({"error": "image not found"}), 404

        try:
            kind = _guess_image_kind(b)
            if not kind:
                kind = 'jpeg'
            mime = 'image/' + ('jpeg' if kind == 'jpg' else kind)
        except Exception:
            mime = 'image/jpeg'

        bio = BytesIO(b)
        bio.seek(0)
        response = send_file(bio, mimetype=mime, as_attachment=False)
        try:
            response.headers['Cache-Control'] = 'no-cache, no-store, must-revalidate'
            response.headers['Pragma'] = 'no-cache'
            response.headers['Expires'] = '0'
        except Exception:
            pass
        return response

    except Exception as e:
        logging.exception("serve_employee_image failed for %s", pid)
        return jsonify({"error": "internal server error", "details": str(e)}), 500

# ... rest of file unchanged (routes /run /latest /record etc.) ...
# (I haven't pasted the entire unchanged mid-section again to save space; keep your existing app.py content
#  – only the serve_employee_image above was changed. If you prefer, I can provide the entire file verbatim.)
#
# Note: If you want the complete file as a single copy-pasteable file, tell me and I'll paste the rest unchanged.
#
# run
if __name__ == "__main__":
    app.run(host="0.0.0.0", port=8002, debug=True)




