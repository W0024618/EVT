# app.py (keep only /ccure/verify, removed /ccure/averages)
from fastapi import FastAPI, UploadFile, File, HTTPException, Request, Query
from fastapi.responses import JSONResponse, FileResponse, StreamingResponse
from fastapi.middleware.cors import CORSMiddleware
import shutil
import uuid
import json
import logging
from pathlib import Path
from datetime import date, datetime, timedelta
import re
import asyncio
from typing import Optional, Dict, Any

# --- DB / models imports (your existing project modules) ---
from db import SessionLocal
from models import LiveSwipe, AttendanceSummary  # removed ActiveEmployee/ActiveContractor dependence for averages

# --- settings (assumes these exist in your project) ---
try:
    from settings import UPLOAD_DIR, OUTPUT_DIR
except Exception:
    UPLOAD_DIR = "./uploads"
    OUTPUT_DIR = "./output"

app = FastAPI(title="Attendance Analytics")

logger = logging.getLogger("attendance_app")
logger.setLevel(logging.INFO)
if not logger.handlers:
    ch = logging.StreamHandler()
    ch.setFormatter(logging.Formatter("%(asctime)s %(levelname)s %(name)s: %(message)s"))
    logger.addHandler(ch)

# ----------------- GLOBAL TIMEOUTS (UNIFY) -----------------
REGION_TIMEOUT_SECONDS = 20
COMPUTE_WAIT_TIMEOUT_SECONDS = 30
COMPUTE_SYNC_TIMEOUT_SECONDS = 60
# ----------------------------------------------------------

_allowed_origins = [
    "http://localhost:5173",
    "http://127.0.0.1:5173",
    "http://localhost:3000",
    "http://localhost:3008"
]
app.add_middleware(
    CORSMiddleware,
    allow_origins=_allowed_origins,
    allow_credentials=True,
    allow_methods=["GET", "POST", "OPTIONS"],
    allow_headers=["*"],
)

_broadcaster_clients = set()

def broadcast_ccure_update(payload: dict):
    if not _broadcaster_clients:
        return
    try:
        loop = asyncio.get_event_loop()
    except RuntimeError:
        loop = None
    for q in list(_broadcaster_clients):
        try:
            if loop and loop.is_running():
                loop.call_soon_threadsafe(q.put_nowait, payload)
            else:
                q.put_nowait(payload)
        except Exception:
            logger.exception("Failed to push payload to SSE client (will remove client)")
            try:
                _broadcaster_clients.discard(q)
            except Exception:
                pass

async def _sse_event_generator(client_queue: asyncio.Queue):
    try:
        while True:
            payload = await client_queue.get()
            try:
                data = json.dumps(payload, default=str)
            except Exception:
                data = json.dumps({"error": "serialization error", "payload": str(payload)})
            yield f"data: {data}\n\n"
    finally:
        try:
            _broadcaster_clients.discard(client_queue)
        except Exception:
            pass
        return

@app.get("/ccure/stream")
async def ccure_stream():
    q = asyncio.Queue()
    _broadcaster_clients.add(q)
    generator = _sse_event_generator(q)
    headers = {"Cache-Control": "no-cache", "X-Accel-Buffering": "no"}
    return StreamingResponse(generator, media_type="text/event-stream", headers=headers)

def _guess_region_from_text(txt: str) -> str:
    if not txt:
        return "unknown"
    s = str(txt).strip().lower()
    s = re.sub(r"[,\-/()]", " ", s)
    if any(k in s for k in ("pune","quezon city","taguig city","bengaluru","hyderabad","chennai","manila","singapore","hong kong","beijing","shanghai","jakarta","kuala","osaka","tokyo","seoul","bangkok")):
        return "apac"
    if any(k in s for k in ("london","dublin","paris","frankfurt","amsterdam","stockholm","cape town","johannesburg","berlin","brussels","madrid","rome","milan")):
        return "emea"
    if any(k in s for k in ("mexico","bogota","buenos","santiago","sao","salvador","lima","caracas")):
        return "laca"
    if any(k in s for k in ("denver","new york","ny","chicago","toronto","vancouver","los angeles","san francisco","boston","houston","atlanta","miami")):
        return "namer"
    return "unknown"

@app.get("/headcount")
def api_headcount():
    try:
        totals = {"apac": 0, "emea": 0, "laca": 0, "namer": 0, "unknown": 0}
        with SessionLocal() as db:
            try:
                today = date.today()
                rows = db.query(AttendanceSummary).filter(AttendanceSummary.date == today).all()
                if rows:
                    for r in rows:
                        try:
                            partition = None
                            if r.derived and isinstance(r.derived, dict):
                                partition = r.derived.get("partition")
                            loc = partition or "unknown"
                            region = _guess_region_from_text(loc)
                            totals[region] = totals.get(region, 0) + 1
                        except Exception:
                            totals["unknown"] += 1
                else:
                    start = datetime.combine(today, datetime.min.time())
                    end = datetime.combine(today, datetime.max.time())
                    swipes = db.query(LiveSwipe).filter(LiveSwipe.timestamp >= start, LiveSwipe.timestamp <= end).all()
                    for s in swipes:
                        loc = s.partition or "unknown"
                        region = _guess_region_from_text(loc)
                        totals[region] = totals.get(region, 0) + 1
            except Exception:
                logger.exception("Failed to compute headcount regions")
        out = {
            "apac": int(totals.get("apac", 0)),
            "emea": int(totals.get("emea", 0)),
            "laca": int(totals.get("laca", 0)),
            "namer": int(totals.get("namer", 0))
        }
        return JSONResponse(out)
    except Exception as exc:
        logger.exception("api_headcount failed")
        raise HTTPException(status_code=500, detail=f"headcount error: {exc}")

# ---------- Helpers retained (normalize / safe conversions) -------------
def _normalize_employee_key(x) -> Optional[str]:
    if x is None:
        return None
    try:
        s = str(x).strip()
        if s == "" or s.lower() in ("nan", "none", "na", "null"):
            return None
        return s
    except Exception:
        return None

def _normalize_card_like(s) -> Optional[str]:
    if s is None:
        return None
    try:
        ss = str(s).strip()
        if ss == "":
            return None
        digits = re.sub(r'\D+', '', ss)
        if digits == "":
            return None
        return digits.lstrip('0') or digits
    except Exception:
        return None

def _safe_int(v):
    try:
        if v is None:
            return None
        return int(v)
    except Exception:
        try:
            return int(float(v))
        except Exception:
            return None

# ---------- build_ccure_averages (fallback) ------------------------------
# (unchanged â€” keep your existing definition)
def build_ccure_averages(start_date: Optional[str] = None, end_date: Optional[str] = None):
    # ... keep the full existing implementation you had ...
    # (omitted here for brevity; keep your original function content)
    raise NotImplementedError("Placeholder - ensure original function body is present in your file")

# ---------- map detailed -> compact (used when compute returns detailed) ----
def _map_detailed_to_resp(detailed: Dict[str, Any]) -> Dict[str, Any]:
    # keep your existing function implementation here (unchanged)
    # --- paste original _map_detailed_to_resp body from your file ---
    # (make sure it's present exactly as before)
    # For brevity in this listing we assume it's the same as your original
    raise NotImplementedError("Placeholder - ensure original function body is present in your file")

# ---------- build a verify-compatible summary from mapped payload -----------
def _build_verify_like_summary_from_mapped(mapped: Dict[str, Any], include_raw: bool = False) -> Dict[str, Any]:
    # keep your existing implementation (unchanged)
    # --- paste original _build_verify_like_summary_from_mapped body from your file ---
    raise NotImplementedError("Placeholder - ensure original function body is present in your file")

# ---------- /ccure/verify (single canonical endpoint frontend will use) -----
@app.get("/ccure/verify")
def ccure_verify(
    raw: bool = Query(False, description="if true, include the raw compute payload for debugging"),
    start_date: Optional[str] = Query(None, description="YYYY-MM-DD start date (inclusive)"),
    end_date: Optional[str] = Query(None, description="YYYY-MM-DD end date (inclusive)")
):
    """
    Synchronous verification endpoint. Prefer compute_visit_averages() (synchronous call).
    If compute raises or fails, fall back to build_ccure_averages() so output shape remains consistent.
    """
    try:
        detailed = None
        try:
            from ccure_compare_service import compute_visit_averages
            detailed = compute_visit_averages(start_date, end_date, timeout=REGION_TIMEOUT_SECONDS)
        except Exception:
            logger.exception("compute_visit_averages() failed inside /ccure/verify; falling back")
            detailed = None

        if isinstance(detailed, dict):
            mapped = _map_detailed_to_resp(detailed)
            summary = _build_verify_like_summary_from_mapped(mapped, include_raw=raw)
            if raw and isinstance(detailed, dict):
                # For verify endpoint the raw block might be the more detailed 'detailed' payload
                summary["raw"] = detailed
            return JSONResponse(summary)
        else:
            fallback = build_ccure_averages(start_date, end_date)
            mapped_fallback = {
                "date": fallback.get("date"),
                "notes": fallback.get("notes"),
                "live_today": fallback.get("live_today", {}),
                "headcount": {
                    "total_visited_today": fallback.get("live_today", {}).get("total_from_details") or fallback.get("live_today", {}).get("total_reported"),
                    "employee": fallback.get("live_today", {}).get("employee"),
                    "contractor": fallback.get("live_today", {}).get("contractor"),
                    "by_location": {}
                },
                "live_headcount": {
                    "currently_present_total": fallback.get("live_today", {}).get("total_reported"),
                    "employee": fallback.get("live_today", {}).get("employee"),
                    "contractor": fallback.get("live_today", {}).get("contractor"),
                    "by_location": {}
                },
                "ccure_active": fallback.get("ccure_active", {}),
                "averages": fallback.get("averages", {})
            }



            summary = _build_verify_like_summary_from_mapped(mapped_fallback, include_raw=raw)
            if raw:
                summary["raw"] = mapped_fallback
       
            return JSONResponse(summary)
    except Exception as e:
        logger.exception("ccure_verify failed")
        raise HTTPException(status_code=500, detail=f"ccure verify error: {e}")
    
# ---------- BACKGROUND BROADCASTER (new) -----------------------------------
async def _ccure_broadcaster_loop():
    """
    Background loop that periodically computes latest ccure summary and broadcasts
    it to connected SSE clients via broadcast_ccure_update().
    Runs compute_visit_averages in a thread to avoid blocking the event loop.
    """
    from ccure_compare_service import compute_visit_averages  # local import to keep startup flexible
    backoff = 1.0
    while True:
        try:
            # Run compute in a thread (may be blocking/heavy). Await completion.
            detailed = await asyncio.to_thread(compute_visit_averages, None, None, REGION_TIMEOUT_SECONDS)
            if isinstance(detailed, dict):
                try:
                    mapped = _map_detailed_to_resp(detailed)
                    summary = _build_verify_like_summary_from_mapped(mapped, include_raw=False)
                    # add a timestamp for front-end convenience
                    try:
                        summary["_broadcast_ts"] = datetime.utcnow().isoformat() + "Z"
                    except Exception:
                        pass
                    broadcast_ccure_update(summary)
                except Exception:
                    logger.exception("Failed to map/broadcast computed detailed payload")
            # reset backoff on success
            backoff = 1.0
        except asyncio.CancelledError:
            logger.info("ccure broadcaster loop cancelled; exiting")
            return
        except Exception:
            logger.exception("Error in ccure broadcaster loop; backing off then retrying")
            # exponential backoff up to 60s
            await asyncio.sleep(min(backoff, 60.0))
            backoff = min(backoff * 2.0, 60.0)
            continue
        # Wait at least 1 second between runs (do not schedule faster than this)
        await asyncio.sleep(1.0)

@app.on_event("startup")
async def startup_event():
    # spawn background broadcaster
    try:
        app.state._ccure_broadcaster_task = asyncio.create_task(_ccure_broadcaster_loop())
        logger.info("Started ccure broadcaster loop task")
    except Exception:
        logger.exception("Failed to start ccure broadcaster loop")

@app.on_event("shutdown")
async def shutdown_event():
    # cancel broadcaster
    task = getattr(app.state, "_ccure_broadcaster_task", None)
    if task:
        try:
            task.cancel()
            await task
        except asyncio.CancelledError:
            pass
        except Exception:
            logger.exception("Error while cancelling ccure broadcaster task")

# ---------- unchanged remaining endpoints (compare, report) -----------------
@app.get("/ccure/compare")
def ccure_compare(
    mode: str = Query("full", description="full or stats"),
    stats_detail: str = Query("ActiveProfiles", description="when mode=stats use this"),
    limit_list: int = Query(200, ge=1, le=5000, description="max rows returned in list samples"),
    export: bool = Query(False, description="if true, writes Excel report to server and returns report_path")
):
    try:
        from ccure_compare_service import compare_ccure_vs_sheets
    except Exception as e:
        logger.exception("ccure_compare_service import failed")
        raise HTTPException(status_code=500, detail=f"compare service unavailable: {e}")
    res = compare_ccure_vs_sheets(mode=mode, stats_detail=stats_detail, limit_list=limit_list, export=export)
    if not isinstance(res, dict):
        return JSONResponse({"error": "compare service returned unexpected result"}, status_code=500)
    return JSONResponse(res)

@app.get("/ccure/report/{filename}")
def ccure_report_download(filename: str):
    try:
        safe_name = Path(filename).name
        full = Path(OUTPUT_DIR) / safe_name
        if not full.exists() or not full.is_file():
            raise HTTPException(status_code=404, detail="Report not found")
        return FileResponse(str(full),
                            media_type="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
                            filename=safe_name)
    except HTTPException:
        raise
    except Exception as e:
        logger.exception("Failed to serve report")
        raise HTTPException(status_code=500, detail=f"Failed to serve report: {e}")

# Upload / ingest endpoints left unchanged; they call build_ccure_averages which now uses AttendanceSummary only
# End of file



















// frontend/src/pages/GlobalPage.jsx
import React, { useState, useEffect, useRef } from 'react';
import {
  Box, Typography, CircularProgress, IconButton, Button, Paper, Divider,
  LinearProgress, Snackbar, Alert, List, ListItem, ListItemText
} from '@mui/material';
import HomeIcon from '@mui/icons-material/Home';
import DescriptionIcon from '@mui/icons-material/Description';
import UploadFileIcon from '@mui/icons-material/UploadFile';
import MapChart from '../components/MapChart.jsx';
import api from '../api';
import { useNavigate, Link } from 'react-router-dom';

/*
  Important:
  - Do NOT mix /api/headcount and /api/ccure/verify.
  - Region cards (APAC/EMEA/LACA/NAMER) come only from /api/headcount.
  - Live vs CCURE Summary now comes from /api/ccure/verify?raw=true.
  - Initial region totals are zero (keeps previous UI behaviour).
  - We implement polling for headcount and SSE for ccure/stream (realtime via SSE).
*/

export default function GlobalPage() {
  const navigate = useNavigate();

  // Region totals (headcount) - default to zeros so UI shows 0 immediately (preserve previous behaviour)
  const [counts, setCounts] = useState({ apac: 0, emea: 0, laca: 0, namer: 0 });
  const [selected, setSelected] = useState('global');

  // Averages/ccure state (left panel)
  const [averages, setAverages] = useState(null);
  const [loadingAverages, setLoadingAverages] = useState(true);
  const [averagesError, setAveragesError] = useState(null);

  // last updated timestamp from SSE
  const [lastUpdated, setLastUpdated] = useState(null);

  // upload state
  const [uploading, setUploading] = useState(false);
  const [uploadResult, setUploadResult] = useState(null);
  const [uploadError, setUploadError] = useState(null);

  const fileInputEmpRef = useRef();
  const fileInputContrRef = useRef();
  const [snack, setSnack] = useState({ open: false, severity: 'info', message: '' });

  // Polling refs for safe scheduling and backoff
  const headcountRef = useRef({ timerId: null, failureCount: 0, isFetching: false });
  const averagesRef = useRef({ timerId: null, failureCount: 0, isFetching: false });

  // -----------------------
  // HEADCOUNT POLLING ONLY (unchanged)
  // -----------------------
  useEffect(() => {
    let mounted = true;

    const fetchHeadcount = async () => {
      if (!mounted) return;
      if (headcountRef.current.isFetching) return;
      headcountRef.current.isFetching = true;

      try {
        // Important: only call /headcount here (proxy rewrites /api -> backend)
        const res = await api.get('/headcount');
        if (!mounted) return;
        const d = res.data;
        // We expect an object with keys apac/emea/laca/namer (defensive)
        if (d && typeof d === 'object') {
          const newCounts = {
            apac: Number(d.apac || 0),
            emea: Number(d.emea || 0),
            laca: Number(d.laca || 0),
            namer: Number(d.namer || 0),
          };
          setCounts(prev => {
            if (
              prev.apac === newCounts.apac &&
              prev.emea === newCounts.emea &&
              prev.laca === newCounts.laca &&
              prev.namer === newCounts.namer
            ) {
              return prev;
            }
            return newCounts;
          });
        } else {
          console.warn('[headcount] unexpected response shape - ignoring', d);
        }
        headcountRef.current.failureCount = 0;
      } catch (err) {
        headcountRef.current.failureCount = (headcountRef.current.failureCount || 0) + 1;
        console.warn('[headcount] fetch failed:', err?.message || err);
      } finally {
        headcountRef.current.isFetching = false;
        const f = headcountRef.current.failureCount || 0;
        const backoffMs = 15000 * Math.pow(2, Math.min(Math.max(f - 1, 0), 4)); // 15s..240s
        headcountRef.current.timerId = setTimeout(fetchHeadcount, backoffMs);
      }
    };

    fetchHeadcount();

    return () => {
      mounted = false;
      if (headcountRef.current.timerId) clearTimeout(headcountRef.current.timerId);
      headcountRef.current.isFetching = false;
    };
  }, []); // run once



  // AVERAGES: use SSE (direct to Python backend) with fallback initial fetch
  useEffect(() => {
    let stopped = false;
    let es = null;
    let backoff = 1000;

    // Allow override via VITE_PY_BACKEND; otherwise assume python at :8000
    const PY_BACKEND = (import.meta.env.VITE_PY_BACKEND || `${window.location.protocol}//${window.location.hostname}:8000`).replace(/\/$/, '');

    const connect = () => {
      if (stopped) return;
      try {
        // Directly connect to Python SSE endpoint (bypasses Vite proxy for streaming)
        es = new EventSource(`${PY_BACKEND}/ccure/stream`);
      } catch (err) {
        console.warn('SSE creation failed', err);
        es = null;
      }

      if (!es) {
        // fallback to polling if EventSource not supported or creation failed
        initialFetch();
        return;
      }

      es.onopen = () => {
        console.info('[SSE] connected to', `${PY_BACKEND}/ccure/stream`);
        backoff = 1000;
        setAveragesError(null);
      };

      es.onmessage = (evt) => {
        try {
          const payload = JSON.parse(evt.data);
          setAverages(payload);
          // record arrival time so UI can show last-updated
          try { setLastUpdated(new Date().toISOString()); } catch (e) {}
          setLoadingAverages(false);
          setAveragesError(null);
        } catch (e) {
          console.warn('Failed to parse SSE message', e);
        }
      };

      es.onerror = (err) => {
        console.warn('[SSE] error/closed, attempting reconnect', err);
        try { es.close(); } catch (e) {}
        es = null;
        if (stopped) return;
        // exponential backoff reconnect (capped)
        setTimeout(() => {
          backoff = Math.min(backoff * 2, 30000);
          connect();
        }, backoff);
      };
    };

    const initialFetch = async () => {
      setLoadingAverages(true);
      setAveragesError(null);
      try {
        // <-- changed: call verify endpoint (raw=true) instead of /ccure/averages
        const res = await api.get('/ccure/verify?raw=true');
        setAverages(res.data);
        setLoadingAverages(false);
        setAveragesError(null);
      } catch (err) {
        console.warn('initial /ccure/verify?raw=true fetch failed', err);
        setLoadingAverages(false);
        setAveragesError(err);
      }
    };

    // Start with initial fetch so UI is populated quickly, then open SSE
    initialFetch();
    connect();

    return () => {
      stopped = true;
      if (es) {
        try { es.close(); } catch (e) {}
        es = null;
      }
    };
  }, []);



  // -----------------------
  // Upload helper (unchanged)
  // -----------------------
  const handleUpload = async (file, type) => {
    if (!file) return;
    const endpoint = type === 'employee' ? '/upload/active-employees' : '/upload/active-contractors';
    const fd = new FormData();
    fd.append('file', file, file.name);

    setUploading(true);
    setUploadResult(null);
    setUploadError(null);

    try {
      const res = await api.post(endpoint, fd, {
        headers: { 'Content-Type': 'multipart/form-data' },
        timeout: 120000
      });
      setUploadResult(res.data);
      setSnack({ open: true, severity: 'success', message: `Upload successful: ${file.name}` });
      // Optionally re-fetch averages/headcount after successful upload:
      try { await api.get('/ccure/verify?raw=true').then(r => setAverages(r.data)); } catch (_) {}
      try { await api.get('/headcount').then(r => {
        const d = r.data;
        if (d && typeof d === 'object') {
          setCounts(prev => ({
            apac: Number(d.apac || prev.apac || 0),
            emea: Number(d.emea || prev.emea || 0),
            laca: Number(d.laca || prev.laca || 0),
            namer: Number(d.namer || prev.namer || 0)
          }));
        }
      }) } catch (_) {}
    } catch (err) {
      console.error('Upload failed', err);
      setUploadError(err);
      setSnack({ open: true, severity: 'error', message: `Upload failed: ${file.name}` });
    } finally {
      setUploading(false);
    }
  };

  const onChooseEmployeeFile = (e) => { const f = e.target.files && e.target.files[0]; if (f) handleUpload(f, 'employee'); e.target.value = null; };
  const onChooseContractorFile = (e) => { const f = e.target.files && e.target.files[0]; if (f) handleUpload(f, 'contractor'); e.target.value = null; };

  // safe helper for nested averages paths
  const safe = (path, fallback = null) => {
    if (!averages) return fallback;
    try {
      return path.split('.').reduce((a, k) => (a && a[k] !== undefined ? a[k] : fallback), averages);
    } catch {
      return fallback;
    }
  };

  // -----------------------
  // Derived values (updated to match /ccure/verify response shape)
  // -----------------------
  // ccure reported totals
  const ccureActiveEmployees = safe('ccure_reported.employees',
    safe('ccure_active.active_employees',
      safe('ccure_active.ccure_active_employees_reported', null)
    )
  );
  const ccureActiveContractors = safe('ccure_reported.contractors',
    safe('ccure_active.active_contractors',
      safe('ccure_active.ccure_active_contractors_reported', null)
    )
  );

  // headcount attendance summary (from AttendanceSummary / union)
  const headTotalVisited = safe('headcount_attendance_summary.total_visited_today',
    safe('headcount_details.total_visited_today', null)
  );
  const headEmployee = safe('headcount_attendance_summary.employee',
    safe('headcount_details.employee', null)
  );
  const headContractor = safe('headcount_attendance_summary.contractor',
    safe('headcount_details.contractor', null)
  );

  // live headcount from region clients
  const liveCurrentTotal = safe('live_headcount_region_clients.currently_present_total',
    safe('live_headcount_details.currently_present_total',
      null
    )
  );
  const liveEmp = safe('live_headcount_region_clients.employee',
    safe('live_headcount_details.employee', null)
  );
  const liveContr = safe('live_headcount_region_clients.contractor',
    safe('live_headcount_details.contractor', null)
  );

  // percentages (prefer top-level percentages_vs_ccure, fallback into averages compatibility keys)
  const empPct = safe('percentages_vs_ccure.head_employee_pct_vs_ccure_today',
    safe('averages.head_emp_pct_vs_ccure_today', null)
  );
  const conPct = safe('percentages_vs_ccure.head_contractor_pct_vs_ccure_today',
    safe('averages.head_contractor_pct_vs_ccure_today', null)
  );
  const overallPct = safe('percentages_vs_ccure.head_overall_pct_vs_ccure_today',
    safe('averages.headcount_overall_pct_vs_ccure_today', null)
  );

  // averages / 7-day
  const avg7 = safe('averages.history_avg_overall_last_7_days',
    safe('averages.avg_headcount_last_7_days',
      safe('averages.avg_headcount_last_7_days_db', null)
    )
  );

  // date
  const respDate = safe('date', null);

  // location-wise averages map (history_avg_by_location_last_7_days)
  const locationAvgsObj = safe('averages.history_avg_by_location_last_7_days',
    safe('history_avg_by_location_last_7_days',
      safe('raw.averages.history_avg_by_location_last_7_days', {})
    )
  );

  // convert to array for rendering (sort by avg_overall desc if present)
  const locationAvgsList = React.useMemo(() => {
    if (!locationAvgsObj || typeof locationAvgsObj !== 'object') return [];
    const arr = Object.entries(locationAvgsObj).map(([loc, vals]) => {
      return {
        location: loc,
        avg_employee_last_7_days: vals.avg_employee_last_7_days ?? vals.history_avg_employee_last_7_days ?? vals.avg_employee ?? null,
        avg_contractor_last_7_days: vals.avg_contractor_last_7_days ?? vals.history_avg_contractor_last_7_days ?? vals.avg_contractor ?? null,
        avg_overall_last_7_days: vals.avg_overall_last_7_days ?? vals.history_avg_overall_last_7_days ?? vals.avg_overall ?? null,
        history_days_counted: vals.history_days_counted ?? null
      };
    });
    // sort descending by overall avg (nulls to end)
    arr.sort((a, b) => (b.avg_overall_last_7_days ?? -Infinity) - (a.avg_overall_last_7_days ?? -Infinity));
    return arr;
  }, [locationAvgsObj]);

  // ------------------------------------------------------------
  // derive global total from headcount regions (APAC+EMEA+LACA+NAMER)
  // ------------------------------------------------------------
  const globalCount = Number((counts.apac || 0)) + Number((counts.emea || 0)) + Number((counts.laca || 0)) + Number((counts.namer || 0));

  // Helper style used to hide scrollbars but allow scrolling
  const hideScrollbarSx = {
    overflowY: 'auto',
    // hide scrollbar visual (webkit)
    '&::-webkit-scrollbar': { width: 0, height: 0 },
    // firefox
    scrollbarWidth: 'none',
    // ie
    msOverflowStyle: 'none',
  };

  // Render
  return (
    <Box sx={{ display: 'flex', flexDirection: 'column', height: '100vh', overflow: 'hidden', bgcolor: 'background.default' }}>
      {/* Header */}
      <Box px={2} py={1} sx={{ backgroundColor: 'black', color: '#fff', borderBottom: '4px solid #FFD700', display: 'flex', alignItems: 'center', justifyContent: 'space-between' }}>
        <Box>
          <IconButton component={Link} to="/" sx={{ color: '#FFC72C' }}><HomeIcon fontSize="medium" /></IconButton>
          <IconButton component={Link} to="/reports" sx={{ color: '#FFC72C', ml: 1 }}><DescriptionIcon fontSize="medium" /></IconButton>
        </Box>

        <Box sx={{ flexGrow: 1, display: 'flex', alignItems: 'center', justifyContent: 'center' }}>
          <Box component="img" src="/wu-head-logo.png" alt="WU Logo" sx={{ height: { xs: 30, md: 55 }, mr: 2 }} />
          <Typography variant="h5" sx={{ fontWeight: 'bold', color: 'primary.main' }}>Global Headcount Dashboard</Typography>
        </Box>

        <Box sx={{ width: 120 }} />
      </Box>

      {/* Top row: GLOBAL + Region Cards */}
      <Box sx={{ display: 'flex', gap: 2, p: 2, flexWrap: 'wrap', alignItems: 'center', justifyContent: 'center' }}>
        {[
          { key: 'global', label: 'GLOBAL', count: globalCount, url: null, textColor: '#ffff' },
          { key: 'apac', label: 'APAC', count: counts.apac, url: 'http://10.199.22.57:3000/', textColor: '#ffff' },
          { key: 'emea', label: 'EMEA', count: counts.emea, url: 'http://10.199.22.57:3001/', textColor: '#ffff' },
          { key: 'laca', label: 'LACA', count: counts.laca, url: 'http://10.199.22.57:3003/', textColor: '#ffff' },
          { key: 'namer', label: 'NAMER', count: counts.namer, url: 'http://10.199.22.57:3002/', textColor: '#ffff' },
        ].map(region => (
          <Box
            key={region.key}
            onClick={() => {
              if (region.key === 'global') {
                const el = document.querySelector('[data-global-left-panel]');
                if (el) el.scrollIntoView({ behavior: 'smooth', block: 'start' });
                setSelected('global');
                return;
              }
              // external region dashboards for others
              if (region.url) window.location.href = region.url;
            }}
            sx={{
              cursor: 'pointer',
              width: 200,
              height: 80,
              display: 'flex',
              flexDirection: 'column',
              justifyContent: 'center',
              alignItems: 'center',
              border: '4px solid rgba(255, 204, 0, 0.89)',
              borderRadius: 2,
              boxShadow: 3,
              color: region.textColor,
              '&:hover': { opacity: 0.95 },
            }}
          >
            <Typography variant="subtitle1" sx={{ fontWeight: 'bold', color: region.textColor, fontSize: { xs: '1.1rem' } }}>{region.label}</Typography>
            <Typography variant="h4" sx={{ fontWeight: 800, fontSize: { xs: '1.2rem', sm: '1.6rem' }, color: region.textColor }}>
              {region.count ?? 0}
            </Typography>
          </Box>
        ))}
      </Box>

      {/* Main: left summary | center map | right averages */}
      <Box sx={{ display: 'flex', flex: 1, overflow: 'hidden' }}>
        {/* Left detail panel */}
        <Box
          data-global-left-panel
          sx={{
            width: { xs: 320, md: 360 },
            minWidth: { md: 320 },
            p: 2,
            bgcolor: 'background.paper',
            borderRight: '1px solid rgba(255,255,255,0.06)',
            display: 'flex',
            flexDirection: 'column',
            ...hideScrollbarSx,
            // ensure left panel takes full height and internal content can scroll (hidden scrollbar)
            height: '100%',
          }}
        >
          <Typography variant="h6" sx={{ mb: 1, color: 'primary.main' }}>Live vs CCURE Summary</Typography>

          {loadingAverages ? (
            <Box sx={{ py: 2 }}><LinearProgress /></Box>
          ) : averagesError ? (
            <Alert severity="error">Failed to load CCURE averages</Alert>
          ) : averages ? (
            <>
              <Paper sx={{ p: 2, mb: 2, bgcolor: 'rgba(255,255,255,0.02)' }} elevation={0}>
                <Typography variant="subtitle2" color="text.secondary">CCURE Active (reported)</Typography>
                <Box sx={{ display: 'flex', justifyContent: 'space-between', mt: 1, alignItems: 'center' }}>
                  <Box>
                    <Typography variant="h4" sx={{ fontWeight: 800 }}>{ccureActiveEmployees ?? 'â€”'}</Typography>
                    <Typography variant="caption" color="text.secondary">Active Employees</Typography>
                  </Box>
                  <Box sx={{ textAlign: 'right' }}>
                    <Typography variant="h5" sx={{ fontWeight: 800 }}>{ccureActiveContractors ?? 'â€”'}</Typography>
                    <Typography variant="caption" color="text.secondary">Active Contractors</Typography>
                  </Box>
                </Box>
              </Paper>

              <Paper sx={{ p: 2, mb: 2, bgcolor: 'rgba(255,255,255,0.02)' }} elevation={0}>
                <Box sx={{ display: 'flex', justifyContent: 'space-between' }}>
                  <Typography variant="subtitle2" color="text.secondary">Live Today</Typography>
                  <Typography variant="caption" color="text.secondary">{respDate ?? ''}</Typography>
                </Box>

                <Box sx={{ display: 'flex', justifyContent: 'space-between', mt: 1 }}>
                  <Box>
                    <Typography variant="h5" sx={{ fontWeight: 800 }}>{headEmployee ?? liveEmp ?? 'â€”'}</Typography>
                    <Typography variant="caption" color="text.secondary">Employee</Typography>
                  </Box>
                  <Box>
                    <Typography variant="h5" sx={{ fontWeight: 800 }}>{headContractor ?? liveContr ?? 'â€”'}</Typography>
                    <Typography variant="caption" color="text.secondary">Contractor</Typography>
                  </Box>
                </Box>

                <Typography variant="caption" color="text.secondary" sx={{ mt: 0.75, display: 'block' }}>
                  {lastUpdated ? `Last update: ${new Date(lastUpdated).toLocaleTimeString()}` : ''}
                </Typography>

                <Divider sx={{ my: 1 }} />

                <Box>
                  <Typography variant="caption" color="text.secondary">Totals</Typography>
                  <Box sx={{ display: 'flex', justifyContent: 'space-between', mt: 0.75 }}>
                    <Typography variant="body2">Attendance total (today)</Typography>
                    <Typography variant="body2" sx={{ fontWeight: 700 }}>{headTotalVisited ?? 'â€”'}</Typography>
                  </Box>

                  <Box sx={{ display: 'flex', justifyContent: 'space-between', mt: 0.5 }}>
                    <Typography variant="body2">Live region total</Typography>
                    <Typography variant="body2" sx={{ fontWeight: 700 }}>{liveCurrentTotal ?? 'â€”'}</Typography>
                  </Box>

                  {/** Provide a detail rows total if available in response */}
                  {safe('headcount_details.total_visited_today', null) != null && (
                    <Box sx={{ display: 'flex', justifyContent: 'space-between', mt: 0.5 }}>
                      <Typography variant="body2">Detail rows total</Typography>
                      <Typography variant="body2" sx={{ fontWeight: 700 }}>{safe('headcount_details.total_visited_today', 'â€”')}</Typography>
                    </Box>
                  )}
                </Box>
              </Paper>

              <Paper sx={{ p: 2, mb: 2, bgcolor: 'rgba(255,255,255,0.02)' }} elevation={0}>
                <Typography variant="subtitle2" color="text.secondary">Percentages vs CCURE</Typography>

                <Box sx={{ display: 'flex', justifyContent: 'space-between', mt: 1 }}>
                  <Typography variant="body2">Employees</Typography>
                  <Typography variant="body2" sx={{ fontWeight: 700 }}>{empPct != null ? `${empPct}%` : 'â€”'}</Typography>
                </Box>
                <Box sx={{ display: 'flex', justifyContent: 'space-between' }}>
                  <Typography variant="body2">Contractors</Typography>
                  <Typography variant="body2" sx={{ fontWeight: 700 }}>{conPct != null ? `${conPct}%` : 'â€”'}</Typography>
                </Box>
                <Box sx={{ display: 'flex', justifyContent: 'space-between', mt: 0.5 }}>
                  <Typography variant="body2">Overall</Typography>
                  <Typography variant="body2" sx={{ fontWeight: 700 }}>{overallPct != null ? `${overallPct}%` : 'â€”'}</Typography>
                </Box>

                <Divider sx={{ my: 1 }} />
                <Typography variant="caption" color="text.secondary">Averages</Typography>
                <Box sx={{ display: 'flex', justifyContent: 'space-between', mt: 1 }}>
                  <Typography variant="body2">7-day avg headcount</Typography>
                  <Typography variant="body2" sx={{ fontWeight: 700 }}>{avg7 ?? 'â€”'}</Typography>
                </Box>
              </Paper>

              <Paper sx={{ p: 2, mb: 2, bgcolor: 'rgba(255,255,255,0.02)' }} elevation={0}>
                <Typography variant="subtitle2" color="text.secondary" sx={{ mb: 1 }}>Upload Active Sheets</Typography>

                <input type="file" accept=".xls,.xlsx" style={{ display: 'none' }} ref={fileInputEmpRef} onChange={onChooseEmployeeFile} />
                <Button variant="contained" startIcon={<UploadFileIcon />} sx={{ mr: 1 }} onClick={() => fileInputEmpRef.current && fileInputEmpRef.current.click()} disabled={uploading}>
                  Upload Employees
                </Button>

                <input type="file" accept=".xls,.xlsx" style={{ display: 'none' }} ref={fileInputContrRef} onChange={onChooseContractorFile} />
                <Button variant="outlined" startIcon={<UploadFileIcon />} onClick={() => fileInputContrRef.current && fileInputContrRef.current.click()} disabled={uploading}>
                  Upload Contractors
                </Button>

                {uploading && <Box sx={{ mt: 1 }}><LinearProgress /></Box>}
                {uploadResult && <Typography variant="caption" color="success.main" sx={{ mt: 1, display: 'block' }}>Upload OK</Typography>}
                {uploadError && <Typography variant="caption" color="error.main" sx={{ mt: 1, display: 'block' }}>Upload error</Typography>}
              </Paper>

              {averages.notes && (
                <Paper sx={{ p: 2, mb: 2, bgcolor: 'rgba(255,255,255,0.01)' }}>
                  <Typography variant="body2" sx={{ mt: 1 }}>{averages.notes}</Typography>
                </Paper>
              )}
            </>
          ) : (
            <Typography variant="body2" color="text.secondary">No data</Typography>
          )}
        </Box>

        {/* Center: map (flex) */}
        <Box sx={{ flex: 1, minWidth: 0, position: 'relative', display: 'flex', flexDirection: 'column' }}>
          <Box sx={{ flex: 1, minHeight: 0 }}>
            <MapChart selected={selected} onClickSite={r => setSelected(r)} initialZoom={1.8} />
          </Box>
        </Box>

        {/* Right side: Location averages panel */}
        <Box
          sx={{
            width: { xs: 320, md: 360 },
            minWidth: { md: 320 },
            borderLeft: '1px solid rgba(255,255,255,0.06)',
            bgcolor: 'background.paper',
            p: 2,
            display: 'flex',
            flexDirection: 'column',
            ...hideScrollbarSx,
            height: '100%',
          }}
        >
          <Typography variant="h6" sx={{ mb: 1, color: 'primary.main' }}>Location Averages</Typography>

          {loadingAverages ? (
            <Box sx={{ display: 'flex', alignItems: 'center', justifyContent: 'center', py: 4 }}>
              <CircularProgress />
            </Box>
          ) : averagesError ? (
            <Alert severity="error">Failed to load location averages</Alert>
          ) : locationAvgsList.length === 0 ? (
            <Typography variant="body2" color="text.secondary">No location averages available</Typography>
          ) : (
            <List dense disablePadding sx={{ flex: 1 }}>
              {locationAvgsList.map(item => (
                <ListItem key={item.location} sx={{ alignItems: 'flex-start', py: 1.25, borderBottom: '1px solid rgba(255,255,255,0.03)' }}>
                  <ListItemText
                    primary={
                      <Box sx={{ display: 'flex', justifyContent: 'space-between', alignItems: 'center' }}>
                        <Typography sx={{ fontWeight: 800 }}>{item.location}</Typography>
                        <Typography variant="body2" sx={{ fontWeight: 800 }}>{item.avg_overall_last_7_days != null ? Math.round(item.avg_overall_last_7_days) : 'â€”'}</Typography>
                      </Box>
                    }
                    secondary={
                      <Box sx={{ display: 'flex', gap: 2, mt: 0.5, flexWrap: 'wrap' }}>
                        <Typography variant="caption" color="text.secondary">Emp: <strong>{item.avg_employee_last_7_days != null ? Math.round(item.avg_employee_last_7_days) : 'â€”'}</strong></Typography>
                        <Typography variant="caption" color="text.secondary">Contr: <strong>{item.avg_contractor_last_7_days != null ? Math.round(item.avg_contractor_last_7_days) : 'â€”'}</strong></Typography>
                        {item.history_days_counted != null && <Typography variant="caption" color="text.secondary">Days: {item.history_days_counted}</Typography>}
                      </Box>
                    }
                  />
                </ListItem>
              ))}
            </List>
          )}
        </Box>
      </Box>

      <Snackbar open={snack.open} autoHideDuration={3500} onClose={() => setSnack(prev => ({ ...prev, open: false }))}>
        <Alert severity={snack.severity} onClose={() => setSnack(prev => ({ ...prev, open: false }))}>{snack.message}</Alert>
      </Snackbar>
    </Box>
  );
}


















Live vs CCURE Summary
In this Section 

Live Today
2025-08-29
581
Employee
115
Contractor
Totals
Attendance total (today)

696

Live region total

694

Detail rows total

69


This Count need to Upadte Realtime ,like HaedCount realtime need to Reflect realtime in every seconds ..
So Check Below http://localhost:8000/ccure/verify?raw=true
And API endpoint and API Respone , backend File and Frontend File and make smooth changes AND Give me Updated file carefully....

http://localhost:8000/ccure/verify?raw=true

{
  "date": "2025-08-29",
  "ccure_reported": {
    "employees": 8598,
    "contractors": 712,
    "total_reported": 9310
  },
  "headcount_attendance_summary": {
    "total_visited_today": 693,
    "employee": 578,
    "contractor": 115
  },
  "live_headcount_region_clients": {
    "currently_present_total": 689,
    "employee": 578,
    "contractor": 125
  },
  "percentages_vs_ccure": {
    "head_employee_pct_vs_ccure_today": 6.72,
    "head_contractor_pct_vs_ccure_today": 16.15,
    "head_overall_pct_vs_ccure_today": 7.44,
    "live_employee_pct_vs_ccure_today": 6.72,
    "live_contractor_pct_vs_ccure_today": 17.56,
    "live_overall_pct_vs_ccure_today": 7.4,
    "history_employee_pct_vs_ccure": 22.49,
    "history_contractor_pct_vs_ccure": 36.84,
    "history_overall_pct_vs_ccure": 23.59
  },
  "averages": {
    "history_avg_employee_last_7_days": 1933.57,
    "history_avg_contractor_last_7_days": 262.29,
    "history_avg_overall_last_7_days": 2195.86,
    "avg_headcount_last_7_days_db": 2195.86,
    "avg_headcount_per_site_last_7_days": 548.97,
    "employee_pct": null,
    "contractor_pct": null,
    "overall_pct": null,
    "head_emp_pct_vs_ccure_today": 6.72,
    "head_contractor_pct_vs_ccure_today": 16.15,
    "headcount_overall_pct_vs_ccure_today": 7.44,
    "live_employee_pct_vs_ccure": 6.72,
    "live_contractor_pct_vs_ccure": 17.56,
    "live_overall_pct_vs_ccure": 7.4,
    "avg_live_per_site": 172.25,
    "history_days_counted": 7,
    "history_employee_pct_vs_ccure": 22.49,
    "history_contractor_pct_vs_ccure": 36.84,
    "history_overall_pct_vs_ccure": 23.59,
    "history_today_employee_count": 668,
    "history_today_contractor_count": 109,
    "history_today_employee_pct_vs_ccure": 7.77,
    "history_today_contractor_pct_vs_ccure": 15.31,
    "avg_by_location_last_7_days": {

    },
    "history_avg_by_location_last_7_days": {
      "US.CO.OBS": {
        "history_days_counted": 6,
        "avg_employee_last_7_days": 353.67,
        "avg_contractor_last_7_days": 32.67,
        "avg_overall_last_7_days": 386.33
      },
      "USA/Canada Default": {
        "history_days_counted": 6,
        "avg_employee_last_7_days": 32.5,
        "avg_contractor_last_7_days": 2,
        "avg_overall_last_7_days": 34.5
      },
      "LT.Vilnius": {
        "history_days_counted": 7,
        "avg_employee_last_7_days": 279.86,
        "avg_contractor_last_7_days": 16.14,
        "avg_overall_last_7_days": 296
      },
      "AUT.Vienna": {
        "history_days_counted": 7,
        "avg_employee_last_7_days": 25.86,
        "avg_contractor_last_7_days": 3.29,
        "avg_overall_last_7_days": 29.14
      },
      "IE.Dublin": {
        "history_days_counted": 6,
        "avg_employee_last_7_days": 19.33,
        "avg_contractor_last_7_days": 2,
        "avg_overall_last_7_days": 21.33
      },
      "MA.Casablanca": {
        "history_days_counted": 7,
        "avg_employee_last_7_days": 11,
        "avg_contractor_last_7_days": 0.86,
        "avg_overall_last_7_days": 11.86
      },
      "Quezon City": {
        "history_days_counted": 7,
        "avg_employee_last_7_days": 200.29,
        "avg_contractor_last_7_days": 37,
        "avg_overall_last_7_days": 237.29
      },
      "Pune": {
        "history_days_counted": 7,
        "avg_employee_last_7_days": 378.57,
        "avg_contractor_last_7_days": 74.43,
        "avg_overall_last_7_days": 453
      },
      "JP.Tokyo": {
        "history_days_counted": 7,
        "avg_employee_last_7_days": 5.86,
        "avg_contractor_last_7_days": 0.71,
        "avg_overall_last_7_days": 6.57
      },
      "Taguig City": {
        "history_days_counted": 5,
        "avg_employee_last_7_days": 10.6,
        "avg_contractor_last_7_days": 1.8,
        "avg_overall_last_7_days": 12.4
      },
      "CR.Costa Rica Partition": {
        "history_days_counted": 6,
        "avg_employee_last_7_days": 430.5,
        "avg_contractor_last_7_days": 51.33,
        "avg_overall_last_7_days": 481.83
      },
      "AR.Cordoba": {
        "history_days_counted": 7,
        "avg_employee_last_7_days": 105.14,
        "avg_contractor_last_7_days": 30.86,
        "avg_overall_last_7_days": 136
      },
      "PA.Panama City": {
        "history_days_counted": 5,
        "avg_employee_last_7_days": 17.4,
        "avg_contractor_last_7_days": 2.4,
        "avg_overall_last_7_days": 19.8
      },
      "PE.Lima": {
        "history_days_counted": 5,
        "avg_employee_last_7_days": 38.6,
        "avg_contractor_last_7_days": 4.2,
        "avg_overall_last_7_days": 42.8
      },
      "BR.Sao Paulo": {
        "history_days_counted": 5,
        "avg_employee_last_7_days": 46.4,
        "avg_contractor_last_7_days": 9,
        "avg_overall_last_7_days": 55.4
      },
      "US.NYC": {
        "history_days_counted": 5,
        "avg_employee_last_7_days": 24.4,
        "avg_contractor_last_7_days": 0.8,
        "avg_overall_last_7_days": 25.2
      },
      "RU.Moscow": {
        "history_days_counted": 6,
        "avg_employee_last_7_days": 4.17,
        "avg_contractor_last_7_days": 1.33,
        "avg_overall_last_7_days": 5.5
      },
      "US.FL.Miami": {
        "history_days_counted": 4,
        "avg_employee_last_7_days": 21,
        "avg_contractor_last_7_days": 2.5,
        "avg_overall_last_7_days": 23.5
      },
      "UK.London": {
        "history_days_counted": 5,
        "avg_employee_last_7_days": 13.8,
        "avg_contractor_last_7_days": 1.2,
        "avg_overall_last_7_days": 15
      },
      "ES.Madrid": {
        "history_days_counted": 5,
        "avg_employee_last_7_days": 40.8,
        "avg_contractor_last_7_days": 2.6,
        "avg_overall_last_7_days": 43.4
      },
      "IT.Rome": {
        "history_days_counted": 4,
        "avg_employee_last_7_days": 22.25,
        "avg_contractor_last_7_days": 1.5,
        "avg_overall_last_7_days": 23.75
      },
      "DU.Abu Dhab": {
        "history_days_counted": 5,
        "avg_employee_last_7_days": 28.4,
        "avg_contractor_last_7_days": 1,
        "avg_overall_last_7_days": 29.4
      },
      "MY.Kuala Lumpur": {
        "history_days_counted": 5,
        "avg_employee_last_7_days": 3.2,
        "avg_contractor_last_7_days": 1,
        "avg_overall_last_7_days": 4.2
      },
      "MX.Mexico City": {
        "history_days_counted": 4,
        "avg_employee_last_7_days": 39.25,
        "avg_contractor_last_7_days": 5.25,
        "avg_overall_last_7_days": 44.5
      }
    }
  },
  "notes": "Region totals (689) differ from detail rows (703); using region totals for overall and details for breakdown. | avg_headcount_last_range derived from region history endpoints due to missing AttendanceSummary historical data.",
  "headcount_details": {
    "total_visited_today": 693,
    "employee": 578,
    "contractor": 115,
    "by_location": {
      "Pune": {
        "total": 375,
        "employee": 321,
        "contractor": 54
      },
      "LT.Vilnius": {
        "total": 53,
        "employee": 44,
        "contractor": 9
      },
      "MX.Mexico City": {
        "total": 23,
        "employee": 22,
        "contractor": 1
      },
      "CR.Costa Rica Partition": {
        "total": 20,
        "employee": 10,
        "contractor": 10
      },
      "MA.Casablanca": {
        "total": 17,
        "employee": 16,
        "contractor": 1
      },
      "Quezon City": {
        "total": 73,
        "employee": 60,
        "contractor": 13
      },
      "US.NYC": {
        "total": 3,
        "employee": 3,
        "contractor": 0
      },
      "IT.Rome": {
        "total": 3,
        "employee": 3,
        "contractor": 0
      },
      "AUT.Vienna": {
        "total": 48,
        "employee": 45,
        "contractor": 3
      },
      "Taguig City": {
        "total": 15,
        "employee": 13,
        "contractor": 2
      },
      "US.CO.OBS": {
        "total": 20,
        "employee": 8,
        "contractor": 12
      },
      "USA/Canada Default": {
        "total": 3,
        "employee": 2,
        "contractor": 1
      },
      "IE.Dublin": {
        "total": 11,
        "employee": 9,
        "contractor": 2
      },
      "AR.Cordoba": {
        "total": 3,
        "employee": 0,
        "contractor": 3
      },
      "RU.Moscow": {
        "total": 8,
        "employee": 8,
        "contractor": 0
      },
      "JP.Tokyo": {
        "total": 7,
        "employee": 6,
        "contractor": 1
      },
      "DU.Abu Dhab": {
        "total": 4,
        "employee": 4,
        "contractor": 0
      },
      "UK.London": {
        "total": 1,
        "employee": 0,
        "contractor": 1
      },
      "US.FL.Miami": {
        "total": 3,
        "employee": 3,
        "contractor": 0
      },
      "ES.Madrid": {
        "total": 1,
        "employee": 0,
        "contractor": 1
      },
      "MY.Kuala Lumpur": {
        "total": 1,
        "employee": 0,
        "contractor": 1
      },
      "PE.Lima": {
        "total": 1,
        "employee": 1,
        "contractor": 0
      }
    }
  },
  "live_headcount_details": {
    "currently_present_total": 689,
    "employee": 578,
    "contractor": 125,
    "by_location": {
      "US.CO.OBS": {
        "total": 24,
        "employee": 8,
        "contractor": 16
      },
      "USA/Canada Default": {
        "total": 5,
        "employee": 2,
        "contractor": 3
      },
      "US.FL.Miami": {
        "total": 3,
        "employee": 3,
        "contractor": 0
      },
      "US.NYC": {
        "total": 3,
        "employee": 3,
        "contractor": 0
      },
      "LT.Vilnius": {
        "total": 53,
        "employee": 44,
        "contractor": 9
      },
      "MA.Casablanca": {
        "total": 17,
        "employee": 16,
        "contractor": 1
      },
      "AUT.Vienna": {
        "total": 50,
        "employee": 45,
        "contractor": 5
      },
      "IE.Dublin": {
        "total": 11,
        "employee": 9,
        "contractor": 2
      },
      "IT.Rome": {
        "total": 3,
        "employee": 3,
        "contractor": 0
      },
      "DU.Abu Dhab": {
        "total": 4,
        "employee": 4,
        "contractor": 0
      },
      "ES.Madrid": {
        "total": 1,
        "employee": 0,
        "contractor": 1
      },
      "RU.Moscow": {
        "total": 10,
        "employee": 8,
        "contractor": 2
      },
      "UK.London": {
        "total": 1,
        "employee": 0,
        "contractor": 1
      },
      "CR.Costa Rica Partition": {
        "total": 20,
        "employee": 10,
        "contractor": 10
      },
      "MX.Mexico City": {
        "total": 23,
        "employee": 22,
        "contractor": 1
      },
      "AR.Cordoba": {
        "total": 3,
        "employee": 0,
        "contractor": 3
      },
      "PE.Lima": {
        "total": 1,
        "employee": 1,
        "contractor": 0
      },
      "Pune": {
        "total": 375,
        "employee": 321,
        "contractor": 54
      },
      "Quezon City": {
        "total": 73,
        "employee": 60,
        "contractor": 13
      },
      "Taguig City": {
        "total": 15,
        "employee": 13,
        "contractor": 2
      },
      "JP.Tokyo": {
        "total": 7,
        "employee": 6,
        "contractor": 1
      },
      "MY.Kuala Lumpur": {
        "total": 1,
        "employee": 0,
        "contractor": 1
      }
    }
  },
  "ccure_active": {
    "active_employees": 8598,
    "active_contractors": 712,
    "ccure_active_employees_reported": 8598,
    "ccure_active_contractors_reported": 712
  },
  "raw": {
    "date": "2025-08-29",
    "headcount": {
      "total_visited_today": 693,
      "employee": 578,
      "contractor": 115,
      "by_location": {
        "Pune": {
          "total": 375,
          "employee": 321,
          "contractor": 54
        },
        "LT.Vilnius": {
          "total": 53,
          "employee": 44,
          "contractor": 9
        },
        "MX.Mexico City": {
          "total": 23,
          "employee": 22,
          "contractor": 1
        },
        "CR.Costa Rica Partition": {
          "total": 20,
          "employee": 10,
          "contractor": 10
        },
        "MA.Casablanca": {
          "total": 17,
          "employee": 16,
          "contractor": 1
        },
        "Quezon City": {
          "total": 73,
          "employee": 60,
          "contractor": 13
        },
        "US.NYC": {
          "total": 3,
          "employee": 3,
          "contractor": 0
        },
        "IT.Rome": {
          "total": 3,
          "employee": 3,
          "contractor": 0
        },
        "AUT.Vienna": {
          "total": 48,
          "employee": 45,
          "contractor": 3
        },
        "Taguig City": {
          "total": 15,
          "employee": 13,
          "contractor": 2
        },
        "US.CO.OBS": {
          "total": 20,
          "employee": 8,
          "contractor": 12
        },
        "USA/Canada Default": {
          "total": 3,
          "employee": 2,
          "contractor": 1
        },
        "IE.Dublin": {
          "total": 11,
          "employee": 9,
          "contractor": 2
        },
        "AR.Cordoba": {
          "total": 3,
          "employee": 0,
          "contractor": 3
        },
        "RU.Moscow": {
          "total": 8,
          "employee": 8,
          "contractor": 0
        },
        "JP.Tokyo": {
          "total": 7,
          "employee": 6,
          "contractor": 1
        },
        "DU.Abu Dhab": {
          "total": 4,
          "employee": 4,
          "contractor": 0
        },
        "UK.London": {
          "total": 1,
          "employee": 0,
          "contractor": 1
        },
        "US.FL.Miami": {
          "total": 3,
          "employee": 3,
          "contractor": 0
        },
        "ES.Madrid": {
          "total": 1,
          "employee": 0,
          "contractor": 1
        },
        "MY.Kuala Lumpur": {
          "total": 1,
          "employee": 0,
          "contractor": 1
        },
        "PE.Lima": {
          "total": 1,
          "employee": 1,
          "contractor": 0
        }
      }
    },
    "live_headcount": {
      "currently_present_total": 689,
      "employee": 578,
      "contractor": 125,
      "by_location": {
        "US.CO.OBS": {
          "total": 24,
          "employee": 8,
          "contractor": 16
        },
        "USA/Canada Default": {
          "total": 5,
          "employee": 2,
          "contractor": 3
        },
        "US.FL.Miami": {
          "total": 3,
          "employee": 3,
          "contractor": 0
        },
        "US.NYC": {
          "total": 3,
          "employee": 3,
          "contractor": 0
        },
        "LT.Vilnius": {
          "total": 53,
          "employee": 44,
          "contractor": 9
        },
        "MA.Casablanca": {
          "total": 17,
          "employee": 16,
          "contractor": 1
        },
        "AUT.Vienna": {
          "total": 50,
          "employee": 45,
          "contractor": 5
        },
        "IE.Dublin": {
          "total": 11,
          "employee": 9,
          "contractor": 2
        },
        "IT.Rome": {
          "total": 3,
          "employee": 3,
          "contractor": 0
        },
        "DU.Abu Dhab": {
          "total": 4,
          "employee": 4,
          "contractor": 0
        },
        "ES.Madrid": {
          "total": 1,
          "employee": 0,
          "contractor": 1
        },
        "RU.Moscow": {
          "total": 10,
          "employee": 8,
          "contractor": 2
        },
        "UK.London": {
          "total": 1,
          "employee": 0,
          "contractor": 1
        },
        "CR.Costa Rica Partition": {
          "total": 20,
          "employee": 10,
          "contractor": 10
        },
        "MX.Mexico City": {
          "total": 23,
          "employee": 22,
          "contractor": 1
        },
        "AR.Cordoba": {
          "total": 3,
          "employee": 0,
          "contractor": 3
        },
        "PE.Lima": {
          "total": 1,
          "employee": 1,
          "contractor": 0
        },
        "Pune": {
          "total": 375,
          "employee": 321,
          "contractor": 54
        },
        "Quezon City": {
          "total": 73,
          "employee": 60,
          "contractor": 13
        },
        "Taguig City": {
          "total": 15,
          "employee": 13,
          "contractor": 2
        },
        "JP.Tokyo": {
          "total": 7,
          "employee": 6,
          "contractor": 1
        },
        "MY.Kuala Lumpur": {
          "total": 1,
          "employee": 0,
          "contractor": 1
        }
      }
    },
    "ccure_active": {
      "ccure_active_employees_reported": 8598,
      "ccure_active_contractors_reported": 712
    },
    "averages": {
      "head_emp_pct_vs_ccure_today": 6.72,
      "head_contractor_pct_vs_ccure_today": 16.15,
      "headcount_overall_pct_vs_ccure_today": 7.44,
      "live_employee_pct_vs_ccure": 6.72,
      "live_contractor_pct_vs_ccure": 17.56,
      "live_overall_pct_vs_ccure": 7.4,
      "avg_headcount_last_7_days": 2195.86,
      "avg_headcount_per_site_last_7_days": 548.97,
      "avg_live_per_site": 172.25,
      "history_avg_employee_last_7_days": 1933.57,
      "history_avg_contractor_last_7_days": 262.29,
      "history_avg_overall_last_7_days": 2195.86,
      "history_days_counted": 7,
      "history_employee_pct_vs_ccure": 22.49,
      "history_contractor_pct_vs_ccure": 36.84,
      "history_overall_pct_vs_ccure": 23.59,
      "history_today_employee_count": 668,
      "history_today_contractor_count": 109,
      "history_today_employee_pct_vs_ccure": 7.77,
      "history_today_contractor_pct_vs_ccure": 15.31,
      "avg_by_location_last_7_days": {

      },
      "history_avg_by_location_last_7_days": {
        "US.CO.OBS": {
          "history_days_counted": 6,
          "avg_employee_last_7_days": 353.67,
          "avg_contractor_last_7_days": 32.67,
          "avg_overall_last_7_days": 386.33
        },
        "USA/Canada Default": {
          "history_days_counted": 6,
          "avg_employee_last_7_days": 32.5,
          "avg_contractor_last_7_days": 2,
          "avg_overall_last_7_days": 34.5
        },
        "LT.Vilnius": {
          "history_days_counted": 7,
          "avg_employee_last_7_days": 279.86,
          "avg_contractor_last_7_days": 16.14,
          "avg_overall_last_7_days": 296
        },
        "AUT.Vienna": {
          "history_days_counted": 7,
          "avg_employee_last_7_days": 25.86,
          "avg_contractor_last_7_days": 3.29,
          "avg_overall_last_7_days": 29.14
        },
        "IE.Dublin": {
          "history_days_counted": 6,
          "avg_employee_last_7_days": 19.33,
          "avg_contractor_last_7_days": 2,
          "avg_overall_last_7_days": 21.33
        },
        "MA.Casablanca": {
          "history_days_counted": 7,
          "avg_employee_last_7_days": 11,
          "avg_contractor_last_7_days": 0.86,
          "avg_overall_last_7_days": 11.86
        },
        "Quezon City": {
          "history_days_counted": 7,
          "avg_employee_last_7_days": 200.29,
          "avg_contractor_last_7_days": 37,
          "avg_overall_last_7_days": 237.29
        },
        "Pune": {
          "history_days_counted": 7,
          "avg_employee_last_7_days": 378.57,
          "avg_contractor_last_7_days": 74.43,
          "avg_overall_last_7_days": 453
        },
        "JP.Tokyo": {
          "history_days_counted": 7,
          "avg_employee_last_7_days": 5.86,
          "avg_contractor_last_7_days": 0.71,
          "avg_overall_last_7_days": 6.57
        },
        "Taguig City": {
          "history_days_counted": 5,
          "avg_employee_last_7_days": 10.6,
          "avg_contractor_last_7_days": 1.8,
          "avg_overall_last_7_days": 12.4
        },
        "CR.Costa Rica Partition": {
          "history_days_counted": 6,
          "avg_employee_last_7_days": 430.5,
          "avg_contractor_last_7_days": 51.33,
          "avg_overall_last_7_days": 481.83
        },
        "AR.Cordoba": {
          "history_days_counted": 7,
          "avg_employee_last_7_days": 105.14,
          "avg_contractor_last_7_days": 30.86,
          "avg_overall_last_7_days": 136
        },
        "PA.Panama City": {
          "history_days_counted": 5,
          "avg_employee_last_7_days": 17.4,
          "avg_contractor_last_7_days": 2.4,
          "avg_overall_last_7_days": 19.8
        },
        "PE.Lima": {
          "history_days_counted": 5,
          "avg_employee_last_7_days": 38.6,
          "avg_contractor_last_7_days": 4.2,
          "avg_overall_last_7_days": 42.8
        },
        "BR.Sao Paulo": {
          "history_days_counted": 5,
          "avg_employee_last_7_days": 46.4,
          "avg_contractor_last_7_days": 9,
          "avg_overall_last_7_days": 55.4
        },
        "US.NYC": {
          "history_days_counted": 5,
          "avg_employee_last_7_days": 24.4,
          "avg_contractor_last_7_days": 0.8,
          "avg_overall_last_7_days": 25.2
        },
        "RU.Moscow": {
          "history_days_counted": 6,
          "avg_employee_last_7_days": 4.17,
          "avg_contractor_last_7_days": 1.33,
          "avg_overall_last_7_days": 5.5
        },
        "US.FL.Miami": {
          "history_days_counted": 4,
          "avg_employee_last_7_days": 21,
          "avg_contractor_last_7_days": 2.5,
          "avg_overall_last_7_days": 23.5
        },
        "UK.London": {
          "history_days_counted": 5,
          "avg_employee_last_7_days": 13.8,
          "avg_contractor_last_7_days": 1.2,
          "avg_overall_last_7_days": 15
        },
        "ES.Madrid": {
          "history_days_counted": 5,
          "avg_employee_last_7_days": 40.8,
          "avg_contractor_last_7_days": 2.6,
          "avg_overall_last_7_days": 43.4
        },
        "IT.Rome": {
          "history_days_counted": 4,
          "avg_employee_last_7_days": 22.25,
          "avg_contractor_last_7_days": 1.5,
          "avg_overall_last_7_days": 23.75
        },
        "DU.Abu Dhab": {
          "history_days_counted": 5,
          "avg_employee_last_7_days": 28.4,
          "avg_contractor_last_7_days": 1,
          "avg_overall_last_7_days": 29.4
        },
        "MY.Kuala Lumpur": {
          "history_days_counted": 5,
          "avg_employee_last_7_days": 3.2,
          "avg_contractor_last_7_days": 1,
          "avg_overall_last_7_days": 4.2
        },
        "MX.Mexico City": {
          "history_days_counted": 4,
          "avg_employee_last_7_days": 39.25,
          "avg_contractor_last_7_days": 5.25,
          "avg_overall_last_7_days": 44.5
        }
      }
    },
    "sites_queried": 4,
    "notes": "Region totals (689) differ from detail rows (703); using region totals for overall and details for breakdown. | avg_headcount_last_range derived from region history endpoints due to missing AttendanceSummary historical data.",
    "region_client_errors": [],
    "region_clients_unavailable": false
  }
}






C:\Users\W0024618\Desktop\global-page\frontend\src\pages\GlobalPage.jsx


// frontend/src/pages/GlobalPage.jsx
import React, { useState, useEffect, useRef } from 'react';
import {
  Box, Typography, CircularProgress, IconButton, Button, Paper, Divider,
  LinearProgress, Snackbar, Alert, List, ListItem, ListItemText
} from '@mui/material';
import HomeIcon from '@mui/icons-material/Home';
import DescriptionIcon from '@mui/icons-material/Description';
import UploadFileIcon from '@mui/icons-material/UploadFile';
import MapChart from '../components/MapChart.jsx';
import api from '../api';
import { useNavigate, Link } from 'react-router-dom';

/*
  Important:
  - Do NOT mix /api/headcount and /api/ccure/verify.
  - Region cards (APAC/EMEA/LACA/NAMER) come only from /api/headcount.
  - Live vs CCURE Summary now comes from /api/ccure/verify?raw=true.
  - Initial region totals are zero (keeps previous UI behaviour).
  - We implement polling for headcount and SSE for ccure/stream (realtime via SSE).
*/

export default function GlobalPage() {
  const navigate = useNavigate();

  // Region totals (headcount) - default to zeros so UI shows 0 immediately (preserve previous behaviour)
  const [counts, setCounts] = useState({ apac: 0, emea: 0, laca: 0, namer: 0 });
  const [selected, setSelected] = useState('global');

  // Averages/ccure state (left panel)
  const [averages, setAverages] = useState(null);
  const [loadingAverages, setLoadingAverages] = useState(true);
  const [averagesError, setAveragesError] = useState(null);

  // upload state
  const [uploading, setUploading] = useState(false);
  const [uploadResult, setUploadResult] = useState(null);
  const [uploadError, setUploadError] = useState(null);

  const fileInputEmpRef = useRef();
  const fileInputContrRef = useRef();
  const [snack, setSnack] = useState({ open: false, severity: 'info', message: '' });

  // Polling refs for safe scheduling and backoff
  const headcountRef = useRef({ timerId: null, failureCount: 0, isFetching: false });
  const averagesRef = useRef({ timerId: null, failureCount: 0, isFetching: false });

  // -----------------------
  // HEADCOUNT POLLING ONLY (unchanged)
  // -----------------------
  useEffect(() => {
    let mounted = true;

    const fetchHeadcount = async () => {
      if (!mounted) return;
      if (headcountRef.current.isFetching) return;
      headcountRef.current.isFetching = true;

      try {
        // Important: only call /headcount here (proxy rewrites /api -> backend)
        const res = await api.get('/headcount');
        if (!mounted) return;
        const d = res.data;
        // We expect an object with keys apac/emea/laca/namer (defensive)
        if (d && typeof d === 'object') {
          const newCounts = {
            apac: Number(d.apac || 0),
            emea: Number(d.emea || 0),
            laca: Number(d.laca || 0),
            namer: Number(d.namer || 0),
          };
          setCounts(prev => {
            if (
              prev.apac === newCounts.apac &&
              prev.emea === newCounts.emea &&
              prev.laca === newCounts.laca &&
              prev.namer === newCounts.namer
            ) {
              return prev;
            }
            return newCounts;
          });
        } else {
          console.warn('[headcount] unexpected response shape - ignoring', d);
        }
        headcountRef.current.failureCount = 0;
      } catch (err) {
        headcountRef.current.failureCount = (headcountRef.current.failureCount || 0) + 1;
        console.warn('[headcount] fetch failed:', err?.message || err);
      } finally {
        headcountRef.current.isFetching = false;
        const f = headcountRef.current.failureCount || 0;
        const backoffMs = 15000 * Math.pow(2, Math.min(Math.max(f - 1, 0), 4)); // 15s..240s
        headcountRef.current.timerId = setTimeout(fetchHeadcount, backoffMs);
      }
    };

    fetchHeadcount();

    return () => {
      mounted = false;
      if (headcountRef.current.timerId) clearTimeout(headcountRef.current.timerId);
      headcountRef.current.isFetching = false;
    };
  }, []); // run once



  // AVERAGES: use SSE (direct to Python backend) with fallback initial fetch
  useEffect(() => {
    let stopped = false;
    let es = null;
    let backoff = 1000;

    // Allow override via VITE_PY_BACKEND; otherwise assume python at :8000
    const PY_BACKEND = (import.meta.env.VITE_PY_BACKEND || `${window.location.protocol}//${window.location.hostname}:8000`).replace(/\/$/, '');

    const connect = () => {
      if (stopped) return;
      try {
        // Directly connect to Python SSE endpoint (bypasses Vite proxy for streaming)
        es = new EventSource(`${PY_BACKEND}/ccure/stream`);
      } catch (err) {
        console.warn('SSE creation failed', err);
        es = null;
      }

      if (!es) {
        // fallback to polling if EventSource not supported or creation failed
        initialFetch();
        return;
      }

      es.onopen = () => {
        console.info('[SSE] connected to', `${PY_BACKEND}/ccure/stream`);
        backoff = 1000;
        setAveragesError(null);
      };

      es.onmessage = (evt) => {
        try {
          const payload = JSON.parse(evt.data);
          setAverages(payload);
          setLoadingAverages(false);
          setAveragesError(null);
        } catch (e) {
          console.warn('Failed to parse SSE message', e);
        }
      };

      es.onerror = (err) => {
        console.warn('[SSE] error/closed, attempting reconnect', err);
        try { es.close(); } catch (e) {}
        es = null;
        if (stopped) return;
        // exponential backoff reconnect (capped)
        setTimeout(() => {
          backoff = Math.min(backoff * 2, 30000);
          connect();
        }, backoff);
      };
    };

    const initialFetch = async () => {
      setLoadingAverages(true);
      setAveragesError(null);
      try {
        // <-- changed: call verify endpoint (raw=true) instead of /ccure/averages
        const res = await api.get('/ccure/verify?raw=true');
        setAverages(res.data);
        setLoadingAverages(false);
        setAveragesError(null);
      } catch (err) {
        console.warn('initial /ccure/verify?raw=true fetch failed', err);
        setLoadingAverages(false);
        setAveragesError(err);
      }
    };

    // Start with initial fetch so UI is populated quickly, then open SSE
    initialFetch();
    connect();

    return () => {
      stopped = true;
      if (es) {
        try { es.close(); } catch (e) {}
        es = null;
      }
    };
  }, []);



  // -----------------------
  // Upload helper (unchanged)
  // -----------------------
  const handleUpload = async (file, type) => {
    if (!file) return;
    const endpoint = type === 'employee' ? '/upload/active-employees' : '/upload/active-contractors';
    const fd = new FormData();
    fd.append('file', file, file.name);

    setUploading(true);
    setUploadResult(null);
    setUploadError(null);

    try {
      const res = await api.post(endpoint, fd, {
        headers: { 'Content-Type': 'multipart/form-data' },
        timeout: 120000
      });
      setUploadResult(res.data);
      setSnack({ open: true, severity: 'success', message: `Upload successful: ${file.name}` });
      // Optionally re-fetch averages/headcount after successful upload:
      try { await api.get('/ccure/verify?raw=true').then(r => setAverages(r.data)); } catch (_) {}
      try { await api.get('/headcount').then(r => {
        const d = r.data;
        if (d && typeof d === 'object') {
          setCounts(prev => ({
            apac: Number(d.apac || prev.apac || 0),
            emea: Number(d.emea || prev.emea || 0),
            laca: Number(d.laca || prev.laca || 0),
            namer: Number(d.namer || prev.namer || 0)
          }));
        }
      }) } catch (_) {}
    } catch (err) {
      console.error('Upload failed', err);
      setUploadError(err);
      setSnack({ open: true, severity: 'error', message: `Upload failed: ${file.name}` });
    } finally {
      setUploading(false);
    }
  };

  const onChooseEmployeeFile = (e) => { const f = e.target.files && e.target.files[0]; if (f) handleUpload(f, 'employee'); e.target.value = null; };
  const onChooseContractorFile = (e) => { const f = e.target.files && e.target.files[0]; if (f) handleUpload(f, 'contractor'); e.target.value = null; };

  // safe helper for nested averages paths
  const safe = (path, fallback = null) => {
    if (!averages) return fallback;
    try {
      return path.split('.').reduce((a, k) => (a && a[k] !== undefined ? a[k] : fallback), averages);
    } catch {
      return fallback;
    }
  };

  // -----------------------
  // Derived values (updated to match /ccure/verify response shape)
  // -----------------------
  // ccure reported totals
  const ccureActiveEmployees = safe('ccure_reported.employees',
    safe('ccure_active.active_employees',
      safe('ccure_active.ccure_active_employees_reported', null)
    )
  );
  const ccureActiveContractors = safe('ccure_reported.contractors',
    safe('ccure_active.active_contractors',
      safe('ccure_active.ccure_active_contractors_reported', null)
    )
  );

  // headcount attendance summary (from AttendanceSummary / union)
  const headTotalVisited = safe('headcount_attendance_summary.total_visited_today',
    safe('headcount_details.total_visited_today', null)
  );
  const headEmployee = safe('headcount_attendance_summary.employee',
    safe('headcount_details.employee', null)
  );
  const headContractor = safe('headcount_attendance_summary.contractor',
    safe('headcount_details.contractor', null)
  );

  // live headcount from region clients
  const liveCurrentTotal = safe('live_headcount_region_clients.currently_present_total',
    safe('live_headcount_details.currently_present_total',
      null
    )
  );
  const liveEmp = safe('live_headcount_region_clients.employee',
    safe('live_headcount_details.employee', null)
  );
  const liveContr = safe('live_headcount_region_clients.contractor',
    safe('live_headcount_details.contractor', null)
  );

  // percentages (prefer top-level percentages_vs_ccure, fallback into averages compatibility keys)
  const empPct = safe('percentages_vs_ccure.head_employee_pct_vs_ccure_today',
    safe('averages.head_emp_pct_vs_ccure_today', null)
  );
  const conPct = safe('percentages_vs_ccure.head_contractor_pct_vs_ccure_today',
    safe('averages.head_contractor_pct_vs_ccure_today', null)
  );
  const overallPct = safe('percentages_vs_ccure.head_overall_pct_vs_ccure_today',
    safe('averages.headcount_overall_pct_vs_ccure_today', null)
  );

  // averages / 7-day
  const avg7 = safe('averages.history_avg_overall_last_7_days',
    safe('averages.avg_headcount_last_7_days',
      safe('averages.avg_headcount_last_7_days_db', null)
    )
  );

  // date
  const respDate = safe('date', null);

  // location-wise averages map (history_avg_by_location_last_7_days)
  const locationAvgsObj = safe('averages.history_avg_by_location_last_7_days',
    safe('history_avg_by_location_last_7_days',
      safe('raw.averages.history_avg_by_location_last_7_days', {})
    )
  );

  // convert to array for rendering (sort by avg_overall desc if present)
  const locationAvgsList = React.useMemo(() => {
    if (!locationAvgsObj || typeof locationAvgsObj !== 'object') return [];
    const arr = Object.entries(locationAvgsObj).map(([loc, vals]) => {
      return {
        location: loc,
        avg_employee_last_7_days: vals.avg_employee_last_7_days ?? vals.history_avg_employee_last_7_days ?? vals.avg_employee ?? null,
        avg_contractor_last_7_days: vals.avg_contractor_last_7_days ?? vals.history_avg_contractor_last_7_days ?? vals.avg_contractor ?? null,
        avg_overall_last_7_days: vals.avg_overall_last_7_days ?? vals.history_avg_overall_last_7_days ?? vals.avg_overall ?? null,
        history_days_counted: vals.history_days_counted ?? null
      };
    });
    // sort descending by overall avg (nulls to end)
    arr.sort((a, b) => (b.avg_overall_last_7_days ?? -Infinity) - (a.avg_overall_last_7_days ?? -Infinity));
    return arr;
  }, [locationAvgsObj]);

  // ------------------------------------------------------------
  // derive global total from headcount regions (APAC+EMEA+LACA+NAMER)
  // ------------------------------------------------------------
  const globalCount = Number((counts.apac || 0)) + Number((counts.emea || 0)) + Number((counts.laca || 0)) + Number((counts.namer || 0));

  // Helper style used to hide scrollbars but allow scrolling
  const hideScrollbarSx = {
    overflowY: 'auto',
    // hide scrollbar visual (webkit)
    '&::-webkit-scrollbar': { width: 0, height: 0 },
    // firefox
    scrollbarWidth: 'none',
    // ie
    msOverflowStyle: 'none',
  };

  // Render
  return (
    <Box sx={{ display: 'flex', flexDirection: 'column', height: '100vh', overflow: 'hidden', bgcolor: 'background.default' }}>
      {/* Header */}
      <Box px={2} py={1} sx={{ backgroundColor: 'black', color: '#fff', borderBottom: '4px solid #FFD700', display: 'flex', alignItems: 'center', justifyContent: 'space-between' }}>
        <Box>
          <IconButton component={Link} to="/" sx={{ color: '#FFC72C' }}><HomeIcon fontSize="medium" /></IconButton>
          <IconButton component={Link} to="/reports" sx={{ color: '#FFC72C', ml: 1 }}><DescriptionIcon fontSize="medium" /></IconButton>
        </Box>

        <Box sx={{ flexGrow: 1, display: 'flex', alignItems: 'center', justifyContent: 'center' }}>
          <Box component="img" src="/wu-head-logo.png" alt="WU Logo" sx={{ height: { xs: 30, md: 55 }, mr: 2 }} />
          <Typography variant="h5" sx={{ fontWeight: 'bold', color: 'primary.main' }}>Global Headcount Dashboard</Typography>
        </Box>

        <Box sx={{ width: 120 }} />
      </Box>

      {/* Top row: GLOBAL + Region Cards */}
      <Box sx={{ display: 'flex', gap: 2, p: 2, flexWrap: 'wrap', alignItems: 'center', justifyContent: 'center' }}>
        {[
          { key: 'global', label: 'GLOBAL', count: globalCount, url: null, textColor: '#ffff' },
          { key: 'apac', label: 'APAC', count: counts.apac, url: 'http://10.199.22.57:3000/', textColor: '#ffff' },
          { key: 'emea', label: 'EMEA', count: counts.emea, url: 'http://10.199.22.57:3001/', textColor: '#ffff' },
          { key: 'laca', label: 'LACA', count: counts.laca, url: 'http://10.199.22.57:3003/', textColor: '#ffff' },
          { key: 'namer', label: 'NAMER', count: counts.namer, url: 'http://10.199.22.57:3002/', textColor: '#ffff' },
        ].map(region => (
          <Box
            key={region.key}
            onClick={() => {
              if (region.key === 'global') {
                const el = document.querySelector('[data-global-left-panel]');
                if (el) el.scrollIntoView({ behavior: 'smooth', block: 'start' });
                setSelected('global');
                return;
              }
              // external region dashboards for others
              if (region.url) window.location.href = region.url;
            }}
            sx={{
              cursor: 'pointer',
              width: 200,
              height: 80,
              display: 'flex',
              flexDirection: 'column',
              justifyContent: 'center',
              alignItems: 'center',
              border: '4px solid rgba(255, 204, 0, 0.89)',
              borderRadius: 2,
              boxShadow: 3,
              color: region.textColor,
              '&:hover': { opacity: 0.95 },
            }}
          >
            <Typography variant="subtitle1" sx={{ fontWeight: 'bold', color: region.textColor, fontSize: { xs: '1.1rem' } }}>{region.label}</Typography>
            <Typography variant="h4" sx={{ fontWeight: 800, fontSize: { xs: '1.2rem', sm: '1.6rem' }, color: region.textColor }}>
              {region.count ?? 0}
            </Typography>
          </Box>
        ))}
      </Box>

      {/* Main: left summary | center map | right averages */}
      <Box sx={{ display: 'flex', flex: 1, overflow: 'hidden' }}>
        {/* Left detail panel */}
        <Box
          data-global-left-panel
          sx={{
            width: { xs: 320, md: 360 },
            minWidth: { md: 320 },
            p: 2,
            bgcolor: 'background.paper',
            borderRight: '1px solid rgba(255,255,255,0.06)',
            display: 'flex',
            flexDirection: 'column',
            ...hideScrollbarSx,
            // ensure left panel takes full height and internal content can scroll (hidden scrollbar)
            height: '100%',
          }}
        >
          <Typography variant="h6" sx={{ mb: 1, color: 'primary.main' }}>Live vs CCURE Summary</Typography>

          {loadingAverages ? (
            <Box sx={{ py: 2 }}><LinearProgress /></Box>
          ) : averagesError ? (
            <Alert severity="error">Failed to load CCURE averages</Alert>
          ) : averages ? (
            <>
              <Paper sx={{ p: 2, mb: 2, bgcolor: 'rgba(255,255,255,0.02)' }} elevation={0}>
                <Typography variant="subtitle2" color="text.secondary">CCURE Active (reported)</Typography>
                <Box sx={{ display: 'flex', justifyContent: 'space-between', mt: 1, alignItems: 'center' }}>
                  <Box>
                    <Typography variant="h4" sx={{ fontWeight: 800 }}>{ccureActiveEmployees ?? 'â€”'}</Typography>
                    <Typography variant="caption" color="text.secondary">Active Employees</Typography>
                  </Box>
                  <Box sx={{ textAlign: 'right' }}>
                    <Typography variant="h5" sx={{ fontWeight: 800 }}>{ccureActiveContractors ?? 'â€”'}</Typography>
                    <Typography variant="caption" color="text.secondary">Active Contractors</Typography>
                  </Box>
                </Box>
              </Paper>

              <Paper sx={{ p: 2, mb: 2, bgcolor: 'rgba(255,255,255,0.02)' }} elevation={0}>
                <Box sx={{ display: 'flex', justifyContent: 'space-between' }}>
                  <Typography variant="subtitle2" color="text.secondary">Live Today</Typography>
                  <Typography variant="caption" color="text.secondary">{respDate ?? ''}</Typography>
                </Box>

                <Box sx={{ display: 'flex', justifyContent: 'space-between', mt: 1 }}>
                  <Box>
                    <Typography variant="h5" sx={{ fontWeight: 800 }}>{headEmployee ?? liveEmp ?? 'â€”'}</Typography>
                    <Typography variant="caption" color="text.secondary">Employee</Typography>
                  </Box>
                  <Box>
                    <Typography variant="h5" sx={{ fontWeight: 800 }}>{headContractor ?? liveContr ?? 'â€”'}</Typography>
                    <Typography variant="caption" color="text.secondary">Contractor</Typography>
                  </Box>
                </Box>

                <Divider sx={{ my: 1 }} />

                <Box>
                  <Typography variant="caption" color="text.secondary">Totals</Typography>
                  <Box sx={{ display: 'flex', justifyContent: 'space-between', mt: 0.75 }}>
                    <Typography variant="body2">Attendance total (today)</Typography>
                    <Typography variant="body2" sx={{ fontWeight: 700 }}>{headTotalVisited ?? 'â€”'}</Typography>
                  </Box>

                  <Box sx={{ display: 'flex', justifyContent: 'space-between', mt: 0.5 }}>
                    <Typography variant="body2">Live region total</Typography>
                    <Typography variant="body2" sx={{ fontWeight: 700 }}>{liveCurrentTotal ?? 'â€”'}</Typography>
                  </Box>

                  {/** Provide a detail rows total if available in response */}
                  {safe('headcount_details.total_visited_today', null) != null && (
                    <Box sx={{ display: 'flex', justifyContent: 'space-between', mt: 0.5 }}>
                      <Typography variant="body2">Detail rows total</Typography>
                      <Typography variant="body2" sx={{ fontWeight: 700 }}>{safe('headcount_details.total_visited_today', 'â€”')}</Typography>
                    </Box>
                  )}
                </Box>
              </Paper>

              <Paper sx={{ p: 2, mb: 2, bgcolor: 'rgba(255,255,255,0.02)' }} elevation={0}>
                <Typography variant="subtitle2" color="text.secondary">Percentages vs CCURE</Typography>

                <Box sx={{ display: 'flex', justifyContent: 'space-between', mt: 1 }}>
                  <Typography variant="body2">Employees</Typography>
                  <Typography variant="body2" sx={{ fontWeight: 700 }}>{empPct != null ? `${empPct}%` : 'â€”'}</Typography>
                </Box>
                <Box sx={{ display: 'flex', justifyContent: 'space-between' }}>
                  <Typography variant="body2">Contractors</Typography>
                  <Typography variant="body2" sx={{ fontWeight: 700 }}>{conPct != null ? `${conPct}%` : 'â€”'}</Typography>
                </Box>
                <Box sx={{ display: 'flex', justifyContent: 'space-between', mt: 0.5 }}>
                  <Typography variant="body2">Overall</Typography>
                  <Typography variant="body2" sx={{ fontWeight: 700 }}>{overallPct != null ? `${overallPct}%` : 'â€”'}</Typography>
                </Box>

                <Divider sx={{ my: 1 }} />
                <Typography variant="caption" color="text.secondary">Averages</Typography>
                <Box sx={{ display: 'flex', justifyContent: 'space-between', mt: 1 }}>
                  <Typography variant="body2">7-day avg headcount</Typography>
                  <Typography variant="body2" sx={{ fontWeight: 700 }}>{avg7 ?? 'â€”'}</Typography>
                </Box>
              </Paper>

              <Paper sx={{ p: 2, mb: 2, bgcolor: 'rgba(255,255,255,0.02)' }} elevation={0}>
                <Typography variant="subtitle2" color="text.secondary" sx={{ mb: 1 }}>Upload Active Sheets</Typography>

                <input type="file" accept=".xls,.xlsx" style={{ display: 'none' }} ref={fileInputEmpRef} onChange={onChooseEmployeeFile} />
                <Button variant="contained" startIcon={<UploadFileIcon />} sx={{ mr: 1 }} onClick={() => fileInputEmpRef.current && fileInputEmpRef.current.click()} disabled={uploading}>
                  Upload Employees
                </Button>

                <input type="file" accept=".xls,.xlsx" style={{ display: 'none' }} ref={fileInputContrRef} onChange={onChooseContractorFile} />
                <Button variant="outlined" startIcon={<UploadFileIcon />} onClick={() => fileInputContrRef.current && fileInputContrRef.current.click()} disabled={uploading}>
                  Upload Contractors
                </Button>

                {uploading && <Box sx={{ mt: 1 }}><LinearProgress /></Box>}
                {uploadResult && <Typography variant="caption" color="success.main" sx={{ mt: 1, display: 'block' }}>Upload OK</Typography>}
                {uploadError && <Typography variant="caption" color="error.main" sx={{ mt: 1, display: 'block' }}>Upload error</Typography>}
              </Paper>

              {averages.notes && (
                <Paper sx={{ p: 2, mb: 2, bgcolor: 'rgba(255,255,255,0.01)' }}>
                  <Typography variant="body2" sx={{ mt: 1 }}>{averages.notes}</Typography>
                </Paper>
              )}
            </>
          ) : (
            <Typography variant="body2" color="text.secondary">No data</Typography>
          )}
        </Box>

        {/* Center: map (flex) */}
        <Box sx={{ flex: 1, minWidth: 0, position: 'relative', display: 'flex', flexDirection: 'column' }}>
          <Box sx={{ flex: 1, minHeight: 0 }}>
            <MapChart selected={selected} onClickSite={r => setSelected(r)} initialZoom={1.8} />
          </Box>
        </Box>

        {/* Right side: Location averages panel */}
        <Box
          sx={{
            width: { xs: 320, md: 360 },
            minWidth: { md: 320 },
            borderLeft: '1px solid rgba(255,255,255,0.06)',
            bgcolor: 'background.paper',
            p: 2,
            display: 'flex',
            flexDirection: 'column',
            ...hideScrollbarSx,
            height: '100%',
          }}
        >
          <Typography variant="h6" sx={{ mb: 1, color: 'primary.main' }}>Location Averages</Typography>

          {loadingAverages ? (
            <Box sx={{ display: 'flex', alignItems: 'center', justifyContent: 'center', py: 4 }}>
              <CircularProgress />
            </Box>
          ) : averagesError ? (
            <Alert severity="error">Failed to load location averages</Alert>
          ) : locationAvgsList.length === 0 ? (
            <Typography variant="body2" color="text.secondary">No location averages available</Typography>
          ) : (
            <List dense disablePadding sx={{ flex: 1 }}>
              {locationAvgsList.map(item => (
                <ListItem key={item.location} sx={{ alignItems: 'flex-start', py: 1.25, borderBottom: '1px solid rgba(255,255,255,0.03)' }}>
                  <ListItemText
                    primary={
                      <Box sx={{ display: 'flex', justifyContent: 'space-between', alignItems: 'center' }}>
                        <Typography sx={{ fontWeight: 800 }}>{item.location}</Typography>
                        <Typography variant="body2" sx={{ fontWeight: 800 }}>{item.avg_overall_last_7_days != null ? Math.round(item.avg_overall_last_7_days) : 'â€”'}</Typography>
                      </Box>
                    }
                    secondary={
                      <Box sx={{ display: 'flex', gap: 2, mt: 0.5, flexWrap: 'wrap' }}>
                        <Typography variant="caption" color="text.secondary">Emp: <strong>{item.avg_employee_last_7_days != null ? Math.round(item.avg_employee_last_7_days) : 'â€”'}</strong></Typography>
                        <Typography variant="caption" color="text.secondary">Contr: <strong>{item.avg_contractor_last_7_days != null ? Math.round(item.avg_contractor_last_7_days) : 'â€”'}</strong></Typography>
                        {item.history_days_counted != null && <Typography variant="caption" color="text.secondary">Days: {item.history_days_counted}</Typography>}
                      </Box>
                    }
                  />
                </ListItem>
              ))}
            </List>
          )}
        </Box>
      </Box>

      <Snackbar open={snack.open} autoHideDuration={3500} onClose={() => setSnack(prev => ({ ...prev, open: false }))}>
        <Alert severity={snack.severity} onClose={() => setSnack(prev => ({ ...prev, open: false }))}>{snack.message}</Alert>
      </Snackbar>
    </Box>
  );
}








# C:\Users\W0024618\Desktop\global-page\backend\attendance-analytics\ccure_compare_service.py
import re
import json
from datetime import date, datetime, timedelta
from typing import List, Dict, Any, Optional, Set, Tuple
import time
import logging

logger = logging.getLogger("ccure_compare_service")
logger.setLevel(logging.INFO)
if not logger.handlers:
    ch = logging.StreamHandler()
    ch.setFormatter(logging.Formatter("%(asctime)s %(levelname)s %(name)s: %(message)s"))
    logger.addHandler(ch)

from db import SessionLocal
from models import AttendanceSummary, LiveSwipe
from settings import OUTPUT_DIR

# ---------- small helpers ----------------------------------------------------

def _normalize_employee_key(x) -> Optional[str]:
    if x is None:
        return None
    try:
        s = str(x).strip()
        if s == "" or s.lower() in ("nan", "none", "na", "null"):
            return None
        return s
    except Exception:
        return None

def _normalize_card_like(s) -> Optional[str]:
    if s is None:
        return None
    try:
        ss = str(s).strip()
        if ss == "":
            return None
        digits = re.sub(r'\D+', '', ss)
        if digits == "":
            return None
        return digits.lstrip('0') or digits
    except Exception:
        return None

def _safe_int(v):
    try:
        if v is None:
            return None
        return int(v)
    except Exception:
        try:
            return int(float(v))
        except Exception:
            return None

def _sanitize_for_json(value):
    try:
        import numpy as _np
    except Exception:
        _np = None
    if value is None:
        return None
    if isinstance(value, (str, bool, int)):
        return value
    if isinstance(value, float):
        if _np is not None and not _np.isfinite(value):
            return None
        return float(value)
    if _np is not None and isinstance(value, (_np.integer,)):
        return int(value)
    if isinstance(value, dict):
        out = {}
        for k, v in value.items():
            try:
                key = str(k)
            except Exception:
                key = repr(k)
            out[key] = _sanitize_for_json(v)
        return out
    if isinstance(value, (list, tuple, set)):
        return [_sanitize_for_json(v) for v in value]
    try:
        return str(value)
    except Exception:
        return None

# ---------- ccure helpers ---------------------------------------------------

def _fetch_ccure_stats():
    try:
        import ccure_client
        if hasattr(ccure_client, "get_global_stats"):
            return ccure_client.get_global_stats()
    except Exception:
        logger.debug("ccure_client.get_global_stats not available", exc_info=True)
    return None

def _fetch_ccure_profiles():
    try:
        import ccure_client
        for fn in ("fetch_all_employees_full", "fetch_all_employees", "fetch_all_profiles", "fetch_profiles", "fetch_all"):
            if hasattr(ccure_client, fn):
                try:
                    res = getattr(ccure_client, fn)()
                    if isinstance(res, list):
                        return res
                except Exception:
                    continue
    except Exception:
        pass
    return []

def _extract_ccure_locations_from_profiles(profiles: List[dict]) -> Set[str]:
    locs = set()
    for p in profiles:
        if not isinstance(p, dict):
            continue
        for k in ("Partition", "PartitionName", "Location", "Location City", "location_city", "location", "Site", "BaseLocation"):
            v = p.get(k) if isinstance(p, dict) else None
            if v and isinstance(v, str) and v.strip():
                locs.add(v.strip())
    return locs

# ---------- classification & partition helpers ------------------------------

def classify_personnel_from_detail(detail: dict) -> str:
    """
    Classify 'detail' dict as 'employee' or 'contractor'.
    Looks for several PersonnelType/status keys; default is contractor.
    """
    try:
        if not isinstance(detail, dict):
            return "contractor"
        candidate_keys = [
            "PersonnelType", "personnelType", "personnel_type", "Personnel Type",
            "PersonnelTypeName", "Personnel", "Type", "personnel", "PersonType", "personType"
        ]
        val = None
        for k in candidate_keys:
            if k in detail and detail.get(k) is not None:
                val = str(detail.get(k)).strip().lower()
                break
        status_keys = ["Employee_Status", "Employee Status", "Status", "Profile_Disabled"]
        status_val = None
        for k in status_keys:
            if k in detail and detail.get(k) is not None:
                status_val = str(detail.get(k)).strip().lower()
                break

        # terminated/disabled rows treated as employee (they were employees historically)
        if status_val is not None and "terminated" in status_val:
            return "employee"
        if val is None or val == "":
            return "contractor"
        if "employee" in val:
            return "employee"
        contractor_terms = ["contractor", "visitor", "property", "temp", "temp badge", "tempbadge"]
        for t in contractor_terms:
            if t in val:
                return "contractor"
        if "contract" in val or "visitor" in val:
            return "contractor"
        # default to contractor if unclear
        return "contractor"
    except Exception:
        return "contractor"

def pick_partition_from_detail(detail: dict) -> str:
    if not isinstance(detail, dict):
        return "Unknown"
    for k in ("PartitionName2","PartitionName1","Partition","PartitionName","Region","Location","Site","location_city","Location City"):
        if k in detail and detail.get(k):
            try:
                return str(detail.get(k)).strip()
            except Exception:
                continue
    if "__region" in detail and detail.get("__region"):
        return str(detail.get("__region")).strip()
    return "Unknown"

# ---------- small resilient fetch helper for region_clients -----------------
def _attempt_region_call(fn, timeout, attempts=2, backoff=0.5) -> Tuple[Optional[Any], Optional[Exception]]:
    """
    Attempt calling a region_clients function fn(timeout=...) multiple times.
    Returns (result, last_exception). On success last_exception is None.
    On persistent failure, returns (None, last_exception). This lets callers record errors
    and attach them to the compute payload instead of spamming WARNING logs.
    """
    last_exc = None
    fn_name = getattr(fn, "__name__", str(fn))
    for i in range(attempts):
        try:
            res = fn(timeout=timeout)
            # successful call
            return res, None
        except Exception as e:
            last_exc = e
            # classify error message â€” many remote 500s/timeouts are transient; log them at INFO,
            # keep full stack at DEBUG. This reduces WARNING spam seen in console.
            msg = str(e)
            low = msg.lower()
            if "500 server error" in low or "internal server error" in low or "read timed out" in low or "timeout" in low:
                logger.info("[region_clients] attempt %d/%d failed for %s: %s", i+1, attempts, fn_name, msg)
                logger.debug("[region_clients] full exception for %s attempt %d: ", fn_name, i+1, exc_info=True)
            else:
                # other exceptions might be more important
                logger.warning("[region_clients] attempt %d/%d failed for %s: %s", i+1, attempts, fn_name, msg)
                logger.debug("[region_clients] full exception for %s attempt %d: ", fn_name, i+1, exc_info=True)
            time.sleep(backoff * (i+1))
            continue
    # All attempts exhausted â€” record at INFO and provide last_exc to caller
    logger.info("[region_clients] all %d attempts failed for %s: last_exc=%s", attempts, fn_name, str(last_exc))
    logger.debug("[region_clients] last exception traceback for %s: ", fn_name, exc_info=True)
    return None, last_exc

# ---------- utility: fallback headcount builder from LiveSwipe --------------

def build_headcount_from_liveswipes_for_today(session) -> (int, Dict[str, Dict[str, int]]):
    start = datetime.combine(date.today(), datetime.min.time())
    end = datetime.combine(date.today(), datetime.max.time())
    swipes = session.query(LiveSwipe).filter(LiveSwipe.timestamp >= start, LiveSwipe.timestamp <= end).all()
    if not swipes:
        return 0, {}
    seen_keys = {}
    per_loc = {}
    for s in swipes:
        key = _normalize_employee_key(s.employee_id) or _normalize_card_like(s.card_number)
        if not key:
            key = f"nokey_{s.id}"
        rec = seen_keys.get(key)
        ts = s.timestamp
        if rec is None:
            seen_keys[key] = {"first_seen": ts, "last_seen": ts, "partition": (s.partition or "Unknown"), "class": None, "card": s.card_number, "raw": s.raw}
        else:
            if ts and rec.get("first_seen") and ts < rec["first_seen"]:
                rec["first_seen"] = ts
            if ts and rec.get("last_seen") and ts > rec["last_seen"]:
                rec["last_seen"] = ts
    for k, v in seen_keys.items():
        loc = v.get("partition") or "Unknown"
        if not isinstance(loc, str) or not loc.strip():
            loc = "Unknown"
        if loc not in per_loc:
            per_loc[loc] = {"total": 0, "employee": 0, "contractor": 0}
        per_loc[loc]["total"] += 1
        classified = "contractor"
        raw = v.get("raw")
        if isinstance(raw, dict):
            try:
                classified = classify_personnel_from_detail(raw)
            except Exception:
                classified = "contractor"
        per_loc[loc][classified] += 1
    total = sum(p["total"] for p in per_loc.values())
    return int(total), per_loc

# ---------- main compute function -----------------------------------------

def compute_visit_averages(start_date: Optional[str] = None, end_date: Optional[str] = None, timeout: int = 6) -> Dict[str, Any]:
    """
    Compute visit averages for an inclusive date range.
    Uses only AttendanceSummary, region_clients.fetch_all_details, region_clients.fetch_all_history and ccure stats.
    Defaults to last 7 days if no valid range provided.
    `timeout` is forwarded to region_clients functions (live/history). We use small retries internally.
    """
    notes = []
    region_client_errors: List[Dict[str, str]] = []
    today = date.today()

    # parse date strings
    def _parse_date_param(s):
        if not s:
            return None
        try:
            return datetime.strptime(s, "%Y-%m-%d").date()
        except Exception:
            try:
                return date.fromisoformat(s)
            except Exception:
                return None

    start_obj = _parse_date_param(start_date) if start_date else (today - timedelta(days=6))
    end_obj = _parse_date_param(end_date) if end_date else today
    if start_obj is None or end_obj is None or start_obj > end_obj:
        start_obj = today - timedelta(days=6)
        end_obj = today
        notes.append("Invalid or missing date range; defaulted to last 7 calendar days inclusive.")

    # gather CCURE stats & profiles (profiles only used if you want to filter â€” currently not used to drop partitions)
    ccure_stats = _fetch_ccure_stats()
    reported_active_emps = _safe_int(ccure_stats.get("ActiveEmployees")) if isinstance(ccure_stats, dict) else None
    reported_active_contractors = _safe_int(ccure_stats.get("ActiveContractors")) if isinstance(ccure_stats, dict) else None

    ccure_profiles = _fetch_ccure_profiles()
    ccure_locations = _extract_ccure_locations_from_profiles(ccure_profiles) if isinstance(ccure_profiles, list) else set()

    # ---------- HEADCOUNT (AttendanceSummary fallback logic) ----------
    head_total = 0
    head_per_location: Dict[str, Dict[str, int]] = {}
    key_map_head: Dict[str, Dict[str, Any]] = {}
    key_map_live: Dict[str, Dict[str, Any]] = {}

    try:
        session = SessionLocal()
        att_rows_today = session.query(AttendanceSummary).filter(AttendanceSummary.date == today).all()
        if not att_rows_today:
            # try to build from LiveSwipe compute_daily_attendance if available
            try:
                from compare_service import compute_daily_attendance as _compute_daily_attendance
                try:
                    built = _compute_daily_attendance(today)
                    if isinstance(built, list) and len(built) > 0:
                        att_rows_today = session.query(AttendanceSummary).filter(AttendanceSummary.date == today).all()
                        notes.append("AttendanceSummary was missing; built from LiveSwipe via compute_daily_attendance().")
                except Exception:
                    logger.exception("compute_daily_attendance execution failed; falling back")
            except Exception:
                logger.debug("compare_service.compute_daily_attendance not importable; falling back", exc_info=True)

            if not att_rows_today:
                built_total, built_per_loc = build_headcount_from_liveswipes_for_today(session)
                head_total = built_total
                head_per_location = built_per_loc
                if head_total > 0:
                    notes.append("AttendanceSummary for today empty; built headcount from LiveSwipe rows (non-persistent fallback).")
        if att_rows_today:
            # classify using AttendanceSummary.derived if possible (don't rely on Active sheets)
            for a in att_rows_today:
                key = _normalize_employee_key(a.employee_id) or _normalize_card_like((a.derived.get('card_number') if (a.derived and isinstance(a.derived, dict)) else None)) or None
                partition = None
                try:
                    if a.derived and isinstance(a.derived, dict):
                        partition = a.derived.get("partition")
                except Exception:
                    partition = None
                loc = partition or "Unknown"
                if not isinstance(loc, str) or not loc.strip():
                    loc = "Unknown"
                if (a.presence_count or 0) > 0:
                    cls = "contractor"
                    try:
                        if a.derived and isinstance(a.derived, dict):
                            cls = classify_personnel_from_detail(a.derived)
                    except Exception:
                        cls = "contractor"
                    if key:
                        key_map_head[key] = {"loc": loc, "cls": cls}
                    if loc not in head_per_location:
                        head_per_location[loc] = {"total": 0, "employee": 0, "contractor": 0}
                    head_per_location[loc][cls] += 1
                    head_per_location[loc]["total"] += 1
                    head_total += 1
        session.expunge_all()
    except Exception:
        logger.exception("Error computing HeadCount")
        notes.append("Failed to compute HeadCount from DB; see server logs.")
    finally:
        try:
            session.close()
        except Exception:
            pass

    # --- LIVE HEADCOUNT via region_clients (realtime) ----------
    live_total = 0
    live_per_location: Dict[str, Dict[str, int]] = {}
    sites_queried = 0
    details = []
    try:
        import region_clients
        regions_info = []
        # Use resilient wrapper with retries/backoff and collect errors
        try:
            if hasattr(region_clients, "fetch_all_regions"):
                maybe_regions, exc_regions = _attempt_region_call(region_clients.fetch_all_regions, timeout=timeout, attempts=2, backoff=0.5)
                if exc_regions is not None:
                    region_client_errors.append({"fn": "fetch_all_regions", "error": str(exc_regions)})
                regions_info = maybe_regions or []
        except Exception:
            logger.exception("region_clients.fetch_all_regions failed")
        try:
            if hasattr(region_clients, "fetch_all_details"):
                maybe_details, exc_details = _attempt_region_call(region_clients.fetch_all_details, timeout=timeout, attempts=2, backoff=0.5)
                if exc_details is not None:
                    region_client_errors.append({"fn": "fetch_all_details", "error": str(exc_details)})
                details = maybe_details or []
        except Exception:
            logger.exception("region_clients.fetch_all_details failed")
        sites_queried = len(regions_info) if isinstance(regions_info, list) else 0
        if regions_info:
            for r in regions_info:
                try:
                    c = r.get("count") if isinstance(r, dict) else None
                    ci = _safe_int(c)
                    if ci is not None:
                        live_total += int(ci)
                except Exception:
                    continue
        derived_detail_sum = 0
        if details and isinstance(details, list):
            for d in details:
                try:
                    loc = pick_partition_from_detail(d) or "Unknown"
                    if not isinstance(loc, str) or not loc.strip():
                        loc = "Unknown"
                    pclass = classify_personnel_from_detail(d)
                    # dedupe key
                    key = _normalize_employee_key(d.get("EmployeeID")) or _normalize_card_like(d.get("CardNumber")) or (d.get("PersonGUID") if d.get("PersonGUID") else None)
                    if not key:
                        key = _normalize_employee_key(d.get("employee_id")) or _normalize_card_like(d.get("Card")) or None
                    if not key:
                        # synthetic key for anonymous row
                        key = f"detail_{derived_detail_sum}_{str(hash(json.dumps(d, default=str)))}"
                    key = str(key)
                    key_map_live[key] = {"loc": loc, "cls": pclass}
                    if loc not in live_per_location:
                        live_per_location[loc] = {"total": 0, "employee": 0, "contractor": 0}
                    live_per_location[loc]["total"] += 1
                    live_per_location[loc][pclass] += 1
                    derived_detail_sum += 1
                except Exception:
                    continue
            # decide final live_total: if regions provided prefer region totals for overall; details used for breakdown
            if live_total == 0 and derived_detail_sum > 0:
                live_total = derived_detail_sum
            else:
                if live_total != derived_detail_sum:
                    notes.append(f"Region totals ({live_total}) differ from detail rows ({derived_detail_sum}); using region totals for overall and details for breakdown.")
        else:
            notes.append("No per-person details available from region_clients; live breakdown unavailable.")
    except Exception:
        logger.exception("Error computing Live HeadCount")
        notes.append("Failed to compute Live HeadCount; see logs.")
        live_total = live_total or 0

    # ---------- Ensure headcount is union(head_keys, live_keys) ----------
    try:
        head_keys = set(k for k in key_map_head.keys() if k)
        live_keys = set(k for k in key_map_live.keys() if k)
        union_keys = head_keys.union(live_keys)

        unified_head_per_location: Dict[str, Dict[str, int]] = {}
        for k in union_keys:
            if k in key_map_head:
                loc = key_map_head[k].get("loc") or "Unknown"
                cls = key_map_head[k].get("cls") or "contractor"
            else:
                loc = key_map_live.get(k, {}).get("loc") or "Unknown"
                cls = key_map_live.get(k, {}).get("cls") or "contractor"
            if not isinstance(loc, str) or not loc.strip():
                loc = "Unknown"
            if loc not in unified_head_per_location:
                unified_head_per_location[loc] = {"total": 0, "employee": 0, "contractor": 0}
            unified_head_per_location[loc]["total"] += 1
            unified_head_per_location[loc][cls] += 1

        if union_keys:
            head_per_location = unified_head_per_location
            head_total = len(union_keys)
    except Exception:
        logger.exception("Error reconciling headcount union with live details")

    # --- Averages from AttendanceSummary (DB) - per-location & overall (range-based) ---
    avg_headcount_last_range = None
    avg_headcount_per_site_last_range = None
    avg_by_location_last_range: Dict[str, Dict[str, Any]] = {}

    try:
        session = SessionLocal()
        # build list of days in range
        days = []
        days_count = (end_obj - start_obj).days + 1
        for i in range(0, days_count):
            days.append(start_obj + timedelta(days=i))

        loc_day_vals: Dict[str, Dict[str, List[int]]] = {}
        for d in days:
            rows = session.query(AttendanceSummary).filter(AttendanceSummary.date == d).all()
            per_loc_counts: Dict[str, Dict[str, int]] = {}
            if rows:
                for r in rows:
                    try:
                        if (r.presence_count or 0) <= 0:
                            continue
                        partition = None
                        try:
                            if r.derived and isinstance(r.derived, dict):
                                partition = r.derived.get("partition")
                        except Exception:
                            partition = None
                        loc = partition or "Unknown"
                        if not isinstance(loc, str) or not loc.strip():
                            loc = "Unknown"
                        if loc not in per_loc_counts:
                            per_loc_counts[loc] = {"employee": 0, "contractor": 0, "total": 0}
                        # classify via derived if possible
                        cls = "contractor"
                        try:
                            if r.derived and isinstance(r.derived, dict):
                                cls = classify_personnel_from_detail(r.derived)
                        except Exception:
                            cls = "contractor"
                        per_loc_counts[loc][cls] += 1
                        per_loc_counts[loc]["total"] += 1
                    except Exception:
                        continue
            for loc, counts in per_loc_counts.items():
                if loc not in loc_day_vals:
                    loc_day_vals[loc] = {"employee": [], "contractor": [], "total": []}
                loc_day_vals[loc]["employee"].append(counts.get("employee", 0))
                loc_day_vals[loc]["contractor"].append(counts.get("contractor", 0))
                loc_day_vals[loc]["total"].append(counts.get("total", 0))

        for loc, lists in loc_day_vals.items():
            emp_list = lists.get("employee", [])
            con_list = lists.get("contractor", [])
            tot_list = lists.get("total", [])
            days_counted = len(tot_list)
            if days_counted == 0:
                continue
            avg_emp = round(sum(emp_list) / float(days_counted), 2)
            avg_con = round(sum(con_list) / float(days_counted), 2)
            avg_tot = round(sum(tot_list) / float(days_counted), 2)
            avg_by_location_last_range[loc] = {
                "history_days_counted": int(days_counted),
                "avg_employee_last_7_days": _sanitize_for_json(avg_emp),
                "avg_contractor_last_7_days": _sanitize_for_json(avg_con),
                "avg_overall_last_7_days": _sanitize_for_json(avg_tot)
            }

        days_totals = []
        for d in days:
            rows = session.query(AttendanceSummary).filter(AttendanceSummary.date == d).all()
            day_total = 0
            if rows:
                for r in rows:
                    if (r.presence_count or 0) > 0:
                        day_total += 1
            days_totals.append(day_total)
        if days_totals:
            avg_headcount_last_range = round(sum(days_totals) / float(len(days_totals)), 2)
            if sites_queried and sites_queried > 0:
                avg_headcount_per_site_last_range = round((sum(days_totals) / float(len(days_totals))) / float(sites_queried), 2)
        session.close()
    except Exception:
        logger.exception("Error computing averages from AttendanceSummary")
        notes.append("Failed to compute historical averages from AttendanceSummary; partial results only.")

    # --- HISTORY AVERAGES: use region_clients.fetch_all_history (range-based) ----------
    history_emp_avg = None
    history_contractor_avg = None
    history_overall_avg = None
    history_days = 0
    history_avg_by_location: Dict[str, Dict[str, Any]] = {}
    history_today_emp = None
    history_today_con = None

    try:
        import region_clients
        if hasattr(region_clients, "fetch_all_history"):
            entries, exc_history = _attempt_region_call(region_clients.fetch_all_history, timeout=timeout, attempts=2, backoff=0.5)
            if exc_history is not None:
                region_client_errors.append({"fn": "fetch_all_history", "error": str(exc_history)})
            entries = entries or []
            agg_by_date = {}
            agg_partitions_by_date = {}
            for e in entries:
                try:
                    dstr = e.get("date")
                    if not dstr:
                        dstr = e.get("day") or e.get("timestamp") or None
                        if isinstance(dstr, datetime):
                            dstr = dstr.date().isoformat()
                    if not dstr:
                        continue
                    # robust region-level extraction (some endpoints return region key, some return fields at top)
                    region_obj = e.get("region") if isinstance(e.get("region"), dict) else None
                    emp = None
                    con = None
                    tot = None
                    if region_obj and isinstance(region_obj, dict):
                        emp = _safe_int(region_obj.get("Employee"))
                        con = _safe_int(region_obj.get("Contractor"))
                        tot = _safe_int(region_obj.get("total")) or ((emp or 0) + (con or 0))
                    else:
                        emp = _safe_int(e.get("Employee") or (e.get("region") and e.get("region").get("Employee") if isinstance(e.get("region"), dict) else None))
                        con = _safe_int(e.get("Contractor") or (e.get("region") and e.get("region").get("Contractor") if isinstance(e.get("region"), dict) else None))
                        tot = _safe_int(e.get("total") or ((emp or 0) + (con or 0)))
                    if emp is None and con is None:
                        try:
                            robj = e.get("region") or {}
                            if isinstance(robj, dict):
                                emp = _safe_int(robj.get("Employee"))
                                con = _safe_int(robj.get("Contractor"))
                                tot = _safe_int(robj.get("total"))
                        except Exception:
                            pass
                    if emp is None and con is None:
                        continue
                    if tot is None:
                        tot = (emp or 0) + (con or 0)
                    if dstr not in agg_by_date:
                        agg_by_date[dstr] = {"employee": 0, "contractor": 0, "total": 0, "counted_regions": 0}
                    agg_by_date[dstr]["employee"] += (emp or 0)
                    agg_by_date[dstr]["contractor"] += (con or 0)
                    agg_by_date[dstr]["total"] += (tot or 0)
                    agg_by_date[dstr]["counted_regions"] += 1

                    parts = e.get("partitions") if isinstance(e.get("partitions"), dict) else {}
                    if dstr not in agg_partitions_by_date:
                        agg_partitions_by_date[dstr] = {}
                    for pname, pstat in parts.items():
                        try:
                            p_emp = _safe_int(pstat.get("Employee"))
                            p_con = _safe_int(pstat.get("Contractor"))
                            p_tot = _safe_int(pstat.get("total")) or ((p_emp or 0) + (p_con or 0))
                            if pname not in agg_partitions_by_date[dstr]:
                                agg_partitions_by_date[dstr][pname] = {"employee": 0, "contractor": 0, "total": 0}
                            agg_partitions_by_date[dstr][pname]["employee"] += (p_emp or 0)
                            agg_partitions_by_date[dstr][pname]["contractor"] += (p_con or 0)
                            agg_partitions_by_date[dstr][pname]["total"] += (p_tot or 0)
                        except Exception:
                            continue
                except Exception:
                    continue

            # history_today (if present)
            today_iso = today.isoformat()
            if today_iso in agg_by_date:
                history_today_emp = agg_by_date[today_iso].get("employee", 0)
                history_today_con = agg_by_date[today_iso].get("contractor", 0)

            # select dates within requested inclusive range
            day_vals_emp = []
            day_vals_con = []
            day_vals_tot = []
            selected_dates = []
            for i in range(0, (end_obj - start_obj).days + 1):
                dcheck = (start_obj + timedelta(days=i)).isoformat()
                entry = agg_by_date.get(dcheck)
                if entry:
                    day_vals_emp.append(entry.get("employee", 0))
                    day_vals_con.append(entry.get("contractor", 0))
                    day_vals_tot.append(entry.get("total", 0))
                    selected_dates.append(dcheck)

            if day_vals_emp:
                history_emp_avg = round(sum(day_vals_emp) / float(len(day_vals_emp)), 2)
            if day_vals_con:
                history_contractor_avg = round(sum(day_vals_con) / float(len(day_vals_con)), 2)
            if day_vals_tot:
                history_overall_avg = round(sum(day_vals_tot) / float(len(day_vals_tot)), 2)
            history_days = len(day_vals_tot)
            if history_days == 0:
                notes.append("History endpoints returned no usable rows in requested range; history averages not available.")

            # per-partition averages across the selected_dates
            partition_day_values = {}
            for d_iso in selected_dates:
                per_parts = agg_partitions_by_date.get(d_iso, {})
                for pname, pvals in per_parts.items():
                    if pname not in partition_day_values:
                        partition_day_values[pname] = {"employee": [], "contractor": [], "total": []}
                    partition_day_values[pname]["employee"].append(pvals.get("employee", 0))
                    partition_day_values[pname]["contractor"].append(pvals.get("contractor", 0))
                    partition_day_values[pname]["total"].append(pvals.get("total", 0))
            for pname, lists in partition_day_values.items():
                emp_list = lists.get("employee", [])
                con_list = lists.get("contractor", [])
                tot_list = lists.get("total", [])
                days_counted = len(tot_list)
                if days_counted == 0:
                    continue
                avg_emp = round(sum(emp_list) / float(days_counted), 2)
                avg_con = round(sum(con_list) / float(days_counted), 2)
                avg_tot = round(sum(tot_list) / float(days_counted), 2)
                history_avg_by_location[pname] = {
                    "history_days_counted": int(days_counted),
                    "avg_employee_last_7_days": _sanitize_for_json(avg_emp),
                    "avg_contractor_last_7_days": _sanitize_for_json(avg_con),
                    "avg_overall_last_7_days": _sanitize_for_json(avg_tot)
                }

            logger.debug("history: dates collected=%d partitions_sample=%d", len(selected_dates), len(history_avg_by_location))
    except Exception:
        logger.exception("Error fetching/processing history endpoints")
        notes.append("Failed to compute history averages from region history endpoints; partial results.")

    # Merge DB-derived per-location (avg_by_location_last_range) with history per-location (history_avg_by_location)
    try:
        merged_history = dict(history_avg_by_location)  # prefer history where present
        for loc, dbvals in (avg_by_location_last_range or {}).items():
            if loc in merged_history:
                continue
            try:
                merged_history[loc] = {
                    "history_days_counted": int(dbvals.get("history_days_counted") or 0),
                    "avg_employee_last_7_days": _sanitize_for_json(dbvals.get("avg_employee_last_7_days")),
                    "avg_contractor_last_7_days": _sanitize_for_json(dbvals.get("avg_contractor_last_7_days")),
                    "avg_overall_last_7_days": _sanitize_for_json(dbvals.get("avg_overall_last_7_days"))
                }
            except Exception:
                merged_history[loc] = {
                    "history_days_counted": int(dbvals.get("history_days_counted") or 0),
                    "avg_employee_last_7_days": _sanitize_for_json(dbvals.get("avg_employee_last_7_days") or None),
                    "avg_contractor_last_7_days": _sanitize_for_json(dbvals.get("avg_contractor_last_7_days") or None),
                    "avg_overall_last_7_days": _sanitize_for_json(dbvals.get("avg_overall_last_7_days") or None)
                }
        history_avg_by_location = merged_history
    except Exception:
        logger.exception("Failed to normalize history_avg_by_location")

    # Fallback: if DB-based avg empty, use history_overall_avg
    if (not avg_headcount_last_range or avg_headcount_last_range == 0) and history_overall_avg:
        try:
            avg_headcount_last_range = history_overall_avg
            avg_headcount_per_site_last_range = round(history_overall_avg / float(sites_queried), 2) if sites_queried and sites_queried > 0 else None
            notes.append("avg_headcount_last_range derived from region history endpoints due to missing AttendanceSummary historical data.")
        except Exception:
            pass

    # --- compute percentages (head/live vs CCURE reported)
    def safe_pct(n, denom):
        try:
            if n is None or denom is None:
                return None
            if float(denom) == 0.0:
                return None
            return round((float(n) / float(denom)) * 100.0, 2)
        except Exception:
            return None

    cc_emp_denom = reported_active_emps
    cc_con_denom = reported_active_contractors
    cc_total_denom = None
    if isinstance(cc_emp_denom, int) and isinstance(cc_con_denom, int):
        cc_total_denom = cc_emp_denom + cc_con_denom

    head_emp_total = sum(v.get("employee", 0) for v in head_per_location.values())
    head_con_total = sum(v.get("contractor", 0) for v in head_per_location.values())
    live_emp_total = sum(v.get("employee", 0) for v in live_per_location.values())
    live_con_total = sum(v.get("contractor", 0) for v in live_per_location.values())

    head_emp_pct_vs_ccure_today = _sanitize_for_json(safe_pct(head_emp_total, cc_emp_denom))
    head_contractor_pct_vs_ccure_today = _sanitize_for_json(safe_pct(head_con_total, cc_con_denom))
    head_overall_pct_vs_ccure_today = _sanitize_for_json(safe_pct(head_total, cc_total_denom))

    live_emp_pct_vs_ccure_today = _sanitize_for_json(safe_pct(live_emp_total, cc_emp_denom))
    live_contractor_pct_vs_ccure_today = _sanitize_for_json(safe_pct(live_con_total, cc_con_denom))
    live_overall_pct_vs_ccure_today = _sanitize_for_json(safe_pct(live_total, cc_total_denom))

    history_emp_pct_vs_ccure = _sanitize_for_json(safe_pct(history_emp_avg, cc_emp_denom))
    history_contractor_pct_vs_ccure = _sanitize_for_json(safe_pct(history_contractor_avg, cc_con_denom))
    history_overall_pct_vs_ccure = _sanitize_for_json(safe_pct(history_overall_avg, cc_total_denom))

    history_today_emp_pct_vs_ccure = _sanitize_for_json(safe_pct(history_today_emp, cc_emp_denom))
    history_today_contractor_pct_vs_ccure = _sanitize_for_json(safe_pct(history_today_con, cc_con_denom))

    # Final result
    result = {
        "date": today.isoformat(),
        "headcount": {
            "total_visited_today": int(head_total),
            "employee": int(head_emp_total),
            "contractor": int(head_con_total),
            "by_location": { loc: {"total": int(stats.get("total", 0)), "employee": int(stats.get("employee", 0)), "contractor": int(stats.get("contractor", 0))} for loc, stats in head_per_location.items() }
        },
        "live_headcount": {
            "currently_present_total": int(live_total),
            "employee": int(live_emp_total),
            "contractor": int(live_con_total),
            "by_location": { loc: {"total": int(stats.get("total", 0)), "employee": int(stats.get("employee", 0)), "contractor": int(stats.get("contractor", 0))} for loc, stats in live_per_location.items() }
        },
        "ccure_active": {
            "ccure_active_employees_reported": _safe_int(reported_active_emps),
            "ccure_active_contractors_reported": _safe_int(reported_active_contractors)
        },
        "averages": {
            "head_emp_pct_vs_ccure_today": head_emp_pct_vs_ccure_today,
            "head_contractor_pct_vs_ccure_today": head_contractor_pct_vs_ccure_today,
            "headcount_overall_pct_vs_ccure_today": head_overall_pct_vs_ccure_today,
            "live_employee_pct_vs_ccure": live_emp_pct_vs_ccure_today,
            "live_contractor_pct_vs_ccure": _sanitize_for_json(safe_pct(live_con_total, cc_con_denom)),
            "live_overall_pct_vs_ccure": live_overall_pct_vs_ccure_today,
            # range-keys (kept for compatibility)
            "avg_headcount_last_7_days": _sanitize_for_json(avg_headcount_last_range),
            "avg_headcount_per_site_last_7_days": _sanitize_for_json(avg_headcount_per_site_last_range),
            "avg_live_per_site": _sanitize_for_json(round(live_total / sites_queried, 2) if sites_queried and sites_queried > 0 else None),

            # history endpoint range averages
            "history_avg_employee_last_7_days": _sanitize_for_json(history_emp_avg),
            "history_avg_contractor_last_7_days": _sanitize_for_json(history_contractor_avg),
            "history_avg_overall_last_7_days": _sanitize_for_json(history_overall_avg),
            "history_days_counted": int(history_days) if history_days is not None else None,
            "history_employee_pct_vs_ccure": history_emp_pct_vs_ccure,
            "history_contractor_pct_vs_ccure": history_contractor_pct_vs_ccure,
            "history_overall_pct_vs_ccure": history_overall_pct_vs_ccure,

            # history-today specific metrics (if present)
            "history_today_employee_count": int(history_today_emp) if history_today_emp is not None else None,
            "history_today_contractor_count": int(history_today_con) if history_today_con is not None else None,
            "history_today_employee_pct_vs_ccure": history_today_emp_pct_vs_ccure,
            "history_today_contractor_pct_vs_ccure": history_today_contractor_pct_vs_ccure,

            "avg_by_location_last_7_days": _sanitize_for_json(avg_by_location_last_range),
            "history_avg_by_location_last_7_days": _sanitize_for_json(history_avg_by_location)
        },
        "sites_queried": int(sites_queried),
        "notes": " | ".join(notes) if notes else f"Computed over range {start_obj.isoformat()} -> {end_obj.isoformat()}",
        # new optional fields that record region client failures
        "region_client_errors": region_client_errors,
        "region_clients_unavailable": True if region_client_errors else False
    }

    return _sanitize_for_json(result)











# app.py (keep only /ccure/verify, removed /ccure/averages)
from fastapi import FastAPI, UploadFile, File, HTTPException, Request, Query
from fastapi.responses import JSONResponse, FileResponse, StreamingResponse
from fastapi.middleware.cors import CORSMiddleware
import shutil
import uuid
import json
import logging
from pathlib import Path
from datetime import date, datetime, timedelta
import re
import asyncio
from typing import Optional, Dict, Any

# --- DB / models imports (your existing project modules) ---
from db import SessionLocal
from models import LiveSwipe, AttendanceSummary  # removed ActiveEmployee/ActiveContractor dependence for averages

# --- settings (assumes these exist in your project) ---
try:
    from settings import UPLOAD_DIR, OUTPUT_DIR
except Exception:
    UPLOAD_DIR = "./uploads"
    OUTPUT_DIR = "./output"

app = FastAPI(title="Attendance Analytics")

logger = logging.getLogger("attendance_app")
logger.setLevel(logging.INFO)
if not logger.handlers:
    ch = logging.StreamHandler()
    ch.setFormatter(logging.Formatter("%(asctime)s %(levelname)s %(name)s: %(message)s"))
    logger.addHandler(ch)

# ----------------- GLOBAL TIMEOUTS (UNIFY) -----------------
REGION_TIMEOUT_SECONDS = 20
COMPUTE_WAIT_TIMEOUT_SECONDS = 30
COMPUTE_SYNC_TIMEOUT_SECONDS = 60
# ----------------------------------------------------------

_allowed_origins = [
    "http://localhost:5173",
    "http://127.0.0.1:5173",
    "http://localhost:3000",
    "http://localhost:3008"
]
app.add_middleware(
    CORSMiddleware,
    allow_origins=_allowed_origins,
    allow_credentials=True,
    allow_methods=["GET", "POST", "OPTIONS"],
    allow_headers=["*"],
)

_broadcaster_clients = set()

def broadcast_ccure_update(payload: dict):
    if not _broadcaster_clients:
        return
    try:
        loop = asyncio.get_event_loop()
    except RuntimeError:
        loop = None
    for q in list(_broadcaster_clients):
        try:
            if loop and loop.is_running():
                loop.call_soon_threadsafe(q.put_nowait, payload)
            else:
                q.put_nowait(payload)
        except Exception:
            logger.exception("Failed to push payload to SSE client (will remove client)")
            try:
                _broadcaster_clients.discard(q)
            except Exception:
                pass

async def _sse_event_generator(client_queue: asyncio.Queue):
    try:
        while True:
            payload = await client_queue.get()
            try:
                data = json.dumps(payload, default=str)
            except Exception:
                data = json.dumps({"error": "serialization error", "payload": str(payload)})
            yield f"data: {data}\n\n"
    finally:
        try:
            _broadcaster_clients.discard(client_queue)
        except Exception:
            pass
        return

@app.get("/ccure/stream")
async def ccure_stream():
    q = asyncio.Queue()
    _broadcaster_clients.add(q)
    generator = _sse_event_generator(q)
    headers = {"Cache-Control": "no-cache", "X-Accel-Buffering": "no"}
    return StreamingResponse(generator, media_type="text/event-stream", headers=headers)

def _guess_region_from_text(txt: str) -> str:
    if not txt:
        return "unknown"
    s = str(txt).strip().lower()
    s = re.sub(r"[,\-/()]", " ", s)
    if any(k in s for k in ("pune","quezon city","taguig city","bengaluru","hyderabad","chennai","manila","singapore","hong kong","beijing","shanghai","jakarta","kuala","osaka","tokyo","seoul","bangkok")):
        return "apac"
    if any(k in s for k in ("london","dublin","paris","frankfurt","amsterdam","stockholm","cape town","johannesburg","berlin","brussels","madrid","rome","milan")):
        return "emea"
    if any(k in s for k in ("mexico","bogota","buenos","santiago","sao","salvador","lima","caracas")):
        return "laca"
    if any(k in s for k in ("denver","new york","ny","chicago","toronto","vancouver","los angeles","san francisco","boston","houston","atlanta","miami")):
        return "namer"
    return "unknown"

@app.get("/headcount")
def api_headcount():
    try:
        totals = {"apac": 0, "emea": 0, "laca": 0, "namer": 0, "unknown": 0}
        with SessionLocal() as db:
            try:
                today = date.today()
                rows = db.query(AttendanceSummary).filter(AttendanceSummary.date == today).all()
                if rows:
                    for r in rows:
                        try:
                            partition = None
                            if r.derived and isinstance(r.derived, dict):
                                partition = r.derived.get("partition")
                            loc = partition or "unknown"
                            region = _guess_region_from_text(loc)
                            totals[region] = totals.get(region, 0) + 1
                        except Exception:
                            totals["unknown"] += 1
                else:
                    start = datetime.combine(today, datetime.min.time())
                    end = datetime.combine(today, datetime.max.time())
                    swipes = db.query(LiveSwipe).filter(LiveSwipe.timestamp >= start, LiveSwipe.timestamp <= end).all()
                    for s in swipes:
                        loc = s.partition or "unknown"
                        region = _guess_region_from_text(loc)
                        totals[region] = totals.get(region, 0) + 1
            except Exception:
                logger.exception("Failed to compute headcount regions")
        out = {
            "apac": int(totals.get("apac", 0)),
            "emea": int(totals.get("emea", 0)),
            "laca": int(totals.get("laca", 0)),
            "namer": int(totals.get("namer", 0))
        }
        return JSONResponse(out)
    except Exception as exc:
        logger.exception("api_headcount failed")
        raise HTTPException(status_code=500, detail=f"headcount error: {exc}")

# ---------- Helpers retained (normalize / safe conversions) -------------
def _normalize_employee_key(x) -> Optional[str]:
    if x is None:
        return None
    try:
        s = str(x).strip()
        if s == "" or s.lower() in ("nan", "none", "na", "null"):
            return None
        return s
    except Exception:
        return None

def _normalize_card_like(s) -> Optional[str]:
    if s is None:
        return None
    try:
        ss = str(s).strip()
        if ss == "":
            return None
        digits = re.sub(r'\D+', '', ss)
        if digits == "":
            return None
        return digits.lstrip('0') or digits
    except Exception:
        return None

def _safe_int(v):
    try:
        if v is None:
            return None
        return int(v)
    except Exception:
        try:
            return int(float(v))
        except Exception:
            return None

# ---------- build_ccure_averages (fallback) ------------------------------
def build_ccure_averages(start_date: Optional[str] = None, end_date: Optional[str] = None):
    """
    Fallback averages computation using AttendanceSummary only.
    Returns a compact shape (live_today, ccure_active, averages, notes).
    """
    try:
        def _parse_date_param(s):
            if not s:
                return None
            try:
                return datetime.strptime(s, "%Y-%m-%d").date()
            except Exception:
                try:
                    return date.fromisoformat(s)
                except Exception:
                    return None

        today = date.today()
        start_obj = _parse_date_param(start_date) if start_date else (today - timedelta(days=6))
        end_obj = _parse_date_param(end_date) if end_date else today
        if start_obj is None or end_obj is None or start_obj > end_obj:
            start_obj = today - timedelta(days=6)
            end_obj = today

        with SessionLocal() as db:
            try:
                att_rows = db.query(AttendanceSummary).filter(AttendanceSummary.date == today).all()
            except Exception:
                logger.exception("Failed to query AttendanceSummary")
                att_rows = []

            live_emp = 0
            live_contr = 0
            unknown_count = 0
            seen_keys = set()

            def classify_from_derived(derived):
                try:
                    if not derived or not isinstance(derived, dict):
                        return "contractor"
                    for k in ("PersonnelType","personnelType","personnel_type","Personnel Type","Type","personnel"):
                        v = derived.get(k)
                        if v and "employee" in str(v).strip().lower():
                            return "employee"
                    for k in ("Employee_Status","Employee Status","Status"):
                        v = derived.get(k)
                        if v and "terminated" in str(v).strip().lower():
                            return "employee"
                    return "contractor"
                except Exception:
                    return "contractor"

            if att_rows:
                for a in att_rows:
                    key = None
                    try:
                        key = _normalize_employee_key(a.employee_id)
                    except Exception:
                        key = None
                    if not key:
                        try:
                            key = _normalize_card_like(a.derived.get('card_number') if (a.derived and isinstance(a.derived, dict)) else None)
                        except Exception:
                            key = None
                    if not key:
                        unknown_count += 1
                        continue
                    if key in seen_keys:
                        continue
                    seen_keys.add(key)
                    cls = classify_from_derived(a.derived)
                    if cls == "employee":
                        live_emp += 1
                    elif cls == "contractor":
                        live_contr += 1
                    else:
                        unknown_count += 1

                live_total_reported = live_emp + live_contr + unknown_count
                live_total_details = len(att_rows)
            else:
                live_total_reported = 0
                live_total_details = 0
                try:
                    import region_clients
                    details = []
                    try:
                        details = region_clients.fetch_all_details(timeout=REGION_TIMEOUT_SECONDS) or []
                    except Exception:
                        logger.exception("region_clients.fetch_all_details failed in build_ccure_averages()")
                        details = []
                    if details:
                        for d in details:
                            try:
                                cls = "contractor"
                                for k in ("PersonnelType","personnelType","personnel_type","Personnel Type","Type","personnel"):
                                    v = d.get(k)
                                    if v and "employee" in str(v).strip().lower():
                                        cls = "employee"
                                        break
                                if cls == "employee":
                                    live_emp += 1
                                else:
                                    live_contr += 1
                                live_total_details += 1
                            except Exception:
                                continue
                        live_total_reported = live_emp + live_contr
                    else:
                        try:
                            regions = region_clients.fetch_all_regions(timeout=REGION_TIMEOUT_SECONDS) or []
                            for r in regions:
                                try:
                                    c = r.get("count")
                                    if isinstance(c, (int, float)):
                                        live_total_reported += int(c)
                                except Exception:
                                    continue
                        except Exception:
                            logger.exception("region_clients.fetch_all_regions failed in build_ccure_averages()")
                except Exception:
                    logger.exception("region_clients not importable in build_ccure_averages()")

            # compute avg range using AttendanceSummary if possible
            avg_range = None
            try:
                q = db.query(AttendanceSummary.date, AttendanceSummary.employee_id, AttendanceSummary.presence_count)\
                      .filter(AttendanceSummary.date >= start_obj, AttendanceSummary.date <= end_obj).all()
                by_date = {}
                for row in q:
                    d = row[0]
                    key = (row[1] or "").strip() if row[1] else None
                    if not key:
                        continue
                    if d not in by_date:
                        by_date[d] = set()
                    try:
                        presence_val = getattr(row, 'presence_count', row[2])
                        if int(presence_val) > 0:
                            by_date[d].add(key)
                    except Exception:
                        by_date[d].add(key)
                days_count = (end_obj - start_obj).days + 1
                daily_counts = [len(by_date.get(start_obj + timedelta(days=i), set())) for i in range(days_count)]
                if days_count and any(daily_counts):
                    avg_range = int(round(sum(daily_counts) / float(days_count)))
                else:
                    avg_range = None
            except Exception:
                logger.exception("Failed computing range average from AttendanceSummary")
                avg_range = None

        # fallback: use region history to compute avg_range if still None
        if avg_range is None:
            try:
                import region_clients
                entries = region_clients.fetch_all_history(timeout=REGION_TIMEOUT_SECONDS) or []
                agg = {}
                for e in entries:
                    try:
                        dstr = e.get("date")
                        if not dstr:
                            continue
                        region_obj = e.get("region") if isinstance(e.get("region"), dict) else None
                        emp = None
                        con = None
                        tot = None
                        if region_obj:
                            emp = _safe_int(region_obj.get("Employee"))
                            con = _safe_int(region_obj.get("Contractor"))
                            tot = _safe_int(region_obj.get("total")) or ((emp or 0) + (con or 0))
                        else:
                            emp = _safe_int(e.get("Employee"))
                            con = _safe_int(e.get("Contractor"))
                            tot = _safe_int(e.get("total"))
                        if emp is None and con is None:
                            continue
                        if tot is None:
                            tot = (emp or 0) + (con or 0)
                        if dstr not in agg:
                            agg[dstr] = {"total": 0, "count": 0}
                        agg[dstr]["total"] += tot or 0
                        agg[dstr]["count"] += 1
                    except Exception:
                        continue
                per_date_totals = []
                days_count = (end_obj - start_obj).days + 1
                for i in range(days_count):
                    dcheck = (start_obj + timedelta(days=i)).isoformat()
                    if dcheck in agg and agg[dcheck]["count"] > 0:
                        per_day_avg = float(agg[dcheck]["total"]) / float(agg[dcheck]["count"])
                        per_date_totals.append(per_day_avg)
                if per_date_totals:
                    avg_range = int(round(sum(per_date_totals) / float(len(per_date_totals))))
            except Exception:
                logger.exception("Failed computing avg_range from region history in fallback")

        # get ccure stats if available
        ccure_stats = {}
        try:
            import ccure_client
            if hasattr(ccure_client, "get_global_stats"):
                ccure_stats = ccure_client.get_global_stats() or {}
        except Exception:
            logger.debug("ccure_client.get_global_stats not available", exc_info=True)

        cc_active_emps = None
        cc_active_contractors = None
        try:
            if isinstance(ccure_stats, dict):
                a = ccure_stats.get("ActiveEmployees") or ccure_stats.get("active_employees") or None
                b = ccure_stats.get("ActiveContractors") or ccure_stats.get("active_contractors") or None
                if a is not None and str(a).strip() != "":
                    cc_active_emps = int(a)
                if b is not None and str(b).strip() != "":
                    cc_active_contractors = int(b)
        except Exception:
            cc_active_emps = cc_active_contractors = None

        emp_pct = None
        contr_pct = None
        overall_pct = None
        try:
            if isinstance(cc_active_emps, int) and cc_active_emps > 0:
                emp_pct = round((live_emp / float(cc_active_emps)) * 100.0, 2)
            if isinstance(cc_active_contractors, int) and cc_active_contractors > 0:
                contr_pct = round((live_contr / float(cc_active_contractors)) * 100.0, 2)
            if isinstance(cc_active_emps, int) and isinstance(cc_active_contractors, int) and (cc_active_emps + cc_active_contractors) > 0:
                overall_pct = round(((live_emp + live_contr) / float(cc_active_emps + cc_active_contractors)) * 100.0, 2)
        except Exception:
            emp_pct = contr_pct = overall_pct = None

        resp = {
            "date": today.isoformat(),
            "notes": f"Computed over range {start_obj.isoformat()} -> {end_obj.isoformat()}" if (start_date or end_date) else None,
            "live_today": {
                "employee": live_emp,
                "contractor": live_contr,
                "total_reported": live_total_reported,
                "total_from_details": live_total_details
            },
            "ccure_active": {
                "active_employees": cc_active_emps,
                "active_contractors": cc_active_contractors,
                "ccure_active_employees_reported": cc_active_emps,
                "ccure_active_contractors_reported": cc_active_contractors
            },
            "averages": {
                "employee_pct": emp_pct,
                "contractor_pct": contr_pct,
                "overall_pct": overall_pct,
                "avg_headcount_last_7_days": avg_range,
                "head_emp_pct_vs_ccure_today": emp_pct,
                "head_contractor_pct_vs_ccure_today": contr_pct,
                "headcount_overall_pct_vs_ccure_today": overall_pct,
                "history_avg_overall_last_7_days": avg_range
            }
        }

        return resp
    except Exception:
        logger.exception("build_ccure_averages failed")
        raise

# ---------- map detailed -> compact (used when compute returns detailed) ----
def _map_detailed_to_resp(detailed: Dict[str, Any]) -> Dict[str, Any]:
    live_h = detailed.get("live_headcount", {}) or {}
    head_h = detailed.get("headcount", {}) or {}
    ccure_active_obj = detailed.get("ccure_active", {}) or {}
    averages_obj = detailed.get("averages", {}) or {}

    live_employee = int(live_h.get("employee") or head_h.get("employee") or 0)
    live_contractor = int(live_h.get("contractor") or head_h.get("contractor") or 0)
    total_reported = int(
        live_h.get("currently_present_total")
        or head_h.get("total_visited_today")
        or (live_employee + live_contractor)
        or 0
    )
    total_from_details = int(head_h.get("total_visited_today") or 0)

    mapped_headcount = {
        "total_visited_today": int(head_h.get("total_visited_today") or 0),
        "employee": int(head_h.get("employee") or 0),
        "contractor": int(head_h.get("contractor") or 0),
        "by_location": head_h.get("by_location") or {}
    }

    resp = {
        "date": detailed.get("date"),
        "notes": detailed.get("notes"),
        "live_today": {
            "employee": live_employee,
            "contractor": live_contractor,
            "total_reported": total_reported,
            "total_from_details": total_from_details
        },
        "headcount": mapped_headcount,
        "live_headcount": live_h,
        "ccure_active": {
            "active_employees": ccure_active_obj.get("ccure_active_employees_reported")
                             or ccure_active_obj.get("active_employees"),
            "active_contractors": ccure_active_obj.get("ccure_active_contractors_reported")
                               or ccure_active_obj.get("active_contractors"),
            "ccure_active_employees_reported": ccure_active_obj.get("ccure_active_employees_reported"),
            "ccure_active_contractors_reported": ccure_active_obj.get("ccure_active_contractors_reported")
        },
        "averages": averages_obj
    }
    return resp

# ---------- build a verify-compatible summary from mapped payload -----------
def _build_verify_like_summary_from_mapped(mapped: Dict[str, Any], include_raw: bool = False) -> Dict[str, Any]:
    """
    Return object shaped exactly like /ccure/verify response so frontend can use a single endpoint.
    Produces:
      - date
      - ccure_reported (employees, contractors, total_reported)
      - headcount_attendance_summary
      - live_headcount_region_clients
      - percentages_vs_ccure
      - averages (merged)
      - notes
      - optionally raw = mapped (detailed debug)
      - headcount_details, live_headcount_details, ccure_active for convenience
    """
    def to_int(v):
        try:
            return None if v is None else int(v)
        except Exception:
            try:
                return int(float(v))
            except Exception:
                return None

    cc = mapped.get("ccure_active", {}) or {}
    head = mapped.get("headcount", {}) or {}
    live_head = mapped.get("live_headcount", {}) or {}
    averages = mapped.get("averages", {}) or {}

    # ccure_reported block (employees/contractors/total_reported)
    cc_emp = to_int(cc.get("ccure_active_employees_reported") or cc.get("active_employees"))
    cc_con = to_int(cc.get("ccure_active_contractors_reported") or cc.get("active_contractors"))

    # headcount attendance summary (from AttendanceSummary / union)
    head_total = to_int(head.get("total_visited_today") or mapped.get("live_today", {}).get("total_from_details"))
    head_emp = to_int(head.get("employee") or mapped.get("live_today", {}).get("employee"))
    head_con = to_int(head.get("contractor") or mapped.get("live_today", {}).get("contractor"))

    # live headcount region clients (prefer live_headcount -> live_today)
    live_total = to_int(live_head.get("currently_present_total") or mapped.get("live_today", {}).get("total_reported"))
    live_emp = to_int(live_head.get("employee") or mapped.get("live_today", {}).get("employee"))
    live_con = to_int(live_head.get("contractor") or mapped.get("live_today", {}).get("contractor"))

    history_emp_avg = averages.get("history_avg_employee_last_7_days")
    history_con_avg = averages.get("history_avg_contractor_last_7_days")
    history_overall_avg = averages.get("history_avg_overall_last_7_days")

    def pct(n, d):
        try:
            if n is None or d is None:
                return None
            if float(d) == 0:
                return None
            return round((float(n) / float(d)) * 100.0, 2)
        except Exception:
            return None

    summary = {
        "date": mapped.get("date"),
        "ccure_reported": {
            "employees": cc_emp,
            "contractors": cc_con,
            "total_reported": (cc_emp + cc_con) if (cc_emp is not None and cc_con is not None) else None
        },
        "headcount_attendance_summary": {
            "total_visited_today": head_total,
            "employee": head_emp,
            "contractor": head_con,
            # by_location intentionally omitted here to mirror /ccure/verify top-level shape; details in 'raw' or headcount_details
        },
        "live_headcount_region_clients": {
            "currently_present_total": live_total,
            "employee": live_emp,
            "contractor": live_con,
        },
        "percentages_vs_ccure": {
            "head_employee_pct_vs_ccure_today": pct(head_emp, cc_emp),
            "head_contractor_pct_vs_ccure_today": pct(head_con, cc_con),
            "head_overall_pct_vs_ccure_today": pct(head_total, (cc_emp + cc_con) if (cc_emp is not None and cc_con is not None) else None),
            "live_employee_pct_vs_ccure_today": pct(live_emp, cc_emp),
            "live_contractor_pct_vs_ccure_today": pct(live_con, cc_con),
            "live_overall_pct_vs_ccure_today": pct(live_total, (cc_emp + cc_con) if (cc_emp is not None and cc_con is not None) else None),
            "history_employee_pct_vs_ccure": pct(history_emp_avg, cc_emp),
            "history_contractor_pct_vs_ccure": pct(history_con_avg, cc_con),
            "history_overall_pct_vs_ccure": pct(history_overall_avg, (cc_emp + cc_con) if (cc_emp is not None and cc_con is not None) else None)
        },
        "averages": {
            # Surface the core expected average fields and keep the rest verbatim
            "history_avg_employee_last_7_days": history_emp_avg,
            "history_avg_contractor_last_7_days": history_con_avg,
            "history_avg_overall_last_7_days": history_overall_avg,
            "avg_headcount_last_7_days_db": averages.get("avg_headcount_last_7_days") or averages.get("avg_headcount_last_7_days_db"),
            "avg_headcount_per_site_last_7_days": averages.get("avg_headcount_per_site_last_7_days"),
            # include compatibility keys (employee_pct, contractor_pct, overall_pct)
            "employee_pct": averages.get("employee_pct"),
            "contractor_pct": averages.get("contractor_pct"),
            "overall_pct": averages.get("overall_pct"),
            # include the rest of averages payload so frontend can use any additional keys
            **({k: v for k, v in averages.items() if k not in (
                "history_avg_employee_last_7_days",
                "history_avg_contractor_last_7_days",
                "history_avg_overall_last_7_days",
                "avg_headcount_last_7_days",
                "avg_headcount_last_7_days_db",
                "avg_headcount_per_site_last_7_days",
                "employee_pct","contractor_pct","overall_pct"
            )})
        },
        "notes": mapped.get("notes")
    }

    # additional convenience blocks for frontend parity with the 'raw' verify response
    summary["headcount_details"] = {
        "total_visited_today": head_total,
        "employee": head_emp,
        "contractor": head_con,
        "by_location": head.get("by_location") if isinstance(head.get("by_location"), dict) else {}
    }
    summary["live_headcount_details"] = {
        "currently_present_total": live_total,
        "employee": live_emp,
        "contractor": live_con,
        "by_location": live_head.get("by_location") if isinstance(live_head.get("by_location"), dict) else {}
    }

    summary["ccure_active"] = {
        "active_employees": cc.get("active_employees") or cc.get("ccure_active_employees_reported"),
        "active_contractors": cc.get("active_contractors") or cc.get("ccure_active_contractors_reported"),
        "ccure_active_employees_reported": cc.get("ccure_active_employees_reported"),
        "ccure_active_contractors_reported": cc.get("ccure_active_contractors_reported")
    }

    if include_raw:
        summary["raw"] = mapped

    return summary

# ---------- /ccure/verify (single canonical endpoint frontend will use) -----
@app.get("/ccure/verify")
def ccure_verify(
    raw: bool = Query(False, description="if true, include the raw compute payload for debugging"),
    start_date: Optional[str] = Query(None, description="YYYY-MM-DD start date (inclusive)"),
    end_date: Optional[str] = Query(None, description="YYYY-MM-DD end date (inclusive)")
):
    """
    Synchronous verification endpoint. Prefer compute_visit_averages() (synchronous call).
    If compute raises or fails, fall back to build_ccure_averages() so output shape remains consistent.
    """
    try:
        detailed = None
        try:
            from ccure_compare_service import compute_visit_averages
            detailed = compute_visit_averages(start_date, end_date, timeout=REGION_TIMEOUT_SECONDS)
        except Exception:
            logger.exception("compute_visit_averages() failed inside /ccure/verify; falling back")
            detailed = None

        if isinstance(detailed, dict):
            mapped = _map_detailed_to_resp(detailed)
            summary = _build_verify_like_summary_from_mapped(mapped, include_raw=raw)
            if raw and isinstance(detailed, dict):
                # For verify endpoint the raw block might be the more detailed 'detailed' payload
                summary["raw"] = detailed
            return JSONResponse(summary)
        else:
            fallback = build_ccure_averages(start_date, end_date)
            mapped_fallback = {
                "date": fallback.get("date"),
                "notes": fallback.get("notes"),
                "live_today": fallback.get("live_today", {}),
                "headcount": {
                    "total_visited_today": fallback.get("live_today", {}).get("total_from_details") or fallback.get("live_today", {}).get("total_reported"),
                    "employee": fallback.get("live_today", {}).get("employee"),
                    "contractor": fallback.get("live_today", {}).get("contractor"),
                    "by_location": {}
                },
                "live_headcount": {
                    "currently_present_total": fallback.get("live_today", {}).get("total_reported"),
                    "employee": fallback.get("live_today", {}).get("employee"),
                    "contractor": fallback.get("live_today", {}).get("contractor"),
                    "by_location": {}
                },
                "ccure_active": fallback.get("ccure_active", {}),
                "averages": fallback.get("averages", {})
            }



            summary = _build_verify_like_summary_from_mapped(mapped_fallback, include_raw=raw)
            if raw:
                summary["raw"] = mapped_fallback
       
            return JSONResponse(summary)
    except Exception as e:
        logger.exception("ccure_verify failed")
        raise HTTPException(status_code=500, detail=f"ccure verify error: {e}")
    
    

# ---------- unchanged remaining endpoints (compare, report) -----------------
@app.get("/ccure/compare")
def ccure_compare(
    mode: str = Query("full", description="full or stats"),
    stats_detail: str = Query("ActiveProfiles", description="when mode=stats use this"),
    limit_list: int = Query(200, ge=1, le=5000, description="max rows returned in list samples"),
    export: bool = Query(False, description="if true, writes Excel report to server and returns report_path")
):
    try:
        from ccure_compare_service import compare_ccure_vs_sheets
    except Exception as e:
        logger.exception("ccure_compare_service import failed")
        raise HTTPException(status_code=500, detail=f"compare service unavailable: {e}")
    res = compare_ccure_vs_sheets(mode=mode, stats_detail=stats_detail, limit_list=limit_list, export=export)
    if not isinstance(res, dict):
        return JSONResponse({"error": "compare service returned unexpected result"}, status_code=500)
    return JSONResponse(res)

@app.get("/ccure/report/{filename}")
def ccure_report_download(filename: str):
    try:
        safe_name = Path(filename).name
        full = Path(OUTPUT_DIR) / safe_name
        if not full.exists() or not full.is_file():
            raise HTTPException(status_code=404, detail="Report not found")
        return FileResponse(str(full),
                            media_type="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
                            filename=safe_name)
    except HTTPException:
        raise
    except Exception as e:
        logger.exception("Failed to serve report")
        raise HTTPException(status_code=500, detail=f"Failed to serve report: {e}")

# Upload / ingest endpoints left unchanged; they call build_ccure_averages which now uses AttendanceSummary only
# End of file





