# ccure_client.py
import requests
import math
from requests.exceptions import RequestException

BASE = "http://10.199.22.57:5001"
DEFAULT_TIMEOUT = 10

# Set auth headers here if CCure requires them:
HEADERS = {
    # "Authorization": "Bearer <TOKEN>",
    "Accept": "application/json"
}


def _safe_get(path, params=None, timeout=DEFAULT_TIMEOUT):
    url = BASE.rstrip("/") + path
    try:
        r = requests.get(url, params=params, headers=HEADERS, timeout=timeout)
        r.raise_for_status()
        return r.json()
    except RequestException as e:
        # caller handles None
        print(f"[ccure_client] request failed {url} params={params} -> {e}")
        return None
    except ValueError:
        print(f"[ccure_client] response JSON decode error for {url}")
        return None


def fetch_all_employees_full():
    """
    Try to fetch a full dump from /api/employees.
    Returns list of dicts or None on failure.
    """
    return _safe_get("/api/employees")


def fetch_stats_page(detail, page=1, limit=500):
    """
    One page of /api/stats?details=detail&page=page&limit=limit
    Returns page dict or None.
    """
    params = {"details": detail, "page": page, "limit": limit}
    return _safe_get("/api/stats", params=params)


def fetch_all_stats(detail, limit=1000):
    """
    Iterate pages for /api/stats detail and return combined data list.
    Returns list or None.
    """
    first = fetch_stats_page(detail, page=1, limit=limit)
    if not first:
        return None
    data = first.get("data") or []
    total = int(first.get("total") or len(data) or 0)
    if total <= len(data):
        return data
    pages = int(math.ceil(total / float(limit)))
    for p in range(2, pages + 1):
        page_res = fetch_stats_page(detail, page=p, limit=limit)
        if not page_res:
            # stop early on error
            break
        data.extend(page_res.get("data") or [])
    return data


def get_global_stats():
    """
    Best-effort summary of CCure totals:
    - Try /api/employees full dump first
    - else try /api/stats endpoints
    Returns dict or None
    """
    full = fetch_all_employees_full()
    if isinstance(full, list):
        total = len(full)
        active_profiles = sum(1 for r in full if (r.get("Employee_Status") or "").lower() == "active")
        active_emps = sum(1 for r in full if (r.get("PersonnelType") or "").lower().startswith("employee") and (r.get("Employee_Status") or "").lower() == "active")
        active_contractors = sum(1 for r in full if (r.get("PersonnelType") or "").lower().startswith("contractor") and (r.get("Employee_Status") or "").lower() == "active")
        terminated = sum(1 for r in full if (r.get("Employee_Status") or "").lower() in ("deactive", "deactivated", "inactive", "terminated"))
        return {
            "TotalProfiles": total,
            "ActiveProfiles": active_profiles,
            "ActiveEmployees": active_emps,
            "ActiveContractors": active_contractors,
            "TerminatedProfiles": terminated
        }

    # fallback: try stats endpoints individually
    details = ["ActiveProfiles", "ActiveEmployees", "ActiveContractors",
               "TerminatedProfiles", "TerminatedEmployees", "TerminatedContractors"]
    out = {}
    for d in details:
        resp = fetch_stats_page(d, page=1, limit=1)
        if isinstance(resp, dict) and 'total' in resp:
            out[d] = resp['total']
    if out:
        return {
            "TotalProfiles": out.get("TotalProfiles"),
            "ActiveProfiles": out.get("ActiveProfiles"),
            "ActiveEmployees": out.get("ActiveEmployees"),
            "ActiveContractors": out.get("ActiveContractors"),
            "TerminatedProfiles": out.get("TerminatedProfiles"),
            "TerminatedEmployees": out.get("TerminatedEmployees"),
            "TerminatedContractors": out.get("TerminatedContractors"),
        }
    return None






# ccure_compare_service.py
import pandas as pd
from ccure_client import fetch_all_employees_full, fetch_all_stats, get_global_stats
from db import SessionLocal
from models import ActiveEmployee, ActiveContractor
from settings import OUTPUT_DIR
from pathlib import Path
import re
import uuid
import traceback

OUTPUT_DIR = Path(OUTPUT_DIR)
OUTPUT_DIR.mkdir(parents=True, exist_ok=True)


def _normalize_empid(e):
    if e is None:
        return None
    s = str(e).strip()
    if s == "" or s.lower() in ("nan", "none", "null"):
        return None
    return s


def _normalize_card(s):
    if s is None:
        return None
    ss = str(s).strip()
    if ss == "":
        return None
    digits = re.sub(r'\D+', '', ss)
    if not digits:
        return None
    return digits.lstrip('0') or digits


def _load_local_active():
    """
    Return (emp_df, cont_df) as pandas DataFrames built from DB tables.
    """
    with SessionLocal() as db:
        emps = db.query(ActiveEmployee).all()
        conts = db.query(ActiveContractor).all()
        emp_rows = []
        for e in emps:
            emp_rows.append({
                "employee_id": _normalize_empid(e.employee_id),
                "full_name": e.full_name,
                "location_city": e.location_city,
                "status": e.current_status,
                "raw_row": e.raw_row
            })
        cont_rows = []
        for c in conts:
            cont_rows.append({
                "worker_system_id": _normalize_empid(c.worker_system_id),
                "ipass_id": _normalize_empid(c.ipass_id),
                "full_name": c.full_name,
                "location": c.location,
                "status": c.status,
                "raw_row": c.raw_row
            })
    emp_df = pd.DataFrame(emp_rows)
    cont_df = pd.DataFrame(cont_rows)
    return emp_df, cont_df


def _ccure_fetch_all(mode="full", stats_detail="ActiveProfiles"):
    """
    mode: 'full' tries /api/employees then fallback
          'stats' uses /api/stats?details=stats_detail
    returns list-of-dicts or empty list
    """
    if mode == "stats":
        lst = fetch_all_stats(stats_detail, limit=1000)
        return lst or []
    # mode full
    lst = fetch_all_employees_full()
    if lst is not None:
        return lst
    # fallback to stats
    lst = fetch_all_stats(stats_detail, limit=1000)
    return lst or []


def compare_ccure_vs_sheets(mode="full", stats_detail="ActiveProfiles", limit_list=200, export=False):
    """
    Compare CCure -> local active sheets.
    Returns dictionary (JSON serializable).
    If export=True writes report to OUTPUT_DIR and returns 'report_path' with file name.
    limit_list limits array sizes sent in JSON for safety.
    """
    try:
        ccure_list = _ccure_fetch_all(mode=mode, stats_detail=stats_detail)
        ccure_df = pd.DataFrame(ccure_list) if ccure_list else pd.DataFrame()
        # normalize EmployeeID column name (if exists)
        if not ccure_df.empty and 'EmployeeID' in ccure_df.columns:
            ccure_df['EmployeeID_norm'] = ccure_df['EmployeeID'].astype(str).str.strip().replace({'nan': None})
        else:
            ccure_df['EmployeeID_norm'] = None

        emp_df, cont_df = _load_local_active()

        # sets (only non-null)
        ccure_emp_set = set(ccure_df[ccure_df['EmployeeID_norm'].notna()]['EmployeeID_norm'].unique())
        local_emp_set = set(emp_df[emp_df['employee_id'].notna()]['employee_id'].unique())

        # contractors
        local_cont_set = set(cont_df['worker_system_id'].dropna().unique())
        ccure_cont_df = ccure_df[ccure_df.get('PersonnelType', '').apply(lambda x: (str(x).lower().find('contractor')!=-1) if pd.notna(x) else False)]
        ccure_cont_set = set(ccure_cont_df['EmployeeID_norm'].dropna().unique())

        in_ccure_not_local = sorted(list(ccure_emp_set - local_emp_set))
        in_local_not_ccure = sorted(list(local_emp_set - ccure_emp_set))

        in_ccure_cont_not_local = sorted(list(ccure_cont_set - local_cont_set))
        in_local_cont_not_ccure = sorted(list(local_cont_set - ccure_cont_set))

        # prepare sample rows (limited)
        rows_ccure_only = ccure_df[ccure_df['EmployeeID_norm'].isin(in_ccure_not_local)].head(limit_list).to_dict(orient='records') if not ccure_df.empty else []
        rows_local_only = emp_df[emp_df['employee_id'].isin(in_local_not_ccure)].head(limit_list).to_dict(orient='records') if not emp_df.empty else []
        rows_ccure_cont_only = ccure_cont_df[ccure_cont_df['EmployeeID_norm'].isin(in_ccure_cont_not_local)].head(limit_list).to_dict(orient='records') if not ccure_cont_df.empty else []
        rows_local_cont_only = cont_df[cont_df['worker_system_id'].isin(in_local_cont_not_ccure)].head(limit_list).to_dict(orient='records') if not cont_df.empty else []

        # summary counts
        ccure_summary = get_global_stats() or {}
        summary = {
            "ccure_total_profiles": int(ccure_summary.get("TotalProfiles") or (len(ccure_df) if not ccure_df.empty else 0)),
            "ccure_active_profiles": int(ccure_summary.get("ActiveProfiles") or None) if ccure_summary else None,
            "ccure_active_employees": int(ccure_summary.get("ActiveEmployees") or None) if ccure_summary else None,
            "ccure_active_contractors": int(ccure_summary.get("ActiveContractors") or None) if ccure_summary else None,
            "local_active_employees": int(len(emp_df)),
            "local_active_contractors": int(len(cont_df)),
            "delta_employees": (int(ccure_summary.get("ActiveEmployees")) - len(emp_df)) if ccure_summary and isinstance(ccure_summary.get("ActiveEmployees"), int) else None,
            "delta_contractors": (int(ccure_summary.get("ActiveContractors")) - len(cont_df)) if ccure_summary and isinstance(ccure_summary.get("ActiveContractors"), int) else None
        }

        result = {
            "summary": summary,
            "lists": {
                "in_ccure_not_local_sample": rows_ccure_only,
                "in_local_not_ccure_sample": rows_local_only,
                "in_ccure_contractors_not_local_sample": rows_ccure_cont_only,
                "in_local_contractors_not_ccure_sample": rows_local_cont_only,
            },
            "counts": {
                "in_ccure_not_local_count": len(in_ccure_not_local),
                "in_local_not_ccure_count": len(in_local_not_ccure),
                "in_ccure_contractors_not_local_count": len(in_ccure_cont_not_local),
                "in_local_contractors_not_ccure_count": len(in_local_cont_not_ccure),
            }
        }

        report_path = None
        if export:
            # write workbook
            fname = f"ccure_vs_local_{uuid.uuid4().hex[:8]}.xlsx"
            fp = OUTPUT_DIR / fname
            try:
                with pd.ExcelWriter(fp, engine="xlsxwriter") as writer:
                    if not ccure_df.empty:
                        ccure_df.to_excel(writer, sheet_name="ccure_all", index=False)
                    if not emp_df.empty:
                        emp_df.to_excel(writer, sheet_name="local_employees", index=False)
                    if not cont_df.empty:
                        cont_df.to_excel(writer, sheet_name="local_contractors", index=False)
                    pd.DataFrame(result['counts'], index=[0]).to_excel(writer, sheet_name="counts", index=False)
                    pd.DataFrame([summary]).to_excel(writer, sheet_name="summary", index=False)
                    # detailed lists
                    pd.DataFrame(rows_ccure_only).to_excel(writer, sheet_name="ccure_only_sample", index=False)
                    pd.DataFrame(rows_local_only).to_excel(writer, sheet_name="local_only_sample", index=False)
                report_path = str(fp.name)
                result['report_path'] = report_path
            except Exception:
                print("[ccure_compare_service] failed to write report:", traceback.format_exc())
                result['report_error'] = "report_write_failed"

        return result

    except Exception as e:
        print("[ccure_compare_service] error:", e, traceback.format_exc())
        return {"error": "internal_error", "message": str(e)}






from fastapi.responses import FileResponse
from fastapi import Query



# GET /ccure/compare
@app.get("/ccure/compare")
def ccure_compare(
    mode: str = Query("full", description="full or stats"),
    stats_detail: str = Query("ActiveProfiles", description="when mode=stats use this"),
    limit_list: int = Query(200, ge=10, le=5000, description="max rows returned in list samples"),
    export: bool = Query(False, description="if true, writes Excel report to server and returns report_path")
):
    """
    Compare CCure profiles with local ActiveEmployee & ActiveContractor sheets.
    mode: 'full' (try /api/employees) or 'stats' (use /api/stats?details=...)
    Query params: mode, stats_detail, limit_list, export
    """
    try:
        from ccure_compare_service import compare_ccure_vs_sheets
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"compare service unavailable: {e}")
    res = compare_ccure_vs_sheets(mode=mode, stats_detail=stats_detail, limit_list=limit_list, export=export)
    return JSONResponse(res)


# GET /ccure/report/{filename}  -> download generated XLSX
@app.get("/ccure/report/{filename}")
def ccure_report_download(filename: str):
    """
    Download generated report by filename (returned as 'report_path' from /ccure/compare?export=true).
    Only serves files inside OUTPUT_DIR.
    """
    safe_name = Path(filename).name  # prevent path traversal
    full = OUTPUT_DIR / safe_name
    if not full.exists() or not full.is_file():
        raise HTTPException(status_code=404, detail="Report not found")
    return FileResponse(str(full), media_type="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet", filename=safe_name)






uvicorn app:app --reload --host 0.0.0.0 --port 8000


curl "http://127.0.0.1:8000/ccure/compare?mode=full&limit_list=100"


curl "http://127.0.0.1:8000/ccure/compare?mode=full&export=true"



curl -O "http://127.0.0.1:8000/ccure/report/ccure_vs_local_xxxxxxxx.xlsx"



pip install requests pandas XlsxWriter










Initailly read below file carefully and fix only ccure data vs sheet data comparision and gave me API for testing carefully think long

C:\Users\W0024618\Desktop\global-page\backend\attendance-analytics\ccure_client.py

# ccure_fetch.py
import requests
import math
import pandas as pd
from requests.exceptions import RequestException

BASE = "http://10.199.22.57:5001"
DEFAULT_TIMEOUT = 10

# If CCure needs auth, set HEADERS accordingly:
HEADERS = {
    # 'Authorization': 'Bearer <token>',
    'Accept': 'application/json'
}

def fetch_all_employees_full():
    """Fetch full list from /api/employees (may return a large list). Returns list or None."""
    try:
        r = requests.get(f"{BASE}/api/employees", headers=HEADERS, timeout=DEFAULT_TIMEOUT)
        r.raise_for_status()
        return r.json()  # expects a list
    except RequestException as e:
        print("ccure: full fetch failed:", e)
        return None

def fetch_stats_page(detail, page=1, limit=500):
    """
    Fetch one page from /api/stats?details=detail&page=page&limit=limit
    Returns dict or None.
    """
    try:
        params = {"details": detail, "page": page, "limit": limit}
        r = requests.get(f"{BASE}/api/stats", params=params, headers=HEADERS, timeout=DEFAULT_TIMEOUT)
        r.raise_for_status()
        return r.json()
    except RequestException as e:
        print(f"ccure: stats page error detail={detail} page={page}:", e)
        return None

def fetch_all_stats(detail, limit=1000):
    """
    Iterate pages and return full list for a given 'details' filter.
    """
    first = fetch_stats_page(detail, page=1, limit=limit)
    if not first:
        return None
    total = first.get("total", 0)
    data = first.get("data", []) or []
    if total <= len(data):
        return data
    pages = math.ceil(total / limit)
    for p in range(2, pages + 1):
        page_res = fetch_stats_page(detail, page=p, limit=limit)
        if not page_res:
            break
        data.extend(page_res.get("data", []) or [])
    return data

def ccure_to_dataframe(list_of_dicts):
    """Return DataFrame normalised with key columns."""
    if not list_of_dicts:
        return pd.DataFrame()
    df = pd.DataFrame(list_of_dicts)
    # standardize column names if needed
    df.columns = [c.strip() for c in df.columns]
    # ensure EmployeeID exists and is string
    if 'EmployeeID' in df.columns:
        df['EmployeeID'] = df['EmployeeID'].astype(str).str.strip().replace({'nan': None})
    else:
        df['EmployeeID'] = None
    return df



C:\Users\W0024618\Desktop\global-page\backend\attendance-analytics\compare_ccure_with_sheets.py


# compare_ccure_with_sheets.py
import pandas as pd
from ccure_fetch import fetch_all_employees_full, fetch_all_stats, ccure_to_dataframe
from db import SessionLocal
from models import ActiveEmployee, ActiveContractor
from pathlib import Path

OUT_DIR = Path("data/outputs")
OUT_DIR.mkdir(parents=True, exist_ok=True)

def normalize_empid(e):
    if e is None:
        return None
    s = str(e).strip()
    if s == "" or s.lower() in ("nan","none","null"):
        return None
    return s

def get_local_active_sets():
    with SessionLocal() as db:
        emps = db.query(ActiveEmployee).all()
        conts = db.query(ActiveContractor).all()

        emp_df = pd.DataFrame([{
            "employee_id": normalize_empid(e.employee_id),
            "full_name": e.full_name,
            "location_city": e.location_city,
            "status": e.current_status
        } for e in emps])

        cont_df = pd.DataFrame([{
            "worker_system_id": normalize_empid(c.worker_system_id),
            "ipass_id": normalize_empid(c.ipass_id),
            "full_name": c.full_name,
            "location": c.location,
            "status": c.status
        } for c in conts])
    return emp_df, cont_df

def compare():
    # 1) fetch ccure master
    ccure_list = fetch_all_employees_full()
    if ccure_list is None:
        # fallback: try fetching ActiveProfiles
        ccure_list = fetch_all_stats("ActiveProfiles", limit=1000)
    ccure_df = ccure_to_dataframe(ccure_list)
    # normalize employee id column name
    ccure_df['EmployeeID_norm'] = ccure_df['EmployeeID'].apply(normalize_empid)

    # 2) local active sets
    emp_df, cont_df = get_local_active_sets()

    # 3) create sets for comparison
    ccure_emp_set = set(ccure_df[ccure_df['EmployeeID_norm'].notna()]['EmployeeID_norm'].unique())
    local_emp_set = set(emp_df[emp_df['employee_id'].notna()]['employee_id'].unique())
    # contractor IDs from CCure sometimes prefixed with W...
    local_cont_set = set(cont_df['worker_system_id'].dropna().unique())
    ccure_contractors = ccure_df[ccure_df['PersonnelType'].str.lower().str.contains('contractor', na=False)]
    ccure_cont_set = set(ccure_contractors['EmployeeID_norm'].dropna().unique())

    # 4) differences
    in_ccure_not_local = sorted(list(ccure_emp_set - local_emp_set))
    in_local_not_ccure = sorted(list(local_emp_set - ccure_emp_set))

    in_ccure_cont_not_local = sorted(list(ccure_cont_set - local_cont_set))
    in_local_cont_not_ccure = sorted(list(local_cont_set - ccure_cont_set))

    # 5) detailed rows for export
    rows_ccure_only = ccure_df[ccure_df['EmployeeID_norm'].isin(in_ccure_not_local)]
    rows_local_only = emp_df[emp_df['employee_id'].isin(in_local_not_ccure)]

    # 6) summary counts
    summary = {
        "ccure_total_profiles": len(ccure_df),
        "ccure_active_profiles": int(ccure_df[ccure_df['Employee_Status'].str.lower().eq('active')].shape[0]) if 'Employee_Status' in ccure_df.columns else None,
        "local_active_employees": emp_df.shape[0],
        "local_active_contractors": cont_df.shape[0],
        "ccure_active_employees_count": int(ccure_df[ccure_df['PersonnelType'].str.contains('employee', na=False).sum()) if 'PersonnelType' in ccure_df.columns else None
    }

    report_path = OUT_DIR / f"ccure_vs_local_report_{pd.Timestamp.now().strftime('%Y%m%d_%H%M%S')}.xlsx"
    with pd.ExcelWriter(report_path, engine="xlsxwriter") as w:
        rows_ccure_only.to_excel(w, sheet_name="ccure_only_profiles", index=False)
        rows_local_only.to_excel(w, sheet_name="local_only_profiles", index=False)
        emp_df.to_excel(w, sheet_name="local_employees", index=False)
        cont_df.to_excel(w, sheet_name="local_contractors", index=False)
        ccure_df.to_excel(w, sheet_name="ccure_all", index=False)
        pd.DataFrame([summary]).to_excel(w, sheet_name="summary", index=False)

    print("Comparison finished.")
    print("Summary:", summary)
    print("Report saved to:", report_path)
    return {
        "in_ccure_not_local_count": len(in_ccure_not_local),
        "in_local_not_ccure_count": len(in_local_not_ccure),
        "report": str(report_path),
        "details": {
            "in_ccure_not_local": in_ccure_not_local[:200],
            "in_local_not_ccure": in_local_not_ccure[:200]
        }
    }

if __name__ == "__main__":
    r = compare()
    print(r)






# ingest_excel.py
import pandas as pd
from datetime import datetime
from sqlalchemy.exc import IntegrityError
from db import SessionLocal, engine
from models import Base, ActiveEmployee, ActiveContractor
from settings import UPLOAD_DIR
import uuid, os

# --- database setup: do NOT run create_all at import time ---
def init_db():
    """
    Create DB tables if they do not exist.
    Call this manually only when you want to initialize/repair the DB:
      python -c "from ingest_excel import init_db; init_db()"
    """
    from db import engine
    from models import Base
    Base.metadata.create_all(bind=engine)

def _first_present(row, candidates):
    for c in candidates:
        v = row.get(c)
        if v is not None and str(v).strip() != "":
            return v
    return None

def ingest_employee_excel(path, uploaded_by="system"):
    df = pd.read_excel(path, sheet_name=0, dtype=str)
    df.columns = [c.strip() for c in df.columns]
    # robust mapping keys
    with SessionLocal() as db:
        for _, row in df.iterrows():
            emp_id = _first_present(row, ['Employee ID','EmployeeID','Employee Id','EmpID','Emp Id'])
            if emp_id:
                emp_id = str(emp_id).strip()
            if not emp_id:
                # skip rows without an employee id
                continue
            full_name = _first_present(row, ['Full Name','FullName','EmpName','Name']) or f"{row.get('First Name','') or ''} {row.get('Last Name','') or ''}".strip()
            # robust current_status detection
            status_candidates = ['Current Status','Status','Employee Status','Employee_Status','Status (Current)','CurrentStatus']
            current_status = _first_present(row, status_candidates)
            email = _first_present(row, ["Employee's Email",'Email','Email Address'])
            location_city = _first_present(row, ['Location City','Location','Location Description','City'])
            rec = ActiveEmployee(
                employee_id=emp_id,
                full_name=full_name,
                email=email,
                location_city=location_city,
                location_desc=row.get('Location Description'),
                current_status=current_status,
                raw_row=row.to_dict(),
                uploaded_at=datetime.utcnow()
            )
            try:
                db.merge(rec)  # upsert
                db.commit()
            except IntegrityError:
                db.rollback()
            except Exception:
                db.rollback()

def ingest_contractor_excel(path):
    df = pd.read_excel(path, sheet_name=0, dtype=str)
    df.columns = [c.strip() for c in df.columns]
    with SessionLocal() as db:
        for _, row in df.iterrows():
            wsid = _first_present(row, ['Worker System Id','Worker System ID','Worker ID','WorkerSystemId'])
            if wsid:
                wsid = str(wsid).strip()
            if not wsid:
                continue
            ipass = _first_present(row, ['iPass ID','"W" iPass ID','IPassID','iPassID','Ipass ID'])
            full_name = _first_present(row, ['Full Name','FullName','Name'])
            rec = ActiveContractor(
                worker_system_id=wsid,
                ipass_id=ipass,
                full_name=full_name,
                vendor=_first_present(row, ['Vendor Company Name','Vendor']),
                location=_first_present(row, ['Worker Location','Location']),
                status=_first_present(row, ['Status','Current Status']),
                raw_row=row.to_dict(),
                uploaded_at=datetime.utcnow()
            )
            try:
                db.merge(rec)
                db.commit()
            except IntegrityError:
                db.rollback()
            except Exception:
                db.rollback()

if __name__ == "__main__":
    # ingestion convenience: read all uploaded files
    for f in os.listdir(UPLOAD_DIR):
        p = UPLOAD_DIR / f
        if 'contractor' in f.lower() or 'contractor' in str(p).lower():
            ingest_contractor_excel(p)
        else:
            ingest_employee_excel(p)
    print("Ingestion completed.")





# app.py
from fastapi import FastAPI, UploadFile, File, HTTPException, Request, Body
from fastapi.responses import JSONResponse
import shutil, uuid, json
from settings import UPLOAD_DIR, OUTPUT_DIR
import os

app = FastAPI(title="Attendance Analytics")

@app.post("/upload/active-employees")
async def upload_active_employees(file: UploadFile = File(...)):
    if not file.filename.endswith(('.xls', '.xlsx')):
        raise HTTPException(400, "Please upload an Excel file")
    dest = UPLOAD_DIR / f"{uuid.uuid4().hex}_{file.filename}"
    with open(dest, "wb") as buffer:
        shutil.copyfileobj(file.file, buffer)
    try:
        from ingest_excel import ingest_employee_excel
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"ingest_excel import failed: {e}")
    ingest_employee_excel(dest)
    return {"status":"ok", "path": str(dest)}

@app.post("/upload/active-contractors")
async def upload_active_contractors(file: UploadFile = File(...)):
    if not file.filename.endswith(('.xls', '.xlsx')):
        raise HTTPException(400, "Please upload an Excel file")
    dest = UPLOAD_DIR / f"{uuid.uuid4().hex}_{file.filename}"
    with open(dest, "wb") as buffer:
        shutil.copyfileobj(file.file, buffer)
    try:
        from ingest_excel import ingest_contractor_excel
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"ingest_excel import failed: {e}")
    ingest_contractor_excel(dest)
    return {"status":"ok", "path": str(dest)}

@app.post("/ingest/live-details")
async def ingest_live(request: Request):
    """
    Accepts:
      - Raw JSON array in body (preferred)
      - JSON object with {"details": [...]} in body
      - multipart/form-data where a form field 'details' contains a JSON string
    """
    details = None
    # Try direct JSON
    try:
        body = await request.json()
        if isinstance(body, dict) and 'details' in body:
            details = body['details']
        else:
            details = body
    except Exception:
        # not JSON, try form
        try:
            form = await request.form()
            if 'details' in form:
                raw = form['details']
                if isinstance(raw, str):
                    details = json.loads(raw)
                else:
                    try:
                        details = json.loads((await raw.read()).decode('utf-8'))
                    except Exception:
                        details = list(form.getlist('details'))
            else:
                # attempt first field
                first = None
                for v in form.values():
                    first = v
                    break
                if isinstance(first, str):
                    details = json.loads(first)
                else:
                    raise HTTPException(status_code=400, detail="No JSON payload found")
        except Exception as e:
            raise HTTPException(status_code=400, detail=f"Could not parse request body as JSON or form: {e}")

    if not isinstance(details, (list, tuple)):
        raise HTTPException(status_code=400, detail="Expected top-level array (JSON list) of detail objects")

    try:
        from compare_service import ingest_live_details_list
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"compare_service import failed: {e}")

    try:
        res = ingest_live_details_list(details)
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Failed to ingest details: {e}")

    if isinstance(res, dict):
        return {"status": "ok", **res}
    return {"status": "ok", "inserted": len(details)}


@app.get("/ingest/fetch-all")
def fetch_all_and_ingest():
    try:
        import region_clients
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"region_clients unavailable: {e}")

    details = region_clients.fetch_all_details()
    if not isinstance(details, list):
        raise HTTPException(status_code=500, detail="Unexpected data from region_clients.fetch_all_details")

    try:
        from compare_service import ingest_live_details_list
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"compare_service import failed: {e}")

    res = ingest_live_details_list(details)
    if isinstance(res, dict):
        return {"status":"ok", **res}
    return {"status":"ok", "inserted": len(details)}


@app.get("/reports/daily/{yyyymmdd}")
def daily_report(yyyymmdd: str):
    import datetime
    try:
        dt = datetime.datetime.strptime(yyyymmdd, "%Y%m%d").date()
    except Exception:
        raise HTTPException(status_code=400, detail="Date must be in YYYYMMDD format")

    try:
        from compare_service import compute_daily_attendance, compare_with_active
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"compare_service import failed: {e}")

    # compute attendance summary (will build attendance_summary rows)
    compute_daily_attendance(dt)

    # compare vs active and CCURE
    summary = compare_with_active(dt)
    return JSONResponse(summary)


# additional endpoints to fetch CCure stats directly (optional)
@app.get("/ccure/stats")
def ccure_stats():
    try:
        import ccure_client
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"ccure_client import failed: {e}")
    try:
        stats = ccure_client.get_global_stats()
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"ccure_client.get_global_stats failed: {e}")
    return stats




