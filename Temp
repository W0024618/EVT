# ccure_compare_service.py
"""
Compare CCURE profiles/stats with local ActiveEmployee & ActiveContractor sheets.

This module is defensive:
 - does not crash on missing ccure_client or DB problems
 - returns a stable JSON structure (see below)
 - 'export' is optional (writes an xlsx when True)
"""

import os
import re
import uuid
import traceback
from datetime import datetime
from typing import List, Dict, Any, Optional

import pandas as pd

from db import SessionLocal
from models import ActiveEmployee, ActiveContractor
from settings import OUTPUT_DIR  # ensure OUTPUT_DIR exists in your settings

# ----- Normalizers -----------------------------------------------------------

def _normalize_employee_key(x) -> Optional[str]:
    if x is None:
        return None
    try:
        s = str(x).strip()
        if s == "" or s.lower() in ("nan", "none", "na", "null"):
            return None
        return s
    except Exception:
        return None

def _normalize_card_like(s) -> Optional[str]:
    if s is None:
        return None
    try:
        ss = str(s).strip()
        if ss == "":
            return None
        digits = re.sub(r'\D+', '', ss)
        if digits == "":
            return None
        # remove leading zeros for matching flexibility, keep at least one digit
        return digits.lstrip('0') or digits
    except Exception:
        return None

def _normalize_name(s) -> Optional[str]:
    if s is None:
        return None
    try:
        t = str(s).strip().lower()
        t = re.sub(r'[^\w\s]', '', t)
        t = re.sub(r'\s+', ' ', t).strip()
        return t if t else None
    except Exception:
        return None

# ----- CCURE client wrappers (best-effort) ----------------------------------

def _fetch_ccure_stats() -> Optional[Dict[str, Any]]:
    """Return ccure_client.get_global_stats() result or None."""
    try:
        import ccure_client
        if hasattr(ccure_client, "get_global_stats"):
            return ccure_client.get_global_stats()
    except Exception:
        return None
    return None

def _fetch_ccure_profiles(mode: str = "full", limit: int = 1000) -> List[Dict[str, Any]]:
    """Attempt to fetch CCURE profiles using common ccure_client method names."""
    try:
        import ccure_client
        if hasattr(ccure_client, "get_profiles"):
            return ccure_client.get_profiles(limit=limit, mode=mode) or []
        if hasattr(ccure_client, "fetch_profiles"):
            return ccure_client.fetch_profiles(limit=limit, mode=mode) or []
        if hasattr(ccure_client, "get_all_profiles"):
            return ccure_client.get_all_profiles(limit=limit) or []
    except Exception:
        return []
    return []

# ----- Helpers ---------------------------------------------------------------

def _extract_card_from_raw(raw: Any) -> Optional[str]:
    if not isinstance(raw, dict):
        return None
    keys = [
        "CardNumber","card_number","Card","Card No","CardNo","Badge","BadgeNo",
        "IPassID","iPass ID","IPASSID","Badge Number"
    ]
    for k in keys:
        v = raw.get(k)
        if v:
            c = _normalize_card_like(v)
            if c:
                return c
    # fallback: scan values for numeric-like candidate
    for v in raw.values():
        try:
            c = _normalize_card_like(v)
            if c and 3 <= len(c) <= 12:
                return c
        except Exception:
            continue
    return None

def _build_sheet_df(session) -> pd.DataFrame:
    """
    Build combined dataframe from ActiveEmployee and ActiveContractor.
    Columns: source, employee_id, full_name, full_name_norm, card_number, card_number_norm, location_city, status, raw_row
    """
    act_rows = session.query(ActiveEmployee).all()
    contr_rows = session.query(ActiveContractor).all()
    recs = []

    for e in act_rows:
        try:
            empid = _normalize_employee_key(getattr(e, "employee_id", None))
            raw_row = getattr(e, "raw_row", None) or {}
            raw_card = _extract_card_from_raw(raw_row) if isinstance(raw_row, dict) else None
            recs.append({
                "source": "employee_sheet",
                "employee_id": empid,
                "full_name": getattr(e, "full_name", None),
                "full_name_norm": _normalize_name(getattr(e, "full_name", None)),
                "card_number": raw_card,
                "card_number_norm": _normalize_card_like(raw_card),
                "location_city": getattr(e, "location_city", None),
                "status": getattr(e, "current_status", None),
                "raw_row": raw_row
            })
        except Exception:
            # don't fail building other rows
            continue

    for c in contr_rows:
        try:
            wsid = _normalize_employee_key(getattr(c, "worker_system_id", None))
            ipass = _normalize_employee_key(getattr(c, "ipass_id", None))
            primary = wsid or ipass or None
            raw_row = getattr(c, "raw_row", None) or {}
            raw_card = _extract_card_from_raw(raw_row) if isinstance(raw_row, dict) else None
            recs.append({
                "source": "contractor_sheet",
                "employee_id": primary,
                "full_name": getattr(c, "full_name", None),
                "full_name_norm": _normalize_name(getattr(c, "full_name", None)),
                "card_number": raw_card,
                "card_number_norm": _normalize_card_like(raw_card),
                "location_city": getattr(c, "location", None),
                "status": getattr(c, "status", None),
                "raw_row": raw_row
            })
        except Exception:
            continue

    df = pd.DataFrame(recs)
    # Ensure stable columns exist
    expected = ["source","employee_id","full_name","full_name_norm","card_number","card_number_norm","location_city","status","raw_row"]
    for c in expected:
        if c not in df.columns:
            df[c] = None
    return df

def _build_ccure_df(profiles: List[Dict[str, Any]]) -> pd.DataFrame:
    rows = []
    for p in profiles:
        try:
            emp = None
            for k in ("EmployeeID","employee_id","Employee Id","BadgeId","Badge"):
                if isinstance(p, dict) and p.get(k):
                    emp = p.get(k)
                    break
            name = None
            for k in ("FullName","full_name","Name","ObjectName1"):
                if isinstance(p, dict) and p.get(k):
                    name = p.get(k)
                    break
            card = None
            for k in ("CardNumber","card_number","BadgeNo","Badge","IPassID","iPass ID"):
                if isinstance(p, dict) and p.get(k):
                    card = p.get(k)
                    break
            loc = None
            for k in ("PartitionName","Partition","Region","Location","Site"):
                if isinstance(p, dict) and p.get(k):
                    loc = p.get(k)
                    break
            rows.append({
                "ccure_raw": p,
                "employee_id": _normalize_employee_key(emp),
                "full_name": name,
                "full_name_norm": _normalize_name(name),
                "card_number": _normalize_card_like(card),
                "location_city": loc
            })
        except Exception:
            continue
    df = pd.DataFrame(rows)
    expected = ["ccure_raw","employee_id","full_name","full_name_norm","card_number","location_city"]
    for c in expected:
        if c not in df.columns:
            df[c] = None
    return df

# ----- Comparison core ------------------------------------------------------

def compare_ccure_vs_sheets(mode: str = "full", stats_detail: str = "ActiveProfiles", limit_list: int = 200, export: bool = False) -> Dict[str, Any]:
    """
    Compare CCURE profiles with sheet rows and return the canonical response structure.

    Returns dict with keys:
     - ccure
     - ccure_profile_count
     - sheet_counts
     - differences
     - samples
     - report_path
    """
    # default safe response
    safe_resp = {
        "ccure": None,
        "ccure_profile_count": 0,
        "sheet_counts": {"employees": 0, "contractors": 0, "total_profiles": 0},
        "differences": {
            "in_ccure_not_in_sheet_count": 0,
            "in_sheet_not_in_ccure_count": 0,
            "ccure_active_employees": None,
            "ccure_active_contractors": None,
            "delta_employees": None,
            "delta_contractors": None
        },
        "samples": {"in_ccure_not_in_sheet": [], "in_sheet_not_in_ccure": []},
        "report_path": None
    }

    # Try/except top-level to avoid unhandled exception -> 500
    try:
        session = SessionLocal()
    except Exception as e:
        # DB session failed: return error-friendly payload
        safe_resp["error"] = f"DB session failed: {str(e)}"
        safe_resp["trace"] = traceback.format_exc()
        return safe_resp

    try:
        # Build sheet dataframe
        sheet_df = _build_sheet_df(session)
        sheet_count = int(len(sheet_df))
        sheet_emp_count = int(sheet_df[sheet_df['source'] == 'employee_sheet'].shape[0])
        sheet_contractor_count = int(sheet_df[sheet_df['source'] == 'contractor_sheet'].shape[0])

        # Fetch CCURE info (best-effort)
        ccure_stats = _fetch_ccure_stats()
        cc_profiles = []
        if mode == "full":
            cc_profiles = _fetch_ccure_profiles(mode=mode, limit=5000) or []
        else:
            cc_profiles = _fetch_ccure_profiles(mode=mode, limit=2000) or []

        cc_df = _build_ccure_df(cc_profiles)
        cc_count = int(len(cc_df))

        # Build sets for quick match checks
        sheet_emp_ids = set([_normalize_employee_key(x) for x in sheet_df['employee_id'].dropna().tolist()])
        sheet_card_ids = set([_normalize_card_like(x) for x in sheet_df['card_number'].dropna().tolist()])
        sheet_names = set([_normalize_name(x) for x in sheet_df['full_name'].dropna().tolist()])

        cc_emp_ids = set([_normalize_employee_key(x) for x in cc_df['employee_id'].dropna().tolist()])
        cc_card_ids = set([_normalize_card_like(x) for x in cc_df['card_number'].dropna().tolist()])
        cc_names = set([_normalize_name(x) for x in cc_df['full_name'].dropna().tolist()])

        # matching helpers (conservative order)
        def _match_cc_row_to_sheet(r) -> Optional[str]:
            if r.get('employee_id') and r['employee_id'] in sheet_emp_ids:
                return r['employee_id']
            if r.get('card_number') and r['card_number'] in sheet_card_ids:
                match = sheet_df[sheet_df['card_number_norm'] == r['card_number']]
                if not match.empty:
                    return match.iloc[0].get('employee_id')
            if r.get('full_name_norm') and r['full_name_norm'] in sheet_names:
                match = sheet_df[sheet_df['full_name_norm'] == r['full_name_norm']]
                if not match.empty:
                    return match.iloc[0].get('employee_id')
            return None

        def _match_sheet_row_to_cc(r) -> Optional[str]:
            if r.get('employee_id') and r['employee_id'] in cc_emp_ids:
                return r['employee_id']
            if r.get('card_number_norm') and r['card_number_norm'] in cc_card_ids:
                match = cc_df[cc_df['card_number'] == r['card_number_norm']]
                if not match.empty:
                    return match.iloc[0].get('employee_id')
            if r.get('full_name_norm') and r['full_name_norm'] in cc_names:
                match = cc_df[cc_df['full_name_norm'] == r['full_name_norm']]
                if not match.empty:
                    return match.iloc[0].get('employee_id')
            return None

        # compute missing samples
        in_ccure_not_in_sheet = []
        for _, row in cc_df.iterrows():
            try:
                matched = _match_cc_row_to_sheet(row)
                if not matched:
                    in_ccure_not_in_sheet.append({
                        "employee_id": _to_native(row.get('employee_id')),
                        "full_name": _to_native(row.get('full_name')),
                        "card_number": _to_native(row.get('card_number')),
                        "location_city": _to_native(row.get('location_city')),
                        "ccure_raw": row.get('ccure_raw')
                    })
            except Exception:
                continue

        in_sheet_not_in_ccure = []
        for _, row in sheet_df.iterrows():
            try:
                matched = _match_sheet_row_to_cc(row)
                if not matched:
                    in_sheet_not_in_ccure.append({
                        "employee_id": _to_native(row.get('employee_id')),
                        "full_name": _to_native(row.get('full_name')),
                        "card_number": _to_native(row.get('card_number')),
                        "location_city": _to_native(row.get('location_city')),
                        "source": row.get('source'),
                        "raw_row": row.get('raw_row')
                    })
            except Exception:
                continue

        missing_sample = in_ccure_not_in_sheet[:limit_list]
        extra_sample = in_sheet_not_in_ccure[:limit_list]

        # ccure stats counts (best-effort)
        cc_active_emps = None
        cc_active_contractors = None
        try:
            if isinstance(ccure_stats, dict):
                cc_active_emps = ccure_stats.get('ActiveEmployees') or ccure_stats.get('ActiveEmployeesCount') or None
                cc_active_contractors = ccure_stats.get('ActiveContractors') or ccure_stats.get('ActiveContractorsCount') or None
        except Exception:
            pass

        # build final response exactly in the requested shape
        resp = {
            "ccure": ccure_stats,
            "ccure_profile_count": int(cc_count),
            "sheet_counts": {
                "employees": int(sheet_emp_count),
                "contractors": int(sheet_contractor_count),
                "total_profiles": int(sheet_count)
            },
            "differences": {
                "in_ccure_not_in_sheet_count": int(len(in_ccure_not_in_sheet)),
                "in_sheet_not_in_ccure_count": int(len(in_sheet_not_in_ccure)),
                "ccure_active_employees": int(cc_active_emps) if isinstance(cc_active_emps, int) else cc_active_emps,
                "ccure_active_contractors": int(cc_active_contractors) if isinstance(cc_active_contractors, int) else cc_active_contractors,
                "delta_employees": (int(cc_active_emps) - int(sheet_emp_count)) if (isinstance(cc_active_emps, int) and isinstance(sheet_emp_count, int)) else None,
                "delta_contractors": (int(cc_active_contractors) - int(sheet_contractor_count)) if (isinstance(cc_active_contractors, int) and isinstance(sheet_contractor_count, int)) else None
            },
            "samples": {
                "in_ccure_not_in_sheet": missing_sample,
                "in_sheet_not_in_ccure": extra_sample
            },
            "report_path": None
        }

        # optional export
        if export:
            try:
                os.makedirs(OUTPUT_DIR, exist_ok=True)
                fname = f"ccure_compare_{datetime.utcnow().strftime('%Y%m%d_%H%M%S')}_{uuid.uuid4().hex[:6]}.xlsx"
                path = os.path.join(OUTPUT_DIR, fname)
                # write Excel workbook
                with pd.ExcelWriter(path, engine="openpyxl") as writer:
                    # safe conversions to DataFrame for writing
                    try:
                        sheet_df.to_excel(writer, sheet_name="sheet_all", index=False)
                    except Exception:
                        pd.DataFrame(sheet_df).to_excel(writer, sheet_name="sheet_all", index=False)
                    try:
                        cc_df.to_excel(writer, sheet_name="ccure_all", index=False)
                    except Exception:
                        pd.DataFrame(cc_df).to_excel(writer, sheet_name="ccure_all", index=False)
                    pd.DataFrame(missing_sample).to_excel(writer, sheet_name="in_ccure_not_in_sheet", index=False)
                    pd.DataFrame(extra_sample).to_excel(writer, sheet_name="in_sheet_not_in_ccure", index=False)
                    summary_df = pd.DataFrame([{
                        "sheet_employees": sheet_emp_count,
                        "sheet_contractors": sheet_contractor_count,
                        "sheet_total": sheet_count,
                        "ccure_profiles": cc_count,
                        "in_ccure_not_in_sheet": len(in_ccure_not_in_sheet),
                        "in_sheet_not_in_ccure": len(in_sheet_not_in_ccure)
                    }])
                    summary_df.to_excel(writer, sheet_name="summary", index=False)
                resp["report_path"] = path
            except Exception as e:
                resp["export_error"] = str(e)
                resp["export_trace"] = traceback.format_exc()

        session.close()
        return resp

    except Exception as e:
        # unexpected failure: return an error friendly response (no 500)
        try:
            session.close()
        except Exception:
            pass
        safe_resp["error"] = f"compare operation failed: {str(e)}"
        safe_resp["trace"] = traceback.format_exc()
        return safe_resp

# ----- small helper to produce JSON-safe primitives --------------------------

def _to_native(value):
    """Return JSON-serializable primitive (str/int/None) for pandas values."""
    if value is None:
        return None
    try:
        if pd.isna(value):
            return None
    except Exception:
        pass
    if isinstance(value, (int, float, str, bool)):
        return value
    try:
        if hasattr(value, "isoformat"):
            return value.isoformat()
    except Exception:
        pass
    try:
        return str(value)
    except Exception:
        return None





GET http://localhost:8000/ccure/compare?mode=full&limit_list=200&export=false









When i run this API we got internal server error ..

http://localhost:8000/ccure/compare?mode=full&limit_list=200&ex-port=false

Internal Server Error

Check below each file line by line check each file with path and fix this issue carefully ...
and share me fully updated file so i can easily swap this file 

C:\Users\W0024618\Desktop\global-page\backend\attendance-analytics\ccure_compare_service.py

# ccure_compare_service.py
"""
Compare CCURE profiles/stats with local ActiveEmployee & ActiveContractor sheets.

Usage:
    from ccure_compare_service import compare_ccure_vs_sheets
    res = compare_ccure_vs_sheets(mode="full", stats_detail="ActiveProfiles", limit_list=200, export=False)

Notes:
 - This module does NOT call any 'live summary' endpoints. It talks only to:
     - ccure_client (if available) for CCURE stats/profiles (best-effort, wrapped in try/except)
     - local DB tables ActiveEmployee and ActiveContractor
 - Export: if export=True, an xlsx file will be written to OUTPUT_DIR (settings). The returned dict includes 'report_path'.
"""

import os
import re
import uuid
import traceback
from datetime import datetime
from typing import List, Dict, Any, Optional

import pandas as pd

from db import SessionLocal
from models import ActiveEmployee, ActiveContractor
from settings import OUTPUT_DIR  # ensure OUTPUT_DIR exists in your settings

# ---------- Normalizers -------------------------------------------------------

def _normalize_employee_key(x) -> Optional[str]:
    if x is None:
        return None
    try:
        s = str(x).strip()
        if s == "" or s.lower() in ("nan", "none", "na", "null"):
            return None
        # keep as-is except trim; do not drop leading zeros here unless you want that behaviour
        return s
    except Exception:
        return None

def _normalize_card_like(s) -> Optional[str]:
    if s is None:
        return None
    try:
        ss = str(s).strip()
        if ss == "":
            return None
        digits = re.sub(r'\D+', '', ss)  # keep digits only
        if digits == "":
            return None
        # normalize by removing leading zeros for matching flexibility
        normalized = digits.lstrip('0') or digits
        return normalized
    except Exception:
        return None

def _normalize_name(s) -> Optional[str]:
    if s is None:
        return None
    try:
        t = str(s).strip().lower()
        t = re.sub(r'[^\w\s]', '', t)  # remove punctuation
        t = re.sub(r'\s+', ' ', t).strip()
        return t if t else None
    except Exception:
        return None

# ---------- CCURE client wrappers (best-effort) -------------------------------

def _fetch_ccure_stats() -> Optional[Dict[str, Any]]:
    """Return ccure_client.get_global_stats() result or None if unavailable/error."""
    try:
        import ccure_client
        if hasattr(ccure_client, "get_global_stats"):
            return ccure_client.get_global_stats()
    except Exception:
        # don't raise — caller will handle None
        return None
    return None

def _fetch_ccure_profiles(mode: str = "full", limit: int = 1000) -> List[Dict[str, Any]]:
    """
    Try to fetch full CCURE profiles (if ccure_client exposes such an API).
    Returns list of dicts (possibly empty).
    """
    try:
        import ccure_client
        # several possible method names used in different integrations
        if hasattr(ccure_client, "get_profiles"):
            return ccure_client.get_profiles(limit=limit, mode=mode) or []
        if hasattr(ccure_client, "fetch_profiles"):
            return ccure_client.fetch_profiles(limit=limit, mode=mode) or []
        if hasattr(ccure_client, "get_all_profiles"):
            return ccure_client.get_all_profiles(limit=limit) or []
    except Exception:
        return []
    return []

# ---------- Helpers ----------------------------------------------------------

def _extract_card_from_raw(raw: Any) -> Optional[str]:
    """If raw is dict-like, scan common card keys and numeric-looking values."""
    if not isinstance(raw, dict):
        return None
    keys = [
        "CardNumber","card_number","Card","Card No","CardNo","Badge","BadgeNo",
        "IPassID","iPass ID","IPASSID","Badge Number"
    ]
    for k in keys:
        v = raw.get(k)
        if v:
            c = _normalize_card_like(v)
            if c:
                return c
    # fallback: scan values for numeric string candidates
    for v in raw.values():
        try:
            c = _normalize_card_like(v)
            if c and 3 <= len(c) <= 12:
                return c
        except Exception:
            continue
    return None

def _build_sheet_df(session) -> pd.DataFrame:
    """Return dataframe of active people (employees + contractors) with normalized keys."""
    act_rows = session.query(ActiveEmployee).all()
    contr_rows = session.query(ActiveContractor).all()

    recs = []
    for e in act_rows:
        empid = _normalize_employee_key(e.employee_id)
        raw_card = _extract_card_from_raw(e.raw_row or {}) if hasattr(e, 'raw_row') else None
        recs.append({
            "source": "employee_sheet",
            "employee_id": empid,
            "full_name": e.full_name,
            "full_name_norm": _normalize_name(e.full_name),
            "card_number": raw_card,
            "card_number_norm": _normalize_card_like(raw_card),
            "location_city": e.location_city,
            "status": e.current_status,
            "raw_row": e.raw_row
        })
    for c in contr_rows:
        # construct primary id heuristics
        wsid = _normalize_employee_key(getattr(c, "worker_system_id", None))
        ipass = _normalize_employee_key(getattr(c, "ipass_id", None))
        primary = wsid or ipass
        raw_card = _extract_card_from_raw(c.raw_row or {}) if hasattr(c, 'raw_row') else None
        recs.append({
            "source": "contractor_sheet",
            "employee_id": primary,
            "full_name": c.full_name,
            "full_name_norm": _normalize_name(c.full_name),
            "card_number": raw_card,
            "card_number_norm": _normalize_card_like(raw_card),
            "location_city": getattr(c, "location", None),
            "status": getattr(c, "status", None),
            "raw_row": c.raw_row
        })
    df = pd.DataFrame(recs)
    if df.empty:
        df = pd.DataFrame(columns=[
            "source","employee_id","full_name","full_name_norm","card_number","card_number_norm","location_city","status","raw_row"
        ])
    # ensure columns exist and types are consistent
    for col in ["employee_id","card_number","full_name","full_name_norm","card_number_norm"]:
        if col not in df.columns:
            df[col] = None
    return df

def _build_ccure_df(profiles: List[Dict[str, Any]]) -> pd.DataFrame:
    """
    Convert a list of CCURE profile dicts into a normalized DataFrame.
    We try to extract employee id, full name, card number, partition/location.
    """
    rows = []
    for p in profiles:
        # Accept different possible keynames used by various ccure integrations
        emp_keys = ["EmployeeID", "employee_id", "Employee Id", "BadgeId", "Badge"]
        name_keys = ["FullName", "full_name", "Name", "ObjectName1"]
        card_keys = ["CardNumber","card_number","BadgeNo","Badge","IPassID","iPass ID"]
        loc_keys = ["PartitionName","Partition","Region","Location","Site"]
        emp = None
        for k in emp_keys:
            if isinstance(p, dict) and k in p and p.get(k):
                emp = p.get(k)
                break
        name = None
        for k in name_keys:
            if isinstance(p, dict) and k in p and p.get(k):
                name = p.get(k)
                break
        card = None
        for k in card_keys:
            if isinstance(p, dict) and k in p and p.get(k):
                card = p.get(k)
                break
        loc = None
        for k in loc_keys:
            if isinstance(p, dict) and k in p and p.get(k):
                loc = p.get(k)
                break
        rows.append({
            "ccure_raw": p,
            "employee_id": _normalize_employee_key(emp),
            "full_name": name,
            "full_name_norm": _normalize_name(name),
            "card_number": _normalize_card_like(card),
            "location_city": loc
        })
    df = pd.DataFrame(rows)
    if df.empty:
        df = pd.DataFrame(columns=["ccure_raw","employee_id","full_name","full_name_norm","card_number","location_city"])
    return df

# ---------- Comparison core --------------------------------------------------

def compare_ccure_vs_sheets(mode: str = "full", stats_detail: str = "ActiveProfiles", limit_list: int = 200, export: bool = False) -> Dict[str, Any]:
    """
    Compare CCURE (stats / profiles) with local sheets.
    - mode: 'full' attempts to fetch profiles; 'stats' may use only get_global_stats
    - stats_detail: which stat detail to prefer when mode=stats (kept for parity)
    - limit_list: how many rows to include in the sample lists
    - export: if True, writes an xlsx report to OUTPUT_DIR and returns report_path
    """
    try:
        session = SessionLocal()
    except Exception as e:
        return {"error": f"DB session failed: {e}", "trace": traceback.format_exc()}

    try:
        sheet_df = _build_sheet_df(session)
        sheet_count = len(sheet_df)
        sheet_emp_count = int(sheet_df[sheet_df['source'] == 'employee_sheet'].shape[0])
        sheet_contractor_count = int(sheet_df[sheet_df['source'] == 'contractor_sheet'].shape[0])
    except Exception as e:
        session.close()
        return {"error": f"Failed to read sheets from DB: {e}", "trace": traceback.format_exc()}

    # fetch ccure stats & profiles (best-effort)
    ccure_stats = _fetch_ccure_stats()
    cc_profiles = []
    if mode == "full":
        try:
            cc_profiles = _fetch_ccure_profiles(mode=mode, limit=5000)
            # ensure it's a list
            if not isinstance(cc_profiles, list):
                cc_profiles = []
        except Exception:
            cc_profiles = []
    else:
        # mode != full: still attempt to fetch profiles if available but do not fail
        try:
            cc_profiles = _fetch_ccure_profiles(mode=mode, limit=2000)
            if not isinstance(cc_profiles, list):
                cc_profiles = []
        except Exception:
            cc_profiles = []

    cc_df = _build_ccure_df(cc_profiles)
    cc_count = len(cc_df)

    # Build mapping sets for robust matching
    sheet_emp_ids = set([_normalize_employee_key(x) for x in sheet_df['employee_id'].dropna().tolist()])
    sheet_card_ids = set([_normalize_card_like(x) for x in sheet_df['card_number'].dropna().tolist()])
    sheet_names = set([_normalize_name(x) for x in sheet_df['full_name'].dropna().tolist()])

    cc_emp_ids = set([_normalize_employee_key(x) for x in cc_df['employee_id'].dropna().tolist()])
    cc_card_ids = set([_normalize_card_like(x) for x in cc_df['card_number'].dropna().tolist()])
    cc_names = set([_normalize_name(x) for x in cc_df['full_name'].dropna().tolist()])

    # Matching helpers
    def _match_cc_row_to_sheet(row) -> Optional[str]:
        """Return matched sheet employee_id or None."""
        # Try employee_id match
        if row.get('employee_id') and row['employee_id'] in sheet_emp_ids:
            return row['employee_id']
        # Try card match
        if row.get('card_number') and row['card_number'] in sheet_card_ids:
            # find the corresponding sheet employee_id for that card
            match = sheet_df[sheet_df['card_number_norm'] == row['card_number']]
            if not match.empty:
                mid = match.iloc[0].get('employee_id')
                return mid
        # Try name match
        if row.get('full_name_norm') and row['full_name_norm'] in sheet_names:
            match = sheet_df[sheet_df['full_name_norm'] == row['full_name_norm']]
            if not match.empty:
                return match.iloc[0].get('employee_id')
        return None

    def _match_sheet_row_to_cc(row) -> Optional[str]:
        """Return matched ccure employee_id (from cc_df) or None."""
        # employee id
        if row.get('employee_id') and row['employee_id'] in cc_emp_ids:
            return row['employee_id']
        # card
        if row.get('card_number_norm') and row['card_number_norm'] in cc_card_ids:
            match = cc_df[cc_df['card_number'] == row['card_number_norm']]
            if not match.empty:
                return match.iloc[0].get('employee_id')
        # name
        if row.get('full_name_norm') and row['full_name_norm'] in cc_names:
            match = cc_df[cc_df['full_name_norm'] == row['full_name_norm']]
            if not match.empty:
                return match.iloc[0].get('employee_id')
        return None

    # Compute "in CCURE but not in sheet" and vice versa
    in_ccure_not_in_sheet = []
    for _, r in cc_df.iterrows():
        try:
            matched = _match_cc_row_to_sheet(r)
            if not matched:
                # include useful fields in sample
                in_ccure_not_in_sheet.append({
                    "employee_id": _to_native(r.get('employee_id')),
                    "full_name": _to_native(r.get('full_name')),
                    "card_number": _to_native(r.get('card_number')),
                    "location_city": _to_native(r.get('location_city')),
                    "ccure_raw": r.get('ccure_raw')
                })
        except Exception:
            continue

    in_sheet_not_in_ccure = []
    for _, r in sheet_df.iterrows():
        try:
            matched = _match_sheet_row_to_cc(r)
            if not matched:
                in_sheet_not_in_ccure.append({
                    "employee_id": _to_native(r.get('employee_id')),
                    "full_name": _to_native(r.get('full_name')),
                    "card_number": _to_native(r.get('card_number')),
                    "location_city": _to_native(r.get('location_city')),
                    "source": r.get('source'),
                    "raw_row": r.get('raw_row')
                })
        except Exception:
            continue

    # Limit samples
    missing_sample = in_ccure_not_in_sheet[:limit_list]
    extra_sample = in_sheet_not_in_ccure[:limit_list]

    # Counts & deltas
    cc_active_emps = None
    cc_active_contractors = None
    try:
        if isinstance(ccure_stats, dict):
            cc_active_emps = ccure_stats.get('ActiveEmployees') or ccure_stats.get('ActiveEmployeesCount') or None
            cc_active_contractors = ccure_stats.get('ActiveContractors') or ccure_stats.get('ActiveContractorsCount') or None
    except Exception:
        pass

    # Fallback counts if ccure_stats not present
    cc_total_profiles = cc_count
    # Build response
    response = {
        "ccure": ccure_stats,
        "ccure_profile_count": cc_total_profiles,
        "sheet_counts": {
            "employees": sheet_emp_count,
            "contractors": sheet_contractor_count,
            "total_profiles": sheet_count
        },
        "differences": {
            "in_ccure_not_in_sheet_count": len(in_ccure_not_in_sheet),
            "in_sheet_not_in_ccure_count": len(in_sheet_not_in_ccure),
            "ccure_active_employees": cc_active_emps,
            "ccure_active_contractors": cc_active_contractors,
            "delta_employees": (cc_active_emps - sheet_emp_count) if (isinstance(cc_active_emps, int) and isinstance(sheet_emp_count, int)) else None,
            "delta_contractors": (cc_active_contractors - sheet_contractor_count) if (isinstance(cc_active_contractors, int) and isinstance(sheet_contractor_count, int)) else None
        },
        "samples": {
            "in_ccure_not_in_sheet": missing_sample,
            "in_sheet_not_in_ccure": extra_sample
        },
        "report_path": None
    }

    # Optional export to Excel: write sheet_df, cc_df, and both sample lists
    if export:
        try:
            os.makedirs(OUTPUT_DIR, exist_ok=True)
            fname = f"ccure_compare_{datetime.utcnow().strftime('%Y%m%d_%H%M%S')}_{uuid.uuid4().hex[:6]}.xlsx"
            path = os.path.join(OUTPUT_DIR, fname)
            with pd.ExcelWriter(path, engine="openpyxl") as writer:
                # full sheets
                try:
                    sheet_df.to_excel(writer, sheet_name="sheet_all", index=False)
                except Exception:
                    pd.DataFrame(sheet_df).to_excel(writer, sheet_name="sheet_all", index=False)
                try:
                    cc_df.to_excel(writer, sheet_name="ccure_all", index=False)
                except Exception:
                    pd.DataFrame(cc_df).to_excel(writer, sheet_name="ccure_all", index=False)
                # samples
                pd.DataFrame(missing_sample).to_excel(writer, sheet_name="in_ccure_not_in_sheet", index=False)
                pd.DataFrame(extra_sample).to_excel(writer, sheet_name="in_sheet_not_in_ccure", index=False)
                # summary sheet
                summary_df = pd.DataFrame([{
                    "sheet_employees": sheet_emp_count,
                    "sheet_contractors": sheet_contractor_count,
                    "sheet_total": sheet_count,
                    "ccure_profiles": cc_total_profiles,
                    "in_ccure_not_in_sheet": len(in_ccure_not_in_sheet),
                    "in_sheet_not_in_ccure": len(in_sheet_not_in_ccure)
                }])
                summary_df.to_excel(writer, sheet_name="summary", index=False)
            response["report_path"] = path
        except Exception as e:
            response["export_error"] = str(e)
            response["export_trace"] = traceback.format_exc()

    session.close()
    return response

# ---------- helpers to convert pandas / values to native ---------------------

def _to_native(value):
    """Return JSON-serializable primitive (str/int/None) for pandas values."""
    if value is None:
        return None
    try:
        if pd.isna(value):
            return None
    except Exception:
        pass
    try:
        if isinstance(value, (int, float, str, bool)):
            return value
        if hasattr(value, "isoformat"):
            try:
                return value.isoformat()
            except Exception:
                return str(value)
    except Exception:
        return str(value)
    return str(value)







C:\Users\W0024618\Desktop\global-page\backend\attendance-analytics\ccure_client.py


# ccure_client.py
import requests
import math
from requests.exceptions import RequestException

BASE = "http://10.199.22.57:5001"
DEFAULT_TIMEOUT = 10

# Set auth headers here if CCure requires them:
HEADERS = {
    # "Authorization": "Bearer <TOKEN>",
    "Accept": "application/json"
}


def _safe_get(path, params=None, timeout=DEFAULT_TIMEOUT):
    url = BASE.rstrip("/") + path
    try:
        r = requests.get(url, params=params, headers=HEADERS, timeout=timeout)
        r.raise_for_status()
        return r.json()
    except RequestException as e:
        # caller handles None
        print(f"[ccure_client] request failed {url} params={params} -> {e}")
        return None
    except ValueError:
        print(f"[ccure_client] response JSON decode error for {url}")
        return None


def fetch_all_employees_full():
    """
    Try to fetch a full dump from /api/employees.
    Returns list of dicts or None on failure.
    """
    return _safe_get("/api/employees")


def fetch_stats_page(detail, page=1, limit=500):
    """
    One page of /api/stats?details=detail&page=page&limit=limit
    Returns page dict or None.
    """
    params = {"details": detail, "page": page, "limit": limit}
    return _safe_get("/api/stats", params=params)


def fetch_all_stats(detail, limit=1000):
    """
    Iterate pages for /api/stats detail and return combined data list.
    Returns list or None.
    """
    first = fetch_stats_page(detail, page=1, limit=limit)
    if not first:
        return None
    data = first.get("data") or []
    total = int(first.get("total") or len(data) or 0)
    if total <= len(data):
        return data
    pages = int(math.ceil(total / float(limit)))
    for p in range(2, pages + 1):
        page_res = fetch_stats_page(detail, page=p, limit=limit)
        if not page_res:
            # stop early on error
            break
        data.extend(page_res.get("data") or [])
    return data


def get_global_stats():
    """
    Best-effort summary of CCure totals:
    - Try /api/employees full dump first
    - else try /api/stats endpoints
    Returns dict or None
    """
    full = fetch_all_employees_full()
    if isinstance(full, list):
        total = len(full)
        active_profiles = sum(1 for r in full if (r.get("Employee_Status") or "").lower() == "active")
        active_emps = sum(1 for r in full if (r.get("PersonnelType") or "").lower().startswith("employee") and (r.get("Employee_Status") or "").lower() == "active")
        active_contractors = sum(1 for r in full if (r.get("PersonnelType") or "").lower().startswith("contractor") and (r.get("Employee_Status") or "").lower() == "active")
        terminated = sum(1 for r in full if (r.get("Employee_Status") or "").lower() in ("deactive", "deactivated", "inactive", "terminated"))
        return {
            "TotalProfiles": total,
            "ActiveProfiles": active_profiles,
            "ActiveEmployees": active_emps,
            "ActiveContractors": active_contractors,
            "TerminatedProfiles": terminated
        }

    # fallback: try stats endpoints individually
    details = ["ActiveProfiles", "ActiveEmployees", "ActiveContractors",
               "TerminatedProfiles", "TerminatedEmployees", "TerminatedContractors"]
    out = {}
    for d in details:
        resp = fetch_stats_page(d, page=1, limit=1)
        if isinstance(resp, dict) and 'total' in resp:
            out[d] = resp['total']
    if out:
        return {
            "TotalProfiles": out.get("TotalProfiles"),
            "ActiveProfiles": out.get("ActiveProfiles"),
            "ActiveEmployees": out.get("ActiveEmployees"),
            "ActiveContractors": out.get("ActiveContractors"),
            "TerminatedProfiles": out.get("TerminatedProfiles"),
            "TerminatedEmployees": out.get("TerminatedEmployees"),
            "TerminatedContractors": out.get("TerminatedContractors"),
        }
    return None






C:\Users\W0024618\Desktop\global-page\backend\attendance-analytics\app.py
# app.py
from fastapi import FastAPI, UploadFile, File, HTTPException, Request, Body, Query
from fastapi.responses import JSONResponse, FileResponse
import shutil, uuid, json
from settings import UPLOAD_DIR, OUTPUT_DIR
import os
from pathlib import Path

app = FastAPI(title="Attendance Analytics")


# GET /ccure/compare
@app.get("/ccure/compare")
def ccure_compare(
    mode: str = Query("full", description="full or stats"),
    stats_detail: str = Query("ActiveProfiles", description="when mode=stats use this"),
    limit_list: int = Query(200, ge=10, le=5000, description="max rows returned in list samples"),
    export: bool = Query(False, description="if true, writes Excel report to server and returns report_path")
):
    """
    Compare CCure profiles with local ActiveEmployee & ActiveContractor sheets.
    mode: 'full' (try /api/employees) or 'stats' (use /api/stats?details=...)
    Query params: mode, stats_detail, limit_list, export
    """
    try:
        from ccure_compare_service import compare_ccure_vs_sheets
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"compare service unavailable: {e}")
    res = compare_ccure_vs_sheets(mode=mode, stats_detail=stats_detail, limit_list=limit_list, export=export)
    return JSONResponse(res)


# GET /ccure/report/{filename}  -> download generated XLSX
@app.get("/ccure/report/{filename}")
def ccure_report_download(filename: str):
    """
    Download generated report by filename (returned as 'report_path' from /ccure/compare?export=true).
    Only serves files inside OUTPUT_DIR.
    """
    try:
        safe_name = Path(filename).name  # prevent path traversal
        full = Path(OUTPUT_DIR) / safe_name
        if not full.exists() or not full.is_file():
            raise HTTPException(status_code=404, detail="Report not found")
        return FileResponse(
            str(full),
            media_type="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
            filename=safe_name
        )
    except HTTPException:
        raise
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Failed to serve report: {e}")


@app.post("/upload/active-employees")
async def upload_active_employees(file: UploadFile = File(...)):
    if not file.filename.endswith(('.xls', '.xlsx')):
        raise HTTPException(400, "Please upload an Excel file")
    dest = UPLOAD_DIR / f"{uuid.uuid4().hex}_{file.filename}"
    with open(dest, "wb") as buffer:
        shutil.copyfileobj(file.file, buffer)
    try:
        from ingest_excel import ingest_employee_excel
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"ingest_excel import failed: {e}")
    ingest_employee_excel(dest)
    return {"status":"ok", "path": str(dest)}

@app.post("/upload/active-contractors")
async def upload_active_contractors(file: UploadFile = File(...)):
    if not file.filename.endswith(('.xls', '.xlsx')):
        raise HTTPException(400, "Please upload an Excel file")
    dest = UPLOAD_DIR / f"{uuid.uuid4().hex}_{file.filename}"
    with open(dest, "wb") as buffer:
        shutil.copyfileobj(file.file, buffer)
    try:
        from ingest_excel import ingest_contractor_excel
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"ingest_excel import failed: {e}")
    ingest_contractor_excel(dest)
    return {"status":"ok", "path": str(dest)}

@app.post("/ingest/live-details")
async def ingest_live(request: Request):
    """
    Accepts:
      - Raw JSON array in body (preferred)
      - JSON object with {"details": [...]} in body
      - multipart/form-data where a form field 'details' contains a JSON string
    """
    details = None
    # Try direct JSON
    try:
        body = await request.json()
        if isinstance(body, dict) and 'details' in body:
            details = body['details']
        else:
            details = body
    except Exception:
        # not JSON, try form
        try:
            form = await request.form()
            if 'details' in form:
                raw = form['details']
                if isinstance(raw, str):
                    details = json.loads(raw)
                else:
                    try:
                        details = json.loads((await raw.read()).decode('utf-8'))
                    except Exception:
                        details = list(form.getlist('details'))
            else:
                # attempt first field
                first = None
                for v in form.values():
                    first = v
                    break
                if isinstance(first, str):
                    details = json.loads(first)
                else:
                    raise HTTPException(status_code=400, detail="No JSON payload found")
        except Exception as e:
            raise HTTPException(status_code=400, detail=f"Could not parse request body as JSON or form: {e}")

    if not isinstance(details, (list, tuple)):
        raise HTTPException(status_code=400, detail="Expected top-level array (JSON list) of detail objects")

    try:
        from compare_service import ingest_live_details_list
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"compare_service import failed: {e}")

    try:
        res = ingest_live_details_list(details)
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Failed to ingest details: {e}")

    if isinstance(res, dict):
        return {"status": "ok", **res}
    return {"status": "ok", "inserted": len(details)}


@app.get("/ingest/fetch-all")
def fetch_all_and_ingest():
    try:
        import region_clients
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"region_clients unavailable: {e}")

    details = region_clients.fetch_all_details()
    if not isinstance(details, list):
        raise HTTPException(status_code=500, detail="Unexpected data from region_clients.fetch_all_details")

    try:
        from compare_service import ingest_live_details_list
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"compare_service import failed: {e}")

    res = ingest_live_details_list(details)
    if isinstance(res, dict):
        return {"status":"ok", **res}
    return {"status":"ok", "inserted": len(details)}


@app.get("/reports/daily/{yyyymmdd}")
def daily_report(yyyymmdd: str):
    import datetime
    try:
        dt = datetime.datetime.strptime(yyyymmdd, "%Y%m%d").date()
    except Exception:
        raise HTTPException(status_code=400, detail="Date must be in YYYYMMDD format")

    try:
        from compare_service import compute_daily_attendance, compare_with_active
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"compare_service import failed: {e}")

    # compute attendance summary (will build attendance_summary rows)
    compute_daily_attendance(dt)

    # compare vs active and CCURE
    summary = compare_with_active(dt)
    return JSONResponse(summary)


# additional endpoints to fetch CCure stats directly (optional)
@app.get("/ccure/stats")
def ccure_stats():
    try:
        import ccure_client
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"ccure_client import failed: {e}")
    try:
        stats = ccure_client.get_global_stats()
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"ccure_client.get_global_stats failed: {e}")
    return stats



C:\Users\W0024618\Desktop\global-page\backend\attendance-analytics\compare_service.py

# compare_service.py
import pandas as pd
import numpy as np
from datetime import datetime, date, timezone
from db import SessionLocal
from models import ActiveEmployee, ActiveContractor, LiveSwipe, AttendanceSummary
import re
from dateutil import parser as dateutil_parser
import traceback

# --- Helpers -----------------------------------------------------------------

def _to_native(value):
    if value is None:
        return None
    try:
        if pd.isna(value):
            return None
    except Exception:
        pass
    if isinstance(value, (np.integer,)):
        return int(value)
    if isinstance(value, (np.floating,)):
        return float(value)
    if isinstance(value, (np.bool_, bool)):
        return bool(value)
    try:
        import datetime as _dt
        if isinstance(value, _dt.datetime):
            try:
                if value.tzinfo is not None:
                    utc = value.astimezone(timezone.utc)
                    return utc.replace(tzinfo=None).isoformat() + "Z"
                else:
                    return value.isoformat()
            except Exception:
                return str(value)
        if hasattr(value, 'isoformat'):
            try:
                return value.isoformat()
            except Exception:
                return str(value)
    except Exception:
        pass
    return value

def _normalize_employee_key(x):
    if x is None:
        return None
    try:
        s = str(x).strip()
        # drop empty placeholders
        if s == "" or s.lower() in ("nan", "none", "na", "null"):
            return None
        return s
    except Exception:
        return None

def _normalize_card_like(s):
    """Return normalized card-like string: digits only, no spaces, trim leading zeros."""
    if s is None:
        return None
    try:
        ss = str(s).strip()
        if ss == "":
            return None
        # remove non-digit characters
        digits = re.sub(r'\D+', '', ss)
        if digits == "":
            return None
        # strip leading zeros so '007' and '7' match; keep at least one digit
        return digits.lstrip('0') or digits
    except Exception:
        return None

def _normalize_name(s):
    if s is None:
        return None
    try:
        t = str(s).strip().lower()
        # remove punctuation, collapse whitespace
        t = re.sub(r'[^\w\s]', '', t)
        t = re.sub(r'\s+', ' ', t).strip()
        return t if t else None
    except Exception:
        return None

# timestamp parsing helpers
def _parse_timestamp_from_value(val):
    if val is None:
        return None
    import datetime as _dt
    # direct datetime
    if isinstance(val, _dt.datetime):
        dt = val
        try:
            if dt.tzinfo is not None:
                return dt.astimezone(timezone.utc).replace(tzinfo=None)
            return dt
        except Exception:
            return dt
    # numeric epoch
    try:
        import numpy as _np
        if isinstance(val, (int, float, _np.integer, _np.floating)):
            v = int(val)
            # heuristics: millisecond vs second
            if v > 1e12:
                return _dt.fromtimestamp(v / 1000.0, tz=timezone.utc).replace(tzinfo=None)
            if v > 1e9:
                return _dt.fromtimestamp(v, tz=timezone.utc).replace(tzinfo=None)
    except Exception:
        pass
    # string parsing using dateutil
    if isinstance(val, str):
        s = val.strip()
        if s == "":
            return None
        try:
            # try iso / dateutil
            dt = dateutil_parser.parse(s)
            if dt.tzinfo is not None:
                dt = dt.astimezone(timezone.utc).replace(tzinfo=None)
            return dt
        except Exception:
            # fallback to custom formats
            fmts = ("%Y-%m-%d %H:%M:%S", "%Y-%m-%d %H:%M:%S.%f",
                    "%d/%m/%Y %H:%M:%S", "%d-%m-%Y %H:%M:%S",
                    "%Y-%m-%dT%H:%M:%S")
            for fmt in fmts:
                try:
                    return _dt.strptime(s, fmt)
                except Exception:
                    pass
    return None

def _extract_timestamp_from_detail(detail):
    # check many likely keys
    fields = [
        "LocaleMessageDateTime", "LocalMessageDateTime", "LocaleMessageTime", "LocalMessageTime",
        "LocaleMessageDate", "Timestamp", "timestamp", "Time", "LocaleTime", "LocalTime",
        "time", "date", "LocaleMessageDateTimeUtc", "LocalMessageDateTimeUtc",
        "Swipe_Time", "SwipeTime", "SwipeTimeLocal", "SwipeTimestamp", "SwipeDateTime"
    ]
    if isinstance(detail, dict):
        for k in fields:
            if k in detail:
                dt = _parse_timestamp_from_value(detail.get(k))
                if dt is not None:
                    return dt
        # scan all values for any parseable timestamp
        for v in detail.values():
            dt = _parse_timestamp_from_value(v)
            if dt is not None:
                return dt
    else:
        return _parse_timestamp_from_value(detail)
    return None

# --- Main functions ----------------------------------------------------------

def ingest_live_details_list(details_list):
    """Persist details_list into LiveSwipe. returns counts."""
    from db import SessionLocal as _SessionLocal
    inserted = 0
    skipped = 0
    with _SessionLocal() as db:
        for d in details_list:
            try:
                ts_parsed = _extract_timestamp_from_detail(d)
            except Exception:
                ts_parsed = None
            if ts_parsed is None:
                # skip rows without parseable timestamp
                skipped += 1
                continue

            # robust extraction of employee id and card fields (many alias names)
            emp = None
            for k in ("EmployeeID", "employee_id", "employeeId", "Employee Id", "EmpID", "Emp Id"):
                if isinstance(d, dict) and k in d:
                    emp = d.get(k)
                    break
            emp = _normalize_employee_key(emp)

            card = None
            for k in ("CardNumber", "card_number", "Card", "Card No", "CardNo", "Badge", "BadgeNo", "badge_number", "IPassID", "iPass ID"):
                if isinstance(d, dict) and k in d:
                    card = d.get(k)
                    break
            card = _normalize_card_like(card)

            full_name = None
            for k in ("ObjectName1", "FullName", "full_name", "EmpName", "Name"):
                if isinstance(d, dict) and k in d:
                    full_name = d.get(k)
                    break

            partition = None
            for k in ("PartitionName2", "PartitionName1", "Partition", "PartitionName", "Region"):
                if isinstance(d, dict) and k in d:
                    partition = d.get(k)
                    break

            floor = d.get("Floor") if isinstance(d, dict) else None
            door = None
            for k in ("Door", "DoorName", "door"):
                if isinstance(d, dict) and k in d:
                    door = d.get(k)
                    break

            region = d.get("__region") if isinstance(d, dict) and "__region" in d else d.get("Region") if isinstance(d, dict) else None

            try:
                rec = LiveSwipe(
                    timestamp=ts_parsed,
                    employee_id=emp,
                    card_number=card,
                    full_name=full_name,
                    partition=partition,
                    floor=floor,
                    door=door,
                    region=region,
                    raw=d
                )
                db.add(rec)
                inserted += 1
            except Exception:
                # skip insertion errors but continue
                db.rollback()
                skipped += 1
                continue
        db.commit()
    print(f"[ingest_live_details_list] inserted={inserted} skipped={skipped}")
    return {"inserted": inserted, "skipped_invalid_timestamp": skipped}


def compute_daily_attendance(target_date: date):
    """Build AttendanceSummary rows for target_date (upserts)."""
    with SessionLocal() as db:
        start = datetime.combine(target_date, datetime.min.time())
        end = datetime.combine(target_date, datetime.max.time())
        swipes = db.query(LiveSwipe).filter(LiveSwipe.timestamp >= start, LiveSwipe.timestamp <= end).all()
        if not swipes:
            print(f"[compute_daily_attendance] no swipes for {target_date}")
            return []

        rows = []
        for s in swipes:
            rows.append({
                "id": s.id,
                "timestamp": s.timestamp,
                "employee_id": _normalize_employee_key(s.employee_id),
                "card_number": _normalize_card_like(s.card_number),
                "full_name": s.full_name,
                "partition": s.partition,
                "floor": s.floor,
                "door": s.door
            })
        df = pd.DataFrame(rows)
        if df.empty:
            print(f"[compute_daily_attendance] dataframe empty after rows -> {target_date}")
            return []

        # create grouping key: prefer employee_id, otherwise card_number
        df['key'] = df['employee_id'].fillna(df['card_number'])
        df = df[df['key'].notna()]
        if df.empty:
            print("[compute_daily_attendance] no usable keys after filling employee_id/card")
            return []

        grouped = df.groupby('key', dropna=False).agg(
            presence_count=('id', 'count'),
            first_seen=('timestamp', 'min'),
            last_seen=('timestamp', 'max'),
            full_name=('full_name', 'first'),
            partition=('partition', 'first'),
            card_number=('card_number', 'first')
        ).reset_index().rename(columns={'key': 'employee_id'})

        # upsert AttendanceSummary rows (merge)
        for _, row in grouped.iterrows():
            try:
                derived_obj = {
                    "partition": (row.get('partition') or None),
                    "full_name": (row.get('full_name') or None),
                    "card_number": (row.get('card_number') or None)
                }
                rec = AttendanceSummary(
                    employee_id=str(row['employee_id']) if pd.notna(row['employee_id']) else None,
                    date=target_date,
                    presence_count=int(row['presence_count']),
                    first_seen=row['first_seen'],
                    last_seen=row['last_seen'],
                    derived=derived_obj
                )
                db.merge(rec)
            except Exception as e:
                print("[compute_daily_attendance] upsert error:", e)
                continue
        db.commit()
        print(f"[compute_daily_attendance] built {len(grouped)} attendance keys for {target_date}")
        return grouped.to_dict(orient='records')


def compare_with_active(target_date: date):
    """Compare AttendanceSummary for date with ActiveEmployee & ActiveContractor and return json-safe dict."""
    # NOTE: we intentionally do NOT import get_global_stats_or_none from ccure_client;
    # a local helper wrapper below will call ccure_client.get_global_stats() safely.
    with SessionLocal() as db:
        att_rows = db.query(AttendanceSummary).filter(AttendanceSummary.date == target_date).all()
        if not att_rows:
            att_df = pd.DataFrame(columns=["employee_id", "presence_count", "first_seen", "last_seen", "card_number", "partition", "full_name"])
        else:
            att_df = pd.DataFrame([{
                "employee_id": _normalize_employee_key(a.employee_id),
                "presence_count": a.presence_count,
                "first_seen": a.first_seen,
                "last_seen": a.last_seen,
                "card_number": _normalize_card_like(a.derived.get('card_number') if (a.derived and isinstance(a.derived, dict)) else None),
                "partition": (a.derived.get('partition') if (a.derived and isinstance(a.derived, dict)) else None),
                "full_name": (a.derived.get('full_name') if (a.derived and isinstance(a.derived, dict)) else None)
            } for a in att_rows])

        act_rows = db.query(ActiveEmployee).all()
        contractor_rows = db.query(ActiveContractor).all()

        # Build maps & active list
        act_list = []
        card_to_emp = {}
        name_to_emp = {}

        # Employees
        for e in act_rows:
            emp_id_norm = _normalize_employee_key(e.employee_id)
            # extract card-like from raw if present
            card_from_raw = None
            try:
                rr = e.raw_row or {}
                if isinstance(rr, dict):
                    ck_list = [
                        "CardNumber","card_number","Card","Card No","CardNo","IPassID","IpassID","iPass ID","IPASSID",
                        "Badge Number","BadgeNo","Badge"
                    ]
                    for ck in ck_list:
                        v = rr.get(ck)
                        if v:
                            ckey = _normalize_card_like(v)
                            if ckey:
                                card_from_raw = ckey
                                break
                    # fallback: scan all values for numeric candidate
                    if not card_from_raw:
                        for v in rr.values():
                            try:
                                tmp = _normalize_card_like(v)
                                if tmp and 3 <= len(tmp) <= 12:
                                    card_from_raw = tmp
                                    break
                            except Exception:
                                pass
            except Exception:
                card_from_raw = None

            act_list.append({
                "employee_id": emp_id_norm,
                "full_name": e.full_name,
                "location_city": e.location_city,
                "status": e.current_status,
                "card_number": card_from_raw
            })
            if emp_id_norm:
                card_to_emp[emp_id_norm] = emp_id_norm
            if card_from_raw:
                card_to_emp[card_from_raw] = emp_id_norm
            n = _normalize_name(e.full_name)
            if n:
                name_to_emp[n] = emp_id_norm

        # Contractors
        for c in contractor_rows:
            worker_id = _normalize_employee_key(c.worker_system_id)
            ipass = _normalize_employee_key(c.ipass_id)
            w_ipass = ("W" + ipass) if ipass and not str(ipass).startswith("W") else ipass
            primary_id = worker_id or ipass or None
            act_list.append({
                "employee_id": primary_id,
                "full_name": c.full_name,
                "location_city": c.location,
                "status": c.status,
                "card_number": None
            })
            if primary_id:
                card_to_emp[primary_id] = primary_id
            if ipass:
                card_to_emp[ipass] = primary_id
            if w_ipass:
                card_to_emp[w_ipass] = primary_id
            try:
                rr = c.raw_row or {}
                if isinstance(rr, dict):
                    for ck in ("Worker System Id","Worker System ID","iPass ID","IPASSID","CardNumber","card_number"):
                        if ck in rr and rr.get(ck):
                            key = _normalize_card_like(rr.get(ck))
                            if key:
                                card_to_emp[key] = primary_id
            except Exception:
                pass
            n = _normalize_name(c.full_name)
            if n:
                name_to_emp[n] = primary_id

        act_df = pd.DataFrame(act_list)

        # If no active rows, return attendance-only view
        if act_df.empty:
            if att_df.empty:
                return {"by_location": [], "merged": [], "ccure": get_global_stats_or_none()}
            att_df['partition'] = att_df.get('partition').fillna('Unknown')
            att_df['presence_count'] = att_df['presence_count'].fillna(0)
            att_df['present_today'] = att_df['presence_count'].apply(lambda x: bool(x and x != 0))
            loc_group = att_df.groupby('partition', dropna=False).agg(
                total_n=('employee_id', 'count'),
                present_n=('present_today', 'sum')
            ).reset_index().rename(columns={'partition':'location_city'})
            loc_group['percent_present'] = loc_group.apply(lambda row: round((row['present_n']/row['total_n'])*100,2) if row['total_n'] and row['total_n']>0 else 0.0, axis=1)
            by_location = [{k:_to_native(v) for k,v in r.items()} for r in loc_group.to_dict(orient='records')]
            merged_list = []
            for r in att_df.to_dict(orient='records'):
                merged_list.append({
                    "employee_id": _to_native(r.get('employee_id')),
                    "presence_count": _to_native(r.get('presence_count')),
                    "first_seen": _to_native(r.get('first_seen')),
                    "last_seen": _to_native(r.get('last_seen')),
                    "full_name": _to_native(r.get('full_name')),
                    "location_city": _to_native(r.get('partition')),
                    "present_today": _to_native(r.get('present_today'))
                })
            return {"by_location": by_location, "merged": merged_list, "ccure": get_global_stats_or_none()}

        # normalize columns
        act_df['employee_id'] = act_df['employee_id'].astype(object).apply(_normalize_employee_key)
        att_df['employee_id'] = att_df['employee_id'].astype(object).apply(_normalize_employee_key)
        act_df['card_number'] = act_df.get('card_number').astype(object).apply(_normalize_card_like) if 'card_number' in act_df.columns else pd.Series([pd.NA]*len(act_df))
        att_df['card_number'] = att_df.get('card_number').astype(object).apply(_normalize_card_like) if 'card_number' in att_df.columns else pd.Series([pd.NA]*len(att_df))

        # ensure card_to_emp includes act_df card_numbers
        for r in act_df.to_dict(orient='records'):
            c = r.get('card_number')
            eid = r.get('employee_id')
            if c and eid:
                card_to_emp[c] = eid
            if eid:
                # also map numeric-only forms of eid
                n = re.sub(r'\D','', str(eid))
                if n:
                    card_to_emp[n.lstrip('0') or n] = eid

        # mapping function tries multiple strategies
        emp_set = set([x for x in act_df['employee_id'].dropna().astype(str)])

        def numeric_variants(s):
            s = str(s)
            clean = re.sub(r'\D','', s)
            variants = set()
            if clean:
                variants.add(clean)
                variants.add(clean.lstrip('0') or clean)
                if not s.startswith('W'):
                    variants.add('W' + clean)
            return list(variants)

        def remap_att_key(row):
            primary = row.get('employee_id') or None
            card = row.get('card_number') or None

            primary_norm = _normalize_employee_key(primary)
            card_norm = _normalize_card_like(card)

            # 1) exact employee id exists in active list
            if primary_norm and primary_norm in emp_set:
                return primary_norm

            # 2) numeric-variants of primary may map to card_to_emp
            if primary_norm:
                for v in numeric_variants(primary_norm):
                    if v in card_to_emp:
                        return card_to_emp[v]
                if primary_norm in card_to_emp:
                    return card_to_emp[primary_norm]

            # 3) direct card mapping
            if card_norm:
                if card_norm in card_to_emp:
                    return card_to_emp[card_norm]
                if (card_norm.lstrip('0') or card_norm) in card_to_emp:
                    return card_to_emp[card_norm.lstrip('0') or card_norm]
                if ('W' + card_norm) in card_to_emp:
                    return card_to_emp['W' + card_norm]

            # 4) name matching fallback
            fname = _normalize_name(row.get('full_name') or row.get('full_name_att') or None)
            if fname and fname in name_to_emp:
                return name_to_emp[fname]

            # 5) last resort - return primary_norm (maybe non-mapped) so it still shows up
            return primary_norm or card_norm or None

        att_df['mapped_employee_id'] = att_df.apply(remap_att_key, axis=1)

        # drop original employee_id column to avoid duplicate label conflict
        att_merge_df = att_df.drop(columns=['employee_id'], errors='ignore').copy()

        # merge left: act_df left_on employee_id, right_on mapped_employee_id
        merged = pd.merge(
            act_df,
            att_merge_df,
            left_on='employee_id',
            right_on='mapped_employee_id',
            how='left',
            suffixes=('', '_att')
        )

        # fill and finalize
        merged['presence_count'] = merged.get('presence_count', pd.Series([0]*len(merged))).fillna(0)
        # ensure ints when possible
        def safe_int(v):
            try:
                if pd.isna(v):
                    return 0
                iv = int(float(v))
                return iv
            except Exception:
                return v
        merged['presence_count'] = merged['presence_count'].apply(safe_int)
        merged['present_today'] = merged['presence_count'].apply(lambda x: bool(x and x != 0))
        merged['location_city'] = merged.get('location_city').fillna('Unknown')

        # by_location
        loc_group = merged.groupby('location_city', dropna=False).agg(
            total_n=('employee_id', 'count'),
            present_n=('present_today', 'sum')
        ).reset_index()
        loc_group['percent_present'] = loc_group.apply(lambda row: round((row['present_n']/row['total_n'])*100,2) if row['total_n'] and row['total_n']>0 else 0.0, axis=1)
        by_location = [{k:_to_native(v) for k,v in r.items()} for r in loc_group.to_dict(orient='records')]

        merged_list = []
        for r in merged.to_dict(orient='records'):
            clean = {k:_to_native(v) for k,v in r.items()}
            # unify keys for clarity in API response
            clean['mapped_employee_id'] = clean.get('mapped_employee_id')
            clean['card_number_att'] = clean.get('card_number') or clean.get('card_number_att') or None
            # include status if present
            if 'status' not in clean:
                clean['status'] = None
            # ensure employee_id key exists
            if 'employee_id' not in clean:
                clean['employee_id'] = None
            merged_list.append(clean)

        # CCURE stats fetch (best-effort)
        ccure_stats = get_global_stats_or_none()

        # compare counts summary between CCure and Active sheets
        try:
            ccure_summary = ccure_stats or {}
            cc_total_profiles = ccure_summary.get('TotalProfiles')
            cc_active_profiles = ccure_summary.get('ActiveProfiles')
            cc_active_emps = ccure_summary.get('ActiveEmployees')
            cc_active_contractors = ccure_summary.get('ActiveContractors')
        except Exception:
            cc_total_profiles = cc_active_profiles = cc_active_emps = cc_active_contractors = None

        # local sheet counts
        active_emp_count = len(act_rows)
        active_contract_count = len(contractor_rows)

        diff = {
            "active_sheet_employee_count": active_emp_count,
            "active_sheet_contractor_count": active_contract_count,
            "ccure_active_employees": cc_active_emps,
            "ccure_active_contractors": cc_active_contractors,
            "delta_employees": (cc_active_emps - active_emp_count) if (isinstance(cc_active_emps, int) and isinstance(active_emp_count, int)) else None,
            "delta_contractors": (cc_active_contractors - active_contract_count) if (isinstance(cc_active_contractors, int) and isinstance(active_contract_count, int)) else None
        }

        result = {
            "by_location": by_location,
            "merged": merged_list,
            "ccure": ccure_stats,
            "count_comparison": diff
        }
        return result


# helper wrapper to fetch CCURE stats without raising
def get_global_stats_or_none():
    try:
        from ccure_client import get_global_stats
        return get_global_stats()
    except Exception:
        return None
