Initailly read below file carefully and fix only ccure data vs sheet data comparision and gave me API for testing carefully think long

C:\Users\W0024618\Desktop\global-page\backend\attendance-analytics\ccure_client.py

# ccure_fetch.py
import requests
import math
import pandas as pd
from requests.exceptions import RequestException

BASE = "http://10.199.22.57:5001"
DEFAULT_TIMEOUT = 10

# If CCure needs auth, set HEADERS accordingly:
HEADERS = {
    # 'Authorization': 'Bearer <token>',
    'Accept': 'application/json'
}

def fetch_all_employees_full():
    """Fetch full list from /api/employees (may return a large list). Returns list or None."""
    try:
        r = requests.get(f"{BASE}/api/employees", headers=HEADERS, timeout=DEFAULT_TIMEOUT)
        r.raise_for_status()
        return r.json()  # expects a list
    except RequestException as e:
        print("ccure: full fetch failed:", e)
        return None

def fetch_stats_page(detail, page=1, limit=500):
    """
    Fetch one page from /api/stats?details=detail&page=page&limit=limit
    Returns dict or None.
    """
    try:
        params = {"details": detail, "page": page, "limit": limit}
        r = requests.get(f"{BASE}/api/stats", params=params, headers=HEADERS, timeout=DEFAULT_TIMEOUT)
        r.raise_for_status()
        return r.json()
    except RequestException as e:
        print(f"ccure: stats page error detail={detail} page={page}:", e)
        return None

def fetch_all_stats(detail, limit=1000):
    """
    Iterate pages and return full list for a given 'details' filter.
    """
    first = fetch_stats_page(detail, page=1, limit=limit)
    if not first:
        return None
    total = first.get("total", 0)
    data = first.get("data", []) or []
    if total <= len(data):
        return data
    pages = math.ceil(total / limit)
    for p in range(2, pages + 1):
        page_res = fetch_stats_page(detail, page=p, limit=limit)
        if not page_res:
            break
        data.extend(page_res.get("data", []) or [])
    return data

def ccure_to_dataframe(list_of_dicts):
    """Return DataFrame normalised with key columns."""
    if not list_of_dicts:
        return pd.DataFrame()
    df = pd.DataFrame(list_of_dicts)
    # standardize column names if needed
    df.columns = [c.strip() for c in df.columns]
    # ensure EmployeeID exists and is string
    if 'EmployeeID' in df.columns:
        df['EmployeeID'] = df['EmployeeID'].astype(str).str.strip().replace({'nan': None})
    else:
        df['EmployeeID'] = None
    return df



C:\Users\W0024618\Desktop\global-page\backend\attendance-analytics\compare_ccure_with_sheets.py


# compare_ccure_with_sheets.py
import pandas as pd
from ccure_fetch import fetch_all_employees_full, fetch_all_stats, ccure_to_dataframe
from db import SessionLocal
from models import ActiveEmployee, ActiveContractor
from pathlib import Path

OUT_DIR = Path("data/outputs")
OUT_DIR.mkdir(parents=True, exist_ok=True)

def normalize_empid(e):
    if e is None:
        return None
    s = str(e).strip()
    if s == "" or s.lower() in ("nan","none","null"):
        return None
    return s

def get_local_active_sets():
    with SessionLocal() as db:
        emps = db.query(ActiveEmployee).all()
        conts = db.query(ActiveContractor).all()

        emp_df = pd.DataFrame([{
            "employee_id": normalize_empid(e.employee_id),
            "full_name": e.full_name,
            "location_city": e.location_city,
            "status": e.current_status
        } for e in emps])

        cont_df = pd.DataFrame([{
            "worker_system_id": normalize_empid(c.worker_system_id),
            "ipass_id": normalize_empid(c.ipass_id),
            "full_name": c.full_name,
            "location": c.location,
            "status": c.status
        } for c in conts])
    return emp_df, cont_df

def compare():
    # 1) fetch ccure master
    ccure_list = fetch_all_employees_full()
    if ccure_list is None:
        # fallback: try fetching ActiveProfiles
        ccure_list = fetch_all_stats("ActiveProfiles", limit=1000)
    ccure_df = ccure_to_dataframe(ccure_list)
    # normalize employee id column name
    ccure_df['EmployeeID_norm'] = ccure_df['EmployeeID'].apply(normalize_empid)

    # 2) local active sets
    emp_df, cont_df = get_local_active_sets()

    # 3) create sets for comparison
    ccure_emp_set = set(ccure_df[ccure_df['EmployeeID_norm'].notna()]['EmployeeID_norm'].unique())
    local_emp_set = set(emp_df[emp_df['employee_id'].notna()]['employee_id'].unique())
    # contractor IDs from CCure sometimes prefixed with W...
    local_cont_set = set(cont_df['worker_system_id'].dropna().unique())
    ccure_contractors = ccure_df[ccure_df['PersonnelType'].str.lower().str.contains('contractor', na=False)]
    ccure_cont_set = set(ccure_contractors['EmployeeID_norm'].dropna().unique())

    # 4) differences
    in_ccure_not_local = sorted(list(ccure_emp_set - local_emp_set))
    in_local_not_ccure = sorted(list(local_emp_set - ccure_emp_set))

    in_ccure_cont_not_local = sorted(list(ccure_cont_set - local_cont_set))
    in_local_cont_not_ccure = sorted(list(local_cont_set - ccure_cont_set))

    # 5) detailed rows for export
    rows_ccure_only = ccure_df[ccure_df['EmployeeID_norm'].isin(in_ccure_not_local)]
    rows_local_only = emp_df[emp_df['employee_id'].isin(in_local_not_ccure)]

    # 6) summary counts
    summary = {
        "ccure_total_profiles": len(ccure_df),
        "ccure_active_profiles": int(ccure_df[ccure_df['Employee_Status'].str.lower().eq('active')].shape[0]) if 'Employee_Status' in ccure_df.columns else None,
        "local_active_employees": emp_df.shape[0],
        "local_active_contractors": cont_df.shape[0],
        "ccure_active_employees_count": int(ccure_df[ccure_df['PersonnelType'].str.contains('employee', na=False).sum()) if 'PersonnelType' in ccure_df.columns else None
    }

    report_path = OUT_DIR / f"ccure_vs_local_report_{pd.Timestamp.now().strftime('%Y%m%d_%H%M%S')}.xlsx"
    with pd.ExcelWriter(report_path, engine="xlsxwriter") as w:
        rows_ccure_only.to_excel(w, sheet_name="ccure_only_profiles", index=False)
        rows_local_only.to_excel(w, sheet_name="local_only_profiles", index=False)
        emp_df.to_excel(w, sheet_name="local_employees", index=False)
        cont_df.to_excel(w, sheet_name="local_contractors", index=False)
        ccure_df.to_excel(w, sheet_name="ccure_all", index=False)
        pd.DataFrame([summary]).to_excel(w, sheet_name="summary", index=False)

    print("Comparison finished.")
    print("Summary:", summary)
    print("Report saved to:", report_path)
    return {
        "in_ccure_not_local_count": len(in_ccure_not_local),
        "in_local_not_ccure_count": len(in_local_not_ccure),
        "report": str(report_path),
        "details": {
            "in_ccure_not_local": in_ccure_not_local[:200],
            "in_local_not_ccure": in_local_not_ccure[:200]
        }
    }

if __name__ == "__main__":
    r = compare()
    print(r)






# ingest_excel.py
import pandas as pd
from datetime import datetime
from sqlalchemy.exc import IntegrityError
from db import SessionLocal, engine
from models import Base, ActiveEmployee, ActiveContractor
from settings import UPLOAD_DIR
import uuid, os

# --- database setup: do NOT run create_all at import time ---
def init_db():
    """
    Create DB tables if they do not exist.
    Call this manually only when you want to initialize/repair the DB:
      python -c "from ingest_excel import init_db; init_db()"
    """
    from db import engine
    from models import Base
    Base.metadata.create_all(bind=engine)

def _first_present(row, candidates):
    for c in candidates:
        v = row.get(c)
        if v is not None and str(v).strip() != "":
            return v
    return None

def ingest_employee_excel(path, uploaded_by="system"):
    df = pd.read_excel(path, sheet_name=0, dtype=str)
    df.columns = [c.strip() for c in df.columns]
    # robust mapping keys
    with SessionLocal() as db:
        for _, row in df.iterrows():
            emp_id = _first_present(row, ['Employee ID','EmployeeID','Employee Id','EmpID','Emp Id'])
            if emp_id:
                emp_id = str(emp_id).strip()
            if not emp_id:
                # skip rows without an employee id
                continue
            full_name = _first_present(row, ['Full Name','FullName','EmpName','Name']) or f"{row.get('First Name','') or ''} {row.get('Last Name','') or ''}".strip()
            # robust current_status detection
            status_candidates = ['Current Status','Status','Employee Status','Employee_Status','Status (Current)','CurrentStatus']
            current_status = _first_present(row, status_candidates)
            email = _first_present(row, ["Employee's Email",'Email','Email Address'])
            location_city = _first_present(row, ['Location City','Location','Location Description','City'])
            rec = ActiveEmployee(
                employee_id=emp_id,
                full_name=full_name,
                email=email,
                location_city=location_city,
                location_desc=row.get('Location Description'),
                current_status=current_status,
                raw_row=row.to_dict(),
                uploaded_at=datetime.utcnow()
            )
            try:
                db.merge(rec)  # upsert
                db.commit()
            except IntegrityError:
                db.rollback()
            except Exception:
                db.rollback()

def ingest_contractor_excel(path):
    df = pd.read_excel(path, sheet_name=0, dtype=str)
    df.columns = [c.strip() for c in df.columns]
    with SessionLocal() as db:
        for _, row in df.iterrows():
            wsid = _first_present(row, ['Worker System Id','Worker System ID','Worker ID','WorkerSystemId'])
            if wsid:
                wsid = str(wsid).strip()
            if not wsid:
                continue
            ipass = _first_present(row, ['iPass ID','"W" iPass ID','IPassID','iPassID','Ipass ID'])
            full_name = _first_present(row, ['Full Name','FullName','Name'])
            rec = ActiveContractor(
                worker_system_id=wsid,
                ipass_id=ipass,
                full_name=full_name,
                vendor=_first_present(row, ['Vendor Company Name','Vendor']),
                location=_first_present(row, ['Worker Location','Location']),
                status=_first_present(row, ['Status','Current Status']),
                raw_row=row.to_dict(),
                uploaded_at=datetime.utcnow()
            )
            try:
                db.merge(rec)
                db.commit()
            except IntegrityError:
                db.rollback()
            except Exception:
                db.rollback()

if __name__ == "__main__":
    # ingestion convenience: read all uploaded files
    for f in os.listdir(UPLOAD_DIR):
        p = UPLOAD_DIR / f
        if 'contractor' in f.lower() or 'contractor' in str(p).lower():
            ingest_contractor_excel(p)
        else:
            ingest_employee_excel(p)
    print("Ingestion completed.")





# app.py
from fastapi import FastAPI, UploadFile, File, HTTPException, Request, Body
from fastapi.responses import JSONResponse
import shutil, uuid, json
from settings import UPLOAD_DIR, OUTPUT_DIR
import os

app = FastAPI(title="Attendance Analytics")

@app.post("/upload/active-employees")
async def upload_active_employees(file: UploadFile = File(...)):
    if not file.filename.endswith(('.xls', '.xlsx')):
        raise HTTPException(400, "Please upload an Excel file")
    dest = UPLOAD_DIR / f"{uuid.uuid4().hex}_{file.filename}"
    with open(dest, "wb") as buffer:
        shutil.copyfileobj(file.file, buffer)
    try:
        from ingest_excel import ingest_employee_excel
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"ingest_excel import failed: {e}")
    ingest_employee_excel(dest)
    return {"status":"ok", "path": str(dest)}

@app.post("/upload/active-contractors")
async def upload_active_contractors(file: UploadFile = File(...)):
    if not file.filename.endswith(('.xls', '.xlsx')):
        raise HTTPException(400, "Please upload an Excel file")
    dest = UPLOAD_DIR / f"{uuid.uuid4().hex}_{file.filename}"
    with open(dest, "wb") as buffer:
        shutil.copyfileobj(file.file, buffer)
    try:
        from ingest_excel import ingest_contractor_excel
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"ingest_excel import failed: {e}")
    ingest_contractor_excel(dest)
    return {"status":"ok", "path": str(dest)}

@app.post("/ingest/live-details")
async def ingest_live(request: Request):
    """
    Accepts:
      - Raw JSON array in body (preferred)
      - JSON object with {"details": [...]} in body
      - multipart/form-data where a form field 'details' contains a JSON string
    """
    details = None
    # Try direct JSON
    try:
        body = await request.json()
        if isinstance(body, dict) and 'details' in body:
            details = body['details']
        else:
            details = body
    except Exception:
        # not JSON, try form
        try:
            form = await request.form()
            if 'details' in form:
                raw = form['details']
                if isinstance(raw, str):
                    details = json.loads(raw)
                else:
                    try:
                        details = json.loads((await raw.read()).decode('utf-8'))
                    except Exception:
                        details = list(form.getlist('details'))
            else:
                # attempt first field
                first = None
                for v in form.values():
                    first = v
                    break
                if isinstance(first, str):
                    details = json.loads(first)
                else:
                    raise HTTPException(status_code=400, detail="No JSON payload found")
        except Exception as e:
            raise HTTPException(status_code=400, detail=f"Could not parse request body as JSON or form: {e}")

    if not isinstance(details, (list, tuple)):
        raise HTTPException(status_code=400, detail="Expected top-level array (JSON list) of detail objects")

    try:
        from compare_service import ingest_live_details_list
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"compare_service import failed: {e}")

    try:
        res = ingest_live_details_list(details)
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Failed to ingest details: {e}")

    if isinstance(res, dict):
        return {"status": "ok", **res}
    return {"status": "ok", "inserted": len(details)}


@app.get("/ingest/fetch-all")
def fetch_all_and_ingest():
    try:
        import region_clients
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"region_clients unavailable: {e}")

    details = region_clients.fetch_all_details()
    if not isinstance(details, list):
        raise HTTPException(status_code=500, detail="Unexpected data from region_clients.fetch_all_details")

    try:
        from compare_service import ingest_live_details_list
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"compare_service import failed: {e}")

    res = ingest_live_details_list(details)
    if isinstance(res, dict):
        return {"status":"ok", **res}
    return {"status":"ok", "inserted": len(details)}


@app.get("/reports/daily/{yyyymmdd}")
def daily_report(yyyymmdd: str):
    import datetime
    try:
        dt = datetime.datetime.strptime(yyyymmdd, "%Y%m%d").date()
    except Exception:
        raise HTTPException(status_code=400, detail="Date must be in YYYYMMDD format")

    try:
        from compare_service import compute_daily_attendance, compare_with_active
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"compare_service import failed: {e}")

    # compute attendance summary (will build attendance_summary rows)
    compute_daily_attendance(dt)

    # compare vs active and CCURE
    summary = compare_with_active(dt)
    return JSONResponse(summary)


# additional endpoints to fetch CCure stats directly (optional)
@app.get("/ccure/stats")
def ccure_stats():
    try:
        import ccure_client
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"ccure_client import failed: {e}")
    try:
        stats = ccure_client.get_global_stats()
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"ccure_client.get_global_stats failed: {e}")
    return stats




