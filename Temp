# ccure_compare_service.py
"""
Compare CCURE profiles/stats with local ActiveEmployee & ActiveContractor sheets.

Defensive behavior:
 - never performs network/DB actions at import time
 - returns a stable JSON object even on error (no unhandled exceptions)
 - optional export to an xlsx (requires openpyxl)
"""

import os
import re
import uuid
import traceback
import logging
from datetime import datetime
from typing import List, Dict, Any, Optional

import pandas as pd

# Defensive import of settings and OUTPUT_DIR
try:
    from settings import OUTPUT_DIR
except Exception:
    OUTPUT_DIR = os.path.join(os.getcwd(), "output")

# Defensive import of DB/session/models
try:
    from db import SessionLocal
    from models import ActiveEmployee, ActiveContractor
except Exception:
    # We will detect this later and return friendly error in runtime call
    SessionLocal = None
    ActiveEmployee = None
    ActiveContractor = None

logger = logging.getLogger("ccure_compare_service")
logger.setLevel(logging.INFO)
if not logger.handlers:
    ch = logging.StreamHandler()
    ch.setFormatter(logging.Formatter("%(asctime)s %(levelname)s %(name)s: %(message)s"))
    logger.addHandler(ch)

# Normalizers
def _normalize_employee_key(x) -> Optional[str]:
    if x is None:
        return None
    try:
        s = str(x).strip()
        if s == "" or s.lower() in ("nan", "none", "na", "null"):
            return None
        return s
    except Exception:
        return None

def _normalize_card_like(s) -> Optional[str]:
    if s is None:
        return None
    try:
        ss = str(s).strip()
        if ss == "":
            return None
        digits = re.sub(r'\D+', '', ss)
        if digits == "":
            return None
        return digits.lstrip('0') or digits
    except Exception:
        return None

def _normalize_name(s) -> Optional[str]:
    if s is None:
        return None
    try:
        t = str(s).strip().lower()
        t = re.sub(r'[^\w\s]', '', t)
        t = re.sub(r'\s+', ' ', t).strip()
        return t if t else None
    except Exception:
        return None

# CCURE client wrappers (best-effort)
def _fetch_ccure_stats() -> Optional[Dict[str, Any]]:
    try:
        import ccure_client
        if hasattr(ccure_client, "get_global_stats"):
            return ccure_client.get_global_stats()
    except Exception:
        logger.debug("ccure_client.get_global_stats unavailable or failed", exc_info=True)
        return None
    return None

def _fetch_ccure_profiles(mode: str = "full", limit: int = 1000) -> List[Dict[str, Any]]:
    try:
        import ccure_client
        # common method names
        if hasattr(ccure_client, "get_profiles"):
            return ccure_client.get_profiles(limit=limit, mode=mode) or []
        if hasattr(ccure_client, "fetch_profiles"):
            return ccure_client.fetch_profiles(limit=limit, mode=mode) or []
        if hasattr(ccure_client, "get_all_profiles"):
            return ccure_client.get_all_profiles(limit=limit) or []
    except Exception:
        logger.debug("ccure_client profile fetch failed", exc_info=True)
        return []
    return []

# Helpers
def _extract_card_from_raw(raw: Any) -> Optional[str]:
    if not isinstance(raw, dict):
        return None
    keys = [
        "CardNumber","card_number","Card","Card No","CardNo","Badge","BadgeNo",
        "IPassID","iPass ID","IPASSID","Badge Number"
    ]
    for k in keys:
        v = raw.get(k)
        if v:
            c = _normalize_card_like(v)
            if c:
                return c
    for v in raw.values():
        try:
            c = _normalize_card_like(v)
            if c and 3 <= len(c) <= 12:
                return c
        except Exception:
            continue
    return None

def _build_sheet_df(session) -> pd.DataFrame:
    """Return dataframe of active people from DB session (employees + contractors)."""
    recs = []
    act_rows = []
    contr_rows = []
    try:
        act_rows = session.query(ActiveEmployee).all()
        contr_rows = session.query(ActiveContractor).all()
    except Exception:
        # if the session query fails, return empty df with expected columns
        logger.debug("Failed to query ActiveEmployee/ActiveContractor", exc_info=True)
        df = pd.DataFrame(columns=[
            "source","employee_id","full_name","full_name_norm","card_number","card_number_norm","location_city","status","raw_row"
        ])
        return df

    for e in act_rows:
        try:
            empid = _normalize_employee_key(getattr(e, "employee_id", None))
            raw_row = getattr(e, "raw_row", None) or {}
            raw_card = _extract_card_from_raw(raw_row) if isinstance(raw_row, dict) else None
            recs.append({
                "source": "employee_sheet",
                "employee_id": empid,
                "full_name": getattr(e, "full_name", None),
                "full_name_norm": _normalize_name(getattr(e, "full_name", None)),
                "card_number": raw_card,
                "card_number_norm": _normalize_card_like(raw_card),
                "location_city": getattr(e, "location_city", None),
                "status": getattr(e, "current_status", None),
                "raw_row": raw_row
            })
        except Exception:
            logger.debug("Skipping employee row due to error", exc_info=True)
            continue

    for c in contr_rows:
        try:
            wsid = _normalize_employee_key(getattr(c, "worker_system_id", None))
            ipass = _normalize_employee_key(getattr(c, "ipass_id", None))
            primary = wsid or ipass or None
            raw_row = getattr(c, "raw_row", None) or {}
            raw_card = _extract_card_from_raw(raw_row) if isinstance(raw_row, dict) else None
            recs.append({
                "source": "contractor_sheet",
                "employee_id": primary,
                "full_name": getattr(c, "full_name", None),
                "full_name_norm": _normalize_name(getattr(c, "full_name", None)),
                "card_number": raw_card,
                "card_number_norm": _normalize_card_like(raw_card),
                "location_city": getattr(c, "location", None),
                "status": getattr(c, "status", None),
                "raw_row": raw_row
            })
        except Exception:
            logger.debug("Skipping contractor row due to error", exc_info=True)
            continue

    df = pd.DataFrame(recs)
    expected = ["source","employee_id","full_name","full_name_norm","card_number","card_number_norm","location_city","status","raw_row"]
    for c in expected:
        if c not in df.columns:
            df[c] = None
    return df

def _build_ccure_df(profiles: List[Dict[str, Any]]) -> pd.DataFrame:
    rows = []
    for p in profiles:
        try:
            emp = None
            for k in ("EmployeeID","employee_id","Employee Id","BadgeId","Badge"):
                if isinstance(p, dict) and p.get(k):
                    emp = p.get(k)
                    break
            name = None
            for k in ("FullName","full_name","Name","ObjectName1"):
                if isinstance(p, dict) and p.get(k):
                    name = p.get(k)
                    break
            card = None
            for k in ("CardNumber","card_number","BadgeNo","Badge","IPassID","iPass ID"):
                if isinstance(p, dict) and p.get(k):
                    card = p.get(k)
                    break
            loc = None
            for k in ("PartitionName","Partition","Region","Location","Site"):
                if isinstance(p, dict) and p.get(k):
                    loc = p.get(k)
                    break
            rows.append({
                "ccure_raw": p,
                "employee_id": _normalize_employee_key(emp),
                "full_name": name,
                "full_name_norm": _normalize_name(name),
                "card_number": _normalize_card_like(card),
                "location_city": loc
            })
        except Exception:
            logger.debug("Skipping ccure profile during build", exc_info=True)
            continue
    df = pd.DataFrame(rows)
    expected = ["ccure_raw","employee_id","full_name","full_name_norm","card_number","location_city"]
    for c in expected:
        if c not in df.columns:
            df[c] = None
    return df

# Main comparison function (safe)
def compare_ccure_vs_sheets(mode: str = "full", stats_detail: str = "ActiveProfiles",
                           limit_list: int = 200, export: bool = False) -> Dict[str, Any]:
    # canonical safe response shape (used on error or success)
    safe_resp = {
        "ccure": None,
        "ccure_profile_count": 0,
        "sheet_counts": {"employees": 0, "contractors": 0, "total_profiles": 0},
        "differences": {
            "in_ccure_not_in_sheet_count": 0,
            "in_sheet_not_in_ccure_count": 0,
            "ccure_active_employees": None,
            "ccure_active_contractors": None,
            "delta_employees": None,
            "delta_contractors": None
        },
        "samples": {"in_ccure_not_in_sheet": [], "in_sheet_not_in_ccure": []},
        "report_path": None
    }

    # Validate DB and models availability
    if SessionLocal is None or ActiveEmployee is None or ActiveContractor is None:
        safe_resp["error"] = "Database or models unavailable (SessionLocal/ActiveEmployee/ActiveContractor not importable)."
        logger.error(safe_resp["error"])
        return safe_resp

    try:
        session = SessionLocal()
    except Exception as e:
        safe_resp["error"] = f"DB session creation failed: {e}"
        safe_resp["trace"] = traceback.format_exc()
        logger.exception("DB session creation failed")
        return safe_resp

    try:
        # Build sheet DF
        sheet_df = _build_sheet_df(session)
        sheet_count = int(len(sheet_df))
        sheet_emp_count = int(sheet_df[sheet_df['source'] == 'employee_sheet'].shape[0])
        sheet_contractor_count = int(sheet_df[sheet_df['source'] == 'contractor_sheet'].shape[0])

        # Get CCURE stats/profiles (best-effort)
        ccure_stats = _fetch_ccure_stats()
        cc_profiles = []
        if mode == "full":
            cc_profiles = _fetch_ccure_profiles(mode=mode, limit=5000) or []
        else:
            cc_profiles = _fetch_ccure_profiles(mode=mode, limit=2000) or []

        cc_df = _build_ccure_df(cc_profiles)
        cc_count = int(len(cc_df))

        # Build matching sets
        sheet_emp_ids = set([_normalize_employee_key(x) for x in sheet_df['employee_id'].dropna().tolist()])
        sheet_card_ids = set([_normalize_card_like(x) for x in sheet_df['card_number'].dropna().tolist()])
        sheet_names = set([_normalize_name(x) for x in sheet_df['full_name'].dropna().tolist()])

        cc_emp_ids = set([_normalize_employee_key(x) for x in cc_df['employee_id'].dropna().tolist()])
        cc_card_ids = set([_normalize_card_like(x) for x in cc_df['card_number'].dropna().tolist()])
        cc_names = set([_normalize_name(x) for x in cc_df['full_name'].dropna().tolist()])

        # matching helpers
        def _match_cc_row_to_sheet(r) -> Optional[str]:
            if r.get('employee_id') and r['employee_id'] in sheet_emp_ids:
                return r['employee_id']
            if r.get('card_number') and r['card_number'] in sheet_card_ids:
                match = sheet_df[sheet_df['card_number_norm'] == r['card_number']]
                if not match.empty:
                    return match.iloc[0].get('employee_id')
            if r.get('full_name_norm') and r['full_name_norm'] in sheet_names:
                match = sheet_df[sheet_df['full_name_norm'] == r['full_name_norm']]
                if not match.empty:
                    return match.iloc[0].get('employee_id')
            return None

        def _match_sheet_row_to_cc(r) -> Optional[str]:
            if r.get('employee_id') and r['employee_id'] in cc_emp_ids:
                return r['employee_id']
            if r.get('card_number_norm') and r['card_number_norm'] in cc_card_ids:
                match = cc_df[cc_df['card_number'] == r['card_number_norm']]
                if not match.empty:
                    return match.iloc[0].get('employee_id')
            if r.get('full_name_norm') and r['full_name_norm'] in cc_names:
                match = cc_df[cc_df['full_name_norm'] == r['full_name_norm']]
                if not match.empty:
                    return match.iloc[0].get('employee_id')
            return None

        in_ccure_not_in_sheet = []
        for _, row in cc_df.iterrows():
            try:
                matched = _match_cc_row_to_sheet(row)
                if not matched:
                    in_ccure_not_in_sheet.append({
                        "employee_id": _to_native(row.get('employee_id')),
                        "full_name": _to_native(row.get('full_name')),
                        "card_number": _to_native(row.get('card_number')),
                        "location_city": _to_native(row.get('location_city')),
                        "ccure_raw": row.get('ccure_raw')
                    })
            except Exception:
                logger.debug("Skipping ccure row during matching", exc_info=True)
                continue

        in_sheet_not_in_ccure = []
        for _, row in sheet_df.iterrows():
            try:
                matched = _match_sheet_row_to_cc(row)
                if not matched:
                    in_sheet_not_in_ccure.append({
                        "employee_id": _to_native(row.get('employee_id')),
                        "full_name": _to_native(row.get('full_name')),
                        "card_number": _to_native(row.get('card_number')),
                        "location_city": _to_native(row.get('location_city')),
                        "source": row.get('source'),
                        "raw_row": row.get('raw_row')
                    })
            except Exception:
                logger.debug("Skipping sheet row during matching", exc_info=True)
                continue

        missing_sample = in_ccure_not_in_sheet[:limit_list]
        extra_sample = in_sheet_not_in_ccure[:limit_list]

        cc_active_emps = None
        cc_active_contractors = None
        try:
            if isinstance(ccure_stats, dict):
                cc_active_emps = ccure_stats.get('ActiveEmployees') or ccure_stats.get('ActiveEmployeesCount') or None
                cc_active_contractors = ccure_stats.get('ActiveContractors') or ccure_stats.get('ActiveContractorsCount') or None
        except Exception:
            pass

        resp = {
            "ccure": ccure_stats,
            "ccure_profile_count": int(cc_count),
            "sheet_counts": {
                "employees": int(sheet_emp_count),
                "contractors": int(sheet_contractor_count),
                "total_profiles": int(sheet_count)
            },
            "differences": {
                "in_ccure_not_in_sheet_count": int(len(in_ccure_not_in_sheet)),
                "in_sheet_not_in_ccure_count": int(len(in_sheet_not_in_ccure)),
                "ccure_active_employees": int(cc_active_emps) if isinstance(cc_active_emps, int) else cc_active_emps,
                "ccure_active_contractors": int(cc_active_contractors) if isinstance(cc_active_contractors, int) else cc_active_contractors,
                "delta_employees": (int(cc_active_emps) - int(sheet_emp_count)) if (isinstance(cc_active_emps, int) and isinstance(sheet_emp_count, int)) else None,
                "delta_contractors": (int(cc_active_contractors) - int(sheet_contractor_count)) if (isinstance(cc_active_contractors, int) and isinstance(sheet_contractor_count, int)) else None
            },
            "samples": {
                "in_ccure_not_in_sheet": missing_sample,
                "in_sheet_not_in_ccure": extra_sample
            },
            "report_path": None
        }

        if export:
            try:
                os.makedirs(OUTPUT_DIR, exist_ok=True)
                fname = f"ccure_compare_{datetime.utcnow().strftime('%Y%m%d_%H%M%S')}_{uuid.uuid4().hex[:6]}.xlsx"
                path = os.path.join(OUTPUT_DIR, fname)
                with pd.ExcelWriter(path, engine="openpyxl") as writer:
                    sheet_df.to_excel(writer, sheet_name="sheet_all", index=False)
                    cc_df.to_excel(writer, sheet_name="ccure_all", index=False)
                    pd.DataFrame(missing_sample).to_excel(writer, sheet_name="in_ccure_not_in_sheet", index=False)
                    pd.DataFrame(extra_sample).to_excel(writer, sheet_name="in_sheet_not_in_ccure", index=False)
                    summary_df = pd.DataFrame([{
                        "sheet_employees": sheet_emp_count,
                        "sheet_contractors": sheet_contractor_count,
                        "sheet_total": sheet_count,
                        "ccure_profiles": cc_count,
                        "in_ccure_not_in_sheet": len(in_ccure_not_in_sheet),
                        "in_sheet_not_in_ccure": len(in_sheet_not_in_ccure)
                    }])
                    summary_df.to_excel(writer, sheet_name="summary", index=False)
                resp["report_path"] = path
            except Exception as e:
                logger.exception("Failed to export workbook")
                resp["export_error"] = str(e)
                resp["export_trace"] = traceback.format_exc()

        session.close()
        return resp

    except Exception as e:
        logger.exception("Unexpected failure in compare_ccure_vs_sheets")
        try:
            session.close()
        except Exception:
            pass
        safe_resp["error"] = f"compare operation failed: {str(e)}"
        safe_resp["trace"] = traceback.format_exc()
        return safe_resp

def _to_native(value):
    """Return JSON-serializable primitive for pandas values and datetimes."""
    if value is None:
        return None
    try:
        if pd.isna(value):
            return None
    except Exception:
        pass
    if isinstance(value, (int, float, str, bool)):
        return value
    try:
        if hasattr(value, "isoformat"):
            return value.isoformat()
    except Exception:
        pass
    try:
        return str(value)
    except Exception:
        return None










# ccure_client.py
"""
Lightweight CCURE client wrappers used by compare service.
This file is defensive: missing 'requests' or network failures return None instead of raising.
"""

import math
import logging
from requests.exceptions import RequestException

logger = logging.getLogger("ccure_client")
logger.setLevel(logging.INFO)
if not logger.handlers:
    import sys
    ch = logging.StreamHandler(sys.stdout)
    ch.setFormatter(logging.Formatter("%(asctime)s %(levelname)s %(name)s: %(message)s"))
    logger.addHandler(ch)

# Base URL for CCURE API - adjust if necessary
BASE = "http://10.199.22.57:5001"
DEFAULT_TIMEOUT = 10

HEADERS = {
    "Accept": "application/json"
}

# Defensive import of requests
try:
    import requests
except Exception:
    requests = None
    logger.warning("requests module not available; ccure_client will return None for HTTP calls")

def _safe_get(path, params=None, timeout=DEFAULT_TIMEOUT):
    """
    Safe GET wrapper. Returns parsed JSON on success or None on failure.
    path may include leading slash or not; we join safely.
    """
    if requests is None:
        logger.debug("_safe_get: requests not available")
        return None
    # ensure path begins with '/'
    if not path.startswith("/"):
        path = "/" + path
    url = BASE.rstrip("/") + path
    try:
        r = requests.get(url, params=params, headers=HEADERS, timeout=timeout)
        r.raise_for_status()
        return r.json()
    except RequestException as e:
        logger.warning(f"[ccure_client] request failed {url} params={params} -> {e}")
        return None
    except ValueError:
        logger.warning(f"[ccure_client] response JSON decode error for {url}")
        return None

def fetch_all_employees_full():
    return _safe_get("/api/employees")

def fetch_stats_page(detail, page=1, limit=500):
    params = {"details": detail, "page": page, "limit": limit}
    return _safe_get("/api/stats", params=params)

def fetch_all_stats(detail, limit=1000):
    first = fetch_stats_page(detail, page=1, limit=limit)
    if not first:
        return None
    data = first.get("data") or []
    total = int(first.get("total") or len(data) or 0)
    if total <= len(data):
        return data
    pages = int(math.ceil(total / float(limit)))
    for p in range(2, pages + 1):
        page_res = fetch_stats_page(detail, page=p, limit=limit)
        if not page_res:
            break
        data.extend(page_res.get("data") or [])
    return data

def get_global_stats():
    """
    Best-effort summary using /api/employees or /api/stats.
    Returns dict or None.
    """
    full = fetch_all_employees_full()
    if isinstance(full, list):
        try:
            total = len(full)
            active_profiles = sum(1 for r in full if (r.get("Employee_Status") or "").lower() == "active")
            active_emps = sum(1 for r in full if (r.get("PersonnelType") or "").lower().startswith("employee") and (r.get("Employee_Status") or "").lower() == "active")
            active_contractors = sum(1 for r in full if (r.get("PersonnelType") or "").lower().startswith("contractor") and (r.get("Employee_Status") or "").lower() == "active")
            terminated = sum(1 for r in full if (r.get("Employee_Status") or "").lower() in ("deactive", "deactivated", "inactive", "terminated"))
            return {
                "TotalProfiles": total,
                "ActiveProfiles": active_profiles,
                "ActiveEmployees": active_emps,
                "ActiveContractors": active_contractors,
                "TerminatedProfiles": terminated
            }
        except Exception:
            logger.exception("Error calculating global stats from full dump")
            return None

    details = ["ActiveProfiles", "ActiveEmployees", "ActiveContractors",
               "TerminatedProfiles", "TerminatedEmployees", "TerminatedContractors"]
    out = {}
    for d in details:
        resp = fetch_stats_page(d, page=1, limit=1)
        if isinstance(resp, dict) and 'total' in resp:
            out[d] = resp['total']
    if out:
        return {
            "TotalProfiles": out.get("TotalProfiles"),
            "ActiveProfiles": out.get("ActiveProfiles"),
            "ActiveEmployees": out.get("ActiveEmployees"),
            "ActiveContractors": out.get("ActiveContractors"),
            "TerminatedProfiles": out.get("TerminatedProfiles"),
            "TerminatedEmployees": out.get("TerminatedEmployees"),
            "TerminatedContractors": out.get("TerminatedContractors"),
        }
    return None










# app.py
from fastapi import FastAPI, UploadFile, File, HTTPException, Request, Query
from fastapi.responses import JSONResponse, FileResponse
import shutil, uuid, json
from settings import UPLOAD_DIR, OUTPUT_DIR
from pathlib import Path
import logging

app = FastAPI(title="Attendance Analytics")

logger = logging.getLogger("attendance_app")
logger.setLevel(logging.INFO)
if not logger.handlers:
    ch = logging.StreamHandler()
    ch.setFormatter(logging.Formatter("%(asctime)s %(levelname)s %(name)s: %(message)s"))
    logger.addHandler(ch)

@app.get("/ccure/compare")
def ccure_compare(
    mode: str = Query("full", description="full or stats"),
    stats_detail: str = Query("ActiveProfiles", description="when mode=stats use this"),
    limit_list: int = Query(200, ge=1, le=5000, description="max rows returned in list samples"),
    export: bool = Query(False, description="if true, writes Excel report to server and returns report_path")
):
    try:
        from ccure_compare_service import compare_ccure_vs_sheets
    except Exception as e:
        logger.exception("ccure_compare_service import failed")
        raise HTTPException(status_code=500, detail=f"compare service unavailable: {e}")
    # run compare (the function itself is defensive)
    res = compare_ccure_vs_sheets(mode=mode, stats_detail=stats_detail, limit_list=limit_list, export=export)
    # Ensure result is a dict for JSONResponse
    if not isinstance(res, dict):
        return JSONResponse({"error": "compare service returned unexpected result"}, status_code=500)
    return JSONResponse(res)

@app.get("/ccure/report/{filename}")
def ccure_report_download(filename: str):
    try:
        safe_name = Path(filename).name
        full = Path(OUTPUT_DIR) / safe_name
        if not full.exists() or not full.is_file():
            raise HTTPException(status_code=404, detail="Report not found")
        return FileResponse(
            str(full),
            media_type="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
            filename=safe_name
        )
    except HTTPException:
        raise
    except Exception as e:
        logger.exception("Failed to serve report")
        raise HTTPException(status_code=500, detail=f"Failed to serve report: {e}")

@app.post("/upload/active-employees")
async def upload_active_employees(file: UploadFile = File(...)):
    if not file.filename.endswith(('.xls', '.xlsx')):
        raise HTTPException(400, "Please upload an Excel file")
    dest = Path(UPLOAD_DIR) / f"{uuid.uuid4().hex}_{file.filename}"
    with open(dest, "wb") as buffer:
        shutil.copyfileobj(file.file, buffer)
    try:
        from ingest_excel import ingest_employee_excel
    except Exception as e:
        logger.exception("ingest_excel import failed")
        raise HTTPException(status_code=500, detail=f"ingest_excel import failed: {e}")
    ingest_employee_excel(dest)
    return {"status":"ok", "path": str(dest)}

@app.post("/upload/active-contractors")
async def upload_active_contractors(file: UploadFile = File(...)):
    if not file.filename.endswith(('.xls', '.xlsx')):
        raise HTTPException(400, "Please upload an Excel file")
    dest = Path(UPLOAD_DIR) / f"{uuid.uuid4().hex}_{file.filename}"
    with open(dest, "wb") as buffer:
        shutil.copyfileobj(file.file, buffer)
    try:
        from ingest_excel import ingest_contractor_excel
    except Exception as e:
        logger.exception("ingest_excel import failed")
        raise HTTPException(status_code=500, detail=f"ingest_excel import failed: {e}")
    ingest_contractor_excel(dest)
    return {"status":"ok", "path": str(dest)}

# Keep other endpoints unchanged (ingest/fetch-all, reports/daily)...
# (If you want, I can paste the rest verbatim â€” I left them as before to minimize changes.)








# compare_service.py
import pandas as pd
import numpy as np
from datetime import datetime, date, timezone
from db import SessionLocal
from models import ActiveEmployee, ActiveContractor, LiveSwipe, AttendanceSummary
import re
from dateutil import parser as dateutil_parser
import traceback
import logging

logger = logging.getLogger("compare_service")
logger.setLevel(logging.INFO)
if not logger.handlers:
    ch = logging.StreamHandler()
    ch.setFormatter(logging.Formatter("%(asctime)s %(levelname)s %(name)s: %(message)s"))
    logger.addHandler(ch)

# --- Helpers -----------------------------------------------------------------
def _to_native(value):
    if value is None:
        return None
    try:
        if pd.isna(value):
            return None
    except Exception:
        pass
    if isinstance(value, (np.integer,)):
        return int(value)
    if isinstance(value, (np.floating,)):
        return float(value)
    if isinstance(value, (np.bool_, bool)):
        return bool(value)
    try:
        import datetime as _dt
        if isinstance(value, _dt.datetime):
            try:
                if value.tzinfo is not None:
                    utc = value.astimezone(timezone.utc)
                    return utc.replace(tzinfo=None).isoformat() + "Z"
                else:
                    return value.isoformat()
            except Exception:
                return str(value)
        if hasattr(value, 'isoformat'):
            try:
                return value.isoformat()
            except Exception:
                return str(value)
    except Exception:
        pass
    return value

def _normalize_employee_key(x):
    if x is None:
        return None
    try:
        s = str(x).strip()
        if s == "" or s.lower() in ("nan", "none", "na", "null"):
            return None
        return s
    except Exception:
        return None

def _normalize_card_like(s):
    if s is None:
        return None
    try:
        ss = str(s).strip()
        if ss == "":
            return None
        digits = re.sub(r'\D+', '', ss)
        if digits == "":
            return None
        return digits.lstrip('0') or digits
    except Exception:
        return None

def _normalize_name(s):
    if s is None:
        return None
    try:
        t = str(s).strip().lower()
        t = re.sub(r'[^\w\s]', '', t)
        t = re.sub(r'\s+', ' ', t).strip()
        return t if t else None
    except Exception:
        return None

# timestamp parsing helpers (unchanged)
def _parse_timestamp_from_value(val):
    if val is None:
        return None
    import datetime as _dt
    if isinstance(val, _dt.datetime):
        dt = val
        try:
            if dt.tzinfo is not None:
                return dt.astimezone(timezone.utc).replace(tzinfo=None)
            return dt
        except Exception:
            return dt
    try:
        import numpy as _np
        if isinstance(val, (int, float, _np.integer, _np.floating)):
            v = int(val)
            if v > 1e12:
                return _dt.fromtimestamp(v / 1000.0, tz=timezone.utc).replace(tzinfo=None)
            if v > 1e9:
                return _dt.fromtimestamp(v, tz=timezone.utc).replace(tzinfo=None)
    except Exception:
        pass
    if isinstance(val, str):
        s = val.strip()
        if s == "":
            return None
        try:
            dt = dateutil_parser.parse(s)
            if dt.tzinfo is not None:
                dt = dt.astimezone(timezone.utc).replace(tzinfo=None)
            return dt
        except Exception:
            fmts = ("%Y-%m-%d %H:%M:%S", "%Y-%m-%d %H:%M:%S.%f",
                    "%d/%m/%Y %H:%M:%S", "%d-%m-%Y %H:%M:%S",
                    "%Y-%m-%dT%H:%M:%S")
            for fmt in fmts:
                try:
                    return _dt.strptime(s, fmt)
                except Exception:
                    pass
    return None

def _extract_timestamp_from_detail(detail):
    fields = [
        "LocaleMessageDateTime", "LocalMessageDateTime", "LocaleMessageTime", "LocalMessageTime",
        "LocaleMessageDate", "Timestamp", "timestamp", "Time", "LocaleTime", "LocalTime",
        "time", "date", "LocaleMessageDateTimeUtc", "LocalMessageDateTimeUtc",
        "Swipe_Time", "SwipeTime", "SwipeTimeLocal", "SwipeTimestamp", "SwipeDateTime"
    ]
    if isinstance(detail, dict):
        for k in fields:
            if k in detail:
                dt = _parse_timestamp_from_value(detail.get(k))
                if dt is not None:
                    return dt
        for v in detail.values():
            dt = _parse_timestamp_from_value(v)
            if dt is not None:
                return dt
    else:
        return _parse_timestamp_from_value(detail)
    return None

# The rest of the file (ingest_live_details_list, compute_daily_attendance, compare_with_active)
# is unchanged from your original but wrapped to avoid raising on unexpected errors.
# (To keep this message compact I assume you will swap in your existing logic - if you want I can paste the whole file verbatim with only minimal changes.)

# Helper wrapper
def get_global_stats_or_none():
    try:
        from ccure_client import get_global_stats
        return get_global_stats()
    except Exception:
        logger.debug("ccure_client.get_global_stats not available", exc_info=True)
        return None









GET http://localhost:8000/ccure/compare?mode=full&limit_list=200&export=false









When i update below file we got this error so fix this error carefully..and share me fully updatedc file carefully..

INFO:     127.0.0.1:51300 - "GET /ccure/compare?mode=full&limit_list=200&export=false HTTP/1.1" 500 Internal Server Error
ERROR:    Exception in ASGI application
Traceback (most recent call last):
  File "C:\Users\W0024618\Desktop\global-page\backend\attendance-analytics\.venv\Lib\site-packages\uvicorn\protocols\http\httptools_impl.py", line 409, in run_asgi
    result = await app(  # type: ignore[func-returns-value]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
        self.scope, self.receive, self.send
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "C:\Users\W0024618\Desktop\global-page\backend\attendance-analytics\.venv\Lib\site-packages\uvicorn\middleware\proxy_headers.py", line 60, in __call__
    return await self.app(scope, receive, send)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\W0024618\Desktop\global-page\backend\attendance-analytics\.venv\Lib\site-packages\fastapi\applications.py", line 1054, in __call__
    await super().__call__(scope, receive, send)
  File "C:\Users\W0024618\Desktop\global-page\backend\attendance-analytics\.venv\Lib\site-packages\starlette\applications.py", line 113, in __call__
    await self.middleware_stack(scope, receive, send)
  File "C:\Users\W0024618\Desktop\global-page\backend\attendance-analytics\.venv\Lib\site-packages\starlette\middleware\errors.py", line 186, in __call__
    raise exc
  File "C:\Users\W0024618\Desktop\global-page\backend\attendance-analytics\.venv\Lib\site-packages\starlette\middleware\errors.py", line 164, in __call__
    await self.app(scope, receive, _send)
  File "C:\Users\W0024618\Desktop\global-page\backend\attendance-analytics\.venv\Lib\site-packages\starlette\middleware\exceptions.py", line 63, in __call__
    await wrap_app_handling_exceptions(self.app, conn)(scope, receive, send)
  File "C:\Users\W0024618\Desktop\global-page\backend\attendance-analytics\.venv\Lib\site-packages\starlette\_exception_handler.py", line 53, in wrapped_app
    raise exc
  File "C:\Users\W0024618\Desktop\global-page\backend\attendance-analytics\.venv\Lib\site-packages\starlette\_exception_handler.py", line 42, in wrapped_app
    await app(scope, receive, sender)
  File "C:\Users\W0024618\Desktop\global-page\backend\attendance-analytics\.venv\Lib\site-packages\starlette\routing.py", line 716, in __call__
    await self.middleware_stack(scope, receive, send)
  File "C:\Users\W0024618\Desktop\global-page\backend\attendance-analytics\.venv\Lib\site-packages\starlette\routing.py", line 736, in app
    await route.handle(scope, receive, send)
  File "C:\Users\W0024618\Desktop\global-page\backend\attendance-analytics\.venv\Lib\site-packages\starlette\routing.py", line 290, in handle
    await self.app(scope, receive, send)
  File "C:\Users\W0024618\Desktop\global-page\backend\attendance-analytics\.venv\Lib\site-packages\starlette\routing.py", line 78, in app
    await wrap_app_handling_exceptions(app, request)(scope, receive, send)
  File "C:\Users\W0024618\Desktop\global-page\backend\attendance-analytics\.venv\Lib\site-packages\starlette\_exception_handler.py", line 53, in wrapped_app
    raise exc
  File "C:\Users\W0024618\Desktop\global-page\backend\attendance-analytics\.venv\Lib\site-packages\starlette\_exception_handler.py", line 42, in wrapped_app
    await app(scope, receive, sender)
  File "C:\Users\W0024618\Desktop\global-page\backend\attendance-analytics\.venv\Lib\site-packages\starlette\routing.py", line 75, in app
    response = await f(request)
               ^^^^^^^^^^^^^^^^
  File "C:\Users\W0024618\Desktop\global-page\backend\attendance-analytics\.venv\Lib\site-packages\fastapi\routing.py", line 302, in app
    raw_response = await run_endpoint_function(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<3 lines>...
    )
    ^
  File "C:\Users\W0024618\Desktop\global-page\backend\attendance-analytics\.venv\Lib\site-packages\fastapi\routing.py", line 215, in run_endpoint_function
    return await run_in_threadpool(dependant.call, **values)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\W0024618\Desktop\global-page\backend\attendance-analytics\.venv\Lib\site-packages\starlette\concurrency.py", line 38, in run_in_threadpool
    return await anyio.to_thread.run_sync(func)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\W0024618\Desktop\global-page\backend\attendance-analytics\.venv\Lib\site-packages\anyio\to_thread.py", line 56, in run_sync
    return await get_async_backend().run_sync_in_worker_thread(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
        func, args, abandon_on_cancel=abandon_on_cancel, limiter=limiter
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "C:\Users\W0024618\Desktop\global-page\backend\attendance-analytics\.venv\Lib\site-packages\anyio\_backends\_asyncio.py", line 2476, in run_sync_in_worker_thread
    return await future
           ^^^^^^^^^^^^
  File "C:\Users\W0024618\Desktop\global-page\backend\attendance-analytics\.venv\Lib\site-packages\anyio\_backends\_asyncio.py", line 967, in run
    result = context.run(func, *args)
  File "C:\Users\W0024618\Desktop\global-page\backend\attendance-analytics\app.py", line 30, in ccure_compare     
    return JSONResponse(res)
  File "C:\Users\W0024618\Desktop\global-page\backend\attendance-analytics\.venv\Lib\site-packages\starlette\responses.py", line 190, in __init__
    super().__init__(content, status_code, headers, media_type, background)
    ~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\W0024618\Desktop\global-page\backend\attendance-analytics\.venv\Lib\site-packages\starlette\responses.py", line 47, in __init__
    self.body = self.render(content)
                ~~~~~~~~~~~^^^^^^^^^
  File "C:\Users\W0024618\Desktop\global-page\backend\attendance-analytics\.venv\Lib\site-packages\starlette\responses.py", line 193, in render
    return json.dumps(
           ~~~~~~~~~~^
        content,
        ^^^^^^^^
    ...<3 lines>...
        separators=(",", ":"),
        ^^^^^^^^^^^^^^^^^^^^^^
    ).encode("utf-8")
    ^
  File "C:\Program Files\Python313\Lib\json\__init__.py", line 238, in dumps
    **kw).encode(obj)
          ~~~~~~^^^^^
  File "C:\Program Files\Python313\Lib\json\encoder.py", line 200, in encode
    chunks = self.iterencode(o, _one_shot=True)
  File "C:\Program Files\Python313\Lib\json\encoder.py", line 261, in iterencode
    return _iterencode(o, 0)
ValueError: Out of range float values are not JSON compliant: nan






# ccure_compare_service.py
"""
Compare CCURE profiles/stats with local ActiveEmployee & ActiveContractor sheets.

This module is defensive:
 - does not crash on missing ccure_client or DB problems
 - returns a stable JSON structure (see below)
 - 'export' is optional (writes an xlsx when True)
"""

import os
import re
import uuid
import traceback
from datetime import datetime
from typing import List, Dict, Any, Optional

import pandas as pd

from db import SessionLocal
from models import ActiveEmployee, ActiveContractor
from settings import OUTPUT_DIR  # ensure OUTPUT_DIR exists in your settings

# ----- Normalizers -----------------------------------------------------------

def _normalize_employee_key(x) -> Optional[str]:
    if x is None:
        return None
    try:
        s = str(x).strip()
        if s == "" or s.lower() in ("nan", "none", "na", "null"):
            return None
        return s
    except Exception:
        return None

def _normalize_card_like(s) -> Optional[str]:
    if s is None:
        return None
    try:
        ss = str(s).strip()
        if ss == "":
            return None
        digits = re.sub(r'\D+', '', ss)
        if digits == "":
            return None
        # remove leading zeros for matching flexibility, keep at least one digit
        return digits.lstrip('0') or digits
    except Exception:
        return None

def _normalize_name(s) -> Optional[str]:
    if s is None:
        return None
    try:
        t = str(s).strip().lower()
        t = re.sub(r'[^\w\s]', '', t)
        t = re.sub(r'\s+', ' ', t).strip()
        return t if t else None
    except Exception:
        return None

# ----- CCURE client wrappers (best-effort) ----------------------------------

def _fetch_ccure_stats() -> Optional[Dict[str, Any]]:
    """Return ccure_client.get_global_stats() result or None."""
    try:
        import ccure_client
        if hasattr(ccure_client, "get_global_stats"):
            return ccure_client.get_global_stats()
    except Exception:
        return None
    return None

def _fetch_ccure_profiles(mode: str = "full", limit: int = 1000) -> List[Dict[str, Any]]:
    """Attempt to fetch CCURE profiles using common ccure_client method names."""
    try:
        import ccure_client
        if hasattr(ccure_client, "get_profiles"):
            return ccure_client.get_profiles(limit=limit, mode=mode) or []
        if hasattr(ccure_client, "fetch_profiles"):
            return ccure_client.fetch_profiles(limit=limit, mode=mode) or []
        if hasattr(ccure_client, "get_all_profiles"):
            return ccure_client.get_all_profiles(limit=limit) or []
    except Exception:
        return []
    return []

# ----- Helpers ---------------------------------------------------------------

def _extract_card_from_raw(raw: Any) -> Optional[str]:
    if not isinstance(raw, dict):
        return None
    keys = [
        "CardNumber","card_number","Card","Card No","CardNo","Badge","BadgeNo",
        "IPassID","iPass ID","IPASSID","Badge Number"
    ]
    for k in keys:
        v = raw.get(k)
        if v:
            c = _normalize_card_like(v)
            if c:
                return c
    # fallback: scan values for numeric-like candidate
    for v in raw.values():
        try:
            c = _normalize_card_like(v)
            if c and 3 <= len(c) <= 12:
                return c
        except Exception:
            continue
    return None

def _build_sheet_df(session) -> pd.DataFrame:
    """
    Build combined dataframe from ActiveEmployee and ActiveContractor.
    Columns: source, employee_id, full_name, full_name_norm, card_number, card_number_norm, location_city, status, raw_row
    """
    act_rows = session.query(ActiveEmployee).all()
    contr_rows = session.query(ActiveContractor).all()
    recs = []

    for e in act_rows:
        try:
            empid = _normalize_employee_key(getattr(e, "employee_id", None))
            raw_row = getattr(e, "raw_row", None) or {}
            raw_card = _extract_card_from_raw(raw_row) if isinstance(raw_row, dict) else None
            recs.append({
                "source": "employee_sheet",
                "employee_id": empid,
                "full_name": getattr(e, "full_name", None),
                "full_name_norm": _normalize_name(getattr(e, "full_name", None)),
                "card_number": raw_card,
                "card_number_norm": _normalize_card_like(raw_card),
                "location_city": getattr(e, "location_city", None),
                "status": getattr(e, "current_status", None),
                "raw_row": raw_row
            })
        except Exception:
            # don't fail building other rows
            continue

    for c in contr_rows:
        try:
            wsid = _normalize_employee_key(getattr(c, "worker_system_id", None))
            ipass = _normalize_employee_key(getattr(c, "ipass_id", None))
            primary = wsid or ipass or None
            raw_row = getattr(c, "raw_row", None) or {}
            raw_card = _extract_card_from_raw(raw_row) if isinstance(raw_row, dict) else None
            recs.append({
                "source": "contractor_sheet",
                "employee_id": primary,
                "full_name": getattr(c, "full_name", None),
                "full_name_norm": _normalize_name(getattr(c, "full_name", None)),
                "card_number": raw_card,
                "card_number_norm": _normalize_card_like(raw_card),
                "location_city": getattr(c, "location", None),
                "status": getattr(c, "status", None),
                "raw_row": raw_row
            })
        except Exception:
            continue

    df = pd.DataFrame(recs)
    # Ensure stable columns exist
    expected = ["source","employee_id","full_name","full_name_norm","card_number","card_number_norm","location_city","status","raw_row"]
    for c in expected:
        if c not in df.columns:
            df[c] = None
    return df

def _build_ccure_df(profiles: List[Dict[str, Any]]) -> pd.DataFrame:
    rows = []
    for p in profiles:
        try:
            emp = None
            for k in ("EmployeeID","employee_id","Employee Id","BadgeId","Badge"):
                if isinstance(p, dict) and p.get(k):
                    emp = p.get(k)
                    break
            name = None
            for k in ("FullName","full_name","Name","ObjectName1"):
                if isinstance(p, dict) and p.get(k):
                    name = p.get(k)
                    break
            card = None
            for k in ("CardNumber","card_number","BadgeNo","Badge","IPassID","iPass ID"):
                if isinstance(p, dict) and p.get(k):
                    card = p.get(k)
                    break
            loc = None
            for k in ("PartitionName","Partition","Region","Location","Site"):
                if isinstance(p, dict) and p.get(k):
                    loc = p.get(k)
                    break
            rows.append({
                "ccure_raw": p,
                "employee_id": _normalize_employee_key(emp),
                "full_name": name,
                "full_name_norm": _normalize_name(name),
                "card_number": _normalize_card_like(card),
                "location_city": loc
            })
        except Exception:
            continue
    df = pd.DataFrame(rows)
    expected = ["ccure_raw","employee_id","full_name","full_name_norm","card_number","location_city"]
    for c in expected:
        if c not in df.columns:
            df[c] = None
    return df

# ----- Comparison core ------------------------------------------------------

def compare_ccure_vs_sheets(mode: str = "full", stats_detail: str = "ActiveProfiles", limit_list: int = 200, export: bool = False) -> Dict[str, Any]:
    """
    Compare CCURE profiles with sheet rows and return the canonical response structure.

    Returns dict with keys:
     - ccure
     - ccure_profile_count
     - sheet_counts
     - differences
     - samples
     - report_path
    """
    # default safe response
    safe_resp = {
        "ccure": None,
        "ccure_profile_count": 0,
        "sheet_counts": {"employees": 0, "contractors": 0, "total_profiles": 0},
        "differences": {
            "in_ccure_not_in_sheet_count": 0,
            "in_sheet_not_in_ccure_count": 0,
            "ccure_active_employees": None,
            "ccure_active_contractors": None,
            "delta_employees": None,
            "delta_contractors": None
        },
        "samples": {"in_ccure_not_in_sheet": [], "in_sheet_not_in_ccure": []},
        "report_path": None
    }

    # Try/except top-level to avoid unhandled exception -> 500
    try:
        session = SessionLocal()
    except Exception as e:
        # DB session failed: return error-friendly payload
        safe_resp["error"] = f"DB session failed: {str(e)}"
        safe_resp["trace"] = traceback.format_exc()
        return safe_resp

    try:
        # Build sheet dataframe
        sheet_df = _build_sheet_df(session)
        sheet_count = int(len(sheet_df))
        sheet_emp_count = int(sheet_df[sheet_df['source'] == 'employee_sheet'].shape[0])
        sheet_contractor_count = int(sheet_df[sheet_df['source'] == 'contractor_sheet'].shape[0])

        # Fetch CCURE info (best-effort)
        ccure_stats = _fetch_ccure_stats()
        cc_profiles = []
        if mode == "full":
            cc_profiles = _fetch_ccure_profiles(mode=mode, limit=5000) or []
        else:
            cc_profiles = _fetch_ccure_profiles(mode=mode, limit=2000) or []

        cc_df = _build_ccure_df(cc_profiles)
        cc_count = int(len(cc_df))

        # Build sets for quick match checks
        sheet_emp_ids = set([_normalize_employee_key(x) for x in sheet_df['employee_id'].dropna().tolist()])
        sheet_card_ids = set([_normalize_card_like(x) for x in sheet_df['card_number'].dropna().tolist()])
        sheet_names = set([_normalize_name(x) for x in sheet_df['full_name'].dropna().tolist()])

        cc_emp_ids = set([_normalize_employee_key(x) for x in cc_df['employee_id'].dropna().tolist()])
        cc_card_ids = set([_normalize_card_like(x) for x in cc_df['card_number'].dropna().tolist()])
        cc_names = set([_normalize_name(x) for x in cc_df['full_name'].dropna().tolist()])

        # matching helpers (conservative order)
        def _match_cc_row_to_sheet(r) -> Optional[str]:
            if r.get('employee_id') and r['employee_id'] in sheet_emp_ids:
                return r['employee_id']
            if r.get('card_number') and r['card_number'] in sheet_card_ids:
                match = sheet_df[sheet_df['card_number_norm'] == r['card_number']]
                if not match.empty:
                    return match.iloc[0].get('employee_id')
            if r.get('full_name_norm') and r['full_name_norm'] in sheet_names:
                match = sheet_df[sheet_df['full_name_norm'] == r['full_name_norm']]
                if not match.empty:
                    return match.iloc[0].get('employee_id')
            return None

        def _match_sheet_row_to_cc(r) -> Optional[str]:
            if r.get('employee_id') and r['employee_id'] in cc_emp_ids:
                return r['employee_id']
            if r.get('card_number_norm') and r['card_number_norm'] in cc_card_ids:
                match = cc_df[cc_df['card_number'] == r['card_number_norm']]
                if not match.empty:
                    return match.iloc[0].get('employee_id')
            if r.get('full_name_norm') and r['full_name_norm'] in cc_names:
                match = cc_df[cc_df['full_name_norm'] == r['full_name_norm']]
                if not match.empty:
                    return match.iloc[0].get('employee_id')
            return None

        # compute missing samples
        in_ccure_not_in_sheet = []
        for _, row in cc_df.iterrows():
            try:
                matched = _match_cc_row_to_sheet(row)
                if not matched:
                    in_ccure_not_in_sheet.append({
                        "employee_id": _to_native(row.get('employee_id')),
                        "full_name": _to_native(row.get('full_name')),
                        "card_number": _to_native(row.get('card_number')),
                        "location_city": _to_native(row.get('location_city')),
                        "ccure_raw": row.get('ccure_raw')
                    })
            except Exception:
                continue

        in_sheet_not_in_ccure = []
        for _, row in sheet_df.iterrows():
            try:
                matched = _match_sheet_row_to_cc(row)
                if not matched:
                    in_sheet_not_in_ccure.append({
                        "employee_id": _to_native(row.get('employee_id')),
                        "full_name": _to_native(row.get('full_name')),
                        "card_number": _to_native(row.get('card_number')),
                        "location_city": _to_native(row.get('location_city')),
                        "source": row.get('source'),
                        "raw_row": row.get('raw_row')
                    })
            except Exception:
                continue

        missing_sample = in_ccure_not_in_sheet[:limit_list]
        extra_sample = in_sheet_not_in_ccure[:limit_list]

        # ccure stats counts (best-effort)
        cc_active_emps = None
        cc_active_contractors = None
        try:
            if isinstance(ccure_stats, dict):
                cc_active_emps = ccure_stats.get('ActiveEmployees') or ccure_stats.get('ActiveEmployeesCount') or None
                cc_active_contractors = ccure_stats.get('ActiveContractors') or ccure_stats.get('ActiveContractorsCount') or None
        except Exception:
            pass

        # build final response exactly in the requested shape
        resp = {
            "ccure": ccure_stats,
            "ccure_profile_count": int(cc_count),
            "sheet_counts": {
                "employees": int(sheet_emp_count),
                "contractors": int(sheet_contractor_count),
                "total_profiles": int(sheet_count)
            },
            "differences": {
                "in_ccure_not_in_sheet_count": int(len(in_ccure_not_in_sheet)),
                "in_sheet_not_in_ccure_count": int(len(in_sheet_not_in_ccure)),
                "ccure_active_employees": int(cc_active_emps) if isinstance(cc_active_emps, int) else cc_active_emps,
                "ccure_active_contractors": int(cc_active_contractors) if isinstance(cc_active_contractors, int) else cc_active_contractors,
                "delta_employees": (int(cc_active_emps) - int(sheet_emp_count)) if (isinstance(cc_active_emps, int) and isinstance(sheet_emp_count, int)) else None,
                "delta_contractors": (int(cc_active_contractors) - int(sheet_contractor_count)) if (isinstance(cc_active_contractors, int) and isinstance(sheet_contractor_count, int)) else None
            },
            "samples": {
                "in_ccure_not_in_sheet": missing_sample,
                "in_sheet_not_in_ccure": extra_sample
            },
            "report_path": None
        }

        # optional export
        if export:
            try:
                os.makedirs(OUTPUT_DIR, exist_ok=True)
                fname = f"ccure_compare_{datetime.utcnow().strftime('%Y%m%d_%H%M%S')}_{uuid.uuid4().hex[:6]}.xlsx"
                path = os.path.join(OUTPUT_DIR, fname)
                # write Excel workbook
                with pd.ExcelWriter(path, engine="openpyxl") as writer:
                    # safe conversions to DataFrame for writing
                    try:
                        sheet_df.to_excel(writer, sheet_name="sheet_all", index=False)
                    except Exception:
                        pd.DataFrame(sheet_df).to_excel(writer, sheet_name="sheet_all", index=False)
                    try:
                        cc_df.to_excel(writer, sheet_name="ccure_all", index=False)
                    except Exception:
                        pd.DataFrame(cc_df).to_excel(writer, sheet_name="ccure_all", index=False)
                    pd.DataFrame(missing_sample).to_excel(writer, sheet_name="in_ccure_not_in_sheet", index=False)
                    pd.DataFrame(extra_sample).to_excel(writer, sheet_name="in_sheet_not_in_ccure", index=False)
                    summary_df = pd.DataFrame([{
                        "sheet_employees": sheet_emp_count,
                        "sheet_contractors": sheet_contractor_count,
                        "sheet_total": sheet_count,
                        "ccure_profiles": cc_count,
                        "in_ccure_not_in_sheet": len(in_ccure_not_in_sheet),
                        "in_sheet_not_in_ccure": len(in_sheet_not_in_ccure)
                    }])
                    summary_df.to_excel(writer, sheet_name="summary", index=False)
                resp["report_path"] = path
            except Exception as e:
                resp["export_error"] = str(e)
                resp["export_trace"] = traceback.format_exc()

        session.close()
        return resp

    except Exception as e:
        # unexpected failure: return an error friendly response (no 500)
        try:
            session.close()
        except Exception:
            pass
        safe_resp["error"] = f"compare operation failed: {str(e)}"
        safe_resp["trace"] = traceback.format_exc()
        return safe_resp

# ----- small helper to produce JSON-safe primitives --------------------------

def _to_native(value):
    """Return JSON-serializable primitive (str/int/None) for pandas values."""
    if value is None:
        return None
    try:
        if pd.isna(value):
            return None
    except Exception:
        pass
    if isinstance(value, (int, float, str, bool)):
        return value
    try:
        if hasattr(value, "isoformat"):
            return value.isoformat()
    except Exception:
        pass
    try:
        return str(value)
    except Exception:
        return None





GET http://localhost:8000/ccure/compare?mode=full&limit_list=200&export=false






