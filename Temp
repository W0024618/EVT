Read Below File Carefully and help me 
http://localhost:8000/duration?date=2025-09-05 so this API works for single date duration 
if i want to check  duration for range like 01 -09-2025 to 05-09-2025 so what is my API endpoint.
refer above file and give me only API endpoint


@app.get("/duration")
async def api_duration(
    date_param: Optional[str] = Query(None, alias="date", description="Target date YYYY-MM-DD. Defaults to today in Asia/Kolkata"),
    start_date: Optional[str] = Query(None, description="Start date for a range (YYYY-MM-DD)"),
    end_date: Optional[str] = Query(None, description="End date for a range (YYYY-MM-DD)"),
    regions: Optional[str] = Query(None, description="Comma-separated list: apac,emea,laca,namer. Default: all"),
    city: Optional[str] = Query(None, description="Optional city/location filter (e.g. Pune). Case-insensitive, matches PartitionName2/PrimaryLocation/Door/EmployeeName"),
    outdir: Optional[str] = Query(None, description="Output directory for CSVs. Defaults to OUTPUT_DIR/duration_reports"),
    sample_rows: int = Query(10, ge=0, le=100, description="How many sample rows to include per region in response")
):
    try:
        # --- parse region list
        if regions:
            regions_list = [r.strip().lower() for r in regions.split(",") if r.strip()]
        else:
            regions_list = ["apac", "emea", "laca", "namer"]

        # --- parse output dir
        if outdir:
            outdir_path = Path(outdir)
        else:
            outdir_path = OUTPUT_DIR / "duration_reports"
        outdir_path.mkdir(parents=True, exist_ok=True)

        # --- determine date(s)
        def _parse_date(s: str) -> date:
            try:
                return datetime.strptime(s, "%Y-%m-%d").date()
            except Exception:
                return date.fromisoformat(s)

        if start_date and end_date:
            try:
                start_obj = _parse_date(start_date)
                end_obj = _parse_date(end_date)
            except Exception:
                raise HTTPException(status_code=400, detail="Invalid start_date or end_date format. Use YYYY-MM-DD.")
            if start_obj > end_obj:
                raise HTTPException(status_code=400, detail="start_date must be <= end_date")
            # safety: limit max days to avoid overloading
            max_days = 31
            days_count = (end_obj - start_obj).days + 1
            if days_count > max_days:
                raise HTTPException(status_code=400, detail=f"Date range too large (> {max_days} days). Please request a smaller range.")
            date_list = [start_obj + timedelta(days=i) for i in range(days_count)]
            range_mode = True
        else:
            # single-date: prefer explicit `date` query param, otherwise today's Asia/Kolkata
            if date_param:
                try:
                    target_date = _parse_date(date_param)
                except Exception:
                    raise HTTPException(status_code=400, detail="Invalid date format. Use YYYY-MM-DD.")
            else:
                tz = ZoneInfo("Asia/Kolkata")
                target_date = datetime.now(tz).date()
            date_list = [target_date]
            start_obj = end_obj = date_list[0]
            range_mode = False

        # --- import duration_report lazily
        try:
            import duration_report
        except Exception as e:
            logger.exception("Failed importing duration_report module")
            raise HTTPException(status_code=500, detail=f"duration module import failed: {e}")

        loop = asyncio.get_running_loop()

        # Helper serializer
        def _to_json_safe(v):
            try:
                if pd.isna(v):
                    return None
            except Exception:
                pass
            if isinstance(v, (datetime, date)):
                return v.isoformat()
            if hasattr(v, "isoformat") and not isinstance(v, str):
                try:
                    return v.isoformat()
                except Exception:
                    pass
            if isinstance(v, (int, float, bool)):
                return v
            return v

        # For each date, call run_for_date and collect results
        per_date_results = {}  # iso_date -> results dict returned by duration_report.run_for_date
        for single_date in date_list:
            try:
                task = loop.run_in_executor(None, duration_report.run_for_date, single_date, regions_list, str(outdir_path), city)
                per_date_results[single_date.isoformat()] = await asyncio.wait_for(task, timeout=COMPUTE_WAIT_TIMEOUT_SECONDS)
            except asyncio.TimeoutError:
                raise HTTPException(status_code=504, detail=f"Duration computation timed out for date {single_date.isoformat()}")
            except Exception as e:
                logger.exception("duration run_for_date failed for date %s", single_date)
                raise HTTPException(status_code=500, detail=f"duration run failed for {single_date.isoformat()}: {e}")

        # Aggregate results per region and per employee across dates
        resp = {
            "start_date": start_obj.isoformat(),
            "end_date": end_obj.isoformat(),
            "regions": {}
        }

        for r in regions_list:
            try:
                # Prepare date list strings
                dates_iso = [d.isoformat() for d in date_list]

                # employee_map keyed by person_uid (prefer) else by EmployeeID|EmployeeName
                employees: Dict[str, Dict[str, Any]] = {}
                date_rows = {}

                for iso_d, day_res in per_date_results.items():
                    # day_res is a dict: region -> {"swipes": df, "durations": df}
                    region_obj = day_res.get(r) if isinstance(day_res, dict) else None
                    durations_df = None
                    swipes_df = None
                    if isinstance(region_obj, dict):
                        swipes_df = region_obj.get("swipes")
                        durations_df = region_obj.get("durations")
                    elif isinstance(region_obj, pd.DataFrame):
                        durations_df = region_obj

                    # count rows for this date / region
                    rows_count = int(len(durations_df)) if durations_df is not None else 0
                    swipe_count = int(len(swipes_df)) if swipes_df is not None else 0
                    date_rows[iso_d] = {"rows": rows_count, "swipe_rows": swipe_count}

                    if durations_df is None or durations_df.empty:
                        continue

                    # normalize columns safety
                    for col in ("person_uid", "EmployeeID", "EmployeeName", "Duration", "DurationSeconds"):
                        if col not in durations_df.columns:
                            durations_df[col] = None

                    # iterate rows and populate map
                    for _, row in durations_df.iterrows():
                        person_uid = row.get("person_uid") or None
                        # fallback key
                        if not person_uid or pd.isna(person_uid):
                            key = f"{str(row.get('EmployeeID') or '').strip()}|{str(row.get('EmployeeName') or '').strip()}"
                            person_uid = key

                        if person_uid not in employees:
                            employees[person_uid] = {
                                "person_uid": person_uid,
                                "EmployeeID": None if pd.isna(row.get("EmployeeID")) else str(row.get("EmployeeID")),
                                "EmployeeName": None if pd.isna(row.get("EmployeeName")) else str(row.get("EmployeeName")),
                                "durations": {d: None for d in dates_iso},
                                "durations_seconds": {d: None for d in dates_iso},
                                "total_seconds_present_in_range": 0
                            }
                        # fill this date
                        dur_str = None if pd.isna(row.get("Duration")) else str(row.get("Duration"))
                        dur_secs = None
                        try:
                            v = row.get("DurationSeconds")
                            if pd.notna(v):
                                dur_secs = int(float(v))
                        except Exception:
                            dur_secs = None

                        employees[person_uid]["durations"][iso_d] = dur_str
                        employees[person_uid]["durations_seconds"][iso_d] = dur_secs
                        if dur_secs is not None:
                            employees[person_uid]["total_seconds_present_in_range"] += dur_secs

                # convert employees map to sorted list (sort by EmployeeName then EmployeeID)
                emp_list = list(employees.values())
                emp_list.sort(key=lambda x: (x.get("EmployeeName") or "").lower(), reverse=False)

                # Keep only top sample_rows in durations_sample (if requested) -- still return full employees list
                durations_sample = emp_list[:sample_rows] if sample_rows and sample_rows > 0 else []

                resp["regions"][r] = {
                    "dates": dates_iso,
                    "employees": emp_list,
                    "durations_sample": durations_sample,
                    "date_rows": date_rows
                }
            except Exception:
                logger.exception("Failed to aggregate range results for region %s", r)
                resp["regions"][r] = {"dates": [d.isoformat() for d in date_list], "employees": [], "durations_sample": [], "date_rows": {}}

        return JSONResponse(resp)
    except HTTPException:
        raise
    except Exception as exc:
        logger.exception("api_duration (range) failed")
        raise HTTPException(status_code=500, detail=f"duration api error: {exc}")


