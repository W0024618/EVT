# Force TLS1.2 for this PowerShell session
[Net.ServicePointManager]::SecurityProtocol = [Net.SecurityProtocolType]::Tls12

# Set variables (replace with real values if not reading from .env)
$clientId = "6222d611-678e-4d57-a98b-83faa86fce76"
$clientSecret = "DKV8Q~Rn4MvlucbxcMsXvAZ6ub_rBVbo-sb6.bGX"
$tenantId = "ce3a67f2-5a22-4fb8-a511-815f8924cda6"

$body = @{
  client_id = $clientId
  scope = "https://graph.microsoft.com/.default"
  client_secret = $clientSecret
  grant_type = "client_credentials"
}

try {
  $resp = Invoke-RestMethod -Method Post -Uri "https://login.microsoftonline.com/$tenantId/oauth2/v2.0/token" -Body $body -ContentType "application/x-www-form-urlencoded" -TimeoutSec 20
  "Got token. Access token length: $($resp.access_token.Length)"
} catch {
  "Token request failed: $($_.Exception.Message)"
  if ($_.Exception.Response) {
    $_.Exception.Response | Select-Object -Property StatusCode, StatusDescription
    try { $_.Exception.Response.GetResponseStream() | Select-String -Pattern '.' -Context 0,1 } catch {}
  }
}








# Show environment proxy variables
Get-ChildItem Env:*proxy* | Format-Table -AutoSize

# Show WinHTTP proxy (used by system services / some apps)
netsh winhttp show proxy









$env:HTTPS_PROXY = "http://proxy.company.local:8080"   # replace with your proxy
$env:HTTP_PROXY  = $env:HTTPS_PROXY
# re-run the token request after forcing TLS1.2 (repeat the Step A block)







$env:CLIENT_ID    = "6222d611-678e-4d57-a98b-83faa86fce76"
$env:CLIENT_SECRET= "DKV8Q~Rn4MvlucbxcMsXvAZ6ub_rBVbo-sb6.bGX"
$env:TENANT_ID    = "ce3a67f2-5a22-4fb8-a511-815f8924cda6"
$env:PRIMARY_EMAIL= "gsoc-globalsecurityoperationcenter.sharedmailbox@westernunion.com"

# then run Python test
python .\test_graph.py







from dotenv import load_dotenv
import os

# load .env from the backend folder (explicit)
root_dir = os.path.dirname(__file__)
dotenv_path = os.path.join(root_dir, '.env')
load_dotenv(dotenv_path)








Get-Content .\log_file.log -Wait
# then trigger a manual fetch via your UI (Refresh) or via curl to /email/inbox endpoint









when i run above command we got below console details 
fix this carefully ...


D:\Email Automation\backend-arun> # Force TLS1.2 for this PowerShell session
>> [Net.ServicePointManager]::SecurityProtocol = [Net.SecurityProtocolType]::Tls12
>>
>> # Set variables (replace with real values if not reading from .env)
>> $clientId = "6222d611-678e-4d57-a98b-83faa86fce76"
>> $clientSecret = "DKV8Q~Rn4MvlucbxcMsXvAZ6ub_rBVbo-sb6.bGX"
>> $tenantId = "ce3a67f2-5a22-4fb8-a511-815f8924cda6"
>>
>> $body = @{
>>   client_id = $clientId
>>   scope = "https://graph.microsoft.com/.default"
>>   client_secret = $clientSecret
>>   grant_type = "client_credentials"
>> }
>>
>> try {
>>   $resp = Invoke-RestMethod -Method Post -Uri "https://login.microsoftonline.com/$tenantId/oauth2/v2.0/token" -
Body $body -ContentType "application/x-www-form-urlencoded" -TimeoutSec 20
>>   "Got token. Access token length: $($resp.access_token.Length)"
>> } catch {
>>   "Token request failed: $($_.Exception.Message)"
>>   if ($_.Exception.Response) {
>>     $_.Exception.Response | Select-Object -Property StatusCode, StatusDescription
>>     try { $_.Exception.Response.GetResponseStream() | Select-String -Pattern '.' -Context 0,1 } catch {}
>>   }
>> }
>>
Got token. Access token length: 1956
PS D:\Email Automation\backend-arun> # Show environment proxy variables
>> Get-ChildItem Env:*proxy* | Format-Table -AutoSize
>>
>> # Show WinHTTP proxy (used by system services / some apps)
>> netsh winhttp show proxy
>>

Current WinHTTP proxy settings:

    Proxy Server(s) :  proxy.wuintranet.net:8080
    Bypass List     :  (none)

PS D:\Email Automation\backend-arun> $env:HTTPS_PROXY = "http://proxy.company.local:8080"   # replace with your pr
oxy
>> $env:HTTP_PROXY  = $env:HTTPS_PROXY
>> # re-run the token request after forcing TLS1.2 (repeat the Step A block)
PS D:\Email Automation\backend-arun> $env:CLIENT_ID    = "6222d611-678e-4d57-a98b-83faa86fce76"
>> $env:CLIENT_SECRET= "DKV8Q~Rn4MvlucbxcMsXvAZ6ub_rBVbo-sb6.bGX"
>> $env:TENANT_ID    = "ce3a67f2-5a22-4fb8-a511-815f8924cda6"
>> $env:PRIMARY_EMAIL= "gsoc-globalsecurityoperationcenter.sharedmailbox@westernunion.com"
>>
PS D:\Email Automation\backend-arun> python .\test_graph.py
>>
CLIENT_ID present: True
TENANT_ID present: True
PRIMARY_EMAIL present: True
Traceback (most recent call last):
  File "C:\Users\S326131HQ\AppData\Roaming\Python\Python312\site-packages\urllib3\connection.py", line 198, in _ne
w_conn
    sock = connection.create_connection(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\S326131HQ\AppData\Roaming\Python\Python312\site-packages\urllib3\util\connection.py", line 60, in
 create_connection
    for res in socket.getaddrinfo(host, port, family, socket.SOCK_STREAM):
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Program Files\Python312\Lib\socket.py", line 963, in getaddrinfo
    for res in _socket.getaddrinfo(host, port, family, type, proto, flags):
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
socket.gaierror: [Errno 11001] getaddrinfo failed

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\S326131HQ\AppData\Roaming\Python\Python312\site-packages\urllib3\connectionpool.py", line 773, in
 urlopen
    self._prepare_proxy(conn)
  File "C:\Users\S326131HQ\AppData\Roaming\Python\Python312\site-packages\urllib3\connectionpool.py", line 1042, i
n _prepare_proxy
    conn.connect()
  File "C:\Users\S326131HQ\AppData\Roaming\Python\Python312\site-packages\urllib3\connection.py", line 753, in con
nect
    self.sock = sock = self._new_conn()
                       ^^^^^^^^^^^^^^^^
  File "C:\Users\S326131HQ\AppData\Roaming\Python\Python312\site-packages\urllib3\connection.py", line 205, in _ne
w_conn
    raise NameResolutionError(self.host, self, e) from e
urllib3.exceptions.NameResolutionError: <urllib3.connection.HTTPSConnection object at 0x000002364AF0A480>: Failed
to resolve 'proxy.company.local' ([Errno 11001] getaddrinfo failed)

The above exception was the direct cause of the following exception:

urllib3.exceptions.ProxyError: ('Unable to connect to proxy', NameResolutionError("<urllib3.connection.HTTPSConnec
tion object at 0x000002364AF0A480>: Failed to resolve 'proxy.company.local' ([Errno 11001] getaddrinfo failed)"))

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\S326131HQ\AppData\Roaming\Python\Python312\site-packages\requests\adapters.py", line 644, in send
    resp = conn.urlopen(
           ^^^^^^^^^^^^^
  File "C:\Users\S326131HQ\AppData\Roaming\Python\Python312\site-packages\urllib3\connectionpool.py", line 871, in
 urlopen
    return self.urlopen(
           ^^^^^^^^^^^^^
  File "C:\Users\S326131HQ\AppData\Roaming\Python\Python312\site-packages\urllib3\connectionpool.py", line 841, in
 urlopen
    retries = retries.increment(
              ^^^^^^^^^^^^^^^^^^
  File "C:\Users\S326131HQ\AppData\Roaming\Python\Python312\site-packages\urllib3\util\retry.py", line 519, in inc
rement
    raise MaxRetryError(_pool, url, reason) from reason  # type: ignore[arg-type]
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='login.microsoftonline.com', port=443): Max retries exc
eeded with url: /ce3a67f2-5a22-4fb8-a511-815f8924cda6/v2.0/.well-known/openid-configuration (Caused by ProxyError(
'Unable to connect to proxy', NameResolutionError("<urllib3.connection.HTTPSConnection object at 0x000002364AF0A48
0>: Failed to resolve 'proxy.company.local' ([Errno 11001] getaddrinfo failed)")))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Email Automation\backend-arun\test_graph.py", line 18, in <module>
    app = msal.ConfidentialClientApplication(CLIENT_ID, authority=authority, client_credential=CLIENT_SECRET)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\S326131HQ\AppData\Roaming\Python\Python312\site-packages\msal\application.py", line 645, in __ini
t__
    self.authority = Authority(
                     ^^^^^^^^^^
  File "C:\Users\S326131HQ\AppData\Roaming\Python\Python312\site-packages\msal\authority.py", line 79, in __init__
    openid_config = tenant_discovery(
                    ^^^^^^^^^^^^^^^^^
  File "C:\Users\S326131HQ\AppData\Roaming\Python\Python312\site-packages\msal\authority.py", line 210, in tenant_
discovery
    resp = http_client.get(tenant_discovery_endpoint, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\S326131HQ\AppData\Roaming\Python\Python312\site-packages\msal\individual_cache.py", line 273, in
wrapper
    value = function(*args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\S326131HQ\AppData\Roaming\Python\Python312\site-packages\msal\throttled_http_client.py", line 99,
 in get
    return NormalizedResponse(self.http_client.get(*args, **kwargs))
                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\S326131HQ\AppData\Roaming\Python\Python312\site-packages\requests\sessions.py", line 602, in get
    return self.request("GET", url, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\S326131HQ\AppData\Roaming\Python\Python312\site-packages\requests\sessions.py", line 589, in requ
est
    resp = self.send(prep, **send_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\S326131HQ\AppData\Roaming\Python\Python312\site-packages\requests\sessions.py", line 703, in send
    r = adapter.send(request, **kwargs)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\S326131HQ\AppData\Roaming\Python\Python312\site-packages\requests\adapters.py", line 671, in send
    raise ProxyError(e, request=request)
requests.exceptions.ProxyError: HTTPSConnectionPool(host='login.microsoftonline.com', port=443): Max retries excee
ded with url: /ce3a67f2-5a22-4fb8-a511-815f8924cda6/v2.0/.well-known/openid-configuration (Caused by ProxyError('U
nable to connect to proxy', NameResolutionError("<urllib3.connection.HTTPSConnection object at 0x000002364AF0A480>
: Failed to resolve 'proxy.company.local' ([Errno 11001] getaddrinfo failed)")))
PS D:\Email Automation\backend-arun> python .\test_graph.py
>>
CLIENT_ID present: True
TENANT_ID present: True
PRIMARY_EMAIL present: True
Traceback (most recent call last):
  File "C:\Users\S326131HQ\AppData\Roaming\Python\Python312\site-packages\urllib3\connection.py", line 198, in _ne
w_conn
    sock = connection.create_connection(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\S326131HQ\AppData\Roaming\Python\Python312\site-packages\urllib3\util\connection.py", line 60, in
 create_connection
    for res in socket.getaddrinfo(host, port, family, socket.SOCK_STREAM):
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Program Files\Python312\Lib\socket.py", line 963, in getaddrinfo
    for res in _socket.getaddrinfo(host, port, family, type, proto, flags):
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
socket.gaierror: [Errno 11001] getaddrinfo failed

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\S326131HQ\AppData\Roaming\Python\Python312\site-packages\urllib3\connectionpool.py", line 773, in
 urlopen
    self._prepare_proxy(conn)
  File "C:\Users\S326131HQ\AppData\Roaming\Python\Python312\site-packages\urllib3\connectionpool.py", line 1042, i
n _prepare_proxy
    conn.connect()
  File "C:\Users\S326131HQ\AppData\Roaming\Python\Python312\site-packages\urllib3\connection.py", line 753, in con
nect
    self.sock = sock = self._new_conn()
                       ^^^^^^^^^^^^^^^^
  File "C:\Users\S326131HQ\AppData\Roaming\Python\Python312\site-packages\urllib3\connection.py", line 205, in _ne
w_conn
    raise NameResolutionError(self.host, self, e) from e
urllib3.exceptions.NameResolutionError: <urllib3.connection.HTTPSConnection object at 0x000001FEE3AB1160>: Failed
to resolve 'proxy.company.local' ([Errno 11001] getaddrinfo failed)

The above exception was the direct cause of the following exception:

urllib3.exceptions.ProxyError: ('Unable to connect to proxy', NameResolutionError("<urllib3.connection.HTTPSConnec
tion object at 0x000001FEE3AB1160>: Failed to resolve 'proxy.company.local' ([Errno 11001] getaddrinfo failed)"))

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\S326131HQ\AppData\Roaming\Python\Python312\site-packages\requests\adapters.py", line 644, in send
    resp = conn.urlopen(
           ^^^^^^^^^^^^^
  File "C:\Users\S326131HQ\AppData\Roaming\Python\Python312\site-packages\urllib3\connectionpool.py", line 871, in
 urlopen
    return self.urlopen(
           ^^^^^^^^^^^^^
  File "C:\Users\S326131HQ\AppData\Roaming\Python\Python312\site-packages\urllib3\connectionpool.py", line 841, in
 urlopen
    retries = retries.increment(
              ^^^^^^^^^^^^^^^^^^
  File "C:\Users\S326131HQ\AppData\Roaming\Python\Python312\site-packages\urllib3\util\retry.py", line 519, in inc
rement
    raise MaxRetryError(_pool, url, reason) from reason  # type: ignore[arg-type]
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='login.microsoftonline.com', port=443): Max retries exc
eeded with url: /ce3a67f2-5a22-4fb8-a511-815f8924cda6/v2.0/.well-known/openid-configuration (Caused by ProxyError(
'Unable to connect to proxy', NameResolutionError("<urllib3.connection.HTTPSConnection object at 0x000001FEE3AB116
0>: Failed to resolve 'proxy.company.local' ([Errno 11001] getaddrinfo failed)")))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Email Automation\backend-arun\test_graph.py", line 20, in <module>
    app = msal.ConfidentialClientApplication(CLIENT_ID, authority=authority, client_credential=CLIENT_SECRET)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\S326131HQ\AppData\Roaming\Python\Python312\site-packages\msal\application.py", line 645, in __ini
t__
    self.authority = Authority(
                     ^^^^^^^^^^
  File "C:\Users\S326131HQ\AppData\Roaming\Python\Python312\site-packages\msal\authority.py", line 79, in __init__
    openid_config = tenant_discovery(
                    ^^^^^^^^^^^^^^^^^
  File "C:\Users\S326131HQ\AppData\Roaming\Python\Python312\site-packages\msal\authority.py", line 210, in tenant_
discovery
    resp = http_client.get(tenant_discovery_endpoint, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\S326131HQ\AppData\Roaming\Python\Python312\site-packages\msal\individual_cache.py", line 273, in
wrapper
    value = function(*args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\S326131HQ\AppData\Roaming\Python\Python312\site-packages\msal\throttled_http_client.py", line 99,
 in get
    return NormalizedResponse(self.http_client.get(*args, **kwargs))
                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\S326131HQ\AppData\Roaming\Python\Python312\site-packages\requests\sessions.py", line 602, in get
    return self.request("GET", url, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\S326131HQ\AppData\Roaming\Python\Python312\site-packages\requests\sessions.py", line 589, in requ
est
    resp = self.send(prep, **send_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\S326131HQ\AppData\Roaming\Python\Python312\site-packages\requests\sessions.py", line 703, in send
    r = adapter.send(request, **kwargs)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\S326131HQ\AppData\Roaming\Python\Python312\site-packages\requests\adapters.py", line 671, in send
    raise ProxyError(e, request=request)
requests.exceptions.ProxyError: HTTPSConnectionPool(host='login.microsoftonline.com', port=443): Max retries excee
ded with url: /ce3a67f2-5a22-4fb8-a511-815f8924cda6/v2.0/.well-known/openid-configuration (Caused by ProxyError('U
nable to connect to proxy', NameResolutionError("<urllib3.connection.HTTPSConnection object at 0x000001FEE3AB1160>
: Failed to resolve 'proxy.company.local' ([Errno 11001] getaddrinfo failed)")))
PS D:\Email Automation\backend-arun> Get-Content .\log_file.log -Wait
>> # then trigger a manual fetch via your UI (Refresh) or via curl to /email/inbox endpoint
2025-09-01 17:20:25,801 - __main__ - INFO - Displayed 137 records from email_logs table.






also check 

D:\Email Automation\backend-arun\test_graph.py

import os, json, sys
from dotenv import load_dotenv
load_dotenv
try:
    import msal, requests
except Exception as e:
    print("Missing packages: ", e)
    sys.exit(1)

CLIENT_ID = os.getenv("CLIENT_ID") or "YOUR_CLIENT_ID"
CLIENT_SECRET = os.getenv("CLIENT_SECRET") or "YOUR_CLIENT_SECRET"
TENANT_ID = os.getenv("TENANT_ID") or "YOUR_TENANT_ID"
PRIMARY_EMAIL = os.getenv("PRIMARY_EMAIL") or "YOUR_PRIMARY_EMAIL"

print("CLIENT_ID present:", CLIENT_ID != "YOUR_CLIENT_ID")
print("TENANT_ID present:", TENANT_ID != "YOUR_TENANT_ID")
print("PRIMARY_EMAIL present:", PRIMARY_EMAIL != "YOUR_PRIMARY_EMAIL")

authority = f"https://login.microsoftonline.com/{TENANT_ID}"
app = msal.ConfidentialClientApplication(CLIENT_ID, authority=authority, client_credential=CLIENT_SECRET)

try:
    token = app.acquire_token_for_client(scopes=["https://graph.microsoft.com/.default"])
    print("MSAL token result keys:", list(token.keys()))
    if "access_token" in token:
        print("Access token length:", len(token["access_token"]))
        headers = {"Authorization": "Bearer " + token["access_token"]}
        r = requests.get(f"https://graph.microsoft.com/v1.0/users/{PRIMARY_EMAIL}/mailFolders/inbox/messages?$top=1", headers=headers, timeout=15)
        print("Graph call status:", r.status_code)
        print("Graph sample response (first 300 chars):", r.text[:300])
    else:
        print("Token error:", json.dumps(token, indent=2))
except Exception as e:
    print("Exception while getting token or calling Graph:", repr(e))







D:\Email Automation\backend-arun\.env

#API key for securing endpoints (replace with your existing API key)
API_KEYS=1b9d6bcd-bbfd-4b2d-9b5d-ab8dfbbd4bed
#Microsoft Graph API credentials (placeholders)
CLIENT_ID=6222d611-678e-4d57-a98b-83faa86fce76
CLIENT_SECRET=DKV8Q~Rn4MvlucbxcMsXvAZ6ub_rBVbo-sb6.bGX 
TENANT_ID=ce3a67f2-5a22-4fb8-a511-815f8924cda6
# BASE_URL=http://localhost:8000

BASE_URL=http://10.199.22.57:3010
# ENV=testing
TEST_EMAIL=gsoc-globalsecurityoperationcenter.sharedmailbox@westernunion.com






D:\Email Automation\backend-arun\app.py

from flask import Flask, Response, request, jsonify
from flask_cors import CORS
from alerts import check_alerts_for_server
from config import Regional_Servers
from log_handler import (
    read_sqlite_alerts_by_date,
    read_email_logs_by_date,
    read_sqlite_alerts_set,
    start_database_writer,
    get_email_response_counts,
    manage_exceptions,
    update_acknowledgment,
    get_image,
    get_allowed_locations,
    manage_location_filter
)
from email_handler import fetch_inbox_emails, trigger_followup_action
import os
import csv
from dotenv import load_dotenv
from functools import wraps
import json
import logging
from apscheduler.schedulers.background import BackgroundScheduler
from filelock import FileLock, Timeout
from datetime import datetime, timedelta
from concurrent.futures import ThreadPoolExecutor

logging.basicConfig(
    level=logging.DEBUG,
    filename='log_file.log',
    filemode='a',
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logging.getLogger("filelock").setLevel(logging.WARNING)
logger = logging.getLogger(__name__)

load_dotenv()
VALID_API_KEYS = os.getenv("API_KEYS", "").split(",")

start_database_writer()

app = Flask(__name__)
CORS(app)
scheduler = BackgroundScheduler()
log = logging.getLogger('werkzeug')
log.disabled = True

executor = ThreadPoolExecutor(max_workers=16)

def check_all_regions():
    job_lock = FileLock("check_all_regions.lock", timeout=10)
    try:
        with job_lock:
            logger.info("Master lock acquired. Starting check_all_regions job.")
            sent_alerts = read_sqlite_alerts_set()
            for server in Regional_Servers:
                check_alerts_for_server(server, sent_alerts)
            logger.info("Finished check_all_regions job. Releasing master lock.")
    except Timeout:
        logger.warning("Could not acquire master lock. Another instance is likely running. Skipping this run.")
    except Exception as e:
        logger.error(f"An exception occurred during check_all_regions: {e}", exc_info=True)

scheduler.add_job(check_all_regions, 'interval', seconds=60, id='check_all_regions_job', max_instances=1)

def require_api_key(f):
    @wraps(f)
    def decorated_function(*args, **kwargs):
        api_key = request.headers.get("X-API-Key") or request.args.get("api_key")
        if not api_key or api_key not in VALID_API_KEYS:
            return jsonify({"description": "Invalid or missing API key"}), 401
        return f(*args, **kwargs)
    return decorated_function

@app.route("/alert-logs-sqlite", methods=["GET"])
@require_api_key
def get_alert_logs_sqlite():
    try:
        today = datetime.now()
        seven_days_ago = today - timedelta(days=7)
        from_date = request.args.get('from_date', seven_days_ago.strftime('%Y-%m-%d'))
        to_date = request.args.get('to_date', today.strftime('%Y-%m-%d'))

        future = executor.submit(read_sqlite_alerts_by_date, from_date, to_date)
        logs = future.result()

        return jsonify(logs)
    except Exception as e:
        logger.error(f"API Error fetching alert logs: {e}", exc_info=True)
        return jsonify({"description": "Error reading database"}), 500

@app.route('/get/email-logs', methods=['GET'])
@require_api_key
def get_email_logs():
    try:
        today = datetime.now()
        seven_days_ago = today - timedelta(days=7)
        from_date = request.args.get('from_date', seven_days_ago.strftime('%Y-%m-%d'))
        to_date = request.args.get('to_date', today.strftime('%Y-%m-%d'))

        future = executor.submit(read_email_logs_by_date, from_date, to_date)
        email_logs = future.result()

        return jsonify(email_logs)
    except Exception as e:
        logger.error(f"API Error fetching email logs: {e}", exc_info=True)
        return jsonify({"error": "Database error"}), 500

@app.route("/acknowledge", methods=["GET"])
def acknowledge_email():
    email_id = request.args.get("email_id")
    logger.debug(f"Acknowledge request received with email_id: {email_id}")
    if not email_id:
        logger.error("Missing 'email_id' in query parameters")
        return """
        <html>
        <body style="font-family: Arial, sans-serif; text-align: center; padding: 20px;">
        <h2>Acknowledgment Failed</h2>
        <p>Missing email ID in the request. Please check the link and try again.</p>
        </body>
        </html>
        """, 400
    try:
        result = update_acknowledgment(email_id)
        if not result:
            logger.error(f"Failed to acknowledge email {email_id}: email_id not found")
            return """
            <html>
            <body style="font-family: Arial, sans-serif; text-align: center; padding: 20px;">
            <h2>Acknowledgment Failed</h2>
            <p>The email ID is invalid or not found. Please check the link and try again.</p>
            </body>
            </html>
            """, 404
        logger.info(f"Email acknowledged successfully: {email_id}")
        return """
        <html>
        <body style="font-family: Arial, sans-serif; text-align: center; padding: 20px;">
        <h2>Acknowledgment Successful</h2>
        <p>Thank you for acknowledging the email (ID: {email_id}).</p>
        <p>You can close this page.</p>
        </body>
        </html>
        """.format(email_id=email_id), 200
    except Exception as e:
        logger.error(f"Error acknowledging email {email_id}: {str(e)}")
        return """
        <html>
        <body style="font-family: Arial, sans-serif; text-align: center; padding: 20px;">
        <h2>Error</h2>
        <p>An error occurred while acknowledging the email: {error}</p>
        <p>Please try again or contact support.</p>
        </body>
        </html>
        """.format(error=str(e)), 500

# (Add any other API routes you need here, following the same pattern)
@app.route("/email/trigger-action", methods=["POST"])
@require_api_key
def trigger_action():
    logger.debug("Triggering action for unacknowledged email")
    data = request.get_json()
    if not data or "email_id" not in data or "action" not in data:
        logger.error("Missing 'email_id' or 'action' in request body")
        return Response(
            json.dumps({"description": "Missing 'email_id' or 'action' in request body"}, indent=2),
            status=400,
            mimetype="application/json"
        )
    email_id = data["email_id"]
    action = data["action"]
    if action not in ["reminder", "hr", "regional_manager"]:
        logger.error(f"Invalid action: {action}")
        return Response(
            json.dumps({"description": f"Invalid action: {action}"}, indent=2),
            status=400,
            mimetype="application/json"
        )
    try:
        trigger_followup_action(email_id, action)
        logger.debug(f"Action triggered: {action} for email {email_id}")
        return Response(
            json.dumps({"status": "success", "message": f"Action {action} triggered for email {email_id}"}, indent=2),
            mimetype="application/json"
        )
    except Exception as e:
        logger.error(f"Error triggering action: {str(e)}")
        return Response(
            json.dumps({"description": f"Error triggering action: {str(e)}"}, indent=2),
            status=500,
            mimetype="application/json"
        )
        
app.route("/curl", methods=["POST"])
@require_api_key
def trigger_alert():
    logger.debug("Trigger alert requested")
    data = request.get_json()
    if not data or "region" not in data:
        logger.error("Missing 'region' in request body")
        return Response(
            json.dumps({"description": "Missing 'region' in request body"}, indent=2),
            status=400,
            mimetype="application/json"
        )
    region = data["region"].upper()
    server = next((s for s in Regional_Servers if s["NAME"] == region), None)
    if not server:
        logger.error(f"Invalid region: {region}")
        return Response(
            json.dumps({"description": f"Invalid region: {region}"}, indent=2),
            status=400,
            mimetype="application/json"
        )
    try:
        check_alerts_for_server(server)
        logger.debug(f"Alert check triggered for {region}")
        return Response(
            json.dumps({"status": "success", "message": f"Alert check triggered for {region}"}, indent=2),
            mimetype="application/json"
        )
    except Exception as e:
        logger.error(f"Error processing alert: {str(e)}")
        return Response(
            json.dumps({"description": f"Error processing alert: {str(e)}"}, indent=2),
            status=500,
            mimetype="application/json"
        )

@app.route("/email/responses-received", methods=["GET"])
@require_api_key
def get_responses_received():
    logger.debug("Fetching count of acknowledged emails")
    try:
        counts = get_email_response_counts()
        return Response(
            json.dumps({"acknowledged_count": counts["acknowledged"]}, indent=2),
            mimetype="application/json"
        )
    except Exception as e:
        logger.error(f"Error fetching acknowledged email count: {str(e)}")
        return Response(
            json.dumps({"description": f"Error fetching acknowledged email count: {str(e)}"}, indent=2),
            status=500,
            mimetype="application/json"
        )

@app.route("/email/responses-sent", methods=["GET"])
@require_api_key
def get_responses_sent():
    logger.debug("Fetching count of sent emails")
    try:
        counts = get_email_response_counts()
        return Response(
            json.dumps({"sent_count": counts["sent"]}, indent=2),
            mimetype="application/json"
        )
    except Exception as e:
        logger.error(f"Error fetching sent email count: {str(e)}")
        return Response(
            json.dumps({"description": f"Error fetching sent email count: {str(e)}"}, indent=2),
            status=500,
            mimetype="application/json"
        )

@app.route("/email/inbox", methods=["GET"])
@require_api_key
def get_inbox():
    logger.debug("Fetching inbox emails")
    try:
        top = int(request.args.get("top", 10))
        skip = int(request.args.get("skip", 0))
        folder = request.args.get("folder", "inbox")
        logger.debug(f"Fetching emails with top={top}, skip={skip}, folder={folder}")
        emails = fetch_inbox_emails(top=top, skip=skip, folder=folder)
        return Response(
            json.dumps({
                "emails": emails,
                "total": len(emails),
                "top": top,
                "skip": skip,
                "folder": folder,
                "has_more": len(emails) == top
            }, indent=2),
            mimetype="application/json"
        )
    except Exception as e:
        logger.error(f"Error fetching inbox emails: {str(e)}")
        return Response(
            json.dumps({"description": f"Error fetching inbox emails: {str(e)}"}, indent=2),
            status=500,
            mimetype="application/json"
        )

@app.route("/email/exceptions", methods=["GET"])
@require_api_key
def get_exceptions():
    logger.debug("Fetching exception list")
    try:
        exceptions = manage_exceptions(action="get")
        return Response(
            json.dumps({"exceptions": exceptions}, indent=2),
            mimetype="application/json"
        )
    except Exception as e:
        logger.error(f"Error fetching exception list: {str(e)}")
        return Response(
            json.dumps({"description": f"Error fetching exception list: {str(e)}"}, indent=2),
            status=500,
            mimetype="application/json"
        )

@app.route("/email/exceptions", methods=["POST"])
@require_api_key
def manage_exceptions_endpoint():
    logger.debug("Managing exception list")
    data = request.get_json()
    if not data or "action" not in data or "email" not in data:
        logger.error("Missing 'action' or 'email' in request body")
        return Response(
            json.dumps({"description": "Missing 'action' or 'email' in request body"}, indent=2),
            status=400,
            mimetype="application/json"
        )
    action = data["action"]
    email = data["email"]
    logger.debug(f"Processing {action} for email: {email}")
    try:
        result = manage_exceptions(action=action, email=email)
        if result is False:
            logger.error(f"Failed to {action} email {email} in exception list")
            return Response(
                json.dumps({"description": f"Failed to {action} email {email} (email not found or invalid)"}, indent=2),
                status=404 if action == "delete" else 400,
                mimetype="application/json"
            )
        logger.info(f"Successfully {action} email {email} in exception list")
        return Response(
            json.dumps({"status": "success", "message": f"Exception list updated: {action} {email}"}, indent=2),
            mimetype="application/json"
        )
    except Exception as e:
        logger.error(f"Error managing exception list for action {action}, email {email}: {str(e)}")
        return Response(
            json.dumps({"description": f"Error managing exception list: {str(e)}"}, indent=2),
            status=500,
            mimetype="application/json"
        )

@app.route("/email/templates", methods=["GET"])
@require_api_key
def get_templates():
    logger.debug("Fetching email templates")
    try:
        with open('templates.json', 'r',encoding='utf-8') as f:
            templates = json.load(f)
        return Response(
            json.dumps({"templates": templates}, indent=2),
            mimetype="application/json"
        )
    except Exception as e:
        logger.error(f"Error fetching email templates: {str(e)}")
        return Response(
            json.dumps({"description": f"Error fetching email templates: {str(e)}"}, indent=2),
            status=500,
            mimetype="application/json"
        )

@app.route("/email/templates", methods=["POST"])
@require_api_key
def manage_templates():
    logger.debug("Managing email templates")
    data = request.get_json()
    logger.debug(f"Received JSON data: {data}")
    if not data or "action" not in data:
        logger.error("Missing 'action' in request body")
        return Response(
            json.dumps({"description": "Missing 'action' in request body"}, indent=2),
            status=400,
            mimetype="application/json"
        )
    action = data["action"]
    if action == "update":
        if "region" not in data or "template_key" not in data or "template_content" not in data:
            logger.error("Missing 'region', 'template_key', or 'template_content' for update action")
            return Response(
                json.dumps({"description": "Missing 'region', 'template_key', or 'template_content' for update action"}, indent=2),
                status=400,
                mimetype="application/json"
            )
        region = data["region"].upper()
        template_key = data["template_key"]
        template_content = data["template_content"]
        logger.debug(f"Processing update: region={region}, template_key={template_key}, template_content={template_content}")
        if not template_content.strip():
            logger.error("Empty template_content provided")
            return Response(
                json.dumps({"description": "Template content cannot be empty"}, indent=2),
                status=400,
                mimetype="application/json"
            )
        try:
            templates = {}
            if os.path.exists('templates.json'):
                with open('templates.json', 'r',encoding='utf-8') as f:
                    templates = json.load(f)
            if region not in templates:
                templates[region] = {}
            templates[region][template_key] = template_content
            with open('templates.json', 'w',encoding='utf-8') as f:
                json.dump(templates, f, indent=2)
            logger.info(f"Successfully updated template for region {region}, key {template_key}")
            return Response(
                json.dumps({"status": "success", "message": f"Template updated for region {region}, key {template_key}"}, indent=2),
                mimetype="application/json"
            )
        except Exception as e:
            logger.error(f"Error updating template for region {region}, key {template_key}: {str(e)}")
            return Response(
                json.dumps({"description": f"Error updating template: {str(e)}"}, indent=2),
                status=500,
                mimetype="application/json"
            )
    elif action == "reset":
        try:
            if reset_templates():
                logger.info("Successfully reset all templates to default")
                return Response(
                    json.dumps({"status": "success", "message": "All templates reset to default"}, indent=2),
                    mimetype="application/json"
                )
            else:
                logger.error("Failed to reset templates to default")
                return Response(
                    json.dumps({"description": "Failed to reset templates to default"}, indent=2),
                    status=500,
                    mimetype="application/json"
                )
        except Exception as e:
            logger.error(f"Error resetting templates: {str(e)}")
            return Response(
                json.dumps({"description": f"Error resetting templates: {str(e)}"}, indent=2),
                status=500,
                mimetype="application/json"
            )
    else:
        logger.error(f"Invalid action: {action}")
        return Response(
            json.dumps({"description": f"Invalid action: {action}"}, indent=2),
            status=400,
            mimetype="application/json"
        )

@app.route("/get/images", methods=["GET"])
@require_api_key
def get_employee_image():
    employee_id = request.args.get("employee_id")
    logger.debug(f"Fetching image for EmployeeID: {employee_id}")
    if not employee_id:
        logger.error("Missing employee_id in query parameters")
        return Response(
            json.dumps({"description": "Missing employee_id in query parameters"}, indent=2),
            status=400,
            mimetype="application/json"
        )
    try:
        image = get_image(employee_id)
        if image:
            logger.debug(f"Image found for EmployeeID: {employee_id}")
            return Response(
                image,
                mimetype="image/jpeg",
                headers={"Content-Disposition": f"inline; filename={employee_id}.jpg"}
            )
        else:
            logger.warning(f"No image found for EmployeeID: {employee_id}")
            return Response(
                json.dumps({"description": f"No image found for EmployeeID: {employee_id}"}, indent=2),
                status=404,
                mimetype="application/json"
            )
    except Exception as e:
        logger.error(f"Error fetching image for EmployeeID {employee_id}: {str(e)}")
        return Response(
            json.dumps({"description": f"Error fetching image: {str(e)}"}, indent=2),
            status=500,
            mimetype="application/json"
        )

@app.route("/alert-logs", methods=["GET"])
@require_api_key
def get_alert_logs():
    log_file = "Book1.csv"
    logger.debug(f"Attempting to read log file: {log_file}")
    if not os.path.exists(log_file):
        logger.error(f"Log file not found: {log_file}")
        return Response(
            json.dumps({"description": "Log file not found"}, indent=2),
            status=404,
            mimetype="application/json"
        )
    try:
        with open(log_file, 'r') as f:
            reader = csv.DictReader(f)
            logs = [row for row in reader]
        logger.debug(f"Successfully read {len(logs)} logs from {log_file}")
        return Response(
            json.dumps(logs, indent=2),
            mimetype="application/json"
        )
    except Exception as e:
        logger.error(f"Error reading log file: {str(e)}")
        return Response(
            json.dumps({"description": f"Error reading log file: {str(e)}"}, indent=2),
            status=500,
            mimetype="application/json"
        )      

@app.route("/locations/filter", methods=["GET"])
@require_api_key
def get_location_filters():
    success, result = manage_location_filter(action="get")
    if success:
        return jsonify({"filters": result})
    else:
        return jsonify({"description": result}), 500

@app.route("/locations/filter", methods=["POST"])
@require_api_key
def add_or_remove_location_filter():
    data = request.get_json()
    if not data or "action" not in data or "region" not in data or "location" not in data:
        return jsonify({"description": "Missing 'action', 'region', or 'location' in request body"}), 400
    
    action = data["action"]
    region = data["region"]
    location = data["location"]

    success, message = manage_location_filter(action=action, region=region, location=location)

    if success:
        return jsonify({"status": "success", "message": message})
    else:
        return jsonify({"description": message}), 500


if __name__ == "__main__":
    # This stricter check ensures the scheduler is NEVER started in the parent
    # reloader process, only in the single, true worker process.
    if os.environ.get('WERKZEUG_RUN_MAIN') == 'true':
        logger.info("Starting scheduler in the main worker process ONLY.")
        if not scheduler.running:
            scheduler.start()
    
    app.run(host="0.0.0.0", port=5000, debug=True)




