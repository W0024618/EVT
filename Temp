(venv) PS C:\Users\W0024618\Desktop\incidenceDashboard\backend> python manage_incidents.py
>>
C:\Users\W0024618\Desktop\incidenceDashboard\backend\manage_incidents.py:18: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).
  ts = datetime.utcnow().strftime("%Y%m%d%H%M%S")
Backed up DB to: C:\Users\W0024618\Desktop\incidenceDashboard\Backend\database.db.bak.20251213075949
Found 3 incident(s):
ID=   3 | Type=Medical              | Impacted=wuemployee           | EmpID=000000       | Date=2025-12-10 | Created=2025-12-12 15:37:55.866653
ID=   2 | Type=Theft                | Impacted=fdgfdg               | EmpID=djfjdfjdjjfj | Date=2025-12-03 | Created=2025-12-03 11:33:05.576336
ID=   1 | Type=Medical              | Impacted=test                 | EmpID=123456       | Date=2025-12-03 | Created=2025-12-03 10:37:14.479089

If you want to remove previous incident(s), you can:
 - enter a single id to delete that incident (e.g. 17)
 - enter 'all' to delete ALL incidents
 - press Enter to skip deletion
Delete choice (id / all / Enter to skip): all
CONFIRM: type YES to actually delete all incidents: yes
Skipping deletion.
Source PDF not found at \mnt\data\DocScanner 13-Dec-2025 10-46 AM.pdf. Please move the file there or change SOURCE_PDF in script.
(venv) PS C:\Users\W0024618\Desktop\incidenceDashboard\backend> 







# database.py
from sqlalchemy import create_engine
from sqlalchemy.ext.declarative import declarative_base
from sqlalchemy.orm import sessionmaker

DATABASE_URL = "sqlite:///./database.db"

engine = create_engine(
    DATABASE_URL,
    connect_args={"check_same_thread": False}
)

SessionLocal = sessionmaker(autocommit=False, autoflush=False, bind=engine)

Base = declarative_base()






# incident_report.py
import os
import json
from typing import Optional, List, Dict, Any
from datetime import datetime, date, time

from fastapi import APIRouter, HTTPException, UploadFile, File, Form
from fastapi.responses import FileResponse
from pydantic import BaseModel, Field, EmailStr, validator
from sqlalchemy import Column, Integer, String, DateTime, Text, func
from sqlalchemy.dialects.sqlite import JSON as SQLITE_JSON

from database import Base, engine, SessionLocal

router = APIRouter(prefix="/incident", tags=["incident"])

# Ensure uploads directory exists
BASE_DIR = os.path.dirname(__file__)
UPLOAD_DIR = os.path.join(BASE_DIR, "uploads")
os.makedirs(UPLOAD_DIR, exist_ok=True)

# -------------------------
# SQLAlchemy model (unchanged structure)
# -------------------------
class IncidentReport(Base):
    __tablename__ = "incident_reports"

    id = Column(Integer, primary_key=True, index=True, autoincrement=True)

    # basic fields (strings)
    type_of_incident = Column(String, nullable=False)   # e.g. Medical / Theft / Other
    other_type_text = Column(String, nullable=True)     # filled when type_of_incident == "Other"

    date_of_report = Column(String, nullable=False)     # ISO date string e.g. "2025-12-03"
    time_of_report = Column(String, nullable=False)     # HH:MM:SS

    impacted_name = Column(String, nullable=False)
    impacted_employee_id = Column(String, nullable=False)

    was_reported_verbally = Column(Integer, default=0)    # 1 = True, 0 = False
    incident_reported_to = Column(String, nullable=True) # JSON-string list when present
    reported_to_details = Column(String, nullable=True)

    location = Column(String, nullable=False)

    reported_by_name = Column(String, nullable=False)
    reported_by_employee_id = Column(String, nullable=False)
    reported_by_email = Column(String, nullable=False)
    reported_by_contact = Column(String, nullable=False)

    date_of_incident = Column(String, nullable=False)
    time_of_incident = Column(String, nullable=False)

    detailed_description = Column(Text, nullable=False)
    immediate_actions_taken = Column(Text, nullable=False)

    accompanying_person = Column(SQLITE_JSON, nullable=True)   # list of {name, contact}
    witnesses = Column(SQLITE_JSON, nullable=True)            # list of strings
    witness_contacts = Column(SQLITE_JSON, nullable=True)     # list of strings

    root_cause_analysis = Column(Text, nullable=True)         # optional
    preventive_actions = Column(Text, nullable=True)          # optional

    proofs = Column(SQLITE_JSON, nullable=True)               # list of uploaded filenames (relative)

    created_at = Column(DateTime, default=datetime.utcnow)

# create tables if not exist
Base.metadata.create_all(bind=engine)


# -------------------------
# Pydantic Schemas (strict types)
# -------------------------
class AccompanyPerson(BaseModel):
    name: str = Field(..., min_length=1)
    contact: str = Field(..., min_length=3)

class IncidentCreate(BaseModel):
    # required
    type_of_incident: str = Field(..., min_length=1)
    other_type_text: Optional[str] = None

    date_of_report: date
    time_of_report: time

    impacted_name: str = Field(..., min_length=1)
    impacted_employee_id: str = Field(..., min_length=1)

    was_reported_verbally: bool

    # If was_reported_verbally true
    incident_reported_to: Optional[List[str]] = None
    reported_to_details: Optional[str] = None

    location: str = Field(..., min_length=1)

    reported_by_name: str = Field(..., min_length=1)
    reported_by_employee_id: str = Field(..., min_length=1)
    reported_by_email: EmailStr
    reported_by_contact: str = Field(..., min_length=3)

    date_of_incident: date
    time_of_incident: time

    detailed_description: str = Field(..., min_length=5)
    immediate_actions_taken: str = Field(..., min_length=1)

    accompanying_person: List[AccompanyPerson] = Field(..., min_items=0)
    witnesses: List[str] = Field(..., min_items=0)
    witness_contacts: List[str] = Field(..., min_items=0)

    root_cause_analysis: Optional[str] = None
    preventive_actions: Optional[str] = None

    @validator("other_type_text", always=True)
    def require_other_text_if_other(cls, v, values):
        if values.get("type_of_incident") and values.get("type_of_incident").strip().lower() == "other":
            if not v or not v.strip():
                raise ValueError("When type_of_incident is 'Other', provide other_type_text.")
            return v
        return v

    @validator("incident_reported_to", always=True)
    def validate_reported_to_if_needed(cls, v, values):
        if values.get("was_reported_verbally"):
            if not v or len(v) == 0:
                raise ValueError("When was_reported_verbally is True, provide incident_reported_to (list).")
        return v

    @validator("reported_to_details", always=True)
    def validate_reported_to_details_if_needed(cls, v, values):
        if values.get("was_reported_verbally"):
            if v is None or not str(v).strip():
                # require details when verbally reported (per your spec)
                raise ValueError("When was_reported_verbally is True, provide reported_to_details (Name and Department).")
        return v

    @validator("witness_contacts", always=True)
    def validate_witness_lengths(cls, v, values):
        w = values.get("witnesses") or []
        if len(w) != len(v):
            raise ValueError("witnesses and witness_contacts must have the same length (parallel arrays).")
        return v

class IncidentOut(BaseModel):
    id: int
    type_of_incident: str
    other_type_text: Optional[str] = None
    date_of_report: str
    time_of_report: str
    impacted_name: str
    impacted_employee_id: str
    was_reported_verbally: bool
    incident_reported_to: Optional[List[str]] = None
    reported_to_details: Optional[str] = None
    location: str
    reported_by_name: str
    reported_by_employee_id: str
    reported_by_email: str
    reported_by_contact: str
    date_of_incident: str
    time_of_incident: str
    detailed_description: str
    immediate_actions_taken: str
    accompanying_person: Optional[List[dict]] = None
    witnesses: Optional[List[str]] = None
    witness_contacts: Optional[List[str]] = None
    root_cause_analysis: Optional[str] = None
    preventive_actions: Optional[str] = None
    proofs: Optional[List[str]] = None
    created_at: datetime

    class Config:
        orm_mode = True


# -------------------------
# Helpers for file saving
# -------------------------
MAX_UPLOAD_BYTES = 10 * 1024 * 1024  # 10 MB per file
ALLOWED_EXTENSIONS = {".png", ".jpg", ".jpeg", ".pdf", ".gif", ".bmp"}

def secure_filename(filename: str) -> str:
    name = "".join(c for c in filename if c.isalnum() or c in (" ", ".", "_", "-")).strip()
    return name or "upload"

def save_uploads_sync(upload_files: Optional[List[UploadFile]]) -> List[str]:
    """
    Save uploaded files under uploads/YYYY/MM/ and return relative paths (YYYY/MM/<ts>_name.ext)
    """
    if not upload_files:
        return []
    saved = []
    for f in upload_files:
        raw_name = getattr(f, "filename", "upload")
        name = secure_filename(raw_name)
        ext = os.path.splitext(name)[1].lower()
        if ext and ext not in ALLOWED_EXTENSIONS:
            raise HTTPException(status_code=400, detail=f"File type not allowed: {ext}")
        f.file.seek(0)
        data = f.file.read()
        if not isinstance(data, (bytes, bytearray)):
            # fallback
            data = bytes(data)
        if len(data) > MAX_UPLOAD_BYTES:
            raise HTTPException(status_code=400, detail=f"File too large: {name}")
        ts = datetime.utcnow().strftime("%Y%m%d%H%M%S%f")
        y = datetime.utcnow().strftime("%Y")
        m = datetime.utcnow().strftime("%m")
        folder = os.path.join(UPLOAD_DIR, y, m)
        os.makedirs(folder, exist_ok=True)
        filename = f"{ts}_{name}"
        path = os.path.join(folder, filename)
        with open(path, "wb") as fh:
            fh.write(data)
        rel = os.path.join(y, m, filename)
        saved.append(rel)
    return saved


# -------------------------
# Endpoints
# -------------------------
@router.post("/create", response_model=IncidentOut)
async def create_incident(
    payload: str = Form(...),
    proofs: Optional[List[UploadFile]] = File(None)
):
    """
    Accepts multipart/form-data:
      - payload: JSON string matching IncidentCreate schema
      - proofs: optional list of files (images, pdf)
    """
    # parse JSON payload
    try:
        data = json.loads(payload)
    except Exception as e:
        raise HTTPException(status_code=400, detail=f"Invalid JSON payload: {e}")

    # validate payload with Pydantic
    try:
        incident = IncidentCreate.parse_obj(data)
    except Exception as e:
        raise HTTPException(status_code=422, detail=str(e))

    db = SessionLocal()
    try:
        saved_files = []
        if proofs:
            # use sync saver (UploadFile.file.read() is OK here)
            saved_files = save_uploads_sync(proofs)

        inst = IncidentReport(
            type_of_incident = incident.type_of_incident.strip(),
            other_type_text = incident.other_type_text.strip() if incident.other_type_text else None,
            date_of_report = incident.date_of_report.isoformat(),
            time_of_report = incident.time_of_report.strftime("%H:%M:%S"),
            impacted_name = incident.impacted_name.strip(),
            impacted_employee_id = incident.impacted_employee_id.strip(),
            was_reported_verbally = 1 if incident.was_reported_verbally else 0,
            incident_reported_to = json.dumps(incident.incident_reported_to) if incident.incident_reported_to else None,
            reported_to_details = incident.reported_to_details.strip() if incident.reported_to_details else None,
            location = incident.location.strip(),
            reported_by_name = incident.reported_by_name.strip(),
            reported_by_employee_id = incident.reported_by_employee_id.strip(),
            reported_by_email = str(incident.reported_by_email),
            reported_by_contact = incident.reported_by_contact.strip(),
            date_of_incident = incident.date_of_incident.isoformat(),
            time_of_incident = incident.time_of_incident.strftime("%H:%M:%S"),
            detailed_description = incident.detailed_description.strip(),
            immediate_actions_taken = incident.immediate_actions_taken.strip(),
            accompanying_person = [p.dict() for p in incident.accompanying_person] if incident.accompanying_person else None,
            witnesses = incident.witnesses if incident.witnesses else None,
            witness_contacts = incident.witness_contacts if incident.witness_contacts else None,
            root_cause_analysis = incident.root_cause_analysis.strip() if incident.root_cause_analysis else None,
            preventive_actions = incident.preventive_actions.strip() if incident.preventive_actions else None,
            proofs = saved_files if saved_files else None,
            created_at = datetime.utcnow()
        )

        db.add(inst)
        db.commit()
        db.refresh(inst)

        # convert incident_reported_to JSON-string back to list for response
        if inst.incident_reported_to:
            try:
                inst.incident_reported_to = json.loads(inst.incident_reported_to)
            except:
                inst.incident_reported_to = None

        return inst

    except Exception as e:
        db.rollback()
        raise HTTPException(status_code=500, detail=str(e))
    finally:
        db.close()


@router.get("/list", response_model=List[IncidentOut])
def list_incidents(
    limit: int = 200,
    page: int = 1,
    page_size: int = 50,
    type_of_incident: Optional[str] = None,
    location: Optional[str] = None,
    start_date: Optional[str] = None,   # ISO date string: YYYY-MM-DD
    end_date: Optional[str] = None      # ISO date string
):
    """
    Returns paginated & filterable incidents.
    Supports: type_of_incident, location substring, start_date, end_date, page, page_size.
    """
    db = SessionLocal()
    try:
        q = db.query(IncidentReport)
        if type_of_incident:
            q = q.filter(IncidentReport.type_of_incident == type_of_incident)
        if location:
            # sqlite uses case-insensitive LIKE by default for ASCII; use lower compare if needed
            q = q.filter(IncidentReport.location.ilike(f"%{location}%"))
        if start_date:
            q = q.filter(IncidentReport.date_of_incident >= start_date)
        if end_date:
            q = q.filter(IncidentReport.date_of_incident <= end_date)

        page = max(page, 1)
        page_size = min(max(page_size, 1), 500)
        offset = (page - 1) * page_size

        rows = q.order_by(IncidentReport.created_at.desc()).offset(offset).limit(page_size).all()

        # parse JSON strings before returning
        for r in rows:
            if isinstance(r.incident_reported_to, str):
                try:
                    r.incident_reported_to = json.loads(r.incident_reported_to)
                except:
                    r.incident_reported_to = None
        return rows
    finally:
        db.close()


@router.get("/{incident_id}", response_model=IncidentOut)
def get_incident(incident_id: int):
    db = SessionLocal()
    try:
        row = db.query(IncidentReport).filter(IncidentReport.id == incident_id).first()
        if not row:
            raise HTTPException(status_code=404, detail="Incident not found")
        if isinstance(row.incident_reported_to, str):
            try:
                row.incident_reported_to = json.loads(row.incident_reported_to)
            except:
                row.incident_reported_to = None
        return row
    finally:
        db.close()


# Attachment download (allow slashes in filename via :path)
@router.get("/{incident_id}/attachment/{filename:path}")
def download_attachment(incident_id: int, filename: str):
    """
    filename should be the relative path stored in 'proofs' (like '2025/12/20251231010101_file.pdf').
    Use the exact relative path when calling (or provide an endpoint that lists attachments).
    """
    safe_path = os.path.normpath(os.path.join(UPLOAD_DIR, filename))
    # Prevent path traversal: ensure safe_path starts with UPLOAD_DIR absolute path
    if not os.path.abspath(safe_path).startswith(os.path.abspath(UPLOAD_DIR)):
        raise HTTPException(status_code=400, detail="Invalid filename")
    if not os.path.exists(safe_path):
        raise HTTPException(status_code=404, detail="Attachment not found")
    return FileResponse(safe_path, filename=os.path.basename(safe_path))


# -------------------------
# Monthly aggregation endpoint
# -------------------------
@router.get("/stats/monthly")
def monthly_stats(year: Optional[int] = None):
    """
    Returns counts grouped by month and incident type.
    Example response:
    {
      "2025-11": {"Medical": 3, "Theft": 1},
      "2025-12": {"Medical": 2, "Other": 5}
    }
    """
    db = SessionLocal()
    try:
        month_label = func.strftime('%Y-%m', IncidentReport.date_of_incident).label('month')
        q = db.query(month_label, IncidentReport.type_of_incident, func.count().label('cnt'))
        if year:
            start = f"{year:04d}-01-01"
            end = f"{year:04d}-12-31"
            q = q.filter(IncidentReport.date_of_incident >= start, IncidentReport.date_of_incident <= end)
        q = q.group_by(month_label, IncidentReport.type_of_incident).order_by(month_label.desc())
        rows = q.all()

        out: Dict[str, Dict[str, int]] = {}
        for month, typ, cnt in rows:
            if month is None:
                month = "unknown"
            out.setdefault(month, {})[typ] = cnt
        return out
    finally:
        db.close()


# -------------------------
# Summary stats endpoint (type-wise & severity estimation)
# -------------------------
@router.get("/stats/summary")
def summary_stats():
    """
    Return overall totals, and totals by type and by month (last 12 months).
    """
    db = SessionLocal()
    try:
        total = db.query(func.count(IncidentReport.id)).scalar()
        by_type = db.query(IncidentReport.type_of_incident, func.count().label('cnt')).group_by(IncidentReport.type_of_incident).all()
        month_label = func.strftime('%Y-%m', IncidentReport.date_of_incident).label('month')
        last_12 = db.query(month_label, func.count().label('cnt')) \
                    .group_by(month_label) \
                    .order_by(month_label.desc()) \
                    .limit(12) \
                    .all()

        return {
            "total": int(total or 0),
            "by_type": {typ: cnt for typ, cnt in by_type},
            "last_12_months": {m: cnt for m, cnt in last_12}
        }
    finally:
        db.close()








# main.py
from fastapi import FastAPI
from fastapi.middleware.cors import CORSMiddleware
from incident_report import router as incident_router

app = FastAPI(title="Incident Reporting API")

origins = [
    "http://localhost:3000",
    "http://127.0.0.1:3000",
    # add other origins if frontend hosted elsewhere
]

app.add_middleware(
    CORSMiddleware,
    allow_origins=origins,
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

app.include_router(incident_router)

@app.get("/")
def read_root():
    return {"message": "Incident Reporting Backend is running"}











# manage_incidents.py
import os
import shutil
import sqlite3
import json
from datetime import datetime
from pathlib import Path

# Path config - update if your paths differ
BASE_DIR = Path(__file__).resolve().parent
DB_PATH = BASE_DIR / "database.db"
BACKUP_DIR = BASE_DIR
UPLOADS_DIR = BASE_DIR / "uploads"
# Path to the PDF you uploaded (adjust if you copied it somewhere else)
SOURCE_PDF = Path("/mnt/data/DocScanner 13-Dec-2025 10-46 AM.pdf")

def backup_db():
    ts = datetime.utcnow().strftime("%Y%m%d%H%M%S")
    bak = BACKUP_DIR / f"database.db.bak.{ts}"
    shutil.copy2(DB_PATH, bak)
    print(f"Backed up DB to: {bak}")
    return bak

def list_incidents(conn):
    cur = conn.cursor()
    cur.execute("SELECT id, type_of_incident, impacted_name, impacted_employee_id, date_of_incident, created_at FROM incident_reports ORDER BY created_at DESC")
    rows = cur.fetchall()
    if not rows:
        print("No incidents found.")
        return []
    print(f"Found {len(rows)} incident(s):")
    for r in rows:
        print(f"ID={r[0]:>4} | Type={r[1]!s:20.20} | Impacted={r[2]!s:20.20} | EmpID={r[3]!s:12.12} | Date={r[4]} | Created={r[5]}")
    return rows

def delete_incident(conn, incident_id):
    cur = conn.cursor()
    cur.execute("SELECT id FROM incident_reports WHERE id = ?", (incident_id,))
    if cur.fetchone() is None:
        print("No such id:", incident_id)
        return False
    cur.execute("DELETE FROM incident_reports WHERE id = ?", (incident_id,))
    conn.commit()
    print(f"Deleted incident id={incident_id}")
    return True

def delete_all_incidents(conn):
    cur = conn.cursor()
    cur.execute("DELETE FROM incident_reports")
    conn.commit()
    print("Deleted ALL incidents (careful!).")

def sanitize_name(name: str) -> str:
    return "".join(c for c in name if c.isalnum() or c in (" ", ".", "_", "-")).strip() or "upload"

def save_pdf_to_uploads(source: Path) -> str:
    # ensure uploads dir exists
    UPLOADS_DIR.mkdir(parents=True, exist_ok=True)
    now = datetime.utcnow()
    y = now.strftime("%Y")
    m = now.strftime("%m")
    folder = UPLOADS_DIR / y / m
    folder.mkdir(parents=True, exist_ok=True)
    name = sanitize_name(source.name)
    ts = now.strftime("%Y%m%d%H%M%S%f")
    dest_name = f"{ts}_{name}"
    dest = folder / dest_name
    shutil.copy2(source, dest)
    rel = os.path.join(y, m, dest_name)  # stored as relative path in DB proofs
    print(f"Saved PDF to: {dest}  (relative path saved in DB: {rel})")
    return rel

def insert_incident(conn, payload: dict):
    cur = conn.cursor()
    # columns in table (as per your model)
    cols = [
        "type_of_incident","other_type_text","date_of_report","time_of_report",
        "impacted_name","impacted_employee_id","was_reported_verbally","incident_reported_to","reported_to_details",
        "location","reported_by_name","reported_by_employee_id","reported_by_email","reported_by_contact",
        "date_of_incident","time_of_incident","detailed_description","immediate_actions_taken",
        "accompanying_person","witnesses","witness_contacts","root_cause_analysis","preventive_actions",
        "proofs","created_at"
    ]
    placeholders = ",".join("?" for _ in cols)
    values = [payload.get(c) for c in cols]
    cur.execute(f"INSERT INTO incident_reports ({','.join(cols)}) VALUES ({placeholders})", values)
    conn.commit()
    return cur.lastrowid

def prompt_with_default(prompt_text, default=None):
    if default:
        v = input(f"{prompt_text} [{default}]: ").strip()
        return v if v else default
    else:
        return input(f"{prompt_text}: ").strip()

def main():
    if not DB_PATH.exists():
        print("Database not found at", DB_PATH)
        return
    # backup
    backup_db()

    conn = sqlite3.connect(str(DB_PATH))
    conn.row_factory = sqlite3.Row

    # list existing incidents
    rows = list_incidents(conn)

    # ask user if they want to delete existing entries
    if rows:
        print("\nIf you want to remove previous incident(s), you can:")
        print(" - enter a single id to delete that incident (e.g. 17)")
        print(" - enter 'all' to delete ALL incidents")
        print(" - press Enter to skip deletion")
        choice = input("Delete choice (id / all / Enter to skip): ").strip().lower()
        if choice == "all":
            confirm = input("CONFIRM: type YES to actually delete all incidents: ")
            if confirm == "YES":
                delete_all_incidents(conn)
            else:
                print("Skipping deletion.")
        elif choice.isdigit():
            delete_incident(conn, int(choice))
        else:
            print("No deletion performed.")

    # ensure source PDF exists
    if not SOURCE_PDF.exists():
        print(f"Source PDF not found at {SOURCE_PDF}. Please move the file there or change SOURCE_PDF in script.")
        return

    # save pdf into uploads and get relative path
    rel_proof_path = save_pdf_to_uploads(SOURCE_PDF)  # e.g. "2025/12/2025....pdf"

    # prefill date fields from file mtime
    mtime = datetime.fromtimestamp(SOURCE_PDF.stat().st_mtime)
    pre_date = mtime.date().isoformat()
    pre_time = mtime.time().strftime("%H:%M:%S")

    print("\nNow enter details for the new incident (press Enter to accept the default shown in brackets).")
    # required fields
    type_of_incident = prompt_with_default("Type of incident (e.g. Medical, Theft, Fire, Other)", "Other")
    other_type_text = None
    if type_of_incident.strip().lower() == "other":
        other_type_text = prompt_with_default("If 'Other', please provide the specific type", "Documented Report (scanned)")
    date_of_report = prompt_with_default("Date of report (YYYY-MM-DD)", pre_date)
    time_of_report = prompt_with_default("Time of report (HH:MM or HH:MM:SS)", pre_time[:8])
    impacted_name = prompt_with_default("Impacted person name", "Unknown")
    impacted_employee_id = prompt_with_default("Impacted employee ID", "N/A")
    was_reported_verbally = prompt_with_default("Was reported verbally before? (yes/no)", "no").lower().startswith("y")
    incident_reported_to = []
    reported_to_details = None
    if was_reported_verbally:
        reporter = prompt_with_default("Incident reported to (comma-separated names/roles)", "Supervisor")
        incident_reported_to = [s.strip() for s in reporter.split(",") if s.strip()]
        reported_to_details = prompt_with_default("Reported to details (Name & Department)", "Supervisor - Operations")
    location = prompt_with_default("Location (Office/Branch)", "Head Office")
    reported_by_name = prompt_with_default("Reported by - Name", "Registrar")
    reported_by_employee_id = prompt_with_default("Reported by - Employee ID", "REG-001")
    reported_by_email = prompt_with_default("Reported by - Email", "registrar@example.com")
    reported_by_contact = prompt_with_default("Reported by - Contact", "+0000000000")
    date_of_incident = prompt_with_default("Date of incident occurred (YYYY-MM-DD)", pre_date)
    time_of_incident = prompt_with_default("Time of incident occurred (HH:MM or HH:MM:SS)", pre_time[:8])
    detailed_description = prompt_with_default("Detailed description (short)", "See attached scanned document.")
    immediate_actions_taken = prompt_with_default("Immediate actions taken", "Recorded in register; further action pending.")
    accompanying_person = []  # left empty; add if needed
    witnesses = []  # empty
    witness_contacts = []  # empty
    root_cause_analysis = prompt_with_default("Root cause analysis (optional)", "")
    preventive_actions = prompt_with_default("Preventive actions (optional)", "")

    payload = {
        "type_of_incident": type_of_incident,
        "other_type_text": other_type_text,
        "date_of_report": date_of_report,
        "time_of_report": time_of_report if len(time_of_report)==8 else (time_of_report + ":00" if len(time_of_report)==5 else time_of_report),
        "impacted_name": impacted_name,
        "impacted_employee_id": impacted_employee_id,
        "was_reported_verbally":  bool(was_reported_verbally),
        "incident_reported_to": incident_reported_to or None,
        "reported_to_details": reported_to_details,
        "location": location,
        "reported_by_name": reported_by_name,
        "reported_by_employee_id": reported_by_employee_id,
        "reported_by_email": reported_by_email,
        "reported_by_contact": reported_by_contact,
        "date_of_incident": date_of_incident,
        "time_of_incident": time_of_incident if len(time_of_incident)==8 else (time_of_incident + ":00" if len(time_of_incident)==5 else time_of_incident),
        "detailed_description": detailed_description,
        "immediate_actions_taken": immediate_actions_taken,
        "accompanying_person": json.dumps(accompanying_person) if accompanying_person else None,
        "witnesses": json.dumps(witnesses) if witnesses else None,
        "witness_contacts": json.dumps(witness_contacts) if witness_contacts else None,
        "root_cause_analysis": root_cause_analysis or None,
        "preventive_actions": preventive_actions or None,
        # proofs: store as JSON array of relative paths (same as your schema)
        "proofs": json.dumps([rel_proof_path]),
        "created_at": datetime.utcnow().isoformat()
    }

    # Convert None to NULL-able values expected by DB insertion: use None for those
    # Prepare insertion using columns used in your model
    insert_data = (
        payload["type_of_incident"],
        payload["other_type_text"],
        payload["date_of_report"],
        payload["time_of_report"],
        payload["impacted_name"],
        payload["impacted_employee_id"],
        1 if payload["was_reported_verbally"] else 0,
        payload["incident_reported_to"],
        payload["reported_to_details"],
        payload["location"],
        payload["reported_by_name"],
        payload["reported_by_employee_id"],
        payload["reported_by_email"],
        payload["reported_by_contact"],
        payload["date_of_incident"],
        payload["time_of_incident"],
        payload["detailed_description"],
        payload["immediate_actions_taken"],
        payload["accompanying_person"],
        payload["witnesses"],
        payload["witness_contacts"],
        payload["root_cause_analysis"],
        payload["preventive_actions"],
        payload["proofs"],
        payload["created_at"]
    )

    cur = conn.cursor()
    cur.execute("""
        INSERT INTO incident_reports (
            type_of_incident, other_type_text, date_of_report, time_of_report,
            impacted_name, impacted_employee_id, was_reported_verbally, incident_reported_to, reported_to_details,
            location, reported_by_name, reported_by_employee_id, reported_by_email, reported_by_contact,
            date_of_incident, time_of_incident, detailed_description, immediate_actions_taken,
            accompanying_person, witnesses, witness_contacts, root_cause_analysis, preventive_actions,
            proofs, created_at
        ) VALUES (?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?)
    """, insert_data)
    conn.commit()
    new_id = cur.lastrowid
    print(f"\nNew incident inserted with id = {new_id}")
    print("Proofs saved (relative path stored in DB):", [rel_proof_path])
    conn.close()

if __name__ == "__main__":
    main()






