i dont understand where add this below helper 
so add this hepler and share me fully uodated file 
so i can easily swap file each orher.

note - dont make any unnecesswry logical changs



2) Recompute per-row gaps/duration from the raw swipe rows after DisplayDate is set

This is the key fix to remove false long_gap items that are only caused because swipes were split across the boundary. Add the helper function and call it just after features['DisplayDate'] is computed (in run_trend_for_date) and before scenario evaluation. The helper re-calculates per-row MaxSwipeGapSeconds, CountSwipes, FirstSwipe, LastSwipe, DurationSeconds, DurationMinutes using the raw sw_for_features with dates assigned the same way the backend used to compute the DisplayDate (it uses AdjustedMessageTime for Pune2AM logic, or LocaleMessageTime otherwise).

Add this helper function somewhere near other helpers (top-level in the file):



def _recompute_gaps_from_raw_swipes(sw_df, features_df, date_col_for_raw='AdjustedMessageTime'):
    """
    Recompute per-feature row MaxSwipeGapSeconds / CountSwipes / FirstSwipe / LastSwipe / Duration*
    by grouping the raw swipe rows by (person_uid, display_date).
    sw_df: raw sw_for_features (must contain 'person_uid' and either 'AdjustedMessageTime' or 'LocaleMessageTime')
    features_df: features DataFrame with 'person_uid' and 'DisplayDate' columns (dates)
    This mutates features_df in place (updates values when more accurate raw info exists).
    """
    try:
        if sw_df is None or sw_df.empty or features_df is None or features_df.empty:
            return
        tmp = sw_df.copy()
        # choose the timestamp used for logical day grouping
        if 'AdjustedMessageTime' in tmp.columns and tmp['AdjustedMessageTime'].notna().any():
            tmp['_ts_local_for_display'] = pd.to_datetime(tmp['AdjustedMessageTime'], errors='coerce')
        else:
            # fall back to LocaleMessageTime
            tmp['_ts_local_for_display'] = pd.to_datetime(tmp['LocaleMessageTime'], errors='coerce')

        # assign display_date per raw row (same boundary that created DisplayDate)
        tmp['_display_date'] = tmp['_ts_local_for_display'].dt.date

        # group
        grp = tmp.dropna(subset=['person_uid', '_display_date']).groupby(['person_uid', '_display_date'])
        counts = grp.size()
        firsts = grp['_ts_local_for_display'].min()
        lasts = grp['_ts_local_for_display'].max()

        # compute max gap per group
        max_gaps = {}
        for (pid, d), g in grp:
            times = sorted(g['_ts_local_for_display'].dropna().tolist())
            mg = 0
            for i in range(1, len(times)):
                s = int((times[i] - times[i-1]).total_seconds())
                if s > mg:
                    mg = s
            max_gaps[(str(pid), d)] = int(mg)

        # iterate features rows and update where raw gives better info for same display date
        for idx, row in features_df.reset_index().iterrows():
            real_idx = int(row['index']) if 'index' in row else row['index'] if 'index' in row else row.name
            pid = row.get('person_uid')
            disp = row.get('DisplayDate') or row.get('Date')
            if pid is None or disp is None:
                continue
            key = (str(pid), disp) if isinstance(disp, (date,)) else (str(pid), disp)
            # our keys in max_gaps use python date; make sure types match
            k2 = (str(pid), disp)
            if k2 in max_gaps:
                try:
                    features_df.at[real_idx, 'MaxSwipeGapSeconds'] = int(max_gaps[k2])
                except Exception:
                    pass
            # counts/first/last/duration
            try:
                c = int(counts.get((pid, disp), counts.get((str(pid), disp), 0)))
                if c and (int(row.get('CountSwipes', 0)) == 0):
                    features_df.at[real_idx, 'CountSwipes'] = int(c)
                f = firsts.get((pid, disp)) if (pid, disp) in firsts.index else firsts.get((str(pid), disp))
                l = lasts.get((pid, disp)) if (pid, disp) in lasts.index else lasts.get((str(pid), disp))
                if pd.notna(f) and (pd.isna(row.get('FirstSwipe')) or row.get('FirstSwipe') is None):
                    features_df.at[real_idx, 'FirstSwipe'] = pd.to_datetime(f)
                if pd.notna(l) and (pd.isna(row.get('LastSwipe')) or row.get('LastSwipe') is None):
                    features_df.at[real_idx, 'LastSwipe'] = pd.to_datetime(l)
                # recompute duration if possible
                fs = features_df.at[real_idx, 'FirstSwipe']
                ls = features_df.at[real_idx, 'LastSwipe']
                if pd.notna(fs) and pd.notna(ls):
                    dursec = max(0, (pd.to_datetime(ls) - pd.to_datetime(fs)).total_seconds())
                    features_df.at[real_idx, 'DurationSeconds'] = float(dursec)
                    features_df.at[real_idx, 'DurationMinutes'] = float(dursec / 60.0)
            except Exception:
                continue
    except Exception:
        logging.exception("Failed to recompute gaps from raw swipes (non-fatal).")






Then, in run_trend_for_date(...), after you compute features and after you set DisplayDate (there is a block:



# ------------------ FIXED: restore 2am boundary then compute DisplayDate ------------------
...
features['DisplayDate'] = ...





) insert a call to recompute gaps using the sw_for_features you already prepared, e.g.:




    # recompute per-row gaps/durations using raw sw_for_features grouped by display date
    try:
        _recompute_gaps_from_raw_swipes(sw_for_features, features)
    except Exception:
        logging.exception("Error during recompute_gaps_from_raw_swipes (non-fatal).")
