Now Backend is Working 
i have check when 
using Employee ID http://localhost:8002/employee/326131/image
We Got Employee Image 
Now Update IN frontend Carefully

i Once Refer Backend File carefully and Fix the Frontend issue beacause backend Fetch Employe image as well Employee image but frontend 
display No image and blank Email section we need to fix this issue ....



INFO:root:Connected to ACVSCore on SRVWUPNQ0986V using SQL auth (region apac).
INFO:root:get_personnel_info: found ObjectID=2097188645 Email=Yamila.Peraza@wu.com for candidate=315037
INFO:root:Connected to ACVSCore on SRVWUPNQ0986V using SQL auth (region apac).
INFO:root:get_personnel_info: found ObjectID=2097188645 Email=Yamila.Peraza@wu.com for candidate=315037
INFO:root:Connected to ACVSCore on SRVWUPNQ0986V using SQL auth (region apac).
INFO:root:get_personnel_info: found ObjectID=2097188645 Email=Yamila.Peraza@wu.com for candidate=315037
INFO:werkzeug:127.0.0.1 - - [20/Nov/2025 12:49:24] "GET /record?employee_id=315037 HTTP/1.1" 200 -




# backend/app.py
from flask import Flask, jsonify, request, send_from_directory, jsonify, send_file
from datetime import datetime, timedelta, date
from pathlib import Path
import logging
import pandas as pd
import numpy as np
import joblib
import math
import re
import io
import base64
import os
import difflib
from io import BytesIO
from flask import send_file  # add if not present
from pathlib import Path
from typing import Optional, List, Dict, Any
from duration_report import REGION_CONFIG
from datetime import date, timedelta, datetime
from flask import jsonify, request
import logging
logging.basicConfig(level=logging.INFO)


# Robust import of employeeimage helpers (use fallback if unavailable)
try:
    from employeeimage import get_person_image_bytes, get_personnel_info
except Exception:
    def get_person_image_bytes(pid):
        return None
    def get_personnel_info(pid):
        return {}


from config.door_zone import map_door_to_zone, BREAK_ZONES, OUT_OF_OFFICE_ZONE


from trend_runner import run_trend_for_date, build_monthly_training


from io import BytesIO
# try to import imghdr (may be missing in some minimal Python builds)
try:
    import imghdr as _imghdr
except Exception:
    _imghdr = None

def _guess_image_kind(data_bytes):
    """Return image kind like 'jpeg', 'png', 'gif', 'webp' or None."""
    # 1) try imghdr if available
    try:
        if _imghdr:
            k = _imghdr.what(None, h=data_bytes)
            if k:
                return k
    except Exception:
        pass

    # 2) try Pillow if installed
    try:
        from io import BytesIO as _BytesIO
        from PIL import Image as _Image
        bio = _BytesIO(data_bytes)
        img = _Image.open(bio)
        fmt = getattr(img, 'format', None)
        if fmt:
            return fmt.lower()
    except Exception:
        pass

    # 3) last-resort: quick magic-bytes sniff for common formats
    try:
        header = data_bytes[:12]
        if header.startswith(b'\xff\xd8\xff'):
            return 'jpeg'
        if header.startswith(b'\x89PNG\r\n\x1a\n'):
            return 'png'
        if header[:6] in (b'GIF87a', b'GIF89a'):
            return 'gif'
        if header.startswith(b'RIFF') and header[8:12] == b'WEBP':
            return 'webp'
    except Exception:
        pass

    return None


# import helpers that exist in your employeeimage.py
try:
    from employeeimage import get_person_image_bytes, get_personnel_info
except Exception:
    # if module missing, define fallbacks so app still runs
    def get_person_image_bytes(pid):
        return None
    def get_personnel_info(pid):
        return {}


# create Flask app early (must exist before any @app.route usage)
from flask import Flask
try:
    from flask_cors import CORS
    _HAS_CORS = True
except Exception:
    CORS = None
    _HAS_CORS = False

app = Flask(__name__, static_folder=None)
if _HAS_CORS:
    CORS(app)
else:
    logging.warning("flask_cors not available; continuing without CORS.")



def _safe_read_csv(fp):
    try:
        return pd.read_csv(fp, parse_dates=['LocaleMessageTime'], low_memory=False)
    except Exception:
        try:
            return pd.read_csv(fp, low_memory=False)
        except Exception:
            return pd.DataFrame()

#path 
BASE_DIR = Path(__file__).parent.resolve()
DEFAULT_OUTDIR = BASE_DIR / "outputs"
DEFAULT_OUTDIR.mkdir(parents=True, exist_ok=True)

OUTDIR = DEFAULT_OUTDIR

OVERRIDES_FILE = DEFAULT_OUTDIR / "overrides.csv"


def _load_overrides():
    if not OVERRIDES_FILE.exists():
        return {}
    try:
        df = pd.read_csv(OVERRIDES_FILE, dtype=str)
        out = {}
        for _, r in df.iterrows():
            emp = str(r.get('EmployeeID') or r.get('person_uid') or '').strip()
            if not emp:
                continue
            out[emp] = {
                'level': str(r.get('OverrideLevel') or '').strip(),
                'reason': str(r.get('Reason') or '').strip(),
                'ts': str(r.get('Timestamp') or '').strip()
            }
        return out
    except Exception:
        logging.exception("Failed reading overrides file")
        return {}

def _save_override(employee_key, level, reason):
    now = datetime.now().isoformat()
    row = {'EmployeeID': employee_key, 'OverrideLevel': level, 'Reason': reason or '', 'Timestamp': now}
    try:
        if OVERRIDES_FILE.exists():
            df = pd.read_csv(OVERRIDES_FILE, dtype=str)
            # pandas.DataFrame.append is deprecated -> use concat
            df = pd.concat([df, pd.DataFrame([row])], ignore_index=True)
        else:
            df = pd.DataFrame([row])
        df.to_csv(OVERRIDES_FILE, index=False)
        return True
    except Exception:
        logging.exception("Failed to save override")
        return False

def _slug_city(s):
    """
    Convert a city/site string into a safe slug: lowercase, alphanumeric+hyphen
    """
    if not s:
        return ''
    # Remove special chars, spaces to hyphens, lower
    slug = re.sub(r'[^\w\s-]', '', str(s)).strip().lower()
    slug = re.sub(r'[\s_]+', '-', slug)
    return slug



_acvscore_backoff = {"ts": None, "failed": False}
_ACVSCORE_BACKOFF_SECONDS = 20


# ODBC driver (keep existing env-based driver)
ODBC_DRIVER = os.getenv("ODBC_DRIVER", "ODBC Driver 17 for SQL Server")

MODELS_DIR = Path(__file__).parent / "models"
_loaded_models = {}

def load_model(name):
    if name in _loaded_models:
        return _loaded_models[name]
    p = MODELS_DIR / f"{name}.joblib"
    if not p.exists():
        return None
    data = joblib.load(p)
    _loaded_models[name] = data
    return data







# send_file is needed for Excel responses
from flask import send_file
try:
    # optional import; used for styling
    from openpyxl import load_workbook
    from openpyxl.styles import Font, Alignment, Border, Side
    OPENPYXL_AVAILABLE = True
except Exception:
    OPENPYXL_AVAILABLE = False

def _to_python_scalar(x):
    """
    Convert numpy/pandas scalar types to built-in Python types and
    convert NaN-like values to None so JSON is safe.
    """
    try:
        import pandas as _pd
        if isinstance(x, _pd.Timestamp):
            return x.to_pydatetime().isoformat()
    except Exception:
        pass

    try:
        import numpy as _np
        if isinstance(x, _np.generic):
            v = x.item()
            if isinstance(v, float) and _np.isnan(v):
                return None
            return v
    except Exception:
        pass

    try:
        if isinstance(x, float) and math.isnan(x):
            return None
    except Exception:
        pass

    if isinstance(x, (datetime,)):
        return x.isoformat()
    if isinstance(x, (bool, int, str, type(None), float)):
        # convert floats NaN handled above
        return x
    try:
        # fallback to string
        return str(x)
    except Exception:
        return None


_uuid_like_re = re.compile(r'^[0-9a-fA-F]{8}\-[0-9a-fA-F]{4}\-[0-9a-fA-F]{4}\-[0-9a-fA-F]{4}\-[0-9a-fA-F]{12}$')

def _looks_like_guid(s):
    try:
        if not s or not isinstance(s, str):
            return False
        s = s.strip()
        return bool(_uuid_like_re.match(s)) or s.startswith('name:') or s.startswith('emp:') or s.startswith('uid:')
    except Exception:
        return False


# Helper: format seconds to HH:MM:SS
def format_seconds_to_hms(seconds):
    try:
        if seconds is None:
            return None
        # guard against floats and NaN
        s = int(float(seconds))
        if s < 0:
            s = 0
        hh = s // 3600
        mm = (s % 3600) // 60
        ss = s % 60
        return f"{hh:02d}:{mm:02d}:{ss:02d}"
    except Exception:
        return None


# Placeholder tokens (keep consistent with trend_runner expectations)
_PLACEHOLDER_STRS = set(['', 'nan', 'na', 'n/a', '-', '—', '–', 'none', 'null'])

def _is_placeholder_str(s: object) -> bool:
    try:
        if s is None:
            return True
        st = str(s).strip().lower()
        return st in _PLACEHOLDER_STRS
    except Exception:
        return False


_CARD_XML_RE = re.compile(r'<Card>([^<]+)</Card>', re.IGNORECASE | re.DOTALL)
def _extract_card_from_xml_text(txt):
    try:
        if not txt or not isinstance(txt, str):
            return None
        m = _CARD_XML_RE.search(txt)
        if m:
            return m.group(1).strip()
        m2 = re.search(r'CHUID.*?Card.*?[:=]\s*([0-9A-Za-z\-\_]+)', txt, re.IGNORECASE | re.DOTALL)
        if m2:
            return m2.group(1).strip()
    except Exception:
        pass
    return None


def _resolve_field_from_record(record: dict, candidate_tokens: list):
    """
    Search a single row `record` (dict) for likely columns listed in candidate_tokens.
    Return first non-placeholder value found (converted to Python scalar), else None.
    """
    if record is None:
        return None

    # 1) exact key matches (case-sensitive & common casing)
    for key in candidate_tokens:
        if key in record:
            v = record.get(key)
            if v is None:
                continue
            if isinstance(v, float) and math.isnan(v):
                continue
            sval = str(v).strip()
            if sval and not _is_placeholder_str(sval):
                return _to_python_scalar(v)

    # 2) case-insensitive contains match
    lower_keys = {k.lower(): k for k in record.keys()}
    for tok in candidate_tokens:
        tok_l = tok.lower()
        for lk, orig_key in lower_keys.items():
            if tok_l in lk:
                v = record.get(orig_key)
                if v is None:
                    continue
                if isinstance(v, float) and math.isnan(v):
                    continue
                sval = str(v).strip()
                if sval and not _is_placeholder_str(sval):
                    return _to_python_scalar(v)

    # 3) xml / value parsing fallback for CardNumber
    card_like = any(tok.lower() in ('cardnumber', 'chuid', 'card') for tok in candidate_tokens)
    if card_like:
        for lk, orig_key in lower_keys.items():
            if 'xml' in lk or 'xmlmessage' in lk or 'xml_msg' in lk or 'msg' in lk or 'value' == lk:
                v = record.get(orig_key)
                if v is None:
                    continue
                try:
                    txt = str(v)
                    extracted = _extract_card_from_xml_text(txt)
                    if extracted and not _is_placeholder_str(extracted):
                        return _to_python_scalar(extracted)
                except Exception:
                    continue

    # 4) final fallback: first non-placeholder value
    for k, v in record.items():
        if v is None:
            continue
        if isinstance(v, float) and math.isnan(v):
            continue
        sval = str(v).strip()
        if sval and not _is_placeholder_str(sval):
            return _to_python_scalar(v)

    return None


def _clean_sample_df(df: pd.DataFrame, max_rows: int = 10):
    """
    Clean a dataframe for JSON output (convert NaN -> None, pandas types -> native, format datetimes).
    """
    if df is None or df.empty:
        return []
    df = df.copy()

    # remove duplicate suffix columns
    cols_to_fix = [c for c in df.columns if c.endswith('_x') or c.endswith('_y')]
    for c in cols_to_fix:
        base = c[:-2]
        if base in df.columns:
            try:
                df.drop(columns=[c], inplace=True)
            except Exception:
                pass
        else:
            try:
                df.rename(columns={c: base}, inplace=True)
            except Exception:
                pass

    # Date normalization
    if 'Date' in df.columns:
        try:
            df['Date'] = pd.to_datetime(df['Date'], errors='coerce').dt.date
            df['Date'] = df['Date'].apply(lambda d: d.isoformat() if pd.notna(d) else None)
        except Exception:
            pass

    # Datetime columns to ISO strings
    for dtcol in ('FirstSwipe', 'LastSwipe', 'LocaleMessageTime'):
        if dtcol in df.columns:
            try:
                df[dtcol] = pd.to_datetime(df[dtcol], errors='coerce')
                df[dtcol] = df[dtcol].apply(lambda t: t.to_pydatetime().isoformat() if pd.notna(t) else None)
            except Exception:
                try:
                    df[dtcol] = df[dtcol].astype(str).replace('NaT', None)
                except Exception:
                    pass

    # Replace NaN/inf -> None
    df = df.where(pd.notnull(df), None)

    # Convert records to safe Python types
    rows = df.head(max_rows).to_dict(orient='records')
    cleaned = []
    for r in rows:
        out = {}
        for k, v in r.items():
            out[k] = _to_python_scalar(v)

        # Typical fields
        emp_name = out.get('EmployeeName')
        emp_id = out.get('EmployeeID') or out.get('EmployeeIdentity')
        person_uid = out.get('person_uid')

        # ----- Schema-aware fallback resolution -----
        if not emp_id:
            emp_tokens = ['Int1', 'Text12', 'EmployeeID', 'empid', 'id']
            resolved_emp = _resolve_field_from_record(r, emp_tokens)
            if resolved_emp is not None:
                try:
                    s = str(resolved_emp).strip()
                    # remove trailing .0 for floats
                    if '.' in s:
                        f = float(s)
                        if math.isfinite(f) and f.is_integer():
                            s = str(int(f))
                    if _looks_like_guid(s):
                        out['EmployeeID'] = None
                        emp_id = None
                    else:
                        out['EmployeeID'] = s
                        emp_id = s
                except Exception:
                    if _looks_like_guid(resolved_emp):
                        out['EmployeeID'] = None
                        emp_id = None
                    else:
                        out['EmployeeID'] = resolved_emp
                        emp_id = resolved_emp

        # Prefer Credential.CardNumber / CHUID / Card as CardNumber when missing — reject GUIDs/placeholders
        if out.get('CardNumber') in (None, '', 'nan'):
            card_tokens = ['CardNumber', 'CHUID', 'Card', 'card_no', 'cardnum']
            resolved_card = _resolve_field_from_record(r, card_tokens)
            if resolved_card is not None:
                try:
                    cs = str(resolved_card).strip()
                    if _looks_like_guid(cs) or _is_placeholder_str(cs):
                        out['CardNumber'] = None
                    else:
                        out['CardNumber'] = cs
                except Exception:
                    out['CardNumber'] = None

        # final safety: ensure EmployeeID/CardNumber are not GUID-like tokens
        if 'EmployeeID' in out and isinstance(out['EmployeeID'], str) and _looks_like_guid(out['EmployeeID']):
            out['EmployeeID'] = None
        if 'CardNumber' in out and isinstance(out['CardNumber'], str) and _looks_like_guid(out['CardNumber']):
            out['CardNumber'] = None

        # If EmployeeName empty or looks like a GUID, prefer EmployeeID (human id) over GUIDs
        if (emp_name in (None, '', 'nan')) or (isinstance(emp_name, str) and _looks_like_guid(emp_name)):
            if emp_id not in (None, '', 'nan') and not _looks_like_guid(emp_id):
                out['EmployeeName'] = str(emp_id)
            else:
                out['EmployeeName'] = None

        cleaned.append(out)
    return cleaned

# ----- Helpers added to match commented (Pune) file functionality but multi-city-aware -----

def _replace_placeholder_strings(obj):
    """
    If obj is a DataFrame, replace known placeholder strings with None (NaN).
    If obj is a scalar/string, return None for placeholder strings else return obj.
    """
    if obj is None:
        return obj
    try:
        if isinstance(obj, pd.DataFrame):
            df = obj.copy()
            for col in df.columns:
                try:
                    # Replace placeholder strings (case-insensitive)
                    df[col] = df[col].apply(lambda x: None if _is_placeholder_str(x) else x)
                except Exception:
                    continue
            return df
        else:
            # scalar
            return None if _is_placeholder_str(obj) else obj
    except Exception:
        return obj

def _normalize_id_local(v):
    """
    Normalize an identifier for robust matching/counting:
    - treat NaN/None/empty as None
    - strip and convert float-like integers to integer strings
    """
    try:
        if pd.isna(v):
            return None
    except Exception:
        pass
    if v is None:
        return None
    s = str(v).strip()
    if s == '' or s.lower() == 'nan':
        return None
    try:
        if '.' in s:
            fv = float(s)
            if math.isfinite(fv) and fv.is_integer():
                s = str(int(fv))
    except Exception:
        pass
    return s




def _find_swipe_files(outdir: Path, date_obj: Optional[date] = None, city_slug: Optional[str] = None, include_shifted: bool = True):
    """
    Robust swipe-file discovery.
    - If include_shifted is False, files with 'shift' in the filename (e.g. _shifted) are excluded.
    - Supports various filename patterns; if date_obj is None returns recent swipe-like files.
    - Returns list of Path objects sorted by mtime (newest first).
    """
    p = Path(outdir)
    files_set = set()
    try:
        city_slug_l = (city_slug or "").lower().strip()

        def add_glob(pattern):
            try:
                for fp in p.glob(pattern):
                    if fp.is_file():
                        files_set.add(fp)
            except Exception:
                pass

        if date_obj is None:
            add_glob("*_swipes_*.csv")
            add_glob("swipes_*.csv")
            add_glob("*swipes*.csv")
            add_glob("*_swipes.csv")
            add_glob("*swipe*.csv")
            if city_slug_l:
                add_glob(f"*{city_slug_l}*_swipes_*.csv")
                add_glob(f"*{city_slug_l}*swipes*.csv")
                add_glob(f"*{city_slug_l}*.csv")
        else:
            target = date_obj.strftime("%Y%m%d")
            patterns = [
                f"*_{target}.csv",
                f"*_swipes_{target}.csv",
                f"swipes*_{target}.csv",
                f"swipes_{target}.csv",
                f"*swipes*_{target}.csv",
                f"*{city_slug_l}*_{target}.csv",
                f"*{city_slug_l}*swipes*_{target}.csv",
                f"*{city_slug_l}_{target}.csv"
            ]
            for pat in patterns:
                add_glob(pat)

        # fallback: any CSV containing 'swipe'/'swipes' in the name
        try:
            for fp in p.iterdir():
                if not fp.is_file():
                    continue
                name = fp.name.lower()
                if ('_swipe' in name) or ('swipe' in name and name.endswith('.csv')):
                    files_set.add(fp)
        except Exception:
            pass

    except Exception:
        logging.exception("Error while searching for swipe files in %s", outdir)

    # Filter out shifted files if requested
    files = sorted(list(files_set), key=lambda f: f.stat().st_mtime if f.exists() else 0, reverse=True)
    if not include_shifted:
        files = [f for f in files if 'shift' not in f.name.lower()]

    return files


# -----------------------
# Routes
# -----------------------




@app.route('/')
def root():
    return "Trend Analysis API — Multi-city"

@app.route('/employee/<path:pid>/image', methods=['GET'])
@app.route('/api/employees/<path:pid>/image', methods=['GET'])
def serve_employee_image(pid):
    """
    Try to return image bytes for pid using employeeimage.get_person_image_bytes.
    Fallbacks:
      - try stripped prefix (emp:, uid:, name:)
      - try resolving pid -> Personnel.ObjectID / GUID using get_personnel_info()
    If none found -> 404 JSON.
    """
    try:
        b = None
        # attempt with raw pid and stripped prefix
        logging.info("serve_employee_image: requested pid=%s", pid)
        b = get_person_image_bytes(pid)
        if not b:
            # try stripping common prefixes if present
            try:
                if ':' in pid:
                    _, rest = pid.split(':', 1)
                    logging.debug("serve_employee_image: trying stripped pid=%s", rest.strip())
                    b = get_person_image_bytes(rest.strip())
            except Exception:
                pass

        # NEW: if still not found, try to resolve pid via personnel lookup (EmployeeID -> ObjectID)
        if not b:
            try:
                logging.debug("serve_employee_image: attempt personnel resolution for pid=%s", pid)
                pinfo = get_personnel_info(pid) or {}
                # prefer ObjectID, then GUID
                obj = pinfo.get("ObjectID")
                guid = pinfo.get("GUID")
                tried = []
                if obj is not None:
                    obj_s = str(obj).strip()
                    tried.append(obj_s)
                    logging.debug("serve_employee_image: trying image with resolved ObjectID=%s", obj_s)
                    b = get_person_image_bytes(obj_s)
                if not b and guid:
                    guid_s = str(guid).strip()
                    tried.append(guid_s)
                    logging.debug("serve_employee_image: trying image with resolved GUID=%s", guid_s)
                    b = get_person_image_bytes(guid_s)
                if b:
                    logging.info("serve_employee_image: resolved pid=%s -> used parent id(s)=%s to fetch image", pid, tried)
            except Exception:
                logging.exception("serve_employee_image: personnel resolution attempt failed for pid=%s", pid)

        if not b:
            logging.warning("serve_employee_image: no image found for pid=%s", pid)
            return jsonify({"error": "image not found"}), 404

        try:
            kind = _guess_image_kind(b)
            if not kind:
                kind = 'jpeg'
            mime = 'image/' + ('jpeg' if kind == 'jpg' else kind)
        except Exception:
            mime = 'image/jpeg'

        bio = BytesIO(b)
        bio.seek(0)
        response = send_file(bio, mimetype=mime, as_attachment=False)
        try:
            response.headers['Cache-Control'] = 'no-cache, no-store, must-revalidate'
            response.headers['Pragma'] = 'no-cache'
            response.headers['Expires'] = '0'
        except Exception:
            pass
        return response

    except Exception as e:
        logging.exception("serve_employee_image failed for %s", pid)
        return jsonify({"error": "internal server error", "details": str(e)}), 500



@app.route('/run', methods=['GET', 'POST'])
def run_trend():
    params = {}
    if request.method == 'GET':
        params = request.args.to_dict()
    else:
        if request.is_json:
            params = request.get_json(force=True) or {}
        else:
            try:
                params = request.form.to_dict() or {}
            except Exception:
                params = {}

    date_str = (params.get('date') or params.get('Date') or '').strip() or None
    start_str = (params.get('start') or params.get('Start') or '').strip() or None
    end_str = (params.get('end') or params.get('End') or '').strip() or None

    dates = []
    try:
        if date_str:
            dt = datetime.strptime(date_str, "%Y-%m-%d").date()
            dates = [dt]
        elif start_str and end_str:
            s = datetime.strptime(start_str, "%Y-%m-%d").date()
            e = datetime.strptime(end_str, "%Y-%m-%d").date()
            if e < s:
                return jsonify({"error":"end must be >= start"}), 400
            cur = s
            while cur <= e:
                dates.append(cur)
                cur = cur + timedelta(days=1)
        else:
            today = datetime.now().date()
            yesterday = today - timedelta(days=1)
            dates = [yesterday, today]
    except Exception as e:
        return jsonify({"error": f"Invalid date format: {e}"}), 400

    regions_param = params.get('regions') or params.get('region') or ''
    if regions_param:
        regions = [r.strip().lower() for r in re.split(r'[;,|]', str(regions_param)) if r.strip()]
    else:
        try:
            regions = [k.lower() for k in list(REGION_CONFIG.keys())]
        except Exception:
            regions = ['apac']

    valid_regions = []
    for r in regions:
        if r in (REGION_CONFIG or {}):
            valid_regions.append(r)
        else:
            logging.debug("Requested region '%s' not in REGION_CONFIG - skipping", r)
    if not valid_regions:
        valid_regions = [k.lower() for k in REGION_CONFIG.keys()] if REGION_CONFIG else ['apac']
    params['_regions_to_run'] = valid_regions

    city_param = params.get('city') or params.get('site') or params.get('site_name') or None
    city_slug = _slug_city(city_param) if city_param else None
    params['_city'] = city_slug

    combined_rows = []
    files = []

    # ---------------------------
    # Run trend for each requested date
    # ---------------------------
    for d in dates:
        try:
            if run_trend_for_date is None:
                raise RuntimeError("run_trend_for_date helper not available in trend_runner")
            try:
                df = run_trend_for_date(d, regions=valid_regions, outdir=str(DEFAULT_OUTDIR), city=city_slug)
            except TypeError:
                try:
                    df = run_trend_for_date(d, outdir=str(DEFAULT_OUTDIR))
                except Exception:
                    # Last-resort: try duration_report fallback if available
                    try:
                        from duration_report import run_for_date as _dr_run_for_date
                        region_results = _dr_run_for_date(d, valid_regions, str(DEFAULT_OUTDIR), city_param)
                        combined_list = []
                        for rkey, res in (region_results or {}).items():
                            try:
                                df_dur = res.get('durations')
                                if df_dur is not None and not df_dur.empty:
                                    combined_list.append(df_dur)
                            except Exception:
                                continue
                        df = pd.concat(combined_list, ignore_index=True) if combined_list else pd.DataFrame()
                    except Exception:
                        raise
        except Exception as e:
            logging.exception("run_trend_for_date failed for %s", d)
            return jsonify({"error": f"runner failed for {d}: {e}"}), 500

        csv_path = DEFAULT_OUTDIR / f"trend_{city_slug}_{d.strftime('%Y%m%d')}.csv"
        if csv_path.exists():
            files.append(csv_path.name)

        if df is None or (hasattr(df, 'empty') and df.empty):
            continue

        try:
            df = _replace_placeholder_strings(df)
        except Exception:
            pass

        if 'IsFlagged' not in df.columns:
            df['IsFlagged'] = False
        if 'Reasons' not in df.columns:
            df['Reasons'] = None

        combined_rows.append(df)

    # *** Important: combine after loop to avoid UnboundLocalError and extra repeated concat inside loop ***
    try:
        combined_df = pd.concat(combined_rows, ignore_index=True) if combined_rows else pd.DataFrame()
    except Exception:
        combined_df = pd.DataFrame()

    try:
        if not combined_df.empty:
            if 'person_uid' in combined_df.columns:
                raw_unique_person_uids = int(combined_df['person_uid'].dropna().astype(str).nunique())
            elif 'EmployeeID' in combined_df.columns:
                raw_unique_person_uids = int(combined_df['EmployeeID'].dropna().astype(str).nunique())
            else:
                raw_unique_person_uids = int(len(combined_df))
        else:
            raw_unique_person_uids = 0
    except Exception:
        raw_unique_person_uids = int(len(combined_df)) if combined_df is not None else 0

    try:
        if not combined_df.empty and 'IsFlagged' in combined_df.columns:
            flagged_df = combined_df[combined_df['IsFlagged'] == True].copy()
        else:
            flagged_df = pd.DataFrame()
    except Exception:
        flagged_df = pd.DataFrame()

    try:
        analysis_count = int(raw_unique_person_uids)
    except Exception:
        analysis_count = int(len(combined_df)) if combined_df is not None else 0

    try:
        flagged_count = int(len(flagged_df))
        flagged_rate_pct = float((flagged_count / analysis_count * 100.0) if analysis_count and analysis_count > 0 else 0.0)
    except Exception:
        flagged_count = int(len(flagged_df))
        flagged_rate_pct = 0.0

    try:
        # If we have flagged rows, return ALL flagged rows (strict)
        if flagged_df is not None and not flagged_df.empty:
            sample_source = flagged_df
            # return exactly flagged_count rows (no hidden head(10) truncation)
            samples = _clean_sample_df(sample_source, max_rows=int(len(flagged_df)))
        else:
            # old behaviour: show a small sample of combined_df
            sample_source = combined_df
            samples = _clean_sample_df(sample_source.head(10), max_rows=10) if sample_source is not None and not sample_source.empty else []
    except Exception:
        samples = []




    resp = {
        "start_date": dates[0].isoformat() if dates else None,
        "end_date": dates[-1].isoformat() if dates else None,
        "aggregated_rows_total_raw": int(len(combined_df)),
        "aggregated_unique_persons": int(analysis_count),
        "rows": int(analysis_count),
        "flagged_rows": int(flagged_count),
        "flagged_rate_percent": float(flagged_rate_pct),
        "files": files,
         "sample": (samples if isinstance(samples, list) else samples),
       # "sample": (samples[:10] if isinstance(samples, list) else samples),
        "reasons_count": {},
        "risk_counts": {},
        #"flagged_persons": (samples if samples else []),
         "flagged_persons": (samples if samples else []),
        "_raw_unique_person_uids": int(raw_unique_person_uids),
        "regions_run": params.get('_regions_to_run', []),
        "city_used": city_slug
    }

    return jsonify(resp)




@app.route('/latest', methods=['GET'])
def latest_results():
    city_param = request.args.get('city') or request.args.get('site') or 'pune'
    city_slug = _slug_city(city_param)

    p = Path(DEFAULT_OUTDIR)
    csvs = sorted(p.glob(f"trend_{city_slug}_*.csv"), reverse=True)
    if not csvs:
        csvs = sorted(p.glob("trend_*.csv"), reverse=True)
    if not csvs:
        return jsonify({"error": "no outputs found"}), 404
    latest = csvs[0]

    start_date_iso = None
    end_date_iso = None
    try:
        m = re.search(r'(\d{8})', latest.name)
        if m:
            ymd = m.group(1)
            dt = datetime.strptime(ymd, "%Y%m%d").date()
            start_date_iso = dt.isoformat()
            end_date_iso = dt.isoformat()
    except Exception:
        start_date_iso = None
        end_date_iso = None

    try:
        df = pd.read_csv(latest)
    except Exception:
        df = pd.read_csv(latest, dtype=str)

    df = _replace_placeholder_strings(df)

    id_candidates = ['person_uid', 'EmployeeID', 'EmployeeIdentity', 'Int1']
    id_col = next((c for c in id_candidates if c in df.columns), None)

    def _norm_val_for_latest(v):
        try:
            if pd.isna(v):
                return None
        except Exception:
            pass
        if v is None:
            return None
        s = str(v).strip()
        if s == '' or s.lower() == 'nan':
            return None
        try:
            if '.' in s:
                fv = float(s)
                if math.isfinite(fv) and fv.is_integer():
                    s = str(int(fv))
        except Exception:
            pass
        return s

    if id_col is None:
        unique_persons = int(len(df))
    else:
        ids_series = df[id_col].apply(_norm_val_for_latest) if id_col in df.columns else pd.Series([None]*len(df))
        if id_col != 'person_uid' and 'person_uid' in df.columns:
            ids_series = ids_series.fillna(df['person_uid'].astype(str).replace('nan','').replace('None',''))
        unique_persons = int(len(set([x for x in ids_series.unique() if x])))

    # build initial sample (list of dicts)
    sample = _clean_sample_df(df, max_rows=5)  # returns list



    resp = {
        
        "file": latest.name,
        "rows_raw": int(len(df)),
        "rows": unique_persons,
        "sample": sample,
        "start_date": start_date_iso,
        "end_date": end_date_iso,
        "city": city_slug
    }
    return jsonify(resp)






@app.route('/record', methods=['GET'])
def record():
    try:
        # --- BEGIN existing record() logic ---
        from pathlib import Path
        import pandas as pd
        import math
        import re
        from datetime import datetime, date
        try:
            q = request.args.get('employee_id') or request.args.get('person_uid')
        except Exception:
            q = None
        include_unflagged = str(request.args.get('include_unflagged', '')).lower() in ('1', 'true', 'yes')
        city_param = request.args.get('city') or request.args.get('site') or 'pune'

        # pick outdir consistently
        try:
            base_out = Path(DEFAULT_OUTDIR)
        except Exception:
            try:
                base_out = Path(OUTDIR)
            except Exception:
                base_out = Path.cwd()


            
        # helper safe wrappers (use existing ones if present)
        def _safe_read(fp, **kwargs):
            try:
                if '_safe_read_csv' in globals():
                    return _safe_read_csv(fp)
                return pd.read_csv(fp, **kwargs)
            except Exception:
                try:
                    return pd.read_csv(fp, dtype=str, **{k: v for k, v in kwargs.items() if k != 'parse_dates'})
                except Exception:
                    return pd.DataFrame()

        def _to_python_scalar(v):
            if pd.isna(v):
                return None
            try:
                return v.item() if hasattr(v, 'item') else v
            except Exception:
                return v

        # 1) find trend CSVs (city-specific first)
        def _slug(s):
            return re.sub(r'[^a-z0-9]+', '_', str(s or '').strip().lower()).strip('_')

        city_slug = _slug(city_param)
        trend_glob = list(base_out.glob(f"trend_{city_slug}_*.csv"))
        if not trend_glob:
            trend_glob = list(base_out.glob("trend_*.csv"))
        trend_glob = sorted(trend_glob, reverse=True)

        df_list = []
        for fp in trend_glob:
            try:
                tmp = pd.read_csv(fp, parse_dates=['Date', 'FirstSwipe', 'LastSwipe'])
            except Exception:
                try:
                    tmp = pd.read_csv(fp, dtype=str)
                    if 'Date' in tmp.columns:
                        tmp['Date'] = pd.to_datetime(tmp['Date'], errors='coerce').dt.date
                except Exception:
                    continue
            df_list.append(tmp)
        if df_list:
            trends_df = pd.concat(df_list, ignore_index=True)
            try:
                trends_df = _replace_placeholder_strings(trends_df)
            except Exception:
                pass
        else:
            trends_df = pd.DataFrame()

            


        # ---------- ADDED: enrichment helper ----------
        def _enrich_with_contact_info(rows):
            """Given list-of-dict rows, best-effort populate EmployeeEmail / Email if missing."""
            try:
                if not rows:
                    return rows
                out = []
                for r in rows:
                    # do not mutate original in-place (defensive)
                    rr = dict(r)
                    if not rr.get('EmployeeEmail') and not rr.get('Email'):
                        candidate = rr.get('EmployeeID') or rr.get('person_uid') or rr.get('ObjectID') or rr.get('GUID')
                        try:
                            if candidate:
                                pinfo = {}
                                try:
                                    pinfo = get_personnel_info(candidate) or {}
                                except Exception:
                                    pinfo = {}
                                # populate from keys commonly provided by get_personnel_info
                                for key in ('EmployeeEmail','EmailAddress','Email','WorkEmail'):
                                    if not rr.get('EmployeeEmail') and pinfo.get(key):
                                        rr['EmployeeEmail'] = pinfo.get(key)
                                        rr['Email'] = pinfo.get(key)
                                        break
                                # fallback: ManagerEmail if nothing else
                                if (not rr.get('EmployeeEmail')) and pinfo.get('ManagerEmail'):
                                    rr['ManagerEmail'] = pinfo.get('ManagerEmail')
                            # else no candidate => nothing we can do
                        except Exception:
                            pass
                    out.append(rr)
                return out
            except Exception:
                return rows
        # ---------- END enrichment helper ----------


        # if no query param, return a small sample of trend rows (if any)
        if q is None:
            try:
                if not trends_df.empty and '_clean_sample_df' in globals():
                    cleaned = _clean_sample_df(trends_df, max_rows=10)
                elif not trends_df.empty:
                    cleaned = trends_df.head(10).to_dict(orient='records')
                else:
                    cleaned = []
            except Exception:
                cleaned = []
            # ENRICH CONTACT INFO
            try:
                cleaned = _enrich_with_contact_info(cleaned)
            except Exception:
                pass
            return jsonify({'aggregated_rows': cleaned, 'raw_swipe_files': [], 'raw_swipes': []}), 200

        q_str = str(q).strip()

        # helper to normalise series values to comparable strings/numerics
        def normalize_series(s):
            if s is None:
                return pd.Series([''] * (len(trends_df) if not trends_df.empty else 0))
            s = s.fillna('').astype(str).str.strip()
            def _norm_val(v):
                if not v:
                    return ''
                try:
                    if '.' in v:
                        fv = float(v)
                        if math.isfinite(fv) and fv.is_integer():
                            return str(int(fv))
                except Exception:
                    pass
                return v
            return s.map(_norm_val)





        # find matching rows in trends_df
        found_mask = pd.Series(False, index=trends_df.index) if not trends_df.empty else pd.Series(dtype=bool)
        candidates_cols = ('EmployeeID', 'person_uid', 'EmployeeIdentity', 'CardNumber', 'Int1', 'Text12', 'EmployeeName')
        for c in candidates_cols:
            if c in trends_df.columns:
                try:
                    ser = normalize_series(trends_df[c])
                    found_mask = found_mask | (ser == q_str)
                except Exception:
                    pass

        # numeric fallback
        if (found_mask is None) or (not found_mask.any() if len(found_mask) else True):
            try:
                q_numeric = float(q_str)
                for c in ('EmployeeID', 'Int1'):
                    if c in trends_df.columns:
                        try:
                            numser = pd.to_numeric(trends_df[c], errors='coerce')
                            found_mask = found_mask | (numser == q_numeric)
                        except Exception:
                            pass
            except Exception:
                pass

        matched = trends_df[found_mask].copy() if not trends_df.empty else pd.DataFrame()
        if matched.empty:
            cleaned_matched = []
        else:
            try:
                cleaned_matched = _clean_sample_df(matched, max_rows=len(matched)) if '_clean_sample_df' in globals() else matched.to_dict(orient='records')
            except Exception:
                cleaned_matched = matched.to_dict(orient='records')

        # ENRICH CONTACT INFO for matched aggregated rows
        try:
            cleaned_matched = _enrich_with_contact_info(cleaned_matched)
        except Exception:
            pass


        # build list of dates to scan for swipe files (from matched rows)
        dates_to_scan = set()
        try:
            for _, r in (matched.iterrows() if not matched.empty else []):
                try:
                    if 'Date' in r and pd.notna(r['Date']):
                        try:
                            d = pd.to_datetime(r['Date']).date()
                            dates_to_scan.add(d)
                        except Exception:
                            pass
                    for col in ('FirstSwipe','LastSwipe'):
                        if col in r and pd.notna(r[col]):
                            try:
                                d = pd.to_datetime(r[col]).date()
                                dates_to_scan.add(d)
                            except Exception:
                                pass
                except Exception:
                    continue
        except Exception:
            pass
        if not dates_to_scan:
            dates_to_scan = {None}  # indicates scan all swipes files

        # ---------- helper: find swipe files for a date (robust) ----------
        def _find_swipes_for_date(date_obj=None):
            try:
                include_shifted = True
                try:
                    if city_slug and str(city_slug).strip().lower() == 'pune':
                        include_shifted = False
                except Exception:
                    include_shifted = True

                if '_find_swipe_files' in globals() and callable(globals().get('_find_swipe_files')):
                    try:
                        cand = _find_swipe_files(str(base_out), date_obj=date_obj, city_slug=city_slug if city_slug else None, include_shifted=include_shifted)
                        if cand:
                            return cand
                    except Exception:
                        logging.exception("_find_swipe_files helper failed; falling back to glob search.")

                files = []
                if date_obj is None:
                    files = list(base_out.glob("swipes_*_*.csv")) + list(base_out.glob("swipes_*.csv")) + list(base_out.glob("*swipe*.csv"))
                else:
                    ymd = date_obj.strftime('%Y-%m-%d')
                    ymd2 = date_obj.strftime('%Y%m%d')
                    cand1 = [p for p in base_out.glob("swipes_*_*.csv") if (ymd in p.name or ymd2 in p.name)]
                    cand2 = [p for p in base_out.glob("swipes_*.csv") if (ymd in p.name or ymd2 in p.name)]
                    files = cand1 + cand2
                files = sorted(list({p for p in files if p.exists()}), key=lambda f: f.stat().st_mtime if f.exists() else 0, reverse=True)
                if not include_shifted:
                    files = [f for f in files if 'shift' not in f.name.lower()]
                return files
            except Exception:
                logging.exception("Error while searching for swipe files for date=%s city=%s", date_obj, city_slug)
                return []


        # ---------- scan swipe files for the target person (dates_to_scan computed earlier) ----------
        raw_files_set = set()
        raw_swipes_out = []
        seen_keys = set()

        def _append_row_for_evidence(out_row, source_name):
            # avoid exact duplicate rows from same file
            key = (
                str(out_row.get('LocaleMessageTime') or ''),
                str(out_row.get('DateOnly') or ''),
                str(out_row.get('Swipe_Time') or ''),
                str(out_row.get('Door') or '').strip(),
                str(out_row.get('Direction') or '').strip(),
                str(out_row.get('CardNumber') or '').strip()
            )
            if key in seen_keys:
                return False
            seen_keys.add(key)
            out_row['_source'] = source_name
            raw_swipes_out.append(out_row)
            return True

        # helper to format datetime to requested display formats
        def _format_time_fields(ts):
            # ts is a pandas Timestamp or datetime or None
            if ts is None or (isinstance(ts, float) and math.isnan(ts)):
                return (None, None, None)
            try:
                dt = pd.to_datetime(ts)
            except Exception:
                return (None, None, None)
            try:
                locale_iso = dt.isoformat()
            except Exception:
                locale_iso = str(dt)
            try:
                date_only = dt.strftime("%d-%b-%y")  # e.g. 17-Nov-25
            except Exception:
                try:
                    date_only = dt.date().isoformat()
                except Exception:
                    date_only = None
            try:
                # 12-hour time with AM/PM, strip leading zero
                swipe_time = dt.strftime("%I:%M:%S %p").lstrip("0")
            except Exception:
                swipe_time = None
            return (locale_iso, date_only, swipe_time)

        # loop over each date we want to scan (these are violation dates if matched rows existed)
        for d in dates_to_scan:
            swipe_candidates = _find_swipes_for_date(d)
            if d is not None and not swipe_candidates:
                # fallback to scanning all swipe files if none found for the exact date pattern
                swipe_candidates = _find_swipes_for_date(None)

            for fp in swipe_candidates:
                try:
                    sdf = _safe_read(fp, parse_dates=['LocaleMessageTime'])
                except Exception:
                    try:
                        sdf = _safe_read(fp)
                    except Exception:
                        continue
                if sdf is None or sdf.empty:
                    continue

                # minimal column-normalization for detection (case-insensitive)
                cols_lower = {c.lower(): c for c in sdf.columns}
                tcol = cols_lower.get('localemessagetime') or cols_lower.get('messagetime') or \
                       cols_lower.get('timestamp') or cols_lower.get('time') or None
                emp_col = cols_lower.get('int1') or cols_lower.get('employeeid') or \
                          cols_lower.get('employeeidentity') or cols_lower.get('employee_id') or None
                name_col = cols_lower.get('employeename') or cols_lower.get('objectname1') or \
                           cols_lower.get('employee_name') or None
                card_col = cols_lower.get('cardnumber') or cols_lower.get('card') or \
                           cols_lower.get('chuid') or cols_lower.get('value') or None
                door_col = cols_lower.get('door') or cols_lower.get('doorname') or cols_lower.get('door_name') or None
                dir_col = cols_lower.get('direction') or cols_lower.get('directionname') or cols_lower.get('direction_name') or None
                admit_cols = [c for c in ('admitcode','admit','admit_code','admit_type','admitstatus') if c in cols_lower]
                admit_col = cols_lower.get(admit_cols[0]) if admit_cols else None
                personnel_col = cols_lower.get('personneltype') or cols_lower.get('personneltypename') or None
                location_col = cols_lower.get('partitionname2') or cols_lower.get('location') or cols_lower.get('partitionname') or None
                person_uid_col = cols_lower.get('person_uid')

                # build boolean mask for rows that match the query identifier q_str
                try:
                    mask = pd.Series(False, index=sdf.index)
                except Exception:
                    mask = pd.Series([False] * len(sdf))

                try:
                    if person_uid_col and person_uid_col in sdf.columns:
                        mask = mask | (sdf[person_uid_col].astype(str).str.strip() == q_str)
                except Exception:
                    pass
                try:
                    if emp_col and emp_col in sdf.columns:
                        mask = mask | (sdf[emp_col].astype(str).str.strip() == q_str)
                except Exception:
                    pass
                # numeric fallback for employee id
                if (not mask.any()) and emp_col and emp_col in sdf.columns:
                    try:
                        q_numeric = float(q_str)
                        emp_numeric = pd.to_numeric(sdf[emp_col], errors='coerce')
                        mask = mask | (emp_numeric == q_numeric)
                    except Exception:
                        pass
                # name fallback
                if (not mask.any()) and name_col and name_col in sdf.columns:
                    try:
                        mask = mask | (sdf[name_col].astype(str).str.strip().str.lower() == q_str.lower())
                    except Exception:
                        pass

                if not mask.any():
                    # no matching rows in this file -> skip adding this file
                    continue

                filtered = sdf[mask].copy()
                if filtered.empty:
                    continue

                # parse/normalize timestamp column if available
                if tcol and tcol in filtered.columns:
                    try:
                        filtered[tcol] = pd.to_datetime(filtered[tcol], errors='coerce')
                    except Exception:
                        pass
                else:
                    # attempt common fallback column names to produce a timestamp
                    for cand in ('MessageUTC', 'MessageTime', 'Timestamp', 'timestamp', 'Date'):
                        if cand in filtered.columns:
                            try:
                                filtered['LocaleMessageTime'] = pd.to_datetime(filtered[cand], errors='coerce')
                                tcol = 'LocaleMessageTime'
                                break
                            except Exception:
                                pass

                # sort by timestamp for consistent timeline order
                if tcol and tcol in filtered.columns:
                    try:
                        filtered = filtered.sort_values(by=tcol)
                    except Exception:
                        pass

                    # --- compute swipe gaps (preserve previous logic) ---
                    try:
                        filtered['_prev_ts'] = filtered[tcol].shift(1)
                        filtered['_swipe_gap_seconds'] = (filtered[tcol] - filtered['_prev_ts']).dt.total_seconds().fillna(0).astype(float)
                        # reset gap at day boundary or when previous is NaT
                        try:
                            cur_dates = filtered[tcol].dt.date
                            prev_dates = cur_dates.shift(1)
                            day_boundary_mask = (prev_dates != cur_dates) | (filtered['_prev_ts'].isna())
                            filtered.loc[day_boundary_mask, '_swipe_gap_seconds'] = 0.0
                        except Exception:
                            pass
                    except Exception:
                        filtered['_swipe_gap_seconds'] = 0.0
                else:
                    # no timestamp column -> defaults
                    filtered['_swipe_gap_seconds'] = 0.0

                # For each matching swipe row, build the slim evidence record expected by frontend
                added_any = False
                for _, r in filtered.iterrows():
                    # timestamp conversions
                    ts_val = None
                    if tcol and tcol in filtered.columns:
                        ts_val = r.get(tcol)
                    else:
                        # fallback: try Date column
                        if 'Date' in filtered.columns:
                            ts_val = r.get('Date')
                    locale_iso, date_only, swipe_time = _format_time_fields(ts_val)

                    # EmployeeID: prefer emp_col, then Int1/Text12, then fallback to matched trends row
                    emp_val = None
                    try:
                        if emp_col and emp_col in filtered.columns:
                            emp_val = _to_python_scalar(r.get(emp_col))
                        else:
                            for cand in ('Int1','Text12','EmployeeID','EmployeeIdentity','empid','id'):
                                cl = cols_lower.get(cand.lower())
                                if cl and cl in filtered.columns:
                                    emp_val = _to_python_scalar(r.get(cl))
                                    if emp_val:
                                        break
                            if emp_val in (None, '', 'nan'):
                                emp_val = _to_python_scalar(matched.iloc[0].get('EmployeeID') if not matched.empty else None)
                    except Exception:
                        emp_val = _to_python_scalar(matched.iloc[0].get('EmployeeID') if not matched.empty else None)

                    # ObjectName1 / EmployeeName (human name)
                    obj_name = None
                    try:
                        if name_col and name_col in filtered.columns:
                            obj_name = _to_python_scalar(r.get(name_col))
                        elif 'ObjectName1' in filtered.columns:
                            obj_name = _to_python_scalar(r.get('ObjectName1'))
                        elif 'EmployeeName' in filtered.columns:
                            obj_name = _to_python_scalar(r.get('EmployeeName'))
                        else:
                            obj_name = _to_python_scalar(matched.iloc[0].get('EmployeeName') if not matched.empty else None)
                    except Exception:
                        obj_name = _to_python_scalar(matched.iloc[0].get('EmployeeName') if not matched.empty else None)

                    # PersonnelType
                    personnel_val = _to_python_scalar(r.get(personnel_col)) if (personnel_col and personnel_col in filtered.columns) else None
                    # Location / Partition
                    location_val = _to_python_scalar(r.get(location_col)) if (location_col and location_col in filtered.columns) else _to_python_scalar(r.get('PartitionName2')) if 'PartitionName2' in filtered.columns else None

                    # CardNumber
                    card_val = None
                    try:
                        if card_col and card_col in filtered.columns:
                            card_val = _to_python_scalar(r.get(card_col))
                        else:
                            for cand in ('CardNumber','CHUID','Card','card_no','cardnum','value','xmlmessage'):
                                cl = cols_lower.get(cand.lower())
                                if cl and cl in filtered.columns:
                                    card_val = _to_python_scalar(r.get(cl))
                                    if card_val not in (None, '', 'nan'):
                                        break
                            if card_val in (None, '', 'nan'):
                                card_val = _to_python_scalar(matched.iloc[0].get('CardNumber') if not matched.empty else None)
                    except Exception:
                        card_val = _to_python_scalar(matched.iloc[0].get('CardNumber') if not matched.empty else None)
                    if card_val is not None:
                        try:
                            card_val = str(card_val).strip()
                        except Exception:
                            pass

                    # AdmitCode / Note
                    admit_val = _to_python_scalar(r.get(admit_col)) if (admit_col and admit_col in filtered.columns) else None
                    # some logs store admit/rejection text in 'Note' or 'Rejection_Type'
                    if not admit_val:
                        for cand in ('Admit','AdmitCode','Admit_Type','Rejection_Type','Note','NoteType','Source'):
                            cl = cols_lower.get(cand.lower())
                            if cl and cl in filtered.columns:
                                admit_val = _to_python_scalar(r.get(cl))
                                if admit_val:
                                    break

                    # Direction & Door
                    direction_val = _to_python_scalar(r.get(dir_col)) if (dir_col and dir_col in filtered.columns) else _to_python_scalar(r.get('Direction')) if 'Direction' in filtered.columns else None
                    door_val = _to_python_scalar(r.get(door_col)) if (door_col and door_col in filtered.columns) else _to_python_scalar(r.get('Door')) if 'Door' in filtered.columns else None

                    # Zone: prefer precomputed _zone, else map using map_door_to_zone if available
                    zone_val = None
                    try:
                        if '_zone' in r and r.get('_zone') not in (None, '', 'nan'):
                            zone_val = _to_python_scalar(r.get('_zone'))
                        else:
                            if 'map_door_to_zone' in globals():
                                try:
                                    zone_val = map_door_to_zone(door_val, direction_val)
                                except Exception:
                                    zone_val = None
                    except Exception:
                        zone_val = None

                    # Swipe gap
                    try:
                        swipe_gap_seconds = float(r.get('_swipe_gap_seconds') or 0.0)
                    except Exception:
                        swipe_gap_seconds = 0.0
                    swipe_gap_str = format_seconds_to_hms(swipe_gap_seconds)

                    # build output row: include EmployeeName (frontend expects this), plus legacy keys
                    row_out = {
                        "EmployeeName": obj_name,
                        "ObjectName1": obj_name,
                        "EmployeeID": emp_val,
                        "CardNumber": card_val,
                        "Card": card_val,
                        "LocaleMessageTime": locale_iso,
                        "DateOnly": date_only,
                        "Date": date_only,
                        "Time": swipe_time,
                        "Swipe_Time": swipe_time,
                        "SwipeGapSeconds": swipe_gap_seconds,
                        "SwipeGap": swipe_gap_str,
                        "Door": door_val,
                        "Direction": direction_val,
                        "Zone": zone_val,
                        "Note": admit_val,
                        "PersonnelType": personnel_val,
                        "Location": location_val,
                        "PartitionName2": _to_python_scalar(r.get('PartitionName2')) if 'PartitionName2' in filtered.columns else None,
                        "_source_file": fp.name
                    }

                    # Attempt to attach an email for the evidence row too
                    try:
                        if not row_out.get('EmployeeEmail') and row_out.get('EmployeeID'):
                            pinfo = {}
                            try:
                                pinfo = get_personnel_info(row_out.get('EmployeeID')) or {}
                            except Exception:
                                pinfo = {}
                            if pinfo:
                                if pinfo.get('EmployeeEmail') and not row_out.get('EmployeeEmail'):
                                    row_out['EmployeeEmail'] = pinfo.get('EmployeeEmail')
                                elif pinfo.get('EmailAddress') and not row_out.get('EmployeeEmail'):
                                    row_out['EmployeeEmail'] = pinfo.get('EmailAddress')
                                elif pinfo.get('Email') and not row_out.get('EmployeeEmail'):
                                    row_out['EmployeeEmail'] = pinfo.get('Email')
                    except Exception:
                        pass

                    added = _append_row_for_evidence(row_out, fp.name)
                    if added:
                        added_any = True

                # only add file name to available evidence list if we actually added rows from it
                if added_any:
                    raw_files_set.add(fp.name)

        raw_swipe_files = sorted(list(raw_files_set))

        return jsonify({
            "aggregated_rows": cleaned_matched,
            "raw_swipe_files": raw_swipe_files,
            "raw_swipes": raw_swipes_out
        }), 200

    except Exception as e:
        # Close the try-block above with a proper except handler to avoid SyntaxError
        logging.exception("Unhandled exception in /record endpoint")
        return jsonify({"error": "internal server error in /record", "details": str(e)}), 500



@app.route('/record/export', methods=['GET'])
def export_record_excel():
    q = request.args.get('employee_id') or request.args.get('person_uid')
    date_str = request.args.get('date')
    city_param = request.args.get('city') or request.args.get('site') or 'pune'
    city_slug = _slug_city(city_param)

    if not q:
        return jsonify({"error":"employee_id or person_uid is required"}), 400

    q_str = str(q).strip()

    # Helper: load trend CSV(s) and build set of flagged (id, date) tuples
    def _load_flagged_map(target_date=None):
        flagged_pairs = set()
        try:
            p = Path(DEFAULT_OUTDIR)
            candidates = []
            if target_date:
                # try city/date specific trend file first
                ymd = target_date.strftime('%Y%m%d')
                f = p / f"trend_{city_slug}_{ymd}.csv"
                if f.exists():
                    candidates = [f]
            if not candidates:
                # fallback to any trend_*.csv in outputs
                candidates = sorted(p.glob("trend_*.csv"), reverse=True)
            for fp in candidates:
                try:
                    tdf = pd.read_csv(fp)
                except Exception:
                    try:
                        tdf = pd.read_csv(fp, dtype=str)
                    except Exception:
                        continue
                if tdf is None or tdf.empty:
                    continue
                tdf = _replace_placeholder_strings(tdf)
                # ensure Date is normalized to iso date string
                if 'Date' in tdf.columns:
                    try:
                        tdf['Date'] = pd.to_datetime(tdf['Date'], errors='coerce').dt.date
                        tdf['DateISO'] = tdf['Date'].apply(lambda d: d.isoformat() if pd.notna(d) else None)
                    except Exception:
                        tdf['DateISO'] = tdf['Date'].astype(str)
                else:
                    tdf['DateISO'] = None
                # find flagged rows (IsFlagged True or AnomalyScore >= threshold)
                if 'IsFlagged' in tdf.columns:
                    sel = tdf[tdf['IsFlagged'] == True]
                else:
                    # fallback: consider AnomalyScore >= ANOMALY_THRESHOLD as flagged
                    if 'AnomalyScore' in tdf.columns:
                        try:
                            sel = tdf[pd.to_numeric(tdf['AnomalyScore'], errors='coerce').fillna(0) >= ANOMALY_THRESHOLD]
                        except Exception:
                            sel = pd.DataFrame()
                    else:
                        sel = pd.DataFrame()

                if sel is None or sel.empty:
                    continue

                for _, rr in sel.iterrows():
                    date_iso = None
                    try:
                        date_iso = rr.get('DateISO') or (pd.to_datetime(rr.get('Date'), errors='coerce').date().isoformat() if rr.get('Date') is not None else None)
                    except Exception:
                        date_iso = None
                    # collect EmployeeID and person_uid if present
                    for idcol in ('EmployeeID', 'person_uid', 'EmployeeIdentity', 'Int1', 'Text12', 'CardNumber'):
                        try:
                            if idcol in rr and rr.get(idcol) not in (None, '', float('nan')):
                                val = str(rr.get(idcol)).strip()
                                if val:
                                    flagged_pairs.add((idcol, val, date_iso))
                                    # also add date-agnostic tuple for easy contains checks
                                    flagged_pairs.add((idcol, val, None))
                        except Exception:
                            continue
            return flagged_pairs
        except Exception:
            return set()

    # parse date param for targeted checking (optional)
    target_date_obj = None
    if date_str:
        try:
            target_date_obj = pd.to_datetime(date_str).date()
        except Exception:
            return jsonify({"error":"invalid date format, expected YYYY-MM-DD"}), 400

    flagged_map = _load_flagged_map(target_date_obj)

    # Quick check: ensure the requested employee/q is flagged for the requested date (or flagged at all)
    def _is_q_flagged(qtoken, date_iso=None):
        if not qtoken:
            return False
        # check across multiple id columns recorded in trend files
        for idcol in ('EmployeeID', 'person_uid', 'EmployeeIdentity', 'Int1', 'Text12', 'CardNumber'):
            if (idcol, qtoken, date_iso) in flagged_map or (idcol, qtoken, None) in flagged_map:
                return True
        return False

    # if date provided require flagged on that date; otherwise accept flagged any-date
    q_flagged = _is_q_flagged(q_str, target_date_obj.isoformat() if target_date_obj else None)
    if not q_flagged:
        # if not flagged with exact id, try numeric-normalized attempts (strip trailing .0 etc)
        try:
            if '.' in q_str:
                fq = None
                try:
                    f = float(q_str)
                    if math.isfinite(f) and f.is_integer():
                        fq = str(int(f))
                except Exception:
                    fq = None
                if fq and _is_q_flagged(fq, target_date_obj.isoformat() if target_date_obj else None):
                    q_flagged = True
        except Exception:
            pass

    if not q_flagged:
        return jsonify({"error": "employee not flagged (no evidence rows for requested employee/date)"}), 404

    # find swipe files to scan
    p = Path(DEFAULT_OUTDIR)
    files_to_scan = []
    if target_date_obj:
        files_to_scan = _find_swipe_files(DEFAULT_OUTDIR, date_obj=target_date_obj, city_slug=city_slug, include_shifted=False if city_slug == 'pune' else True)
    else:
        files_to_scan = _find_swipe_files(DEFAULT_OUTDIR, date_obj=None, city_slug=city_slug)
    if not files_to_scan:
        avail = _find_swipe_files(DEFAULT_OUTDIR, date_obj=None, city_slug=None, include_shifted=False)
        avail_names = [f.name for f in avail] if avail else []
        logging.info("export_record_excel: no files matched for date=%s city=%s; available swipe files=%s", date_str, city_slug, avail_names)
        return jsonify({"error": "no raw swipe files found for requested date / outputs", "available_swipe_files": avail_names}), 404

    all_rows = []
    for fp in files_to_scan:
        try:
            raw_df = pd.read_csv(fp, dtype=str, parse_dates=['LocaleMessageTime'])
        except Exception:
            try:
                raw_df = pd.read_csv(fp, dtype=str)
            except Exception:
                continue

        raw_df = _replace_placeholder_strings(raw_df)
        cols_lower = {c.lower(): c for c in raw_df.columns}
        tcol = cols_lower.get('localemessagetime') or cols_lower.get('messagetime') or cols_lower.get('timestamp') or cols_lower.get('time') or None
        emp_col = cols_lower.get('int1') or cols_lower.get('employeeid') or cols_lower.get('employeeidentity') or cols_lower.get('employee_id') or None
        name_col = cols_lower.get('employeename') or cols_lower.get('objectname1') or cols_lower.get('employee_name') or None
        card_col = cols_lower.get('cardnumber') or cols_lower.get('card') or cols_lower.get('chuid') or cols_lower.get('value') or None
        door_col = cols_lower.get('door') or cols_lower.get('doorname') or cols_lower.get('door_name') or None
        dir_col = cols_lower.get('direction') or cols_lower.get('directionname') or cols_lower.get('direction_name') or None
        admit_cols = [c for c in ('admitcode','admit','admit_code','admit_type','admitstatus') if c in cols_lower]
        admit_col = cols_lower.get(admit_cols[0]) if admit_cols else None
        personnel_col = cols_lower.get('personneltype') or cols_lower.get('personneltypename') or None
        location_col = cols_lower.get('partitionname2') or cols_lower.get('location') or cols_lower.get('partitionname') or None
        person_uid_col = cols_lower.get('person_uid')

        mask = pd.Series(False, index=raw_df.index)
        if person_uid_col and person_uid_col in raw_df.columns:
            mask = mask | (raw_df[person_uid_col].astype(str).str.strip() == q_str)
        if emp_col and emp_col in raw_df.columns:
            mask = mask | (raw_df[emp_col].astype(str).str.strip() == q_str)
        if not mask.any() and emp_col and emp_col in raw_df.columns:
            try:
                q_numeric = float(q_str)
                emp_numeric = pd.to_numeric(raw_df[emp_col], errors='coerce')
                mask = mask | (emp_numeric == q_numeric)
            except Exception:
                pass
        if not mask.any() and name_col and name_col in raw_df.columns:
            try:
                mask = mask | (raw_df[name_col].astype(str).str.strip().str.lower() == q_str.lower())
            except Exception:
                pass

        if not mask.any():
            continue

        filtered = raw_df[mask].copy()
        if filtered.empty:
            continue

        if tcol and tcol in filtered.columns:
            try:
                filtered[tcol] = pd.to_datetime(filtered[tcol], errors='coerce')
            except Exception:
                pass

        if tcol and tcol in filtered.columns:
            filtered = filtered.sort_values(by=tcol)
            filtered['_prev_ts'] = filtered[tcol].shift(1)
            try:
                filtered['_swipe_gap_seconds'] = (filtered[tcol] - filtered['_prev_ts']).dt.total_seconds().fillna(0).astype(float)
            except Exception:
                filtered['_swipe_gap_seconds'] = 0.0
        else:
            filtered['_swipe_gap_seconds'] = 0.0

        try:
            if door_col and door_col in filtered.columns:
                if dir_col and dir_col in filtered.columns:
                    filtered['_zone'] = filtered.apply(lambda rr: map_door_to_zone(rr.get(door_col), rr.get(dir_col)), axis=1)
                else:
                    filtered['_zone'] = filtered[door_col].apply(lambda dv: map_door_to_zone(dv, None))
            else:
                filtered['_zone'] = filtered.get('PartitionName2', None)
        except Exception:
            filtered['_zone'] = None

        for _, r in filtered.iterrows():
            # compute timestamp variants
            ts_val = None
            if tcol and tcol in filtered.columns:
                ts_val = r.get(tcol)
            else:
                if 'Date' in filtered.columns:
                    ts_val = r.get('Date')
            try:
                dt = pd.to_datetime(ts_val)
                locale_iso = dt.isoformat() if pd.notna(dt) else None
            except Exception:
                locale_iso = str(ts_val) if ts_val is not None else None
            try:
                date_only = dt.strftime("%d-%b-%y") if pd.notna(dt) else None
            except Exception:
                date_only = None
            try:
                swipe_time = dt.strftime("%I:%M:%S %p").lstrip("0") if pd.notna(dt) else None
            except Exception:
                swipe_time = None

            # EmployeeID resolution
            emp_val = None
            try:
                if emp_col and emp_col in filtered.columns:
                    emp_val = _to_python_scalar(r.get(emp_col))
                else:
                    for cand in ('Int1','Text12','EmployeeID','EmployeeIdentity','empid','id'):
                        cl = cols_lower.get(cand.lower())
                        if cl and cl in filtered.columns:
                            emp_val = _to_python_scalar(r.get(cl))
                            if emp_val:
                                break
            except Exception:
                emp_val = None
            if emp_val is not None:
                try:
                    s = str(emp_val).strip()
                    if '.' in s:
                        try:
                            f = float(s)
                            if math.isfinite(f) and f.is_integer():
                                s = str(int(f))
                        except Exception:
                            pass
                    emp_val = s
                except Exception:
                    pass

            # ObjectName1 / EmployeeName
            obj_name = None
            try:
                if name_col and name_col in filtered.columns:
                    obj_name = _to_python_scalar(r.get(name_col))
                elif 'ObjectName1' in filtered.columns:
                    obj_name = _to_python_scalar(r.get('ObjectName1'))
                elif 'EmployeeName' in filtered.columns:
                    obj_name = _to_python_scalar(r.get('EmployeeName'))
            except Exception:
                obj_name = None

            personnel_val = _to_python_scalar(r.get(personnel_col)) if (personnel_col and personnel_col in filtered.columns) else None
            location_val = _to_python_scalar(r.get(location_col)) if (location_col and location_col in filtered.columns) else (_to_python_scalar(r.get('PartitionName2')) if 'PartitionName2' in filtered.columns else None)

            # Card Number
            card_val = None
            try:
                if card_col and card_col in filtered.columns:
                    card_val = _to_python_scalar(r.get(card_col))
                else:
                    for cand in ('CardNumber','CHUID','Card','card_no','cardnum','value','xmlmessage'):
                        cl = cols_lower.get(cand.lower())
                        if cl and cl in filtered.columns:
                            card_val = _to_python_scalar(r.get(cl))
                            if card_val not in (None, '', 'nan'):
                                break
                if card_val is not None:
                    card_val = str(card_val).strip()
            except Exception:
                card_val = None

            admit_val = _to_python_scalar(r.get(admit_col)) if (admit_col and admit_col in filtered.columns) else None
            if not admit_val:
                for cand in ('Admit','AdmitCode','Admit_Type','Rejection_Type','Note','NoteType','Source'):
                    cl = cols_lower.get(cand.lower())
                    if cl and cl in filtered.columns:
                        admit_val = _to_python_scalar(r.get(cl))
                        if admit_val:
                            break

            direction_val = _to_python_scalar(r.get(dir_col)) if (dir_col and dir_col in filtered.columns) else _to_python_scalar(r.get('Direction')) if 'Direction' in filtered.columns else None
            door_val = _to_python_scalar(r.get(door_col)) if (door_col and door_col in filtered.columns) else _to_python_scalar(r.get('Door')) if 'Door' in filtered.columns else None

            row_out = {
                "LocaleMessageTime": locale_iso,
                "DateOnly": date_only,
                "Swipe_Time": swipe_time,
                "EmployeeID": emp_val,
                "ObjectName1": obj_name,
                "PersonnelType": personnel_val,
                "Location": location_val,
                "CardNumber": card_val,
                "AdmitCode": admit_val,
                "Direction": direction_val,
                "Door": door_val,
                "_source_file": fp.name
            }

            all_rows.append(row_out)

    if not all_rows:
        return jsonify({"error":"no swipe rows matched the requested employee/date"}), 404

    df_out = pd.DataFrame(all_rows)

    # Further restrict to only rows that match a flagged trend row on the same Date & EmployeeID/person_uid
    # Build flagged lookup using trend CSV(s) again but now keyed by EmployeeID/Date
    flagged_dates = set()
    try:
        p = Path(DEFAULT_OUTDIR)
        # load relevant trend csv(s)
        trend_candidates = []
        if target_date_obj:
            fp_try = p / f"trend_{city_slug}_{target_date_obj.strftime('%Y%m%d')}.csv"
            if fp_try.exists():
                trend_candidates = [fp_try]
        if not trend_candidates:
            trend_candidates = sorted(p.glob("trend_*.csv"), reverse=True)
        for tf in trend_candidates:
            try:
                tdf = pd.read_csv(tf)
            except Exception:
                try:
                    tdf = pd.read_csv(tf, dtype=str)
                except Exception:
                    continue
            if tdf is None or tdf.empty:
                continue
            tdf = _replace_placeholder_strings(tdf)
            if 'IsFlagged' in tdf.columns:
                tsel = tdf[tdf['IsFlagged'] == True]
            else:
                if 'AnomalyScore' in tdf.columns:
                    try:
                        tsel = tdf[pd.to_numeric(tdf['AnomalyScore'], errors='coerce').fillna(0) >= ANOMALY_THRESHOLD]
                    except Exception:
                        tsel = pd.DataFrame()
                else:
                    tsel = pd.DataFrame()
            if tsel is None or tsel.empty:
                continue
            for _, tt in tsel.iterrows():
                try:
                    dval = None
                    if 'Date' in tt and pd.notna(tt.get('Date')):
                        try:
                            dval = pd.to_datetime(tt.get('Date')).date().isoformat()
                        except Exception:
                            dval = str(tt.get('Date'))
                    # collect candidate ids
                    for idcol in ('EmployeeID','person_uid','EmployeeIdentity','Int1','Text12','CardNumber'):
                        if idcol in tt and tt.get(idcol) not in (None, '', float('nan')):
                            try:
                                ival = str(tt.get(idcol)).strip()
                                if ival:
                                    flagged_dates.add((idcol, ival, dval))
                                    flagged_dates.add((idcol, ival, None))
                            except Exception:
                                continue
                except Exception:
                    continue
    except Exception:
        flagged_dates = set()

    # Keep rows where employee/date is present in flagged_dates
    def _row_is_flagged(r):
        emp = r.get('EmployeeID') or ''
        date_only = r.get('DateOnly')
        # try iso date from DateOnly (it is in DD-MMM-YY), so translate to iso for matching if possible
        date_iso = None
        try:
            if date_only:
                # parse using day-month-year short form
                date_iso = pd.to_datetime(date_only, format="%d-%b-%y", errors='coerce')
                if pd.notna(date_iso):
                    date_iso = date_iso.date().isoformat()
                else:
                    date_iso = None
        except Exception:
            date_iso = None
        # match by EmployeeID & date or EmployeeID with any date
        if emp and ((('EmployeeID', emp, date_iso) in flagged_dates) or (('EmployeeID', emp, None) in flagged_dates)):
            return True
        # also try matching by person_uid if employee string includes emp:/uid: patterns
        for idcol in ('person_uid', 'EmployeeIdentity', 'Int1', 'Text12', 'CardNumber'):
            if ((idcol, q_str, date_iso) in flagged_dates) or ((idcol, q_str, None) in flagged_dates):
                return True
        # fallback: if q matched and we earlier accepted q_flagged, accept rows for q
        try:
            if str(q_str) and (str(q_str) == str(emp) or str(q_str) == str(r.get('CardNumber'))):
                return True
        except Exception:
            pass
        return False

    df_filtered = df_out[df_out.apply(_row_is_flagged, axis=1)].copy()
    if df_filtered.empty:
        return jsonify({"error":"no flagged swipe rows found for the requested employee/date"}), 404

    # final column ordering and ensure only the columns requested
    final_cols = ["LocaleMessageTime","DateOnly","Swipe_Time","EmployeeID","ObjectName1","PersonnelType","Location","CardNumber","AdmitCode","Direction","Door"]
    # ensure all final_cols exist in df_filtered (create missing as None)
    for c in final_cols:
        if c not in df_filtered.columns:
            df_filtered[c] = None
    df_final = df_filtered[final_cols].copy()

    # write excel with single sheet "Evidence" (strict columns only)
    output = io.BytesIO()
    try:
        with pd.ExcelWriter(output, engine='openpyxl') as writer:
            df_final.to_excel(writer, sheet_name='Evidence', index=False)
            writer.save()
            output.seek(0)
    except Exception as e:
        logging.exception("Failed to create Excel: %s", e)
        return jsonify({"error":"failed to create excel"}), 500

    if OPENPYXL_AVAILABLE:
        try:
            wb = load_workbook(output)
            thin = Side(border_style="thin", color="000000")
            thick = Side(border_style="medium", color="000000")
            for ws in wb.worksheets:
                header = ws[1]
                for cell in header:
                    cell.font = Font(bold=True)
                    cell.alignment = Alignment(horizontal="center", vertical="center")
                    cell.border = Border(top=thick, left=thick, right=thick, bottom=thick)
                for row in ws.iter_rows(min_row=2, max_row=ws.max_row, min_col=1, max_col=ws.max_column):
                    for cell in row:
                        cell.alignment = Alignment(horizontal="center", vertical="center")
                        cell.border = Border(top=thin, left=thin, right=thin, bottom=thin)
                for col in ws.columns:
                    max_len = 0
                    col_letter = col[0].column_letter
                    for cell in col:
                        try:
                            v = str(cell.value) if cell.value is not None else ""
                        except Exception:
                            v = ""
                        if len(v) > max_len:
                            max_len = len(v)
                    width = min(max(10, max_len + 2), 50)
                    ws.column_dimensions[col_letter].width = width
            out2 = io.BytesIO()
            wb.save(out2)
            out2.seek(0)
            return send_file(out2, as_attachment=True,
                             download_name=f"evidence_{str(q).replace(' ','_')}_{date_str or 'all'}.xlsx",
                             mimetype="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet")
        except Exception:
            logging.exception("Excel styling failed, returning raw file")
            output.seek(0)
            return send_file(output, as_attachment=True,
                             download_name=f"evidence_{str(q).replace(' ','_')}_{date_str or 'all'}.xlsx",
                             mimetype="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet")
    else:
        output.seek(0)
        return send_file(output, as_attachment=True,
                         download_name=f"evidence_{str(q).replace(' ','_')}_{date_str or 'all'}.xlsx",
                         mimetype="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet")



@app.route('/swipes/<filename>', methods=['GET'])
def download_swipes(filename):
    fp = DEFAULT_OUTDIR / filename
    if not fp.exists():
        return jsonify({"error":"file not found"}), 404
    return send_from_directory(str(DEFAULT_OUTDIR), filename, as_attachment=True)


@app.route('/train', methods=['GET'])
def build_training_endpoint():
    end_date_str = request.args.get('end_date')
    months = int(request.args.get('months') or 3)
    min_unique = int(request.args.get('min_unique') or 1000)
    try:
        if end_date_str:
            end_date = datetime.strptime(end_date_str, "%Y-%m-%d").date()
        else:
            end_date = datetime.now().date()
    except Exception as e:
        return jsonify({"error": f"invalid end_date: {e}"}), 400

    try:
        if build_monthly_training is None:
            raise RuntimeError("build_monthly_training not available")
        csv_path = build_monthly_training(end_date=end_date, months=months, min_unique_employees=min_unique, outdir=str(DEFAULT_OUTDIR))
        if csv_path is None:
            return jsonify({"error":"no training CSV produced (no data)"}), 500
        return jsonify({"training_csv": str(csv_path)})
    except Exception as e:
        logging.exception("build_monthly_training failed")
        return jsonify({"error": str(e)}), 500




# chatbot helpers (kept mostly as-is)
try:
    from trend_runner import _read_past_trend_csvs, _normalize_id_val, SCENARIO_EXPLANATIONS
except Exception:
    _read_past_trend_csvs = None
    _normalize_id_val = None
    SCENARIO_EXPLANATIONS = {}

def _load_latest_trend_df(outdir: Path, city: str = "pune"):
    city_slug = _slug_city(city)
    csvs = sorted(outdir.glob(f"trend_{city_slug}_*.csv"), reverse=True)
    if not csvs:
        csvs = sorted(outdir.glob("trend_*.csv"), reverse=True)
    if not csvs:
        return None, None
    latest = csvs[0]
    try:
        df = pd.read_csv(latest)
    except Exception:
        df = pd.read_csv(latest, dtype=str)
    df = _replace_placeholder_strings(df)
    return df, latest.name

def _find_person_rows(identifier: str, days: int = 90, outdir: Path = DEFAULT_OUTDIR):
    if _normalize_id_val:
        norm = _normalize_id_val(identifier)
    else:
        norm = str(identifier).strip()
        if '.' in norm:
            try:
                f = float(norm)
                if f.is_integer():
                    norm = str(int(f))
            except Exception:
                pass
    today = datetime.now().date()
    try:
        if _read_past_trend_csvs:
            past = _read_past_trend_csvs(str(outdir), days, today)

            
        else:
            files = sorted(Path(outdir).glob("trend_pune_*.csv"), reverse=True)
            dfs = []
            cutoff = today - timedelta(days=days)
            for fp in files:
                try:
                    tmp = pd.read_csv(fp, parse_dates=['Date'])
                    tmp['Date'] = pd.to_datetime(tmp['Date'], errors='coerce').dt.date
                    tmp = tmp[tmp['Date'].apply(lambda d: d is not None and d >= cutoff and d <= today)]
                    dfs.append(tmp)
                except Exception:
                    try:
                        tmp = pd.read_csv(fp, dtype=str)
                        if 'Date' in tmp.columns:
                            tmp['Date'] = pd.to_datetime(tmp['Date'], errors='coerce').dt.date
                            tmp = tmp[tmp['Date'].apply(lambda d: d is not None and d >= cutoff and d <= today)]
                            dfs.append(tmp)
                    except Exception:
                        continue
            past = pd.concat(dfs, ignore_index=True) if dfs else pd.DataFrame()





    except Exception:
        past = pd.DataFrame()

    if past is None or past.empty:
        return pd.DataFrame()

    past = _replace_placeholder_strings(past)
    match_mask = pd.Series(False, index=past.index)
    for col in ('EmployeeID','person_uid','EmployeeIdentity','CardNumber','Int1','Text12'):
        if col in past.columns:
            try:
                match_mask = match_mask | (past[col].astype(str).fillna('').str.strip() == str(norm).strip())
            except Exception:
                continue

    if not match_mask.any():
        try:
            qnum = float(norm)
            for col in ('EmployeeID','Int1'):
                if col in past.columns:
                    try:
                        numcol = pd.to_numeric(past[col], errors='coerce')
                        match_mask = match_mask | (numcol == qnum)
                    except Exception:
                        continue
        except Exception:
            pass

    if not match_mask.any() and 'EmployeeName' in past.columns:
        names = past['EmployeeName'].dropna().astype(str).unique().tolist()
        close = difflib.get_close_matches(str(identifier), names, n=5, cutoff=0.7)
        if close:
            match_mask = match_mask | past['EmployeeName'].astype(str).isin(close)

    return past[match_mask].copy()

def _explain_scenario_code(code):
    if not code:
        return None
    code = str(code).strip()
    if code in SCENARIO_EXPLANATIONS:
        try:
            fn = SCENARIO_EXPLANATIONS.get(code)
            try:
                txt = fn({})
                return txt
            except Exception:
                return code.replace("_", " ").replace(">= ", "≥ ")
        except Exception:
            return code.replace("_", " ").replace(">= ", "≥ ")
    return code.replace("_", " ").replace(">=", "≥")

def _map_score_to_label_fallback(score: float):
    try:
        s = float(score)
    except Exception:
        return (0.0, "Low")
    if s >= 0.75:
        return (s, "High")
    if s >= 0.4:
        return (s, "Medium")
    return (s, "Low")

@app.route('/chatbot/query', methods=['POST'])
def chatbot_query():
    payload = request.get_json(force=True)
    q = (payload.get('q') or '').strip()
    if not q:
        return jsonify({"error":"query text 'q' required"}), 400
    lang = payload.get('lang')
    q_l = q.lower().strip()

    if re.search(r"\bwho is (high|low) risk\b", q_l) or re.search(r"\b(high|low) risk (people|persons|people) (today)?\b", q_l):
        want = 'high' if 'high' in q_l else 'low' if 'low' in q_l else None
        df, fname = _load_latest_trend_df(DEFAULT_OUTDIR)
        if df is None:
            return jsonify({"answer": "No trend data available.", "evidence": []})
        if 'RiskLevel' not in df.columns:
            if 'RiskScore' in df.columns:
                def _map_rs(s):
                    try:
                        if pd.isna(s):
                            return 'Low'
                    except Exception:
                        pass
                    try:
                        if 'map_score_to_label' in globals() and callable(globals().get('map_score_to_label')):
                            try:
                                return globals().get('map_score_to_label')(float(s))[1]
                            except Exception:
                                pass
                        return _map_score_to_label_fallback(float(s))[1]
                    except Exception:
                        return 'Low'
                df['RiskLevel'] = df['RiskScore'].apply(lambda s: _map_rs(s))
            else:
                df['RiskLevel'] = df.get('RiskLevel', 'Low')
        if want == 'high':
            sel = df[df['RiskLevel'].astype(str).str.lower() == 'high']
        elif want == 'low':
            sel = df[df['RiskLevel'].astype(str).str.lower() == 'low']
        else:
            sel = df
        names = sel['EmployeeName'].dropna().astype(str).unique().tolist()
        if not names:
            ans = f"No {want} risk persons found in the latest data." if want else "No persons found."
            return jsonify({"answer": ans, "evidence": []})
        else:
            ans = f"{want.capitalize()} risk persons today: " + ", ".join(names[:40])
            sample = _clean_sample_df(sel.head(10), max_rows=10)
            return jsonify({"answer": ans, "evidence": sample})

    m = re.match(r".*\bexplain\s+([A-Za-z0-9_\-]+)\b.*", q_l)
    if m:
        code = m.group(1).strip()
        explanation = _explain_scenario_code(code)
        ans = f"Explanation for '{code}': {explanation}"
        return jsonify({"answer": ans, "evidence": []})

    if 'trend details' in q_l or 'top reasons' in q_l or 'trend details for today' in q_l:
        df, fname = _load_latest_trend_df(DEFAULT_OUTDIR)
        if df is None:
            return jsonify({"answer":"No trend data available.","evidence":[]})
        if 'Reasons' in df.columns:
            reasons = {}
            for v in df['Reasons'].dropna().astype(str):
                for part in re.split(r'[;,\|]', v):
                    key = part.strip()
                    if key and not _is_placeholder_str(key):
                        reasons[key] = reasons.get(key, 0) + 1
            top = sorted(reasons.items(), key=lambda x: x[1], reverse=True)[:10]
            if not top:
                return jsonify({"answer":"No reason counts available today.","evidence":[]})
            ans = "Top reasons today: " + ", ".join([f"{k} ({c})" for k,c in top])
            sample = []
            try:
                top_reasons = [k for k,_ in top]
                mask = df['Reasons'].astype(str).apply(lambda s: any(tr in s for tr in top_reasons))
                sample_df = df[mask].head(10)
                sample = _clean_sample_df(sample_df, max_rows=10)
            except Exception:
                sample = []
            return jsonify({"answer": ans, "evidence": sample})

    m = re.match(r".*\bshow (?:me )?([A-Za-z0-9\-\:\s]+?) (?:for )?(?:last )?(\d+)\s*days\b", q_l)
    if not m:
        m = re.match(r".*\b(show|display)\s+(?:me\s+)?([A-Za-z0-9\-\:\s]+?)\s+last\s+(\d+)\s*days\b", q_l)
    if m:
        if len(m.groups()) == 2:
            identifier, days = m.group(1).strip(), int(m.group(2))
        else:
            identifier = m.group(1).strip()
            days = int(m.group(2))
        rows = _find_person_rows(identifier, days=days, outdir=DEFAULT_OUTDIR)
        if rows is None or rows.empty:
            return jsonify({"answer": f"No records found for '{identifier}' in last {days} days.", "evidence": []})
        flagged = rows[rows.get('IsFlagged', False) == True] if 'IsFlagged' in rows.columns else pd.DataFrame()
        flagged_count = int(len(flagged))
        total_days = int(len(rows))
        latest_row = rows.sort_values('Date', ascending=False).iloc[0].to_dict()
        name = latest_row.get('EmployeeName') or latest_row.get('person_uid') or latest_row.get('EmployeeID')
        ans = f"Found {total_days} day(s) for {name} in the last {days} days. Flagged days: {flagged_count}."
        sample = _clean_sample_df(rows.sort_values('Date', ascending=False).head(10), max_rows=10)
        return jsonify({"answer": ans, "evidence": sample})

    if 'present today' in q_l or 'who is present today' in q_l:
        df, fname = _load_latest_trend_df(DEFAULT_OUTDIR)
        if df is None:
            return jsonify({"answer":"No trend data available.","evidence":[]})
        if 'PresentToday' in df.columns:
            present = df[df['PresentToday'] == True]
            names = present['EmployeeName'].dropna().unique().tolist()
            ans = f"Present today: {', '.join(names[:40]) if names else 'None'}"
            sample = _clean_sample_df(present.head(10), max_rows=10)
            return jsonify({"answer": ans, "evidence": sample})
        else:
            return jsonify({"answer":"PresentToday field not available in latest trends.","evidence":[]})

    hint = "I can answer: 'Who is high risk today', 'Who is low risk today', 'Show me <EmployeeID|Name> last 90 days', 'Explain <scenario_code>', 'Trend details for today — top reasons'."
    return jsonify({"answer": f"I can help with trend & risk questions. I recognized: {q}. Try: {hint}", "evidence":[]})


# run
if __name__ == "__main__":
    app.run(host="0.0.0.0", port=8002, debug=True)







# backend/employeeimage.py


from __future__ import annotations
import logging
import os
import base64
from pathlib import Path
from typing import Optional, Dict, Any

# optional imports (handled gracefully)
try:
    import pyodbc
except Exception:
    pyodbc = None

# optional region configuration (if available)
try:
    from duration_report import REGION_CONFIG
except Exception:
    REGION_CONFIG = {}

ODBC_DRIVER = os.getenv("ODBC_DRIVER", "ODBC Driver 17 for SQL Server")
DEFAULT_OUTDIR = Path(__file__).resolve().parent / "outputs"
DEFAULT_OUTDIR.mkdir(parents=True, exist_ok=True)

# uuid-like regex (optional)
try:
    import re

    _uuid_like_re = re.compile(
        r'^[0-9A-Fa-f]{8}\-[0-9A-Fa-f]{4}\-[0-9A-Fa-f]{4}\-[0-9A-Fa-f]{4}\-[0-9A-Fa-f]{12}$'
    )
except Exception:
    _uuid_like_re = None


def _looks_like_guid(s: object) -> bool:
    try:
        if s is None:
            return False
        st = str(s).strip()
        if not st:
            return False
        if _uuid_like_re:
            if _uuid_like_re.match(st):
                return True
        # support legacy prefixes used in some pipelines
        lower = st.lower()
        if lower.startswith("emp:") or lower.startswith("uid:") or lower.startswith("name:"):
            return True
        return False
    except Exception:
        return False


def _strip_person_uid_prefix(token: object) -> Optional[str]:
    if token is None:
        return None
    try:
        s = str(token).strip()
        if not s:
            return None
        if ":" in s:
            prefix, rest = s.split(":", 1)
            if prefix.lower() in ("emp", "uid", "name"):
                rest = rest.strip()
                if rest:
                    return rest
        return s
    except Exception:
        return None


# ACVSCore connection backoff state (module-level)
_acvscore_backoff = {"ts": None, "failed": False}
_ACVSCORE_BACKOFF_SECONDS = 20


def _get_acvscore_conn(timeout: int = 5):
    """
    Try to connect to ACVSCore using REGION_CONFIG. Returns pyodbc.Connection or None.
    Respects a short backoff to avoid repeated noisy attempts.
    """
    try:
        import time
        now = time.time()
        last = _acvscore_backoff.get("ts")
        if last and _acvscore_backoff.get("failed") and (now - last) < _ACVSCORE_BACKOFF_SECONDS:
            logging.debug("ACVSCore backoff active.")
            return None
    except Exception:
        # if something goes wrong in time/backoff handling, continue attempting connection
        pass

    if pyodbc is None:
        logging.debug("pyodbc not installed - ACVSCore lookup unavailable.")
        return None

    tried = []
    for rkey, rc in (REGION_CONFIG or {}).items():
        server = rc.get("server")
        user = rc.get("user")
        pwd = rc.get("password")
        if not server:
            continue

        # 1) SQL auth (if credentials present)
        if user and pwd:
            tried.append(f"{rkey}@{server}(sql)")
            conn_str = (
                f"DRIVER={{{ODBC_DRIVER}}};"
                f"SERVER={server};DATABASE=ACVSCore;UID={user};PWD={pwd};"
                "TrustServerCertificate=Yes;"
            )
            try:
                conn = pyodbc.connect(conn_str, autocommit=True, timeout=timeout)
                logging.info("Connected to ACVSCore on %s using SQL auth (region %s).", server, rkey)
                _acvscore_backoff["failed"] = False
                _acvscore_backoff["ts"] = None
                return conn
            except Exception:
                logging.debug("SQL auth to %s failed", server)

        # 2) Trusted connection fallback
        tried.append(f"{rkey}@{server}(trusted)")
        conn_str_trusted = (
            f"DRIVER={{{ODBC_DRIVER}}};"
            f"SERVER={server};DATABASE=ACVSCore;Trusted_Connection=yes;"
            "TrustServerCertificate=Yes;"
        )
        try:
            conn = pyodbc.connect(conn_str_trusted, autocommit=True, timeout=timeout)
            logging.info("Connected to ACVSCore on %s using trusted connection (region %s).", server, rkey)
            _acvscore_backoff["failed"] = False
            _acvscore_backoff["ts"] = None
            return conn
        except Exception:
            logging.debug("Trusted connection to %s failed", server)
            continue

    # mark failure & set backoff timestamp
    try:
        import time
        _acvscore_backoff["ts"] = time.time()
        _acvscore_backoff["failed"] = True
    except Exception:
        pass

    logging.error("Failed ACVSCore connection attempts: %s", tried)
    return None


def get_personnel_info(candidate_identifier: object) -> Dict[str, Any]:
    """
    Lookup personnel in ACVSCore.Access.Personnel. Returns dict or {} on failure/unavailable.
    Keys commonly returned: ObjectID, GUID, Name, EmailAddress, EmployeeEmail, ManagerEmail
    """
    out: Dict[str, Any] = {}
    if candidate_identifier is None:
        return out

    conn = _get_acvscore_conn()
    if conn is None:
        logging.debug("get_personnel_info: ACVSCore unavailable.")
        return out

    cur = None
    try:
        cur = conn.cursor()
        sql = """
            SELECT TOP 1 ObjectID, GUID, Name, EmailAddress, ManagerEmail
            FROM ACVSCore.Access.Personnel
            WHERE
              (CAST(ObjectID AS NVARCHAR(200)) = ?)
              OR (GUID = ?)
              OR (CAST(Int1 AS NVARCHAR(200)) = ?)
              OR (Text12 = ?)
              OR (Name = ?)
            ORDER BY ObjectID DESC
        """
        cand = str(candidate_identifier).strip()
        cand_guid = cand if _looks_like_guid(cand) else None
        params = (cand, cand_guid, cand, cand, cand)
        cur.execute(sql, params)
        row = cur.fetchone()
        if row:
            try:
                out["ObjectID"] = row[0] if len(row) > 0 else None
                out["GUID"] = row[1] if len(row) > 1 else None
                out["Name"] = row[2] if len(row) > 2 else None
                email_val = row[3] if len(row) > 3 else None
                out["EmailAddress"] = email_val or None
                out["EmployeeEmail"] = email_val or None
                out["ManagerEmail"] = row[4] if len(row) > 4 else None
                logging.info(
                    "get_personnel_info: found ObjectID=%s Email=%s for candidate=%s",
                    out.get("ObjectID"),
                    out.get("EmailAddress"),
                    candidate_identifier,
                )
            except Exception:
                logging.exception("get_personnel_info: failed parsing DB row")
    except Exception:
        logging.exception("get_personnel_info: DB query failed for %s", candidate_identifier)
    finally:
        try:
            if cur is not None:
                cur.close()
        except Exception:
            pass
        try:
            conn.close()
        except Exception:
            pass

    return out


def get_person_image_bytes(parent_id) -> Optional[bytes]:
    """
    Retrieve an employee image by parent_id:
      1) DB (ACVSCore.Access.Images) - if available
      2) Filesystem under outputs/images, outputs, repo/images, repo root, cwd
      3) Base64 text files (.b64/.txt)
    Returns bytes or None.

    NOTE: This function will attempt to resolve the incoming identifier to Personnel.ObjectID/GUID
    via get_personnel_info() and try those values as ParentId in Images as a fallback.
    """
    if parent_id is None:
        return None

    # Attempt DB lookup first (best-effort)
    try:
        conn = _get_acvscore_conn()
        if conn is not None:
            cur = None
            try:
                cur = conn.cursor()
                sql = """
                    SELECT TOP 1 AI.Image
                    FROM ACVSCore.Access.Images AI
                    WHERE AI.ParentId = ?
                      AND DATALENGTH(AI.Image) > 0
                    ORDER BY AI.ObjectID DESC
                """
                raw_pid = str(parent_id).strip()
                cand_parent_ids = [raw_pid]
                stripped = _strip_person_uid_prefix(raw_pid)
                if stripped and stripped != raw_pid:
                    cand_parent_ids.append(stripped)
                # integer/float fallback forms
                try:
                    if stripped and "." in stripped:
                        f = float(stripped)
                        if f.is_integer():
                            cand_parent_ids.append(str(int(f)))
                except Exception:
                    pass
                try:
                    if stripped and stripped.isdigit():
                        cand_parent_ids.append(f"emp_{stripped}")
                except Exception:
                    pass

                # --- NEW: attempt to resolve candidate -> Personnel.ObjectID / GUID and append ---
                try:
                    pinfo = get_personnel_info(raw_pid) or {}
                    if pinfo:
                        obj = pinfo.get("ObjectID")
                        guid = pinfo.get("GUID")
                        # add objectid/guid as strings (preserve order: prefer ObjectID first)
                        if obj is not None:
                            obj_s = str(obj).strip()
                            if obj_s:
                                cand_parent_ids.append(obj_s)
                        if guid:
                            guid_s = str(guid).strip()
                            if guid_s:
                                cand_parent_ids.append(guid_s)
                except Exception:
                    logging.debug("get_person_image_bytes: personnel resolution failed for %s", raw_pid)

                # dedupe preserving order
                seen = set()
                cand_parent_ids = [x for x in cand_parent_ids if x and (not (x in seen or seen.add(x)))]

                for pid_try in cand_parent_ids:
                    try:
                        cur.execute(sql, (str(pid_try),))
                        row = cur.fetchone()
                        if row and row[0] is not None:
                            try:
                                b = bytes(row[0])
                                logging.info(
                                    "get_person_image_bytes: DB image found for ParentId=%s (len=%d)",
                                    pid_try,
                                    len(b),
                                )
                                return b
                            except Exception:
                                logging.exception(
                                    "get_person_image_bytes: convert DB image to bytes failed for %s", pid_try
                                )
                                return row[0]
                    except Exception:
                        logging.debug("get_person_image_bytes: DB fetch failed for ParentId=%s", pid_try)
                        continue
            except Exception:
                logging.exception("get_person_image_bytes: DB query failed")
            finally:
                try:
                    if cur is not None:
                        cur.close()
                except Exception:
                    pass
                try:
                    conn.close()
                except Exception:
                    pass
    except Exception:
        logging.exception("get_person_image_bytes: unexpected DB path error")

    # Filesystem + base64 fallback
    try:
        pid_raw = str(parent_id).strip()
        cand_ids = [pid_raw]
        try:
            f = float(pid_raw)
            if f.is_integer():
                int_form = str(int(f))
                if int_form not in cand_ids:
                    cand_ids.append(int_form)
        except Exception:
            pass
        try:
            if pid_raw.isdigit():
                cand_ids.append(f"emp_{pid_raw}")
                if len(pid_raw) < 8:
                    cand_ids.append(pid_raw.zfill(8))
        except Exception:
            pass

        # unique preserve order
        cand_ids = list(dict.fromkeys(cand_ids))

        candidate_dirs = [
            (Path(DEFAULT_OUTDIR) / "images"),
            Path(DEFAULT_OUTDIR),
            Path(__file__).resolve().parent / "images",
            Path(__file__).resolve().parent,
            Path.cwd(),
        ]

        exts = (".jpg", ".jpeg", ".png", ".bmp", ".gif", ".webp")
        b64_exts = (".b64", ".txt")

        for c in cand_ids:
            for folder in candidate_dirs:
                try:
                    if not folder.exists():
                        continue
                except Exception:
                    continue

                # exact filename match with normal image extensions
                for ext in exts:
                    fp = folder / f"{c}{ext}"
                    try:
                        if fp.exists() and fp.is_file():
                            try:
                                return fp.read_bytes()
                            except Exception:
                                logging.exception("get_person_image_bytes: failed reading %s", fp)
                                continue
                    except Exception:
                        continue

                # base64 text file containers
                for ext in b64_exts:
                    fp = folder / f"{c}{ext}"
                    try:
                        if fp.exists() and fp.is_file():
                            try:
                                txt = fp.read_text(encoding="utf-8", errors="ignore").strip()
                                if txt:
                                    if "," in txt and txt.startswith("data:"):
                                        try:
                                            b64 = txt.split(",", 1)[1]
                                            return base64.b64decode(b64)
                                        except Exception:
                                            pass
                                    try:
                                        return base64.b64decode(txt)
                                    except Exception:
                                        logging.exception(
                                            "get_person_image_bytes: base64 decode failed for %s", fp
                                        )
                                        continue
                            except Exception:
                                logging.exception("get_person_image_bytes: failed reading base64 file %s", fp)
                                continue
                    except Exception:
                        continue

                # glob fallback: any file containing token c
                try:
                    for fp in folder.glob(f"*{c}*"):
                        if fp.is_file():
                            try:
                                b = fp.read_bytes()
                                if b:
                                    logging.info("get_person_image_bytes: loaded image via glob %s", fp)
                                    return b
                            except Exception:
                                logging.exception("get_person_image_bytes: failed reading glob file %s", fp)
                                continue
                except Exception:
                    logging.exception(
                        "get_person_image_bytes: glob check failed in %s for token %s", folder, c
                    )
                    continue
    except Exception:
        logging.exception("get_person_image_bytes: filesystem search failed for ParentId=%s", parent_id)

    logging.debug("get_person_image_bytes: no image found for ParentId=%s", parent_id)
    return None


# exported symbols
__all__ = ["get_person_image_bytes", "get_personnel_info", "_get_acvscore_conn"]







C:\Users\W0024618\Desktop\Trend Analysis\frontend\index.html

<!doctype html>
<html>

<head>
  <meta charset="utf-8" />
  <title>Behaviour Analysis — Dashboard</title>
  <meta name="viewport" content="width=device-width,initial-scale=1" />
  <!-- React + ReactDOM + Babel (quick prototyping) -->
  <script crossorigin src="https://unpkg.com/react@18/umd/react.development.js"></script>
  <script crossorigin src="https://unpkg.com/react-dom@18/umd/react-dom.development.js"></script>
  <script crossorigin src="https://unpkg.com/babel-standalone@6.26.0/babel.min.js"></script>

  <!-- Chart.js -->
  <script src="https://cdn.jsdelivr.net/npm/chart.js"></script>

  <!-- Flatpickr -->
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/flatpickr/dist/flatpickr.min.css">
  <script src="https://cdn.jsdelivr.net/npm/flatpickr"></script>

  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap-icons@1.11.1/font/bootstrap-icons.css">
  <link rel="stylesheet" href="style.css">
</head>

<body>
  <div id="root"></div>

  <script type="text/babel">
    (function () {
      const { useState, useEffect, useRef } = React;

      // CHANGE IF YOUR API HOST DIFFERS
      const API_BASE = "http://localhost:8002";

      function resolveApiImageUrl(imgUrl) {
        if (!imgUrl) return null;
        try {
          if (imgUrl.startsWith('http://') || imgUrl.startsWith('https://')) return imgUrl;
          // ensure API_BASE has no trailing slash
          var base = API_BASE.replace(/\/$/, '');
          if (imgUrl.startsWith('/')) return base + imgUrl;
          return base + '/' + imgUrl;
        } catch (e) {
          return imgUrl;
        }
      }


      // --- Region / Location mapping copied from backend/duration_report.REGION_CONFIG (friendly / UI names) ---
      // Keep the keys lowercase to match backend region keys.
      const REGION_OPTIONS = {
        "apac": {
          label: "APAC",
          // Friendly names used by backend normalisation (duration_report) for APAC
          partitions: ["Pune", "Quezon City", "Taguig City", "MY.Kuala Lumpur", "IN.HYD", "SG.Singapore"]
        },
        "emea": {
          label: "EMEA",
          partitions: ["LT.Vilnius", "IT.Rome", "UK.London", "IE.DUblin", "DU.Abu Dhab", "ES.Madrid"]
        },
        "laca": {
          label: "LACA",
          partitions: ["AR.Cordoba", "BR.Sao Paulo", "CR.Costa Rica Partition", "PA.Panama City", "PE.Lima", "MX.Mexico City"]
        },
        "namer": {
          label: "NAMER",
          // show friendly names to the user, but we map them to backend partition tokens before sending
          partitions: ["Denver", "Austin Texas", "Miami", "New York"]
        }
      };

      // Map from UI-friendly location label -> backend search token (used for &city=)
      // For APAC, friendly labels match backend PartitionName2 normalised values so they map to themselves.
      // For NAMER, backend normalisation sets PartitionName2 to tokens like "US.CO.OBS", "USA/Canada Default" etc.
      const LOCATION_QUERY_VALUE = {
        "apac": {
          "Pune": "Pune",
          "Quezon City": "Quezon City",
          "Taguig City": "Taguig City",
          "MY.Kuala Lumpur": "MY.Kuala Lumpur",
          "IN.HYD": "IN.HYD",
          "SG.Singapore": "SG.Singapore"
        },
        "namer": {
          // friendly->backend tokens (this matches the backend duration_report normalisation)
          "Denver": "US.CO.OBS",
          "Austin Texas": "USA/Canada Default",
          "Miami": "US.FL.Miami",
          "New York": "US.NYC"
        },
        // default passthrough for other regions (if needed)
        "emea": {},
        "laca": {}
      };

      // Map risk text/colors (same as backend map_score_to_label buckets)
      const RISK_COLORS = {
        "Low": "#10b981",
        "Low Medium": "#86efac",
        "Medium": "#facc15",
        "Medium High": "#fb923c",
        "High": "#ef4444"
      };
      const RISK_LABELS = ["Low", "Low Medium", "Medium", "Medium High", "High"];

      // (rest unchanged) Explanations...
      const SCENARIO_EXPLANATIONS = {
        "long_gap_>=4.5h": "Long gap between swipes (>=4.5 hours).",
        "short_duration_<4h": "Short total presence (<4 hours).",
        "coffee_badging": "Multiple short swipes — possible coffee badging.",
        "low_swipe_count_<=2": "Very few swipes recorded for day (<=2).",
        "single_door": "Single door used during day.",
        "only_in": "Only IN events present.",
        "only_out": "Only OUT events present.",
        "overtime_>=10h": "Overtime (>=10 hours).",
        "very_long_duration_>=16h": "Very long presence (>=16 hours).",
        "unusually_high_swipes": "Unusually high number of swipes vs history.",
        "repeated_short_breaks": "Multiple short breaks in day.",
        "multiple_location_same_day": "Multiple locations used same day.",
        "weekend_activity": "Activity on weekend.",
        "repeated_rejection_count": "Multiple rejections.",
        "badge_sharing_suspected": "Same card used by multiple persons on same day.",
        "early_arrival_before_06": "First swipe earlier than 06:00.",
        "late_exit_after_22": "Last swipe after 22:00.",
        "shift_inconsistency": "Duration inconsistent with historical shift.",
        "trending_decline": "Historical trending decline.",
        "consecutive_absent_days": "Consecutive absent days historically.",
        "high_variance_duration": "High variance in durations historically.",
        "short_duration_on_high_presence_days": "Short duration despite high typical presence.",
        "swipe_overlap": "Swipes overlapping other users (possible tailgating).",
        "shortstay_longout_repeat": "Short in -> long out -> short return pattern."
      };

      // small utilities
      function pad(n) { return n.toString().padStart(2, '0'); }
      function formatDateISO(d) {
        if (!d) return "";
        const dt = (d instanceof Date) ? d : new Date(d);
        return dt.getFullYear() + "-" + pad(dt.getMonth() + 1) + "-" + pad(dt.getDate());
      }
      function safeDateDisplay(val) {
        if (!val && val !== 0) return "";
        try {
          const d = (val instanceof Date) ? val : new Date(val);
          if (isNaN(d.getTime())) return String(val);
          return d.toLocaleString();
        } catch (e) {
          return String(val);
        }
      }

      function sanitizeName(row) {
        if (!row) return "";
        // prefer feature/duration versions if present
        return row.EmployeeName_feat || row.EmployeeName_dur || row.EmployeeName || row.ObjectName1 || row.objectname1 || row.employee_name || row.person_uid || "";
      }


      function downloadCSV(rows, filename) {
        if (!rows || !rows.length) { alert("No rows to export"); return; }
        var cols = Object.keys(rows[0]);
        var lines = [cols.join(",")];
        rows.forEach(function (r) {
          var row = cols.map(function (c) {
            var v = (r[c] === undefined || r[c] === null) ? "" : String(r[c]).replace(/\n/g, ' ');
            return JSON.stringify(v);
          }).join(",");
          lines.push(row);
        });
        var blob = new Blob([lines.join("\n")], { type: 'text/csv' });
        var url = URL.createObjectURL(blob);
        var a = document.createElement('a'); a.href = url; a.download = filename || 'export.csv'; a.click(); URL.revokeObjectURL(url);
      }

      // duration formatting helper
      function formatSecondsToHmsJS(seconds) {
        if (seconds === null || seconds === undefined || seconds === '') return "-";
        const n = Number(seconds);
        if (isNaN(n) || !isFinite(n)) return "-";
        const s = Math.max(0, Math.floor(n));
        const hh = Math.floor(s / 3600);
        const mm = Math.floor((s % 3600) / 60);
        const ss = s % 60;
        return pad(hh) + ":" + pad(mm) + ":" + pad(ss);
      }



      // duration formatting helper (HH:MM) — used for Duration fields (strict HH:MM)
      function formatSecondsToHmJS(seconds) {
        if (seconds === null || seconds === undefined || seconds === '') return "-";
        const n = Number(seconds);
        if (isNaN(n) || !isFinite(n)) return "-";
        const s = Math.max(0, Math.floor(n));
        const hh = Math.floor(s / 3600);
        const mm = Math.floor((s % 3600) / 60);
        // return HH:MM (hours may be >23)
        return String(hh) + ":" + String(mm).padStart(2, '0');
      }


      // ----- Day-boundary helpers -----
      // Backend assigns Date using LocaleMessageTime.date() (no 2AM shift).
      // Keep frontend day-boundary at 0 so logical dates match backend.
      const DAY_BOUNDARY_HOUR = 0;

      function logicalDateForTs(dt, boundaryHour = DAY_BOUNDARY_HOUR) {
        if (!dt || !(dt instanceof Date) || isNaN(dt.getTime())) return null;
        const hour = dt.getHours();
        const year = dt.getFullYear();
        const month = dt.getMonth();
        const day = dt.getDate();
        const out = new Date(year, month, day, 0, 0, 0, 0);
        // with boundaryHour = 0, this never subtracts a day -> matches backend date assignment
        if (hour < boundaryHour) {
          out.setDate(out.getDate() - 1);
        }
        const y = out.getFullYear();
        const m = String(out.getMonth() + 1).padStart(2, '0');
        const d = String(out.getDate()).padStart(2, '0');
        return `${y}-${m}-${d}`;
      }

      function makeLocalDateFromRow(r) {
        try {
          if (!r) return null;

          // backend usually includes LocaleMessageTime (ISO string). Prefer that.
          if (r.LocaleMessageTime) {
            const t = new Date(r.LocaleMessageTime);
            if (!isNaN(t.getTime())) return t;
          }

          function toInt(v, fallback = 0) {
            const n = Number(v);
            return Number.isFinite(n) ? n : fallback;
          }

          // Backend also supplies DateOnly + Time for frontend convenience — use those if present.
          if (r.DateOnly && r.Time) {
            try {
              // DateOnly might be a Date object or 'YYYY-MM-DD' string.
              const dateStr = String(r.DateOnly).slice(0, 10).replace(/\//g, '-');
              const dateParts = dateStr.split('-').map(p => toInt(p, NaN));
              if (dateParts.length === 3 && !isNaN(dateParts[0])) {
                const year = dateParts[0];
                const month = dateParts[1];
                const day = dateParts[2];

                const timeRaw = String(r.Time).split(/[.+Z ]/)[0];
                const timeParts = timeRaw.split(':').map(p => toInt(p, 0));
                const hh = timeParts[0] || 0;
                const mm = timeParts[1] || 0;
                const ss = timeParts[2] || 0;

                return new Date(year, month - 1, day, hh, mm, ss, 0);
              }
            } catch (e) { /* fallthrough */ }
          }

          // fallback: if Date and Time fields exist (older API formats)
          if (r.Date && r.Time) {
            try {
              const dateStr = String(r.Date).slice(0, 10).replace(/\//g, '-');
              const dateParts = dateStr.split('-').map(p => toInt(p, NaN));
              if (dateParts.length === 3 && !isNaN(dateParts[0])) {
                const year = dateParts[0];
                const month = dateParts[1];
                const day = dateParts[2];

                const timeRaw = String(r.Time).split(/[.+Z ]/)[0];
                const timeParts = timeRaw.split(':').map(p => toInt(p, 0));
                const hh = timeParts[0] || 0;
                const mm = timeParts[1] || 0;
                const ss = timeParts[2] || 0;

                return new Date(year, month - 1, day, hh, mm, ss, 0);
              }
            } catch (e) { /* fallthrough */ }
          }

          // if only DateOnly present, return midnight of that date
          if (r.DateOnly) {
            try {
              const parts = String(r.DateOnly).slice(0, 10).replace(/\//g, '-').split('-');
              if (parts.length === 3) {
                const y = toInt(parts[0], NaN);
                const m = toInt(parts[1], NaN);
                const d = toInt(parts[2], NaN);
                if (!isNaN(y)) return new Date(y, m - 1, d, 0, 0, 0, 0);
              }
            } catch (e) { /* fallthrough */ }
          }

          // if only Date present, use that
          if (r.Date) {
            try {
              const parts = String(r.Date).slice(0, 10).replace(/\//g, '-').split('-');
              if (parts.length === 3) {
                const y = toInt(parts[0], NaN);
                const m = toInt(parts[1], NaN);
                const d = toInt(parts[2], NaN);
                if (!isNaN(y)) return new Date(y, m - 1, d, 0, 0, 0, 0);
              }
            } catch (e) { /* fallthrough */ }
          }

        } catch (e) { }
        return null;
      }

      // App component
      function App() {
        var yesterday = new Date();
        yesterday.setDate(yesterday.getDate() - 1);

        const [dateFrom, setDateFrom] = useState(formatDateISO(yesterday));
        const [dateTo, setDateTo] = useState(formatDateISO(new Date()));
        const [loading, setLoading] = useState(false);
        const [summary, setSummary] = useState({ rows: 0, flagged_rows: 0, files: [], end_date: null });
        const [rows, setRows] = useState([]);
        const [reasonsCount, setReasonsCount] = useState({});
        const [riskCounts, setRiskCounts] = useState({ "Low": 0, "Low Medium": 0, "Medium": 0, "Medium High": 0, "High": 0 });
        const [filterText, setFilterText] = useState("");
        const [page, setPage] = useState(1);
        const [selectedReason, setSelectedReason] = useState("");
        const [reasonFilterText, setReasonFilterText] = useState("");
        const [modalRow, setModalRow] = useState(null);
        const [modalDetails, setModalDetails] = useState(null);
        const [modalLoading, setModalLoading] = useState(false);
        const [selectedRiskFilter, setSelectedRiskFilter] = useState("");

        // New: region & location
        const [selectedRegion, setSelectedRegion] = useState("apac"); // default APAC
        const [selectedLocation, setSelectedLocation] = useState("All locations"); // default no city filter

        const pageSize = 25;
        const chartRef = useRef(null);
        const chartInst = useRef(null);

        const fromRef = useRef(null);
        const toRef = useRef(null);
        const fromFp = useRef(null);
        const toFp = useRef(null);

        // Chat state
        const [chatOpen, setChatOpen] = useState(false);
        const [chatMessages, setChatMessages] = useState([]);
        const [chatInput, setChatInput] = useState("");
        const [chatLoading, setChatLoading] = useState(false);

        useEffect(function () {
          if (window.flatpickr && fromRef.current && toRef.current) {
            try { if (fromFp.current) fromFp.current.destroy(); } catch (e) { }
            try { if (toFp.current) toFp.current.destroy(); } catch (e) { }
            fromFp.current = window.flatpickr(fromRef.current, {
              dateFormat: "Y-m-d",
              defaultDate: dateFrom,
              allowInput: true,
              onChange: function (selectedDates, str) {
                if (selectedDates && selectedDates.length) {
                  const iso = formatDateISO(selectedDates[0]);
                  setDateFrom(iso);
                  try { if (toFp.current) toFp.current.set('minDate', iso); } catch (e) { }
                  if (dateTo && new Date(iso) > new Date(dateTo)) {
                    setDateTo(iso);
                    try { if (toFp.current) toFp.current.setDate(iso, true); } catch (e) { }
                  }
                }
              }
            });
            toFp.current = window.flatpickr(toRef.current, {
              dateFormat: "Y-m-d",
              defaultDate: dateTo,
              allowInput: true,
              onChange: function (selectedDates, str) {
                if (selectedDates && selectedDates.length) {
                  const iso = formatDateISO(selectedDates[0]);
                  setDateTo(iso);
                  try { if (fromFp.current) fromFp.current.set('maxDate', iso); } catch (e) { }
                  if (dateFrom && new Date(iso) < new Date(dateFrom)) {
                    setDateFrom(iso);
                    try { if (fromFp.current) fromFp.current.setDate(iso, true); } catch (e) { }
                  }
                }
              }
            });
            try { if (fromFp.current) fromFp.current.set('maxDate', dateTo); if (toFp.current) toFp.current.set('minDate', dateFrom); } catch (e) { }
          }
          loadLatest();
          return function () { try { if (fromFp.current) fromFp.current.destroy(); } catch (e) { } try { if (toFp.current) toFp.current.destroy(); } catch (e) { } };
          // eslint-disable-next-line
        }, []);

        useEffect(function () {
          try { if (fromFp.current && dateFrom) fromFp.current.setDate(dateFrom, false); } catch (e) { }
          try { if (toFp.current && dateTo) toFp.current.setDate(dateTo, false); } catch (e) { }
          try { if (fromFp.current) fromFp.current.set('maxDate', dateTo); } catch (e) { }
          try { if (toFp.current) toFp.current.set('minDate', dateFrom); } catch (e) { }
        }, [dateFrom, dateTo]);

        // When region changes, reset location to "All locations"
        useEffect(() => {
          setSelectedLocation("All locations");
        }, [selectedRegion]);

        async function runForRange() {
          setLoading(true);
          setRows([]);
          setSummary({ rows: 0, flagged_rows: 0, files: [], end_date: null });
          setReasonsCount({});
          setRiskCounts({ "Low": 0, "Low Medium": 0, "Medium": 0, "Medium High": 0, "High": 0 });
          try {
            const start = encodeURIComponent(dateFrom);
            const end = encodeURIComponent(dateTo);
            // include selected region & city if provided
            let url = API_BASE + "/run?start=" + start + "&end=" + end + "&full=true";
            if (selectedRegion) {
              url += "&region=" + encodeURIComponent(selectedRegion);
            }
            if (selectedLocation && selectedLocation !== "All locations") {
              // send backend-aware partition token (use mapping)
              const mapForRegion = LOCATION_QUERY_VALUE[selectedRegion] || {};
              const queryCity = mapForRegion[selectedLocation] || selectedLocation;
              url += "&city=" + encodeURIComponent(queryCity);
            }
            let r = await fetch(url, { method: 'GET' });
            if (!r.ok) { const txt = await r.text(); throw new Error("API returned " + r.status + ": " + txt); }
            let js = await r.json();

            const totalRows = (typeof js.aggregated_unique_persons === 'number') ? js.aggregated_unique_persons
              : (typeof js.rows === 'number') ? js.rows : 0;
            const totalFlagged = (typeof js.flagged_rows === 'number') ? js.flagged_rows : 0;
            const files = js.files || [];

            const sample = Array.isArray(js.flagged_persons) && js.flagged_persons.length ? js.flagged_persons
              : (Array.isArray(js.sample) ? js.sample : []);
            setRows(sample);

            setSummary({ rows: totalRows, flagged_rows: totalFlagged, files: files, end_date: formatDateISO(new Date(dateTo)) });

            if (js.reasons_count && Object.keys(js.reasons_count).length > 0) {
              setReasonsCount(js.reasons_count);
            } else {
              computeReasonsAndRisks(sample);
            }
            if (js.risk_counts && Object.keys(js.risk_counts).length > 0) {
              const all = { "Low": 0, "Low Medium": 0, "Medium": 0, "Medium High": 0, "High": 0 };
              Object.keys(js.risk_counts).forEach(k => { all[k] = js.risk_counts[k]; });
              setRiskCounts(all);
            } else {
              computeReasonsAndRisks(sample);
            }
            setPage(1);
          } catch (err) {
            alert("Error: " + err.message);
            console.error(err);
          } finally {
            setLoading(false);
          }
        }

        function pushChatMessage(msg) {
          setChatMessages(prev => [...prev, msg]);
          setTimeout(() => {
            const el = document.querySelector('.chat-body');
            if (el) el.scrollTop = el.scrollHeight;
          }, 50);
        }

        function computeReasonsAndRisks(dataRows) {
          var counts = {};
          var rcounts = { "Low": 0, "Low Medium": 0, "Medium": 0, "Medium High": 0, "High": 0 };
          (dataRows || []).forEach(function (r) {
            const reasonsField = r.Reasons || r.DetectedScenarios || r.Detected || null;
            if (reasonsField) {
              var parts = String(reasonsField).split(";").map(function (s) { return s.trim(); }).filter(Boolean);
              parts.forEach(function (p) { counts[p] = (counts[p] || 0) + 1; });
            }
            var rl = getRiskLabelForRow(r);
            if (rl && rcounts[rl] !== undefined) {
              rcounts[rl] += 1;
            } else if (rl) {
              rcounts[rl] = (rcounts[rl] || 0) + 1;
            } else {
              rcounts["Low"] += 1;
            }
          });
          setReasonsCount(counts);
          setRiskCounts(rcounts);
        }

        async function loadLatest() {
          setLoading(true);
          try {
            // run for yesterday (to match backend's default behaviour)
            var d = new Date();
            d.setDate(d.getDate() - 1);
            var yesterday = formatDateISO(d);
            setDateFrom(yesterday);
            setDateTo(yesterday);

            const start = encodeURIComponent(yesterday);
            const end = encodeURIComponent(yesterday);
            let url = API_BASE + "/run?start=" + start + "&end=" + end + "&full=true";
            if (selectedRegion) {
              url += "&region=" + encodeURIComponent(selectedRegion);
            }
            if (selectedLocation && selectedLocation !== "All locations") {
              const mapForRegion = LOCATION_QUERY_VALUE[selectedRegion] || {};
              const queryCity = mapForRegion[selectedLocation] || selectedLocation;
              url += "&city=" + encodeURIComponent(queryCity);
            }
            let r = await fetch(url, { method: 'GET' });
            if (!r.ok) { const txt = await r.text(); throw new Error("API returned " + r.status + ": " + txt); }
            let js = await r.json();

            const totalRows = (typeof js.aggregated_unique_persons === 'number') ? js.aggregated_unique_persons
              : (typeof js.rows === 'number') ? js.rows : 0;
            const totalFlagged = (typeof js.flagged_rows === 'number') ? js.flagged_rows : 0;
            const files = js.files || [];

            const sample = Array.isArray(js.sample) ? js.sample : (Array.isArray(js.flagged_persons) ? js.flagged_persons : []);
            setRows(sample);
            setSummary({ rows: totalRows, flagged_rows: totalFlagged, files: files, end_date: yesterday });

            if (js.reasons_count && Object.keys(js.reasons_count).length > 0) {
              setReasonsCount(js.reasons_count);
            } else {
              computeReasonsAndRisks(sample);
            }
            if (js.risk_counts && Object.keys(js.risk_counts).length > 0) {
              const all = { "Low": 0, "Low Medium": 0, "Medium": 0, "Medium High": 0, "High": 0 };
              Object.keys(js.risk_counts).forEach(k => { all[k] = js.risk_counts[k]; });
              setRiskCounts(all);
            } else {
              computeReasonsAndRisks(sample);
            }
            setPage(1);
          } catch (err) {
            alert("Error: " + err.message);
            console.error(err);
          } finally {
            setLoading(false);
          }
        }

        function getRiskLabelForRow(r) {
          if (!r) return null;
          var rl = r.RiskLevel || r.Risk || null;
          if (rl) return String(rl);
          if (r.RiskScore !== undefined && r.RiskScore !== null) {
            const mapNum = { 1: "Low", 2: "Low Medium", 3: "Medium", 4: "Medium High", 5: "High" };
            return mapNum[String(r.RiskScore)] || null;
          }
          if (r.AnomalyScore !== undefined && r.AnomalyScore !== null) {
            if (r.AnomalyScore >= 5) return "High";
            if (r.AnomalyScore >= 4) return "Medium High";
            if (r.AnomalyScore >= 3) return "Medium";
            if (r.AnomalyScore >= 2) return "Low Medium";
            return "Low";
          }
          return null;
        }

        function buildChart(rcounts) {
          var labels = RISK_LABELS;
          var values = labels.map(l => rcounts && rcounts[l] ? rcounts[l] : 0);
          var colors = labels.map(l => {
            if (selectedRiskFilter) {
              return (l === selectedRiskFilter) ? RISK_COLORS[l] : '#e6edf3';
            } else {
              return RISK_COLORS[l] || '#cccccc';
            }
          });

          var ctx = chartRef.current && chartRef.current.getContext ? chartRef.current.getContext('2d') : null;
          if (!ctx) return;
          try { if (chartInst.current) chartInst.current.destroy(); } catch (e) { }

          chartInst.current = new Chart(ctx, {
            type: 'line',
            data: {
              labels: labels,
              datasets: [{
                label: 'Flagged by Risk Level',
                data: values,
                borderColor: '#2563eb',
                backgroundColor: 'rgba(37,99,235,0.2)',
                fill: true,
                tension: 0.3,
                pointBackgroundColor: colors,
                pointRadius: 5,
                pointHoverRadius: 7
              }]
            },
            options: {
              responsive: true,
              maintainAspectRatio: false,
              plugins: {
                legend: { display: false },
                tooltip: {
                  callbacks: {
                    label: function (context) {
                      return context.parsed.y + ' cases';
                    }
                  }
                }
              },
              onClick: function (evt, elements) {
                if (elements && elements.length > 0) {
                  var idx = elements[0].index;
                  var label = this.data.labels[idx];
                  handleRiskBarClick(label);
                }
              },
              scales: {
                y: { beginAtZero: true, ticks: { precision: 0 } }
              }
            }
          });

        }

        useEffect(function () {
          buildChart(riskCounts);
        }, [riskCounts, selectedRiskFilter]);

        // Filtering & pagination
        var filtered = (rows || []).filter(function (r) {
          var hay = (sanitizeName(r) + " " + (r.EmployeeID || "") + " " + (r.CardNumber || "") + " " + (r.Reasons || r.DetectedScenarios || "")).toLowerCase();
          var textOk = !filterText || hay.indexOf(filterText.toLowerCase()) !== -1;
          var reasonOk = !selectedReason || (r.Reasons && ((";" + String(r.Reasons) + ";").indexOf(selectedReason) !== -1)) || (r.DetectedScenarios && ((";" + String(r.DetectedScenarios) + ";").indexOf(selectedReason) !== -1));
          var riskOk = true;
          if (selectedRiskFilter) {
            var rl = getRiskLabelForRow(r);
            if (!rl) { riskOk = false; }
            else riskOk = (String(rl) === String(selectedRiskFilter));
          }
          return textOk && reasonOk && riskOk;
        })
          .sort(function (a, b) {
            var va = Number(a.ViolationDaysLast90 || a.ViolationDaysLast_90 || 0);
            var vb = Number(b.ViolationDaysLast90 || b.ViolationDaysLast_90 || 0);
            if (isNaN(va)) va = 0;
            if (isNaN(vb)) vb = 0;
            if (vb !== va) return vb - va;
            return (sanitizeName(a) || "").localeCompare(sanitizeName(b) || "");
          });

        var totalPages = Math.max(1, Math.ceil(filtered.length / pageSize));
        var pageRows = filtered.slice((page - 1) * pageSize, page * pageSize);

        function exportFiltered() { downloadCSV(filtered, "trend_filtered_export.csv"); }

        function onReasonClick(reason) {
          if (!reason) { setSelectedReason(""); return; }
          if (selectedReason === reason) setSelectedReason(""); else setSelectedReason(reason);
          setPage(1);
        }

        async function openEvidence(row) {
          setModalRow(row);
          setModalDetails(null);
          setModalLoading(true);
          try {
            const q = encodeURIComponent(row.EmployeeID || row.person_uid || "");
            const resp = await fetch(API_BASE + "/record?employee_id=" + q);
            if (!resp.ok) { const txt = await resp.text(); throw new Error("record failed: " + resp.status + " - " + txt); }
            const js = await resp.json();
            const details = { aggregated_rows: js.aggregated_rows || [], raw_swipe_files: js.raw_swipe_files || [], raw_swipes: js.raw_swipes || [] };
            setModalDetails(details);
          } catch (e) {
            alert("Failed loading details: " + e.message);
            console.error(e);
          } finally { setModalLoading(false); }
        }

        function closeModal() { setModalRow(null); setModalDetails(null); }

        // helper to render overlap
        function renderOverlapCell(r) {
          var ov = r.OverlapWith || r.swipe_overlap || r.overlap_with || null;
          if (ov && typeof ov === 'string') {
            var parts = ov.split(";").map(function (s) { return s.trim(); }).filter(Boolean);
            if (parts.length === 0) return <span className="muted">—</span>;
            return <span className="pill" title={ov}>{parts.length} overlap</span>;
          }
          return <span className="muted">—</span>;
        }

        function renderReasonChips(reasonText) {
          if (!reasonText) return <span className="muted">—</span>;
          const parts = String(reasonText).split(";").map(s => s.trim()).filter(Boolean);
          return parts.map((p, idx) => (<span key={idx} className="pill" title={SCENARIO_EXPLANATIONS[p] || p}>{p}</span>));
        }

        function renderReasonExplanations(reasonText) {
          if (!reasonText) return <div className="muted">No flags</div>;
          const parts = String(reasonText).split(";").map(s => s.trim()).filter(Boolean);
          return (
            <div>
              {parts.map((p, idx) => (
                <div key={idx} className="why-item" style={{ marginBottom: 8 }}>
                  <b>{p}</b>
                  <div className="small">{SCENARIO_EXPLANATIONS[p] || "No explanation available."}</div>
                </div>
              ))}
            </div>
          );
        }

        async function sendChat(qText, opts = { top_k: 5 }) {
          if (!qText || !qText.toString().trim()) return;
          const text = qText.toString().trim();
          pushChatMessage({ who: 'user', text });
          setChatInput("");
          setChatLoading(true);
          try {
            const payload = Object.assign({ q: text }, opts);
            const resp = await fetch(API_BASE + "/chatbot/query", {
              method: 'POST',
              headers: { 'Content-Type': 'application/json' },
              body: JSON.stringify(payload)
            });
            if (!resp.ok) {
              const t = await resp.text().catch(() => '');
              throw new Error("Server: " + resp.status + " " + t);
            }
            const js = await resp.json();
            const answer = js.answer || js.answer_text || js.result || "No answer returned.";
            const evidence = Array.isArray(js.evidence) ? js.evidence : (js.evidence ? [js.evidence] : []);
            pushChatMessage({ who: 'bot', text: answer, evidence });
          } catch (err) {
            pushChatMessage({ who: 'bot', text: "Error: " + err.message, evidence: [] });
            console.error("chat error", err);
          } finally {
            setChatLoading(false);
            setTimeout(() => {
              const el = document.querySelector('.chat-body');
              if (el) el.scrollTop = el.scrollHeight;
            }, 80);
          }
        }

        const QUICK_PROMPTS = [
          "Who is high risk today",
          "Who is low risk today",
          "Show me 320172 last 90 days",
          "Trend details for today — top reasons",
          "Explain repeated_short_breaks"
        ];
        function useQuickPrompt(q) {
          setChatOpen(true);
          sendChat(q);
        }

        // Swipe timeline rendering uses DAY_BOUNDARY_HOUR = 0 to match backend date assignment
        function renderSwipeTimeline(details, modalRow) {
          if (!details || !details.raw_swipes || details.raw_swipes.length === 0) {
            return <div className="muted">No raw swipe evidence available (person not flagged or raw file missing).</div>;
          }

          const all = details.raw_swipes.map(r => {
            const obj = Object.assign({}, r);
            try { obj.__ts = makeLocalDateFromRow(obj); } catch (e) { obj.__ts = null; }

            let gap = null;
            if (obj.SwipeGapSeconds !== undefined && obj.SwipeGapSeconds !== null) {
              gap = Number(obj.SwipeGapSeconds);
              if (isNaN(gap)) gap = null;
            } else if (obj.SwipeGap) {
              try {
                const parts = String(obj.SwipeGap).split(':').map(p => Number(p));
                if (parts.length === 3 && parts.every(p => !isNaN(p))) gap = parts[0] * 3600 + parts[1] * 60 + parts[2];
              } catch (e) { gap = null; }
            }
            obj.__gap = gap;
            obj.__zone_l = String((obj.Zone || '')).toLowerCase();

            // Prefer backend-provided date fields (DateOnly) or computed timestamp
            if (obj.__ts) {
              obj.__logical_date = logicalDateForTs(obj.__ts, DAY_BOUNDARY_HOUR);
            } else if (obj.DateOnly) {
              // DateOnly may be a string or object; coerce to YYYY-MM-DD
              obj.__logical_date = String(obj.DateOnly).slice(0, 10);
            } else if (obj.Date) {
              obj.__logical_date = String(obj.Date).slice(0, 10);
            } else {
              obj.__logical_date = null;
            }
            return obj;
          }).sort((a, b) => {
            // Primary sort: parsed timestamp if present
            if (a.__ts && b.__ts) return a.__ts - b.__ts;
            if (a.__ts) return -1;
            if (b.__ts) return 1;
            // Fallback: use DateOnly + Time or Date+Time strings
            const ka = (a.DateOnly || a.Date || '') + ' ' + (a.Time || '');
            const kb = (b.DateOnly || b.Date || '') + ' ' + (b.Time || '');
            return ka.localeCompare(kb);
          });

          // flags: dayStart for first row OR when logical date changes between rows
          const flags = new Array(all.length).fill(null).map(() => ({ dayStart: false, outReturn: false }));
          for (let i = 0; i < all.length; i++) {
            const cur = all[i];
            const prev = all[i - 1];
            const curDate = cur.__logical_date || (cur.DateOnly ? String(cur.DateOnly).slice(0, 10) : (cur.Date ? String(cur.Date).slice(0, 10) : null));
            const prevDate = prev ? (prev.__logical_date || (prev.DateOnly ? String(prev.DateOnly).slice(0, 10) : (prev.Date ? String(prev.Date).slice(0, 10) : null))) : null;
            if (!prev || prevDate !== curDate) {
              flags[i].dayStart = true;
            }
          }

          const OUT_RETURN_GAP_SECONDS = 60 * 60;
          for (let i = 0; i < all.length - 1; i++) {
            const a = all[i], b = all[i + 1];
            const aZone = a.__zone_l || ''; const bZone = b.__zone_l || ''; const bGap = b.__gap || 0;
            if (aZone.includes('out of office') || aZone.includes('out_of_office') || aZone.includes('out of')) {
              if (!bZone.includes('out of office') && (bGap >= OUT_RETURN_GAP_SECONDS || (bGap === null && aZone.includes('out')))) {
                flags[i].outReturn = true; flags[i + 1].outReturn = true;
              }
            }
          }

          for (let i = 0; i < all.length; i++) {
            if (flags[i].dayStart) {
              all[i].__gap = 0;
            }
          }

          return (
            <div className="table-scroll">
              <table className="evidence-table" role="table" aria-label="Swipe timeline">
                <thead>
                  <tr>
                    <th>Employee Name</th>
                    <th>Employee ID</th>
                    <th>Card</th>
                    <th>Date</th>
                    <th>Time</th>
                    <th>SwipeGap</th>
                    <th>Door</th>
                    <th>Direction</th>
                    <th>Zone</th>
                    <th>Note</th>
                  </tr>
                </thead>
                <tbody>
                  {all.map((rObj, idx) => {
                    const r = rObj || {};
                    const g = (r.__gap !== undefined && r.__gap !== null) ? Number(r.__gap) : null;
                    const isDayStart = flags[idx].dayStart;
                    const gapFormatted = (isDayStart)
                      ? formatSecondsToHmsJS(0)
                      : (
                        (r.SwipeGap && String(r.SwipeGap).trim())
                          ? String(r.SwipeGap)
                          : (g !== null && g !== undefined)
                            ? formatSecondsToHmsJS(g)
                            : "-"
                      );

                    // display date: prefer logical (backend date), then DateOnly, then Date
                    const displayDate = r.__logical_date || (r.DateOnly ? String(r.DateOnly).slice(0, 10) : (r.Date ? String(r.Date).slice(0, 10) : '-'));
                    const displayTime = r.Time || (r.__ts ? r.__ts.toTimeString().slice(0, 8) : '-');

                    const cls = [];
                    if (isDayStart) cls.push('row-day-start');
                    if (flags[idx].outReturn) cls.push('row-out-return');
                    const rowStyle = isDayStart ? { background: '#e6ffed' } : {};
                    let extraNote = "";
                    try {
                      const originalDate = r.Date ? String(r.Date).slice(0, 10) : null;
                      const logical = r.__logical_date || null;
                      if (originalDate && logical && originalDate !== logical) {
                        extraNote = `Orig: ${originalDate}`;
                        if ((String(r.Direction || '').toLowerCase().indexOf('out') !== -1)) {
                          extraNote += " — Out";
                        }
                      }
                    } catch (e) { extraNote = ""; }

                    return (
                      <tr key={idx} className={cls.join(' ')} style={rowStyle}>
                        <td className="small">{r.EmployeeName || '-'}</td>
                        <td className="small">{r.EmployeeID || '-'}</td>
                        <td className="small">{r.CardNumber || r.Card || '-'}</td>
                        <td className="small">{displayDate}</td>
                        <td className="small">{displayTime}</td>
                        <td className="small">{gapFormatted}</td>
                        <td className="small" style={{ minWidth: 160 }}>{r.Door || '-'}</td>
                        <td className="small">{r.Direction || '-'}</td>
                        <td className="small">{r.Zone || '-'}</td>
                        <td className="small">{r.Note || '-'}{r._source ? <span className="muted"> ({r._source})</span> : null}
                          {extraNote ? <div className="muted" style={{ fontSize: 11, marginTop: 4 }}>{extraNote}</div> : null}
                        </td>
                      </tr>
                    );
                  })}
                </tbody>
              </table>
            </div>
          );
        }

        function handleRiskBarClick(label) {
          if (!label) return;
          if (selectedRiskFilter === label) {
            setSelectedRiskFilter("");
          } else {
            setSelectedRiskFilter(label);
          }
          setPage(1);
        }

        function clearRiskFilter() {
          setSelectedRiskFilter("");
        }

        var rowsCount = (summary && typeof summary.rows === 'number') ? summary.rows : (rows ? rows.length : 0);
        var flaggedCount = (summary && typeof summary.flagged_rows === 'number') ? summary.flagged_rows : (rows ? rows.filter(function (r) { return !!(r.Reasons || r.DetectedScenarios); }).length : 0);
        var flaggedPct = rowsCount ? Math.round((flaggedCount * 100) / (rowsCount || 1)) : 0;

        // helper to get display label for current region
        function regionDisplayLabel(key) {
          if (!key) return '';
          return (REGION_OPTIONS[key] && REGION_OPTIONS[key].label) ? REGION_OPTIONS[key].label : key.toUpperCase();
        }

        return (
          <div className="container" aria-live="polite">
            {loading && (
              <div className="spinner-overlay" role="status" aria-label="Loading">
                <div className="spinner-box">
                  <div className="spinner" />
                  <div style={{ fontWeight: 700 }}>Loading…</div>
                </div>
              </div>
            )}

            <div className="topbar" role="banner">
              <div className="wu-brand" aria-hidden={false}>
                <div className="wu-logo">WU</div>
                <div className="title-block">
                  <h1>Western Union — Trend Analysis</h1>
                  <p style={{ margin: 0, fontSize: 13 }}>
                    {regionDisplayLabel(selectedRegion)} {selectedLocation && selectedLocation !== "All locations" ? "— " + selectedLocation : ""}
                  </p>
                </div>
              </div>

              <div className="header-actions" role="region" aria-label="controls">
                <div className="control">
                  <label className="small" htmlFor="fromDate">From</label>
                  <input id="fromDate" ref={fromRef} className="date-input" type="text" placeholder="YYYY-MM-DD" />
                </div>

                <div className="control">
                  <label className="small" htmlFor="toDate">To</label>
                  <input id="toDate" ref={toRef} className="date-input" type="text" placeholder="YYYY-MM-DD" />
                </div>

                <button className="btn-primary" onClick={runForRange} disabled={loading}>Run</button>
                <button className="btn-ghost" onClick={loadLatest} disabled={loading}>Load latest</button>
              </div>
            </div>

            <div className="card-shell">
              <div className="cards" aria-hidden={loading}>
                <div className="card" title="Rows analysed">
                  <div className="card-content">
                    <div className="card-text">
                      <h3>{(rowsCount !== undefined && rowsCount !== null) ? rowsCount.toLocaleString() : 0}</h3>
                      <p>Rows analysed</p>
                    </div>
                  </div>
                </div>
                <div className="card card-flagged" title="Flagged rows">
                  <div className="card-content">
                    <div className="card-text">
                      <h3>{(flaggedCount !== undefined && flaggedCount !== null) ? flaggedCount.toLocaleString() : 0}</h3>
                      <p>Flagged rows</p>
                    </div>
                  </div>
                </div>
                <div className="card card-rate" title="Flagged rate">
                  <div className="card-content">
                    <div className="card-text">
                      <h3>{flaggedPct}%</h3>
                      <p>Flagged rate</p>
                    </div>
                  </div>
                </div>
              </div>

              <div className="main">
                <div className="left">
                  <div className="chart-wrap" aria-label="Risk level chart">
                    <canvas ref={chartRef}></canvas>
                  </div>

                  <div style={{ display: 'flex', alignItems: 'center', gap: 8, marginTop: 6 }}>
                    <input placeholder="Search name, employee id, card or reason..." value={filterText} onChange={function (e) { setFilterText(e.target.value); setPage(1); }} style={{ flex: 1, padding: 10, borderRadius: 6, border: '1px solid #e6edf3' }} />
                    <div className="muted">Showing {filtered.length} / {rows.length} rows</div>
                    <button className="small-button" onClick={exportFiltered}>Export filtered</button>
                    {selectedRiskFilter ? <button className="small-button" onClick={clearRiskFilter}>Clear risk filter</button> : null}
                  </div>

                  <div style={{ marginTop: 10 }} className="table-scroll" role="region" aria-label="results table">
                    <table>
                      <thead>
                        <tr>
                          <th>Employee</th>
                          <th className="small">ID</th>
                          <th className="small">Card</th>
                          <th className="small">Date</th>
                          <th className="small">Duration</th>
                          <th className="small">ViolationDaysLast90</th>
                          <th className="small">Reasons</th>
                          <th className="small">Evidence</th>
                        </tr>
                      </thead>
                      <tbody>
                        {pageRows.map(function (r, idx) {
                          var empName = sanitizeName(r);
                          var displayDate = safeDateDisplay(r.DisplayDate || r.Date || r.DateOnly || r.FirstSwipe || r.LastSwipe);
                          // var durText = r.Duration || (r.DurationMinutes ? Math.round(r.DurationMinutes) + " min" : (r.DurationSeconds ? formatSecondsToHmsJS(r.DurationSeconds) : ""));

                          var durText = r.Duration
                            || (r.DurationSeconds ? formatSecondsToHmJS(Number(r.DurationSeconds))
                              : (r.DurationMinutes ? formatSecondsToHmJS(Number(r.DurationMinutes) * 60) : ""));


                          var flagged = r.Reasons && String(r.Reasons).trim();
                          return (
                            <tr key={idx} className={flagged ? "flagged-row" : ""}>
                              <td className="row-click" onClick={function () { openEvidence(r); }}>{empName || <span className="muted">—</span>}</td>
                              <td className="small">{r.EmployeeID || ""}</td>
                              <td className="small">{r.CardNumber || ""}</td>
                              <td className="small">{displayDate}</td>
                              <td className="small">{durText}</td>
                              <td className="small">
                                {(r.ViolationDaysLast90 !== undefined && r.ViolationDaysLast90 !== null && r.ViolationDaysLast90 !== "")
                                  ? (Number(r.ViolationDaysLast90).toString())
                                  : ((r.ViolationDaysLast_90 !== undefined && r.ViolationDaysLast_90 !== null && r.ViolationDaysLast_90 !== "")
                                    ? String(r.ViolationDaysLast_90)
                                    : ((r.ViolationDays !== undefined && r.ViolationDays !== null) ? String(r.ViolationDays) : "")
                                  )
                                }
                              </td>
                              <td className="small">{renderReasonChips(r.Reasons || r.DetectedScenarios)}</td>
                              <td className="small">
                                <button className="evidence-btn" onClick={function () { openEvidence(r); }}>Evidence</button>
                              </td>
                            </tr>
                          );
                        })}
                      </tbody>
                    </table>
                  </div>

                  <div style={{ display: 'flex', gap: 8, alignItems: 'center', marginTop: 10 }}>
                    <button onClick={function () { setPage(function (p) { return Math.max(1, p - 1); }); }} disabled={page <= 1}>Prev</button>
                    <div className="muted">Page {page} / {totalPages}</div>
                    <button onClick={function () { setPage(function (p) { return Math.min(totalPages, p + 1); }); }} disabled={page >= totalPages}>Next</button>
                  </div>
                </div>

                <aside className="right" aria-label="side panel">

                  {/* NEW: Region & Location controls */}
                  <div className="sidebar-section" style={{ marginBottom: 12 }}>
                    <strong>Risk filters</strong>
                    <div className="small muted" style={{ marginTop: 6 }}>Select Region and Location to scope the run.</div>

                    <div style={{ display: 'flex', gap: 8, marginTop: 8, alignItems: 'center' }}>
                      <div style={{ flex: 1 }}>
                        <label className="small">Region</label>
                        <select
                          value={selectedRegion}
                          onChange={(e) => { setSelectedRegion(e.target.value); setPage(1); }}
                          style={{ width: '100%', padding: '6px 8px', borderRadius: 6, border: '1px solid #e2e8f0' }}
                        >
                          {Object.keys(REGION_OPTIONS).map(k => (
                            <option key={k} value={k}>{REGION_OPTIONS[k].label}</option>
                          ))}
                        </select>
                      </div>

                      <div style={{ flex: 1 }}>
                        <label className="small">Location</label>
                        <select
                          value={selectedLocation}
                          onChange={(e) => { setSelectedLocation(e.target.value); setPage(1); }}
                          style={{ width: '100%', padding: '6px 8px', borderRadius: 6, border: '1px solid #e2e8f0' }}
                        >
                          <option key="__all" value="All locations">All locations</option>
                          {(REGION_OPTIONS[selectedRegion] && REGION_OPTIONS[selectedRegion].partitions || []).map(loc => (
                            <option key={loc} value={loc}>{loc}</option>
                          ))}
                        </select>
                      </div>
                    </div>
                  </div>

                  {/* existing risk chips */}
                  <div className="sidebar-section">
                    <div className="risk-filter-list" style={{ marginTop: 8 }}>
                      {RISK_LABELS.map((lab) => {
                        const cnt = (riskCounts && riskCounts[lab]) ? riskCounts[lab] : 0;
                        const active = selectedRiskFilter === lab;
                        return (
                          <div key={lab} role="button" tabIndex={0} aria-pressed={active} className={"risk-chip " + (active ? "active" : "")} onClick={function () { handleRiskBarClick(lab); }} onKeyDown={function (e) { if (e.key === 'Enter' || e.key === ' ') { handleRiskBarClick(lab); } }}>
                            <div style={{ width: 10, height: 10, borderRadius: 999, background: RISK_COLORS[lab], boxShadow: '0 2px 6px rgba(0,0,0,0.08)' }}></div>
                            <div style={{ fontSize: 13 }}>{lab} <span className="muted" style={{ marginLeft: 6 }}>({cnt})</span></div>
                          </div>
                        );
                      })}
                    </div>

                    <div style={{ marginTop: 8 }}>
                      <button className="small-button" onClick={clearRiskFilter}>Clear risk filter</button>
                    </div>
                  </div>

                  <div className="sidebar-section" style={{ marginTop: 12 }}>
                    <strong>Top reasons summary</strong>
                    <div className="small muted" style={{ marginTop: 6 }}>Click a reason to filter the table by that reason. Click again to clear.</div>

                    <div style={{ marginTop: 8, display: 'flex', gap: 8 }}>
                      <input placeholder="Filter reason list..." value={reasonFilterText} onChange={function (e) { setReasonFilterText(e.target.value); }} style={{ flex: 1, padding: '6px 8px', borderRadius: 6, border: '1px solid #e2e8f0' }} />
                      <button className="small-button" onClick={function () { setSelectedReason(''); setReasonFilterText(''); }}>Clear</button>
                    </div>

                    <div style={{ marginTop: 8, maxHeight: 320, overflow: 'auto' }}>
                      {Object.keys(reasonsCount).length === 0 && <div className="muted">No flags found</div>}
                      {Object.entries(reasonsCount).sort(function (a, b) { return b[1] - a[1]; }).filter(function (kv) {
                        var name = kv[0];
                        if (!reasonFilterText) return true;
                        return name.toLowerCase().indexOf(reasonFilterText.toLowerCase()) !== -1;
                      }).slice(0, 50).map(function (kv) {
                        var name = kv[0], count = kv[1];
                        var active = selectedReason === name;
                        return (
                          <div key={name} style={{ display: 'flex', alignItems: 'center', justifyContent: 'space-between', gap: 8, marginBottom: 6 }}>
                            <button className={"chip " + (active ? "active" : "")} style={{ textAlign: 'left', flex: 1 }} onClick={function () { onReasonClick(name); }}>
                              {name}
                            </button>
                            <div style={{ minWidth: 48, textAlign: 'right' }} className="small"><b>{count}</b></div>
                          </div>
                        );
                      })}
                    </div>
                  </div>
                </aside>
              </div>
            </div>

            {modalRow &&
              <div className="modal" onClick={closeModal}>
                <div className="modal-inner" onClick={function (e) { e.stopPropagation(); }}>
                  <div className="modal-header">
                    <div className="header-content">
                      <div className="header-icon">
                        <i className="bi bi-clipboard2-data-fill"></i>
                      </div>
                      <div className="header-text">
                        <h3>Details — Evidence</h3>
                        <div className="header-subtitle small">Evidence & explanation for selected row</div>
                      </div>
                    </div>
                    <button className="close-btn" onClick={closeModal}>
                      <i className="bi bi-x-lg"></i>
                      Close
                    </button>
                  </div>
                  <div className="modal-body">
                    {modalLoading && (
                      <div className="loading-state">
                        <div className="loading-spinner"></div>
                        <span>Loading evidence…</span>
                      </div>
                    )}
                    <div className="modal-top" role="region" aria-label="evidence summary">
                      <div className="image-section">
                        <div className="image-container">
                          <div className="multi-color-border">
                            <div className="color-ring color-1"></div>
                            <div className="color-ring color-2"></div>
                            <div className="color-ring color-3"></div>
                            <div className="color-ring color-4"></div>
                            <div className="image-content">




                              {/* Improved modal image block: try several keys and fallbacks */}
{(modalDetails && modalDetails.aggregated_rows && modalDetails.aggregated_rows.length > 0) ? (
  (() => {
    const md = modalDetails.aggregated_rows[0] || {};
    // Prefer explicit imageUrl variants, then fall back to object/emp ids
    const candidateImageKeys = [
      'imageUrl', 'image_url', 'ImageUrl', 'image', 'Image', 'img', 'imgUrl'
    ];
    let imgPath = null;
    for (let k of candidateImageKeys) {
      if (md[k]) { imgPath = md[k]; break; }
    }

    // If we didn't find image path, try building from ObjectID/GUID/EmployeeID/person_uid
    const fallbackId = (md.ObjectID || md.ObjectId || md.ObjectID || md.EmployeeID || md.person_uid || md.EmployeeObjID || md.ObjectId || md.ObjectID);
    if (!imgPath && fallbackId) {
      imgPath = `/employee/${fallbackId}/image`;
    }

    if (imgPath) {
      const imgSrc = resolveApiImageUrl(imgPath) || imgPath;
      return (
    
    
    


<img
  className="modal-image"
  src={resolveApiImageUrl(imgPath) || imgPath}
  alt={sanitizeName(modalRow) || "Employee image"}
  onLoad={(e) => {
    try { console.info("employee image loaded:", e.target.src); } catch (err) {}
  }}
  onError={async (e) => {
    try {
      e.persist && e.persist(); // defensive for future React versions
    } catch (_) {}

    try {
      console.warn("image load failed for:", e.target.src);
      e.target.onerror = null;

      // build list of candidate endpoints to try (cache-busted)
      const fbId = (modalDetails && modalDetails.aggregated_rows && modalDetails.aggregated_rows[0] &&
                    (modalDetails.aggregated_rows[0].ObjectID || modalDetails.aggregated_rows[0].GUID))
                   || (modalRow && (modalRow.EmployeeID || modalRow.person_uid));

      const candidates = [];
      // if original imgPath present, try it with cache buster
      if (imgPath) {
        candidates.push(resolveApiImageUrl(imgPath));
        candidates.push(resolveApiImageUrl(imgPath) + (imgPath.indexOf('?') === -1 ? '?cb=' + Date.now() : '&cb=' + Date.now()));
      }
      // standard API variants (try both /api/employees and /employee)
      if (fbId) {
        candidates.push(resolveApiImageUrl(`/api/employees/${fbId}/image`));
        candidates.push(resolveApiImageUrl(`/employee/${fbId}/image`));
        // cache-busted variants too
        candidates.push(resolveApiImageUrl(`/api/employees/${fbId}/image`) + '?cb=' + Date.now());
        candidates.push(resolveApiImageUrl(`/employee/${fbId}/image`) + '?cb=' + Date.now());
      }

      // normalize candidates, remove falsy/duplicate
      const uniq = [];
      candidates.forEach(u => { if (u && uniq.indexOf(u) === -1) uniq.push(u); });

      // Try them sequentially using a lightweight HEAD (or GET fallback).
      // Some servers do not support HEAD; in that case we fall back to GET with mode:'no-cors' blocked by CORS - but same-origin should be OK.
      let found = null;
      for (const url of uniq) {
        if (!url) continue;
        try {
          // Attempt HEAD to quickly check existence
          const head = await fetch(url, { method: 'HEAD', cache: 'no-store' });
          if (head && head.ok && head.headers.get('content-type') && head.headers.get('content-type').startsWith('image')) {
            found = url;
            break;
          }
        } catch (err) {
          // HEAD might be blocked; try a short GET but avoid reading body
          try {
            const getr = await fetch(url, { method: 'GET', cache: 'no-store' });
            if (getr && getr.ok && getr.headers.get('content-type') && getr.headers.get('content-type').startsWith('image')) {
              found = url;
              break;
            }
          } catch (err2) {
            // ignore and continue to next candidate
            console.debug("image candidate failed", url, err2);
            continue;
          }
        }
      }

      if (found) {
        // attach timestamp cache-buster to ensure we pick up new bytes
        const newSrc = found + (found.indexOf('?') === -1 ? ('?cb=' + Date.now()) : ('&cb=' + Date.now()));
        console.info("image fallback found:", newSrc);
        e.target.src = newSrc;
        return;
      }

      // Final fallback: inline SVG placeholder (data URI)
      const svg = '<svg xmlns="http://www.w3.org/2000/svg" width="160" height="160"><rect fill="#eef2f7" width="100%" height="100%"/><text x="50%" y="50%" dominant-baseline="middle" text-anchor="middle" fill="#64748b" font-size="18">No image</text></svg>';
      e.target.src = 'data:image/svg+xml;utf8,' + encodeURIComponent(svg);

    } catch (err) {
      try { e.target.style.display = 'none'; } catch (err2) {}
      console.error("image fallback error", err);
    }
  }}

/>

      );
    } else {
      // No candidate image info at all
      return <div className="modal-image-placeholder">No image</div>;
    }
  })()
) : (
  <div className="modal-image-placeholder">
    <i className="bi bi-person-square"></i>
    <span>No image</span>
  </div>
)}

                            </div>
                          </div>
                        </div>
                      </div>

                      <div className="modal-details">
                        <div className="details-header">
                          <div className="emp-info">
                            <div className="emp-name">
                              {sanitizeName(modalRow) || "—"}
                              <span
                                className="risk-badge"
                                style={{
                                  marginLeft: "12px",
                                  background:
                                    RISK_COLORS[modalRow.RiskLevel] ||
                                    RISK_COLORS[getRiskLabelForRow(modalRow)] ||
                                    RISK_COLORS["Low"],
                                }}
                              >
                                {modalRow.RiskLevel ||
                                  (modalRow.RiskScore ? "Score " + modalRow.RiskScore : "Low")}
                              </span>
                            </div>
                            <div className="emp-badge">
                              <i className="bi bi-person-badge"></i>
                              ID: {modalRow.EmployeeID || "—"}
                            </div>
                          </div>
                        </div>
                        <div className="details-grid">
                          <div className="detail-item">
                            <div className="detail-icon">
                              <i className="bi bi-credit-card"></i>
                            </div>
                            <div className="detail-content">
                              <label>Card Number</label>
                              <span>{modalRow.CardNumber || "—"}</span>
                            </div>
                          </div>
                          <div className="detail-item">
                            <div className="detail-icon">
                              <i className="bi bi-envelope"></i>
                            </div>
                            <div className="detail-content">
                              <label>Email</label>
                              <span>
                                {(
                                  (modalDetails && modalDetails.aggregated_rows && modalDetails.aggregated_rows[0] && (modalDetails.aggregated_rows[0].EmployeeEmail || modalDetails.aggregated_rows[0].Email))
                                  || modalRow.EmployeeEmail
                                  || modalRow.Email
                                  || (modalDetails && modalDetails.aggregated_rows && modalDetails.aggregated_rows[0] && (modalDetails.aggregated_rows[0].WorkEmail || modalDetails.aggregated_rows[0].EMail))
                                )
                                  ? (
                                    (modalDetails && modalDetails.aggregated_rows && modalDetails.aggregated_rows[0] && (modalDetails.aggregated_rows[0].EmployeeEmail || modalDetails.aggregated_rows[0].Email))
                                    || modalRow.EmployeeEmail
                                    || modalRow.Email
                                    || (modalDetails && modalDetails.aggregated_rows && modalDetails.aggregated_rows[0] && (modalDetails.aggregated_rows[0].WorkEmail || modalDetails.aggregated_rows[0].EMail))
                                  )
                                  : <span className="muted">—</span>
                                }
                              </span>

                            </div>
                          </div>
                          <div className="detail-item">
                            <div className="detail-icon">
                              <i className="bi bi-calendar-date"></i>
                            </div>
                            <div className="detail-content">
                              <label>Date</label>
                              <span>{safeDateDisplay(modalRow.DisplayDate || modalRow.Date || modalRow.DateOnly || modalRow.FirstSwipe)}</span>
                            </div>
                          </div>
                          <div className="detail-item">
                            <div className="detail-icon">
                              <i className="bi bi-clock"></i>
                            </div>
                            <div className="detail-content">
                              <label>Duration</label>

                              <span className="duration-badge">
                                {modalRow.Duration
                                  || (modalRow.DurationSeconds ? formatSecondsToHmJS(Number(modalRow.DurationSeconds))
                                    : (modalRow.DurationMinutes ? formatSecondsToHmJS(Number(modalRow.DurationMinutes) * 60) : "—"))}
                              </span>


                            </div>
                            <div style={{ marginTop: 8, textAlign: 'right' }}>
                              <div className="muted">Violation days (90d)</div>
                              <div style={{ fontWeight: 700 }}>
                                {(modalRow.ViolationDaysLast90 !== undefined && modalRow.ViolationDaysLast90 !== null)
                                  ? modalRow.ViolationDaysLast90
                                  : 0}
                              </div>
                            </div>
                          </div>
                        </div>
                      </div>

                      <div className="modal-reasons">
                        <div className="explanation-section" style={{ marginTop: 12 }}>
                          <div style={{ fontWeight: 700 }}>Explanation</div>
                          <div style={{
                            marginTop: 8,
                            maxHeight: 160,
                            overflow: 'auto',
                            background: '#fff',
                            border: '1px solid #eef2f7',
                            padding: 8,
                            borderRadius: 6
                          }}>
                            {(modalRow.Explanation || modalRow.ViolationExplanation)
                              ? <div style={{ whiteSpace: 'pre-wrap' }}>{modalRow.Explanation || modalRow.ViolationExplanation}</div>
                              : <div className="muted">No explanation provided.</div>}

                          </div>
                        </div>
                        <div className="reasons-section">
                          <div className="section-title">
                            <i className="bi bi-list-check"></i>
                            Reasons Flagged
                          </div>
                          <div className="reasons-list">
                            {renderReasonChips(modalRow.Reasons || modalRow.DetectedScenarios)}
                          </div>
                        </div>
                      </div>
                    </div>

                    <div className="evidence-section">
                      <div className="section-header">
                        <i className="bi bi-folder2-open"></i>
                        <h4>Available Evidence Files</h4>
                      </div>
                      <div className="files-container">
                        {modalDetails && modalDetails.raw_swipe_files && modalDetails.raw_swipe_files.length > 0 ? (
                          <div className="files-list">
                            {modalDetails.raw_swipe_files.map((f, i) => (
                              <div key={i} className="file-item">
                                <i className="bi bi-file-earmark-text"></i>
                                <span className="file-name">{f}</span>
                                <button
                                  className="download-btn"
                                  onClick={function () { window.location = API_BASE + "/swipes/" + encodeURIComponent(f); }}
                                >
                                  <i className="bi bi-download"></i>
                                  Download
                                </button>
                              </div>
                            ))}
                          </div>
                        ) : (
                          <div className="no-files">
                            <i className="bi bi-folder-x"></i>
                            <span>No raw swipe files found for this person/date.</span>
                          </div>
                        )}
                      </div>
                    </div>

                    <div className="timeline-section">
                      <div className="section-header">
                        <i className="bi bi-clock-history"></i>
                        <h4>Swipe Timeline</h4>
                        <span className="subtitle">Filtered for this person/date</span>
                      </div>
                      <div className="timeline-content">
                        {modalDetails ? renderSwipeTimeline(modalDetails, modalRow) : (
                          <div className="loading-timeline">
                            <i className="bi bi-hourglass-split"></i>
                            <span>Evidence not loaded yet.</span>
                          </div>
                        )}
                      </div>
                    </div>

                    <div className="raw-json-section">
                      <label className="toggle-label">
                        <input
                          type="checkbox"
                          id="showraw"
                          onChange={function (e) {
                            const el = document.getElementById('rawpayload');
                            if (el) el.style.display = e.target.checked ? 'block' : 'none';
                          }}
                        />
                        <span className="toggle-slider"></span>
                        <span className="toggle-text">
                          <i className="bi bi-code-slash"></i>
                          Show raw aggregated JSON
                        </span>
                      </label>
                      <div id="rawpayload" className="raw-json" style={{ display: 'none' }}>
                        <pre>{JSON.stringify(modalRow, null, 2)}</pre>
                      </div>
                    </div>
                  </div>
                </div>
              </div>
            }

            <button className="chat-fab" title="Ask Trend Details (Ask Me )" onClick={() => setChatOpen(true)} aria-label="Open chat">
              <span className="meta-icon"><img src="chat-bot.png" alt="" /></span>
            </button>


            {chatOpen && (
              <div className="chat-modal" role="dialog" aria-modal="true" aria-label="Trend Chatbot">
                <div className="chat-header">
                  <div style={{ display: 'flex', alignItems: 'center', gap: 8 }}>
                    <div style={{ width: 36, height: 36, borderRadius: 8, background: '#', display: 'flex', alignItems: 'center', justifyContent: 'center', color: '#2563eb', fontWeight: 800 }}><img src="chat-bot.png" alt="" style={{ width: 36, height: 36, }} /></div>
                    <div>
                      <div className="title">Ask me — Trend Details</div>
                      <div style={{ fontSize: 12, opacity: 0.85 }}>Ask trend & risk questions</div>
                    </div>
                  </div>
                  <div style={{ marginLeft: 'auto' }}>
                    <button className="small-button bot-close" onClick={() => { setChatOpen(false); }}>Close</button>
                  </div>
                </div>

                <div className="chat-body">
                  {chatMessages.length === 0 && (
                    <div style={{ color: '#64748b', fontSize: 13 }}>
                      Hi — ask about trends (e.g. "Who is high risk today"). Use the quick prompts below.
                    </div>
                  )}
                  {chatMessages.map((m, i) => (
                    <div key={i} style={{ display: 'block' }}>
                      <div className={"chat-bubble " + (m.who === 'user' ? 'user' : 'bot')}>
                        {m.text}
                        {m.who === 'bot' && m.evidence && m.evidence.length > 0 && (
                          <div className="chat-evidence">
                            <strong>Evidence</strong>
                            <div style={{ marginTop: 6 }}>{m.evidence.slice(0, 5).map((e, j) => (<div key={j}>{typeof e === 'string' ? e : JSON.stringify(e)}</div>))}</div>
                          </div>
                        )}
                      </div>
                    </div>
                  ))}

                  {chatLoading && <div className="chat-loading" style={{ marginTop: 6 }}>Thinking…</div>}
                  <div style={{ marginTop: 8 }} className="quick-prompts" aria-hidden={chatLoading}>
                    {QUICK_PROMPTS.map((q, idx) => (
                      <button key={idx} onClick={() => useQuickPrompt(q)} disabled={chatLoading}>{q}</button>
                    ))}
                  </div>
                </div>

                <div className="chat-input-row">
                  <input
                    className="chat-input"
                    placeholder="Type a question, e.g. 'Who is high risk today'…"
                    value={chatInput}
                    onChange={(e) => setChatInput(e.target.value)}
                    onKeyDown={(e) => { if (e.key === 'Enter' && !e.shiftKey) { e.preventDefault(); sendChat(chatInput); } }}
                  />
                  <button className="chat-send-btn" onClick={() => sendChat(chatInput)} disabled={chatLoading}>Send</button>
                </div>
              </div>
            )}

          </div>
        );
      }

      const root = ReactDOM.createRoot(document.getElementById('root'));
      root.render(React.createElement(App));
    })();
  </script>
</body>

</html>
