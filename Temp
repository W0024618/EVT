When I Upadte File WE got error 

(.venv) PS C:\Users\W0024618\Desktop\global-page\backend\attendance-analytics> python -m uvicorn app:app --host 0.0.0.0 --port 8000
INFO:     Started server process [28512]
INFO:     Waiting for application startup.
INFO:     Application startup complete.
INFO:     Uvicorn running on http://0.0.0.0:8000 (Press CTRL+C to quit)
[compute_daily_attendance] no swipes for 2025-08-25
2025-08-25 14:20:58,425 WARNING region_clients: [region_clients] cannot fetch history for apac@http://10.199.22.57:3008/api/occupancy/history: HTTPConnectionPool(host='10.199.22.57', port=3008): Read timed out. (read timeout=6) 
2025-08-25 14:21:04,450 WARNING region_clients: [region_clients] cannot fetch history for laca@http://10.199.22.57:4000/api/occupancy/history: HTTPConnectionPool(host='10.199.22.57', port=4000): Read timed out. (read timeout=6) 
2025-08-25 14:21:04,451 ERROR attendance_app: compute_visit_averages execution failed
Traceback (most recent call last):
  File "C:\Users\W0024618\Desktop\global-page\backend\attendance-analytics\app.py", line 58, in ccure_averages    
    res = compute_visit_averages(timeout=timeout)
  File "C:\Users\W0024618\Desktop\global-page\backend\attendance-analytics\ccure_compare_service.py", line 976, in compute_visit_averages
    "head_contractor_pct_vs_ccure_today": head_contractor_pct_vs_ccure_today,
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
NameError: name 'head_contractor_pct_vs_ccure_today' is not defined. Did you mean: 'head_con_pct_vs_ccure_today'? 





http://localhost:8000/ccure/averages

{"detail":"compute_visit_averages failed: name 'head_contractor_pct_vs_ccure_today' is not defined"}




Check below Both file and Fix issue and Share me Fully Upadted File Catefully

Compare both code and Fix issue.


# # ccure_compare_service.py
# """
# Compare CCURE profiles/stats with local sheets + compute visit averages + compliance.

# Key behaviors:
#  - If AttendanceSummary for today is empty, attempt to call compute_daily_attendance() to build it from LiveSwipe.
#  - Provide headcount (AttendanceSummary) and live_headcount (region_clients) with per-location breakdowns.
#  - ccure_active exposes only reported ActiveEmployees and ActiveContractors (no derived fields).
#  - Computes averages (last 7 days) and today's percentages vs CCURE reported counts.
#  - Compliance (meets_5days_8h, meets_3days_8h, defaulters) computed using AttendanceSummary historical data.
# """

# import re
# import traceback
# from datetime import date, datetime, timedelta
# from typing import List, Dict, Any, Optional, Set

# import logging

# logger = logging.getLogger("ccure_compare_service")
# logger.setLevel(logging.INFO)
# if not logger.handlers:
#     ch = logging.StreamHandler()
#     ch.setFormatter(logging.Formatter("%(asctime)s %(levelname)s %(name)s: %(message)s"))
#     logger.addHandler(ch)

# from db import SessionLocal
# from models import ActiveEmployee, ActiveContractor, AttendanceSummary, LiveSwipe
# from settings import OUTPUT_DIR

# # ---------- small helpers ----------------------------------------------------

# def _normalize_employee_key(x) -> Optional[str]:
#     if x is None:
#         return None
#     try:
#         s = str(x).strip()
#         if s == "" or s.lower() in ("nan", "none", "na", "null"):
#             return None
#         return s
#     except Exception:
#         return None

# def _normalize_card_like(s) -> Optional[str]:
#     if s is None:
#         return None
#     try:
#         ss = str(s).strip()
#         if ss == "":
#             return None
#         digits = re.sub(r'\D+', '', ss)
#         if digits == "":
#             return None
#         return digits.lstrip('0') or digits
#     except Exception:
#         return None

# def _safe_int(v):
#     try:
#         if v is None:
#             return None
#         return int(v)
#     except Exception:
#         try:
#             return int(float(v))
#         except Exception:
#             return None

# def _sanitize_for_json(value):
#     try:
#         import numpy as _np
#     except Exception:
#         _np = None
#     if value is None:
#         return None
#     if isinstance(value, (str, bool, int)):
#         return value
#     if isinstance(value, float):
#         if _np is not None and not _np.isfinite(value):
#             return None
#         return float(value)
#     if _np is not None and isinstance(value, (_np.integer,)):
#         return int(value)
#     if isinstance(value, dict):
#         out = {}
#         for k, v in value.items():
#             try:
#                 key = str(k)
#             except Exception:
#                 key = repr(k)
#             out[key] = _sanitize_for_json(v)
#         return out
#     if isinstance(value, (list, tuple, set)):
#         return [_sanitize_for_json(v) for v in value]
#     try:
#         return str(value)
#     except Exception:
#         return None

# # ---------- ccure helpers ---------------------------------------------------

# def _fetch_ccure_stats():
#     try:
#         import ccure_client
#         if hasattr(ccure_client, "get_global_stats"):
#             return ccure_client.get_global_stats()
#     except Exception:
#         logger.debug("ccure_client.get_global_stats not available", exc_info=True)
#     return None

# def _fetch_ccure_profiles():
#     try:
#         import ccure_client
#         for fn in ("fetch_all_employees_full", "fetch_all_employees", "fetch_all_profiles", "fetch_profiles", "fetch_all"):
#             if hasattr(ccure_client, fn):
#                 try:
#                     res = getattr(ccure_client, fn)()
#                     if isinstance(res, list):
#                         return res
#                 except Exception:
#                     continue
#     except Exception:
#         pass
#     return []

# def _extract_ccure_locations_from_profiles(profiles: List[dict]) -> Set[str]:
#     locs = set()
#     for p in profiles:
#         if not isinstance(p, dict):
#             continue
#         for k in ("Partition", "PartitionName", "Location", "Location City", "location_city", "location", "Site", "BaseLocation"):
#             v = p.get(k) if isinstance(p, dict) else None
#             if v and isinstance(v, str) and v.strip():
#                 locs.add(v.strip())
#     return locs

# # ---------- classification & partition helpers ------------------------------

# def classify_personnel_from_detail(detail: dict) -> str:
#     """Map many CCURE / live-summary personnel strings to 'employee' or 'contractor'."""
#     try:
#         if not isinstance(detail, dict):
#             return "contractor"
#         candidate_keys = [
#             "PersonnelType", "personnelType", "personnel_type", "Personnel Type",
#             "PersonnelTypeName", "Personnel", "Type", "personnel", "PersonType", "personType"
#         ]
#         val = None
#         for k in candidate_keys:
#             if k in detail and detail.get(k) is not None:
#                 val = str(detail.get(k)).strip().lower()
#                 break
#         status_keys = ["Employee_Status", "Employee Status", "Status", "Profile_Disabled"]
#         status_val = None
#         for k in status_keys:
#             if k in detail and detail.get(k) is not None:
#                 status_val = str(detail.get(k)).strip().lower()
#                 break

#         if status_val is not None and "terminated" in status_val:
#             return "employee"
#         if val is None or val == "":
#             return "contractor"
#         if "employee" in val:
#             return "employee"
#         if "terminated" in val:
#             return "employee"
#         contractor_terms = ["contractor", "visitor", "property", "property management", "temp", "temp badge", "tempbadge"]
#         for t in contractor_terms:
#             if t in val:
#                 return "contractor"
#         if "contract" in val or "visitor" in val:
#             return "contractor"
#         return "contractor"
#     except Exception:
#         return "contractor"

# def pick_partition_from_detail(detail: dict) -> str:
#     if not isinstance(detail, dict):
#         return "Unknown"
#     for k in ("PartitionName2","PartitionName1","Partition","PartitionName","Region","Location","Site","location_city","Location City"):
#         if k in detail and detail.get(k):
#             try:
#                 return str(detail.get(k)).strip()
#             except Exception:
#                 continue
#     if "__region" in detail and detail.get("__region"):
#         return str(detail.get("__region")).strip()
#     return "Unknown"

# # ---------- WFH detection helper -------------------------------------------

# def is_employee_wfh(active_emp_row: ActiveEmployee) -> bool:
#     try:
#         wfh_keywords = ("work from home", "wfh", "remote", "workfromhome", "home")
#         for attr in ("is_wfh", "work_from_home", "wfh", "remote_flag"):
#             if hasattr(active_emp_row, attr):
#                 try:
#                     val = getattr(active_emp_row, attr)
#                     if isinstance(val, bool) and val:
#                         return True
#                     if isinstance(val, str) and any(k in val.strip().lower() for k in wfh_keywords):
#                         return True
#                 except Exception:
#                     pass
#         for attr in ("location_description", "location_desc", "location_description1", "base_location", "location", "location_city"):
#             if hasattr(active_emp_row, attr):
#                 try:
#                     v = getattr(active_emp_row, attr)
#                     if v and isinstance(v, str):
#                         s = v.strip().lower()
#                         if any(k in s for k in wfh_keywords):
#                             return True
#                 except Exception:
#                     pass
#         try:
#             rr = getattr(active_emp_row, "raw_row", None)
#             if rr and isinstance(rr, dict):
#                 for k, v in rr.items():
#                     try:
#                         if v and isinstance(v, str) and any(word in v.strip().lower() for word in wfh_keywords):
#                             return True
#                     except Exception:
#                         continue
#         except Exception:
#             pass
#     except Exception:
#         pass
#     return False

# # ---------- utility: fallback headcount builder from LiveSwipe --------------

# def build_headcount_from_liveswipes_for_today(session) -> (int, Dict[str, Dict[str, int]]):
#     """
#     When AttendanceSummary for today is empty, build headcount by scanning LiveSwipe rows for today
#     Deduplicate by key (employee_id or card) and compute per-location counts.
#     Returns (total_count, by_location dict)
#     """
#     start = datetime.combine(date.today(), datetime.min.time())
#     end = datetime.combine(date.today(), datetime.max.time())
#     swipes = session.query(LiveSwipe).filter(LiveSwipe.timestamp >= start, LiveSwipe.timestamp <= end).all()
#     if not swipes:
#         return 0, {}
#     seen_keys = {}
#     per_loc = {}
#     for s in swipes:
#         key = _normalize_employee_key(s.employee_id) or _normalize_card_like(s.card_number)
#         if not key:
#             key = f"nokey_{s.id}"
#         rec = seen_keys.get(key)
#         ts = s.timestamp
#         if rec is None:
#             seen_keys[key] = {"first_seen": ts, "last_seen": ts, "partition": (s.partition or "Unknown"), "class": None, "card": s.card_number, "raw": s.raw}
#         else:
#             if ts and rec.get("first_seen") and ts < rec["first_seen"]:
#                 rec["first_seen"] = ts
#             if ts and rec.get("last_seen") and ts > rec["last_seen"]:
#                 rec["last_seen"] = ts
#     for k, v in seen_keys.items():
#         loc = v.get("partition") or "Unknown"
#         if not isinstance(loc, str) or not loc.strip():
#             loc = "Unknown"
#         if loc not in per_loc:
#             per_loc[loc] = {"total": 0, "employee": 0, "contractor": 0}
#         per_loc[loc]["total"] += 1
#         classified = "contractor"
#         raw = v.get("raw")
#         if isinstance(raw, dict):
#             try:
#                 classified = classify_personnel_from_detail(raw)
#             except Exception:
#                 classified = "contractor"
#         per_loc[loc][classified] += 1
#     total = sum(p["total"] for p in per_loc.values())
#     return int(total), per_loc

# # ---------- main compute function -----------------------------------------

# def compute_visit_averages(timeout: int = 6) -> Dict[str, Any]:
#     notes = []
#     today = date.today()
#     week_start = today - timedelta(days=6)  # last 7 days inclusive

#     # --- try to get CCURE stats/profiles early for filtering & denominators
#     ccure_stats = _fetch_ccure_stats()
#     reported_active_emps = _safe_int(ccure_stats.get("ActiveEmployees")) if isinstance(ccure_stats, dict) else None
#     reported_active_contractors = _safe_int(ccure_stats.get("ActiveContractors")) if isinstance(ccure_stats, dict) else None

#     ccure_profiles = _fetch_ccure_profiles()
#     ccure_locations = _extract_ccure_locations_from_profiles(ccure_profiles) if isinstance(ccure_profiles, list) else set()

#     # --- HEADCOUNT (AttendanceSummary for today) with fallback
#     head_total = 0
#     head_per_location: Dict[str, Dict[str, int]] = {}
#     try:
#         session = SessionLocal()
#         att_rows_today = session.query(AttendanceSummary).filter(AttendanceSummary.date == today).all()
#         if not att_rows_today:
#             # Attempt to build AttendanceSummary from LiveSwipe using compute_daily_attendance (if available)
#             built_ok = False
#             try:
#                 # import local compare_service.compute_daily_attendance if available
#                 from compare_service import compute_daily_attendance as _compute_daily_attendance
#                 try:
#                     built = _compute_daily_attendance(today)
#                     # If compute_daily_attendance returns rows, requery AttendanceSummary
#                     if isinstance(built, list) and len(built) > 0:
#                         att_rows_today = session.query(AttendanceSummary).filter(AttendanceSummary.date == today).all()
#                         built_ok = True
#                         notes.append("AttendanceSummary was missing; built from LiveSwipe via compute_daily_attendance().")
#                 except Exception:
#                     # fall through to fallback builder
#                     logger.exception("compute_daily_attendance execution failed; falling back")
#             except Exception:
#                 # compare_service not importable -> fallback
#                 logger.debug("compare_service.compute_daily_attendance not importable; falling back", exc_info=True)

#             if not att_rows_today:
#                 # fallback: build headcount from LiveSwipe directly (non-persistent)
#                 built_total, built_per_loc = build_headcount_from_liveswipes_for_today(session)
#                 head_total = built_total
#                 head_per_location = built_per_loc
#                 if head_total > 0:
#                     notes.append("AttendanceSummary for today empty; built headcount from LiveSwipe rows (non-persistent fallback).")
#         if att_rows_today:
#             # classify using ActiveEmployee / ActiveContractor sets
#             act_emps = session.query(ActiveEmployee).all()
#             act_contrs = session.query(ActiveContractor).all()
#             emp_id_set = set()
#             contr_id_set = set()
#             card_to_emp = {}
#             for e in act_emps:
#                 v = _normalize_employee_key(getattr(e, "employee_id", None))
#                 if v:
#                     emp_id_set.add(v)
#                 try:
#                     rr = getattr(e, "raw_row", None)
#                     if rr and isinstance(rr, dict):
#                         for ck in ("CardNumber","card_number","Card","Card No","CardNo","Badge","BadgeNo","IPassID","iPass ID","IPASSID"):
#                             if ck in rr and rr.get(ck):
#                                 cn = _normalize_card_like(rr.get(ck))
#                                 if cn:
#                                     card_to_emp[cn] = v
#                 except Exception:
#                     pass
#             for c in act_contrs:
#                 wid = _normalize_employee_key(getattr(c, "worker_system_id", None))
#                 ip = _normalize_employee_key(getattr(c, "ipass_id", None))
#                 primary = wid or ip
#                 if primary:
#                     contr_id_set.add(primary)

#             for a in att_rows_today:
#                 key = _normalize_employee_key(a.employee_id)
#                 partition = None
#                 try:
#                     if a.derived and isinstance(a.derived, dict):
#                         partition = a.derived.get("partition")
#                 except Exception:
#                     partition = None
#                 loc = partition or "Unknown"
#                 if not isinstance(loc, str) or not loc.strip():
#                     loc = "Unknown"
#                 if loc not in head_per_location:
#                     head_per_location[loc] = {"total": 0, "employee": 0, "contractor": 0}
#                 if (a.presence_count or 0) > 0:
#                     head_total += 1
#                     head_per_location[loc]["total"] += 1
#                     cls = "contractor"
#                     if key and key in emp_id_set:
#                         cls = "employee"
#                     elif key and key in contr_id_set:
#                         cls = "contractor"
#                     else:
#                         try:
#                             card = (a.derived.get("card_number") if (a.derived and isinstance(a.derived, dict)) else None)
#                         except Exception:
#                             card = None
#                         cnorm = _normalize_card_like(card)
#                         if cnorm and cnorm in card_to_emp:
#                             cls = "employee" if card_to_emp.get(cnorm) in emp_id_set else "contractor"
#                         else:
#                             cls = "contractor"
#                     head_per_location[loc][cls] += 1
#         session.expunge_all()
#     except Exception:
#         logger.exception("Error computing HeadCount")
#         notes.append("Failed to compute HeadCount from DB; see server logs.")
#     finally:
#         try:
#             session.close()
#         except Exception:
#             pass

#     # --- LIVE HEADCOUNT via region_clients (as before)
#     live_total = 0
#     live_per_location: Dict[str, Dict[str, int]] = {}
#     sites_queried = 0
#     details = []  # ensure defined for later fallbacks
#     try:
#         import region_clients
#         regions_info = []
#         try:
#             if hasattr(region_clients, "fetch_all_regions"):
#                 regions_info = region_clients.fetch_all_regions(timeout=timeout) or []
#         except Exception:
#             logger.exception("region_clients.fetch_all_regions failed")
#         try:
#             if hasattr(region_clients, "fetch_all_details"):
#                 details = region_clients.fetch_all_details(timeout=timeout) or []
#         except Exception:
#             logger.exception("region_clients.fetch_all_details failed")
#         sites_queried = len(regions_info) if isinstance(regions_info, list) else 0
#         if regions_info:
#             for r in regions_info:
#                 try:
#                     c = r.get("count") if isinstance(r, dict) else None
#                     ci = _safe_int(c)
#                     if ci is not None:
#                         live_total += int(ci)
#                 except Exception:
#                     continue
#         derived_detail_sum = 0
#         if details and isinstance(details, list):
#             for d in details:
#                 try:
#                     loc = pick_partition_from_detail(d) or "Unknown"
#                     if not isinstance(loc, str) or not loc.strip():
#                         loc = "Unknown"
#                     pclass = classify_personnel_from_detail(d)
#                     if loc not in live_per_location:
#                         live_per_location[loc] = {"total": 0, "employee": 0, "contractor": 0}
#                     live_per_location[loc]["total"] += 1
#                     live_per_location[loc][pclass] += 1
#                     derived_detail_sum += 1
#                 except Exception:
#                     continue
#             if live_total == 0 and derived_detail_sum > 0:
#                 live_total = derived_detail_sum
#             else:
#                 if live_total != derived_detail_sum:
#                     notes.append(f"Region totals ({live_total}) differ from detail rows ({derived_detail_sum}); using region totals for overall and details for breakdown.")
#         else:
#             notes.append("No per-person details available from region_clients; live breakdown unavailable.")
#     except Exception:
#         logger.exception("Error computing Live HeadCount")
#         notes.append("Failed to compute Live HeadCount; see logs.")
#         live_total = live_total or 0

#     # ---------- NEW FALLBACK: if head_total still zero, build from region_clients details ----------
#     if (head_total == 0) and details:
#         try:
#             seen_keys = set()
#             for d in details:
#                 try:
#                     # Prefer EmployeeID or CardNumber or PersonGUID as dedupe key
#                     key = _normalize_employee_key(d.get("EmployeeID")) or _normalize_card_like(d.get("CardNumber")) or (d.get("PersonGUID") if d.get("PersonGUID") else None)
#                     if not key:
#                         # try other possible id-like fields
#                         key = _normalize_employee_key(d.get("employee_id")) or _normalize_card_like(d.get("Card")) or None
#                     if not key:
#                         continue
#                     key = str(key)
#                     if key in seen_keys:
#                         continue
#                     seen_keys.add(key)
#                     loc = pick_partition_from_detail(d) or "Unknown"
#                     pclass = classify_personnel_from_detail(d)
#                     if loc not in head_per_location:
#                         head_per_location[loc] = {"total": 0, "employee": 0, "contractor": 0}
#                     head_per_location[loc]["total"] += 1
#                     head_per_location[loc][pclass] += 1
#                     head_total += 1
#                 except Exception:
#                     continue
#             if head_total > 0:
#                 notes.append("AttendanceSummary and LiveSwipe empty; built headcount from region_clients live-summary details (fallback).")
#         except Exception:
#             logger.exception("Error building headcount from region details fallback")

#     # --- CCURE active: exposed only as reported (not derived)
#     # reported_active_emps, reported_active_contractors already from ccure_stats above

#     # --- Compliance: compute using AttendanceSummary last 7 days (DB)
#     compliance = {
#         "meets_5days_8h": {"count": 0, "percent_of_ccure_employees": None, "by_location": {}},
#         "meets_3days_8h": {"count": 0, "percent_of_ccure_employees": None, "by_location": {}},
#         "defaulters": {"count": 0, "percent_of_ccure_employees": None, "by_location": {}, "sample": []}
#     }

#     try:
#         session = SessionLocal()
#         active_emps = session.query(ActiveEmployee).all()
#         emp_map = {}
#         card_to_emp = {}
#         for e in active_emps:
#             eid = _normalize_employee_key(getattr(e, "employee_id", None))
#             emp_map[eid] = e
#             try:
#                 rr = getattr(e, "raw_row", None)
#                 if rr and isinstance(rr, dict):
#                     for ck in ("CardNumber","card_number","Card","Card No","CardNo","Badge","BadgeNo","IPassID","iPass ID","IPASSID"):
#                         if ck in rr and rr.get(ck):
#                             cn = _normalize_card_like(rr.get(ck))
#                             if cn:
#                                 card_to_emp[cn] = eid
#             except Exception:
#                 pass

#         att_rows_range = session.query(AttendanceSummary).filter(AttendanceSummary.date >= week_start, AttendanceSummary.date <= today).all()
#         rows_by_key = {}
#         for r in att_rows_range:
#             key = _normalize_employee_key(r.employee_id)
#             if key not in rows_by_key:
#                 rows_by_key[key] = []
#             rows_by_key[key].append(r)

#         meets_5 = []
#         meets_3 = []
#         defaulters_list = []
#         for eid, e in emp_map.items():
#             candidate_rows = []
#             if eid and eid in rows_by_key:
#                 candidate_rows.extend(rows_by_key[eid])
#             for k in list(rows_by_key.keys()):
#                 if not k:
#                     continue
#                 k_norm = _normalize_card_like(k)
#                 if k_norm and k_norm in card_to_emp and card_to_emp[k_norm] == eid:
#                     candidate_rows.extend(rows_by_key[k])
#             by_date = {}
#             for r in candidate_rows:
#                 try:
#                     d = r.date
#                     if d not in by_date:
#                         by_date[d] = r
#                     else:
#                         if (r.presence_count or 0) > (by_date[d].presence_count or 0):
#                             by_date[d] = r
#                 except Exception:
#                     continue
#             days_with_8h = 0
#             for d, row in by_date.items():
#                 if (row.presence_count or 0) > 0:
#                     try:
#                         if row.first_seen and row.last_seen:
#                             dur = (row.last_seen - row.first_seen).total_seconds() / 3600.0
#                             if dur >= 8.0:
#                                 days_with_8h += 1
#                     except Exception:
#                         pass
#             meets5 = (days_with_8h >= 5)
#             meets3 = (days_with_8h >= 3)
#             wfh_flag = is_employee_wfh(e)
#             location = None
#             for loc_attr in ("location_city", "location", "base_location", "location_desc", "location_description"):
#                 if hasattr(e, loc_attr):
#                     v = getattr(e, loc_attr)
#                     if v and isinstance(v, str) and v.strip():
#                         location = v.strip()
#                         break
#             if not location:
#                 try:
#                     rr = getattr(e, "raw_row", None)
#                     if rr and isinstance(rr, dict):
#                         for ck in ("Partition","PartitionName","Location","Site","location_city","Location City"):
#                             if ck in rr and rr.get(ck):
#                                 location = str(rr.get(ck)).strip()
#                                 break
#                 except Exception:
#                     pass
#             if not location:
#                 location = "Unknown"

#             if meets5:
#                 meets_5.append((eid, e, location))
#             if meets3:
#                 meets_3.append((eid, e, location))
#             if (not meets5) and (not meets3):
#                 if not wfh_flag:
#                     defaulters_list.append((eid, e, location))

#         def _build_location_counts(list_of_tuples):
#             loc_map = {}
#             for (_id, e_obj, loc) in list_of_tuples:
#                 if not loc:
#                     loc = "Unknown"
#                 if ccure_locations:
#                     if loc not in ccure_locations:
#                         continue
#                 if loc not in loc_map:
#                     loc_map[loc] = {"count": 0}
#                 loc_map[loc]["count"] += 1
#             return loc_map

#         meets_5_count = len(meets_5)
#         meets_3_count = len(meets_3)
#         defaulter_count = len(defaulters_list)

#         compliance["meets_5days_8h"]["count"] = int(meets_5_count)
#         compliance["meets_5days_8h"]["by_location"] = {k: {"count": int(v["count"])} for k, v in _build_location_counts(meets_5).items()}
#         compliance["meets_3days_8h"]["count"] = int(meets_3_count)
#         compliance["meets_3days_8h"]["by_location"] = {k: {"count": int(v["count"])} for k, v in _build_location_counts(meets_3).items()}
#         compliance["defaulters"]["count"] = int(defaulter_count)
#         compliance["defaulters"]["by_location"] = {k: {"count": int(v["count"])} for k, v in _build_location_counts(defaulters_list).items()}

#         denom_emp = reported_active_emps if reported_active_emps is not None else None
#         if isinstance(denom_emp, int) and denom_emp > 0:
#             compliance["meets_5days_8h"]["percent_of_ccure_employees"] = round((meets_5_count / denom_emp) * 100.0, 2)
#             compliance["meets_3days_8h"]["percent_of_ccure_employees"] = round((meets_3_count / denom_emp) * 100.0, 2)
#             compliance["defaulters"]["percent_of_ccure_employees"] = round((defaulter_count / denom_emp) * 100.0, 2)
#         else:
#             compliance["meets_5days_8h"]["percent_of_ccure_employees"] = None
#             compliance["meets_3days_8h"]["percent_of_ccure_employees"] = None
#             compliance["defaulters"]["percent_of_ccure_employees"] = None

#         sample = []
#         for (eid, e_obj, loc) in defaulters_list[:50]:
#             try:
#                 sample.append({
#                     "employee_id": _sanitize_for_json(eid),
#                     "full_name": _sanitize_for_json(getattr(e_obj, "full_name", None)),
#                     "location": _sanitize_for_json(loc),
#                     "wfh_flag": bool(is_employee_wfh(e_obj))
#                 })
#             except Exception:
#                 continue
#         compliance["defaulters"]["sample"] = sample

#         session.expunge_all()
#         session.close()
#     except Exception:
#         logger.exception("Error computing compliance section")
#         notes.append("Failed to compute compliance metrics; check server logs for trace.")
#     finally:
#         try:
#             session.close()
#         except Exception:
#             pass

#     # --- Averages: compute last 7 days headcount averages from AttendanceSummary (DB)
#     avg_headcount_last_7_days = None
#     avg_headcount_per_site_last_7_days = None
#     try:
#         session = SessionLocal()
#         days = []
#         for i in range(0, 7):
#             d = today - timedelta(days=i)
#             rows = session.query(AttendanceSummary).filter(AttendanceSummary.date == d).all()
#             # compute total visited that day (presence_count>0)
#             day_total = 0
#             if rows:
#                 for r in rows:
#                     if (r.presence_count or 0) > 0:
#                         day_total += 1
#             days.append(day_total)
#         if days:
#             avg_headcount_last_7_days = round(sum(days) / float(len(days)), 2)
#             if sites_queried and sites_queried > 0:
#                 avg_headcount_per_site_last_7_days = round((sum(days) / float(len(days))) / float(sites_queried), 2)
#         session.close()
#     except Exception:
#         logger.exception("Error computing averages from AttendanceSummary")
#         notes.append("Failed to compute historical averages from AttendanceSummary; partial results only.")

#     # --- HISTORY AVERAGES: use region_clients history endpoints (new)
#     history_emp_avg = None
#     history_contractor_avg = None
#     history_overall_avg = None
#     history_days = 0
#     try:
#         import region_clients
#         if hasattr(region_clients, "fetch_all_history"):
#             entries = region_clients.fetch_all_history(timeout=timeout) or []
#             # aggregate by date across regions
#             agg_by_date = {}  # date_str -> {"employee": int, "contractor": int, "total": int}
#             for e in entries:
#                 try:
#                     dstr = e.get("date")
#                     if not dstr:
#                         continue
#                     region_obj = e.get("region") if isinstance(e.get("region"), dict) else None
#                     emp = None
#                     con = None
#                     tot = None
#                     if region_obj and isinstance(region_obj, dict):
#                         emp = _safe_int(region_obj.get("Employee"))
#                         con = _safe_int(region_obj.get("Contractor"))
#                         tot = _safe_int(region_obj.get("total")) or ( (emp or 0) + (con or 0) )
#                     else:
#                         emp = _safe_int(e.get("Employee") or (e.get("region") and e.get("region").get("Employee") if isinstance(e.get("region"), dict) else None))
#                         con = _safe_int(e.get("Contractor") or (e.get("region") and e.get("region").get("Contractor") if isinstance(e.get("region"), dict) else None))
#                         tot = _safe_int(e.get("total") or ( (emp or 0) + (con or 0) ))
#                     if emp is None and con is None and tot is None:
#                         try:
#                             robj = e.get("region") or {}
#                             if isinstance(robj, dict):
#                                 emp = _safe_int(robj.get("Employee"))
#                                 con = _safe_int(robj.get("Contractor"))
#                                 tot = _safe_int(robj.get("total"))
#                         except Exception:
#                             pass
#                     if emp is None and con is None:
#                         continue
#                     if tot is None:
#                         tot = (emp or 0) + (con or 0)
#                     if dstr not in agg_by_date:
#                         agg_by_date[dstr] = {"employee": 0, "contractor": 0, "total": 0, "counted_regions": 0}
#                     agg_by_date[dstr]["employee"] += (emp or 0)
#                     agg_by_date[dstr]["contractor"] += (con or 0)
#                     agg_by_date[dstr]["total"] += (tot or 0)
#                     agg_by_date[dstr]["counted_regions"] += 1
#                 except Exception:
#                     continue
#             # Now compute per-date totals normalized (we can average across available regions)
#             day_vals_emp = []
#             day_vals_con = []
#             day_vals_tot = []
#             # Only consider the last 7 calendar days (if present)
#             for i in range(0, 7):
#                 d = (today - timedelta(days=i)).isoformat()
#                 entry = agg_by_date.get(d)
#                 if entry:
#                     day_vals_emp.append(entry.get("employee", 0))
#                     day_vals_con.append(entry.get("contractor", 0))
#                     day_vals_tot.append(entry.get("total", 0))
#             if day_vals_emp:
#                 history_emp_avg = round(sum(day_vals_emp) / float(len(day_vals_emp)), 2)
#             if day_vals_con:
#                 history_contractor_avg = round(sum(day_vals_con) / float(len(day_vals_con)), 2)
#             if day_vals_tot:
#                 history_overall_avg = round(sum(day_vals_tot) / float(len(day_vals_tot)), 2)
#             history_days = len(day_vals_tot)
#             if history_days == 0:
#                 notes.append("History endpoints returned no usable last-7-day rows; history averages not available.")
#     except Exception:
#         logger.exception("Error fetching/processing history endpoints")
#         notes.append("Failed to compute history averages from region history endpoints; partial results.")

#     # ---------- NEW: if DB-based 7-day avg empty, fallback to history_overall_avg ----------
#     if (not avg_headcount_last_7_days or avg_headcount_last_7_days == 0) and history_overall_avg:
#         try:
#             avg_headcount_last_7_days = history_overall_avg
#             avg_headcount_per_site_last_7_days = round(history_overall_avg / float(sites_queried), 2) if sites_queried and sites_queried > 0 else None
#             notes.append("avg_headcount_last_7_days derived from region history endpoints due to missing AttendanceSummary historical data.")
#         except Exception:
#             pass

#     # --- compute percentages (head/live vs CCURE reported)
#     def safe_pct(n, denom):
#         try:
#             if n is None or denom is None:
#                 return None
#             d = float(denom)
#             if d == 0.0:
#                 return None
#             return round((float(n) / d) * 100.0, 2)
#         except Exception:
#             return None

#     cc_emp_denom = reported_active_emps
#     cc_con_denom = reported_active_contractors
#     cc_total_denom = None
#     if isinstance(cc_emp_denom, int) and isinstance(cc_con_denom, int):
#         cc_total_denom = cc_emp_denom + cc_con_denom

#     head_emp_total = sum(v.get("employee", 0) for v in head_per_location.values())
#     head_con_total = sum(v.get("contractor", 0) for v in head_per_location.values())
#     live_emp_total = sum(v.get("employee", 0) for v in live_per_location.values())
#     live_con_total = sum(v.get("contractor", 0) for v in live_per_location.values())

#     # percent of CCURE employees/contractors present today (headcount basis)
#     head_emp_pct_vs_ccure_today = _sanitize_for_json(safe_pct(head_emp_total, cc_emp_denom))
#     head_con_pct_vs_ccure_today = _sanitize_for_json(safe_pct(head_con_total, cc_con_denom))
#     head_overall_pct_vs_ccure_today = _sanitize_for_json(safe_pct(head_total, cc_total_denom))

#     live_emp_pct_vs_ccure_today = _sanitize_for_json(safe_pct(live_emp_total, cc_emp_denom))
#     live_con_pct_vs_ccure_today = _sanitize_for_json(safe_pct(live_con_total, cc_con_denom))
#     live_overall_pct_vs_ccure_today = _sanitize_for_json(safe_pct(live_total, cc_total_denom))

#     # history percentages vs CCURE (if denominators exist)
#     history_emp_pct_vs_ccure = _sanitize_for_json(safe_pct(history_emp_avg, cc_emp_denom))
#     history_con_pct_vs_ccure = _sanitize_for_json(safe_pct(history_contractor_avg, cc_con_denom))
#     history_overall_pct_vs_ccure = _sanitize_for_json(safe_pct(history_overall_avg, cc_total_denom))

#     result = {
#         "date": today.isoformat(),
#         "headcount": {
#             "total_visited_today": int(head_total),
#             "employee": int(head_emp_total),
#             "contractor": int(head_con_total),
#             "by_location": { loc: {"total": int(stats.get("total", 0)), "employee": int(stats.get("employee", 0)), "contractor": int(stats.get("contractor", 0))} for loc, stats in head_per_location.items() }
#         },
#         "live_headcount": {
#             "currently_present_total": int(live_total),
#             "employee": int(live_emp_total),
#             "contractor": int(live_con_total),
#             "by_location": { loc: {"total": int(stats.get("total", 0)), "employee": int(stats.get("employee", 0)), "contractor": int(stats.get("contractor", 0))} for loc, stats in live_per_location.items() }
#         },
#         "ccure_active": {
#             "ccure_active_employees_reported": _safe_int(reported_active_emps),
#             "ccure_active_contractors_reported": _safe_int(reported_active_contractors)
#         },
#         "averages": {
#             # existing AttendanceSummary averages
#             "head_emp_pct_vs_ccure_today": head_emp_pct_vs_ccure_today,
#             "head_contractor_pct_vs_ccure_today": head_con_pct_vs_ccure_today,
#             "headcount_overall_pct_vs_ccure_today": head_overall_pct_vs_ccure_today,
#             "live_employee_pct_vs_ccure": live_emp_pct_vs_ccure_today,
#             "live_contractor_pct_vs_ccure": live_con_pct_vs_ccure_today if False else live_con_pct_vs_ccure_today if 'live_con_pct_vs_ccure_today' in locals() else _sanitize_for_json(safe_pct(live_con_total, cc_con_denom)),
#             "live_overall_pct_vs_ccure": live_overall_pct_vs_ccure_today,
#             "avg_headcount_last_7_days": _sanitize_for_json(avg_headcount_last_7_days),
#             "avg_headcount_per_site_last_7_days": _sanitize_for_json(avg_headcount_per_site_last_7_days),
#             "avg_live_per_site": _sanitize_for_json(round(live_total / sites_queried, 2) if sites_queried and sites_queried > 0 else None),

#             # NEW: history endpoint averages (region-provided)
#             "history_avg_employee_last_7_days": _sanitize_for_json(history_emp_avg),
#             "history_avg_contractor_last_7_days": _sanitize_for_json(history_contractor_avg),
#             "history_avg_overall_last_7_days": _sanitize_for_json(history_overall_avg),
#             "history_days_counted": int(history_days) if history_days is not None else None,
#             "history_employee_pct_vs_ccure": history_emp_pct_vs_ccure,
#             "history_contractor_pct_vs_ccure": history_con_pct_vs_ccure,
#             "history_overall_pct_vs_ccure": history_overall_pct_vs_ccure
#         },
#         "compliance": _sanitize_for_json(compliance),
#         "sites_queried": int(sites_queried),
#         "notes": " | ".join(notes) if notes else None
#     }

#     # sanitize and return
#     return _sanitize_for_json(result)












# ccure_compare_service.py
"""
Compare CCURE profiles/stats with local sheets + compute visit averages + compliance.

Key behaviors:
 - If AttendanceSummary for today is empty, attempt to call compute_daily_attendance() to build it from LiveSwipe.
 - Provide headcount (AttendanceSummary) and live_headcount (region_clients) with per-location breakdowns.
 - ccure_active exposes only reported ActiveEmployees and ActiveContractors (no derived fields).
 - Computes averages (last 7 days) and today's percentages vs CCURE reported counts.
 - Compliance (meets_5days_8h, meets_3days_8h, defaulters) computed using AttendanceSummary historical data.
"""

import re
import traceback
from datetime import date, datetime, timedelta
from typing import List, Dict, Any, Optional, Set

import logging

logger = logging.getLogger("ccure_compare_service")
logger.setLevel(logging.INFO)
if not logger.handlers:
    ch = logging.StreamHandler()
    ch.setFormatter(logging.Formatter("%(asctime)s %(levelname)s %(name)s: %(message)s"))
    logger.addHandler(ch)

from db import SessionLocal
from models import ActiveEmployee, ActiveContractor, AttendanceSummary, LiveSwipe
from settings import OUTPUT_DIR

# ---------- small helpers ----------------------------------------------------

def _normalize_employee_key(x) -> Optional[str]:
    if x is None:
        return None
    try:
        s = str(x).strip()
        if s == "" or s.lower() in ("nan", "none", "na", "null"):
            return None
        return s
    except Exception:
        return None

def _normalize_card_like(s) -> Optional[str]:
    if s is None:
        return None
    try:
        ss = str(s).strip()
        if ss == "":
            return None
        digits = re.sub(r'\D+', '', ss)
        if digits == "":
            return None
        return digits.lstrip('0') or digits
    except Exception:
        return None

def _safe_int(v):
    try:
        if v is None:
            return None
        return int(v)
    except Exception:
        try:
            return int(float(v))
        except Exception:
            return None

def _sanitize_for_json(value):
    try:
        import numpy as _np
    except Exception:
        _np = None
    if value is None:
        return None
    if isinstance(value, (str, bool, int)):
        return value
    if isinstance(value, float):
        if _np is not None and not _np.isfinite(value):
            return None
        return float(value)
    if _np is not None and isinstance(value, (_np.integer,)):
        return int(value)
    if isinstance(value, dict):
        out = {}
        for k, v in value.items():
            try:
                key = str(k)
            except Exception:
                key = repr(k)
            out[key] = _sanitize_for_json(v)
        return out
    if isinstance(value, (list, tuple, set)):
        return [_sanitize_for_json(v) for v in value]
    try:
        return str(value)
    except Exception:
        return None

# ---------- ccure helpers ---------------------------------------------------

def _fetch_ccure_stats():
    try:
        import ccure_client
        if hasattr(ccure_client, "get_global_stats"):
            return ccure_client.get_global_stats()
    except Exception:
        logger.debug("ccure_client.get_global_stats not available", exc_info=True)
    return None

def _fetch_ccure_profiles():
    try:
        import ccure_client
        for fn in ("fetch_all_employees_full", "fetch_all_employees", "fetch_all_profiles", "fetch_profiles", "fetch_all"):
            if hasattr(ccure_client, fn):
                try:
                    res = getattr(ccure_client, fn)()
                    if isinstance(res, list):
                        return res
                except Exception:
                    continue
    except Exception:
        pass
    return []

def _extract_ccure_locations_from_profiles(profiles: List[dict]) -> Set[str]:
    locs = set()
    for p in profiles:
        if not isinstance(p, dict):
            continue
        for k in ("Partition", "PartitionName", "Location", "Location City", "location_city", "location", "Site", "BaseLocation"):
            v = p.get(k) if isinstance(p, dict) else None
            if v and isinstance(v, str) and v.strip():
                locs.add(v.strip())
    return locs

# ---------- classification & partition helpers ------------------------------

def classify_personnel_from_detail(detail: dict) -> str:
    """Map many CCURE / live-summary personnel strings to 'employee' or 'contractor'."""
    try:
        if not isinstance(detail, dict):
            return "contractor"
        candidate_keys = [
            "PersonnelType", "personnelType", "personnel_type", "Personnel Type",
            "PersonnelTypeName", "Personnel", "Type", "personnel", "PersonType", "personType"
        ]
        val = None
        for k in candidate_keys:
            if k in detail and detail.get(k) is not None:
                val = str(detail.get(k)).strip().lower()
                break
        status_keys = ["Employee_Status", "Employee Status", "Status", "Profile_Disabled"]
        status_val = None
        for k in status_keys:
            if k in detail and detail.get(k) is not None:
                status_val = str(detail.get(k)).strip().lower()
                break

        if status_val is not None and "terminated" in status_val:
            return "employee"
        if val is None or val == "":
            return "contractor"
        if "employee" in val:
            return "employee"
        if "terminated" in val:
            return "employee"
        contractor_terms = ["contractor", "visitor", "property", "property management", "temp", "temp badge", "tempbadge"]
        for t in contractor_terms:
            if t in val:
                return "contractor"
        if "contract" in val or "visitor" in val:
            return "contractor"
        return "contractor"
    except Exception:
        return "contractor"

def pick_partition_from_detail(detail: dict) -> str:
    if not isinstance(detail, dict):
        return "Unknown"
    for k in ("PartitionName2","PartitionName1","Partition","PartitionName","Region","Location","Site","location_city","Location City"):
        if k in detail and detail.get(k):
            try:
                return str(detail.get(k)).strip()
            except Exception:
                continue
    if "__region" in detail and detail.get("__region"):
        return str(detail.get("__region")).strip()
    return "Unknown"

# ---------- WFH detection helper -------------------------------------------

def is_employee_wfh(active_emp_row: ActiveEmployee) -> bool:
    try:
        wfh_keywords = ("work from home", "wfh", "remote", "workfromhome", "home")
        for attr in ("is_wfh", "work_from_home", "wfh", "remote_flag"):
            if hasattr(active_emp_row, attr):
                try:
                    val = getattr(active_emp_row, attr)
                    if isinstance(val, bool) and val:
                        return True
                    if isinstance(val, str) and any(k in val.strip().lower() for k in wfh_keywords):
                        return True
                except Exception:
                    pass
        for attr in ("location_description", "location_desc", "location_description1", "base_location", "location", "location_city"):
            if hasattr(active_emp_row, attr):
                try:
                    v = getattr(active_emp_row, attr)
                    if v and isinstance(v, str):
                        s = v.strip().lower()
                        if any(k in s for k in wfh_keywords):
                            return True
                except Exception:
                    pass
        try:
            rr = getattr(active_emp_row, "raw_row", None)
            if rr and isinstance(rr, dict):
                for k, v in rr.items():
                    try:
                        if v and isinstance(v, str) and any(word in v.strip().lower() for word in wfh_keywords):
                            return True
                    except Exception:
                        continue
        except Exception:
            pass
    except Exception:
        pass
    return False

# ---------- utility: fallback headcount builder from LiveSwipe --------------

def build_headcount_from_liveswipes_for_today(session) -> (int, Dict[str, Dict[str, int]]):
    """
    When AttendanceSummary for today is empty, build headcount by scanning LiveSwipe rows for today
    Deduplicate by key (employee_id or card) and compute per-location counts.
    Returns (total_count, by_location dict)
    """
    start = datetime.combine(date.today(), datetime.min.time())
    end = datetime.combine(date.today(), datetime.max.time())
    swipes = session.query(LiveSwipe).filter(LiveSwipe.timestamp >= start, LiveSwipe.timestamp <= end).all()
    if not swipes:
        return 0, {}
    seen_keys = {}
    per_loc = {}
    for s in swipes:
        key = _normalize_employee_key(s.employee_id) or _normalize_card_like(s.card_number)
        if not key:
            key = f"nokey_{s.id}"
        rec = seen_keys.get(key)
        ts = s.timestamp
        if rec is None:
            seen_keys[key] = {"first_seen": ts, "last_seen": ts, "partition": (s.partition or "Unknown"), "class": None, "card": s.card_number, "raw": s.raw}
        else:
            if ts and rec.get("first_seen") and ts < rec["first_seen"]:
                rec["first_seen"] = ts
            if ts and rec.get("last_seen") and ts > rec["last_seen"]:
                rec["last_seen"] = ts
    for k, v in seen_keys.items():
        loc = v.get("partition") or "Unknown"
        if not isinstance(loc, str) or not loc.strip():
            loc = "Unknown"
        if loc not in per_loc:
            per_loc[loc] = {"total": 0, "employee": 0, "contractor": 0}
        per_loc[loc]["total"] += 1
        classified = "contractor"
        raw = v.get("raw")
        if isinstance(raw, dict):
            try:
                classified = classify_personnel_from_detail(raw)
            except Exception:
                classified = "contractor"
        per_loc[loc][classified] += 1
    total = sum(p["total"] for p in per_loc.values())
    return int(total), per_loc

# ---------- main compute function -----------------------------------------

def compute_visit_averages(timeout: int = 6) -> Dict[str, Any]:
    notes = []
    today = date.today()
    week_start = today - timedelta(days=6)  # last 7 days inclusive

    # --- try to get CCURE stats/profiles early for filtering & denominators
    ccure_stats = _fetch_ccure_stats()
    reported_active_emps = _safe_int(ccure_stats.get("ActiveEmployees")) if isinstance(ccure_stats, dict) else None
    reported_active_contractors = _safe_int(ccure_stats.get("ActiveContractors")) if isinstance(ccure_stats, dict) else None

    ccure_profiles = _fetch_ccure_profiles()
    ccure_locations = _extract_ccure_locations_from_profiles(ccure_profiles) if isinstance(ccure_profiles, list) else set()

    # --- HEADCOUNT (AttendanceSummary for today) with fallback
    head_total = 0
    head_per_location: Dict[str, Dict[str, int]] = {}
    try:
        session = SessionLocal()
        att_rows_today = session.query(AttendanceSummary).filter(AttendanceSummary.date == today).all()
        if not att_rows_today:
            # Attempt to build AttendanceSummary from LiveSwipe using compute_daily_attendance (if available)
            built_ok = False
            try:
                # import local compare_service.compute_daily_attendance if available
                from compare_service import compute_daily_attendance as _compute_daily_attendance
                try:
                    built = _compute_daily_attendance(today)
                    # If compute_daily_attendance returns rows, requery AttendanceSummary
                    if isinstance(built, list) and len(built) > 0:
                        att_rows_today = session.query(AttendanceSummary).filter(AttendanceSummary.date == today).all()
                        built_ok = True
                        notes.append("AttendanceSummary was missing; built from LiveSwipe via compute_daily_attendance().")
                except Exception:
                    # fall through to fallback builder
                    logger.exception("compute_daily_attendance execution failed; falling back")
            except Exception:
                # compare_service not importable -> fallback
                logger.debug("compare_service.compute_daily_attendance not importable; falling back", exc_info=True)

            if not att_rows_today:
                # fallback: build headcount from LiveSwipe directly (non-persistent)
                built_total, built_per_loc = build_headcount_from_liveswipes_for_today(session)
                head_total = built_total
                head_per_location = built_per_loc
                if head_total > 0:
                    notes.append("AttendanceSummary for today empty; built headcount from LiveSwipe rows (non-persistent fallback).")
        if att_rows_today:
            # classify using ActiveEmployee / ActiveContractor sets
            act_emps = session.query(ActiveEmployee).all()
            act_contrs = session.query(ActiveContractor).all()
            emp_id_set = set()
            contr_id_set = set()
            card_to_emp = {}
            for e in act_emps:
                v = _normalize_employee_key(getattr(e, "employee_id", None))
                if v:
                    emp_id_set.add(v)
                try:
                    rr = getattr(e, "raw_row", None)
                    if rr and isinstance(rr, dict):
                        for ck in ("CardNumber","card_number","Card","Card No","CardNo","Badge","BadgeNo","IPassID","iPass ID","IPASSID"):
                            if ck in rr and rr.get(ck):
                                cn = _normalize_card_like(rr.get(ck))
                                if cn:
                                    card_to_emp[cn] = v
                except Exception:
                    pass
            for c in act_contrs:
                wid = _normalize_employee_key(getattr(c, "worker_system_id", None))
                ip = _normalize_employee_key(getattr(c, "ipass_id", None))
                primary = wid or ip
                if primary:
                    contr_id_set.add(primary)

            for a in att_rows_today:
                key = _normalize_employee_key(a.employee_id)
                partition = None
                try:
                    if a.derived and isinstance(a.derived, dict):
                        partition = a.derived.get("partition")
                except Exception:
                    partition = None
                loc = partition or "Unknown"
                if not isinstance(loc, str) or not loc.strip():
                    loc = "Unknown"
                if loc not in head_per_location:
                    head_per_location[loc] = {"total": 0, "employee": 0, "contractor": 0}
                if (a.presence_count or 0) > 0:
                    head_total += 1
                    head_per_location[loc]["total"] += 1
                    cls = "contractor"
                    if key and key in emp_id_set:
                        cls = "employee"
                    elif key and key in contr_id_set:
                        cls = "contractor"
                    else:
                        try:
                            card = (a.derived.get("card_number") if (a.derived and isinstance(a.derived, dict)) else None)
                        except Exception:
                            card = None
                        cnorm = _normalize_card_like(card)
                        if cnorm and cnorm in card_to_emp:
                            cls = "employee" if card_to_emp.get(cnorm) in emp_id_set else "contractor"
                        else:
                            cls = "contractor"
                    head_per_location[loc][cls] += 1
        session.expunge_all()
    except Exception:
        logger.exception("Error computing HeadCount")
        notes.append("Failed to compute HeadCount from DB; see server logs.")
    finally:
        try:
            session.close()
        except Exception:
            pass

    # --- LIVE HEADCOUNT via region_clients (as before)
    live_total = 0
    live_per_location: Dict[str, Dict[str, int]] = {}
    sites_queried = 0
    details = []  # ensure defined for later fallbacks
    try:
        import region_clients
        regions_info = []
        try:
            if hasattr(region_clients, "fetch_all_regions"):
                regions_info = region_clients.fetch_all_regions(timeout=timeout) or []
        except Exception:
            logger.exception("region_clients.fetch_all_regions failed")
        try:
            if hasattr(region_clients, "fetch_all_details"):
                details = region_clients.fetch_all_details(timeout=timeout) or []
        except Exception:
            logger.exception("region_clients.fetch_all_details failed")
        sites_queried = len(regions_info) if isinstance(regions_info, list) else 0
        if regions_info:
            for r in regions_info:
                try:
                    c = r.get("count") if isinstance(r, dict) else None
                    ci = _safe_int(c)
                    if ci is not None:
                        live_total += int(ci)
                except Exception:
                    continue
        derived_detail_sum = 0
        if details and isinstance(details, list):
            for d in details:
                try:
                    loc = pick_partition_from_detail(d) or "Unknown"
                    if not isinstance(loc, str) or not loc.strip():
                        loc = "Unknown"
                    pclass = classify_personnel_from_detail(d)
                    if loc not in live_per_location:
                        live_per_location[loc] = {"total": 0, "employee": 0, "contractor": 0}
                    live_per_location[loc]["total"] += 1
                    live_per_location[loc][pclass] += 1
                    derived_detail_sum += 1
                except Exception:
                    continue
            if live_total == 0 and derived_detail_sum > 0:
                live_total = derived_detail_sum
            else:
                if live_total != derived_detail_sum:
                    notes.append(f"Region totals ({live_total}) differ from detail rows ({derived_detail_sum}); using region totals for overall and details for breakdown.")
        else:
            notes.append("No per-person details available from region_clients; live breakdown unavailable.")
    except Exception:
        logger.exception("Error computing Live HeadCount")
        notes.append("Failed to compute Live HeadCount; see logs.")
        live_total = live_total or 0

    # ---------- NEW FALLBACK: if head_total still zero, build from region_clients details ----------
    if (head_total == 0) and details:
        try:
            seen_keys = set()
            for d in details:
                try:
                    # Prefer EmployeeID or CardNumber or PersonGUID as dedupe key
                    key = _normalize_employee_key(d.get("EmployeeID")) or _normalize_card_like(d.get("CardNumber")) or (d.get("PersonGUID") if d.get("PersonGUID") else None)
                    if not key:
                        # try other possible id-like fields
                        key = _normalize_employee_key(d.get("employee_id")) or _normalize_card_like(d.get("Card")) or None
                    if not key:
                        continue
                    key = str(key)
                    if key in seen_keys:
                        continue
                    seen_keys.add(key)
                    loc = pick_partition_from_detail(d) or "Unknown"
                    pclass = classify_personnel_from_detail(d)
                    if loc not in head_per_location:
                        head_per_location[loc] = {"total": 0, "employee": 0, "contractor": 0}
                    head_per_location[loc]["total"] += 1
                    head_per_location[loc][pclass] += 1
                    head_total += 1
                except Exception:
                    continue
            if head_total > 0:
                notes.append("AttendanceSummary and LiveSwipe empty; built headcount from region_clients live-summary details (fallback).")
        except Exception:
            logger.exception("Error building headcount from region details fallback")

    # --- CCURE active: exposed only as reported (not derived)
    # reported_active_emps, reported_active_contractors already from ccure_stats above

    # --- Compliance: compute using AttendanceSummary last 7 days (DB)
    compliance = {
        "meets_5days_8h": {"count": 0, "percent_of_ccure_employees": None, "by_location": {}},
        "meets_3days_8h": {"count": 0, "percent_of_ccure_employees": None, "by_location": {}},
        "defaulters": {"count": 0, "percent_of_ccure_employees": None, "by_location": {}, "sample": []}
    }

    try:
        session = SessionLocal()
        active_emps = session.query(ActiveEmployee).all()
        emp_map = {}
        card_to_emp = {}
        for e in active_emps:
            eid = _normalize_employee_key(getattr(e, "employee_id", None))
            emp_map[eid] = e
            try:
                rr = getattr(e, "raw_row", None)
                if rr and isinstance(rr, dict):
                    for ck in ("CardNumber","card_number","Card","Card No","CardNo","Badge","BadgeNo","IPassID","iPass ID","IPASSID"):
                        if ck in rr and rr.get(ck):
                            cn = _normalize_card_like(rr.get(ck))
                            if cn:
                                card_to_emp[cn] = eid
            except Exception:
                pass

        att_rows_range = session.query(AttendanceSummary).filter(AttendanceSummary.date >= week_start, AttendanceSummary.date <= today).all()
        rows_by_key = {}
        for r in att_rows_range:
            key = _normalize_employee_key(r.employee_id)
            if key not in rows_by_key:
                rows_by_key[key] = []
            rows_by_key[key].append(r)

        meets_5 = []
        meets_3 = []
        defaulters_list = []
        for eid, e in emp_map.items():
            candidate_rows = []
            if eid and eid in rows_by_key:
                candidate_rows.extend(rows_by_key[eid])
            for k in list(rows_by_key.keys()):
                if not k:
                    continue
                k_norm = _normalize_card_like(k)
                if k_norm and k_norm in card_to_emp and card_to_emp[k_norm] == eid:
                    candidate_rows.extend(rows_by_key[k])
            by_date = {}
            for r in candidate_rows:
                try:
                    d = r.date
                    if d not in by_date:
                        by_date[d] = r
                    else:
                        if (r.presence_count or 0) > (by_date[d].presence_count or 0):
                            by_date[d] = r
                except Exception:
                    continue
            days_with_8h = 0
            for d, row in by_date.items():
                if (row.presence_count or 0) > 0:
                    try:
                        if row.first_seen and row.last_seen:
                            dur = (row.last_seen - row.first_seen).total_seconds() / 3600.0
                            if dur >= 8.0:
                                days_with_8h += 1
                    except Exception:
                        pass
            meets5 = (days_with_8h >= 5)
            meets3 = (days_with_8h >= 3)
            wfh_flag = is_employee_wfh(e)
            location = None
            for loc_attr in ("location_city", "location", "base_location", "location_desc", "location_description"):
                if hasattr(e, loc_attr):
                    v = getattr(e, loc_attr)
                    if v and isinstance(v, str) and v.strip():
                        location = v.strip()
                        break
            if not location:
                try:
                    rr = getattr(e, "raw_row", None)
                    if rr and isinstance(rr, dict):
                        for ck in ("Partition","PartitionName","Location","Site","location_city","Location City"):
                            if ck in rr and rr.get(ck):
                                location = str(rr.get(ck)).strip()
                                break
                except Exception:
                    pass
            if not location:
                location = "Unknown"

            if meets5:
                meets_5.append((eid, e, location))
            if meets3:
                meets_3.append((eid, e, location))
            if (not meets5) and (not meets3):
                if not wfh_flag:
                    defaulters_list.append((eid, e, location))

        def _build_location_counts(list_of_tuples):
            loc_map = {}
            for (_id, e_obj, loc) in list_of_tuples:
                if not loc:
                    loc = "Unknown"
                if ccure_locations:
                    if loc not in ccure_locations:
                        continue
                if loc not in loc_map:
                    loc_map[loc] = {"count": 0}
                loc_map[loc]["count"] += 1
            return loc_map

        meets_5_count = len(meets_5)
        meets_3_count = len(meets_3)
        defaulter_count = len(defaulters_list)

        compliance["meets_5days_8h"]["count"] = int(meets_5_count)
        compliance["meets_5days_8h"]["by_location"] = {k: {"count": int(v["count"])} for k, v in _build_location_counts(meets_5).items()}
        compliance["meets_3days_8h"]["count"] = int(meets_3_count)
        compliance["meets_3days_8h"]["by_location"] = {k: {"count": int(v["count"])} for k, v in _build_location_counts(meets_3).items()}
        compliance["defaulters"]["count"] = int(defaulter_count)
        compliance["defaulters"]["by_location"] = {k: {"count": int(v["count"])} for k, v in _build_location_counts(defaulters_list).items()}

        denom_emp = reported_active_emps if reported_active_emps is not None else None
        if isinstance(denom_emp, int) and denom_emp > 0:
            compliance["meets_5days_8h"]["percent_of_ccure_employees"] = round((meets_5_count / denom_emp) * 100.0, 2)
            compliance["meets_3days_8h"]["percent_of_ccure_employees"] = round((meets_3_count / denom_emp) * 100.0, 2)
            compliance["defaulters"]["percent_of_ccure_employees"] = round((defaulter_count / denom_emp) * 100.0, 2)
        else:
            compliance["meets_5days_8h"]["percent_of_ccure_employees"] = None
            compliance["meets_3days_8h"]["percent_of_ccure_employees"] = None
            compliance["defaulters"]["percent_of_ccure_employees"] = None

        sample = []
        for (eid, e_obj, loc) in defaulters_list[:50]:
            try:
                sample.append({
                    "employee_id": _sanitize_for_json(eid),
                    "full_name": _sanitize_for_json(getattr(e_obj, "full_name", None)),
                    "location": _sanitize_for_json(loc),
                    "wfh_flag": bool(is_employee_wfh(e_obj))
                })
            except Exception:
                continue
        compliance["defaulters"]["sample"] = sample

        session.expunge_all()
        session.close()
    except Exception:
        logger.exception("Error computing compliance section")
        notes.append("Failed to compute compliance metrics; check server logs for trace.")
    finally:
        try:
            session.close()
        except Exception:
            pass

    # --- Averages: compute last 7 days headcount averages from AttendanceSummary (DB)
    avg_headcount_last_7_days = None
    avg_headcount_per_site_last_7_days = None
    # Per-location DB aggregates (new)
    avg_by_location_last_7_days: Dict[str, Dict[str, Any]] = {}

    try:
        session = SessionLocal()

        # Build ActiveEmployee/ActiveContractor maps for classification during per-day scans
        act_emps = session.query(ActiveEmployee).all()
        act_contrs = session.query(ActiveContractor).all()
        emp_id_set = set()
        contr_id_set = set()
        card_to_emp = {}
        for e in act_emps:
            eid = _normalize_employee_key(getattr(e, "employee_id", None))
            if eid:
                emp_id_set.add(eid)
            try:
                rr = getattr(e, "raw_row", None) or {}
                if isinstance(rr, dict):
                    for ck in ("CardNumber","card_number","Card","Card No","CardNo","IPassID","iPass ID","IPASSID","Badge","BadgeNo"):
                        if ck in rr and rr.get(ck):
                            cn = _normalize_card_like(rr.get(ck))
                            if cn:
                                card_to_emp[cn] = eid
            except Exception:
                pass
        for c in act_contrs:
            wid = _normalize_employee_key(getattr(c, "worker_system_id", None))
            ip = _normalize_employee_key(getattr(c, "ipass_id", None))
            primary = wid or ip
            if primary:
                contr_id_set.add(primary)
            try:
                rr = getattr(c, "raw_row", None) or {}
                if isinstance(rr, dict):
                    for ck in ("Worker System Id","Worker System ID","iPass ID","IPASSID","CardNumber","card_number"):
                        if ck in rr and rr.get(ck):
                            cn = _normalize_card_like(rr.get(ck))
                            if cn:
                                # map to contractor primary
                                card_to_emp[cn] = primary
            except Exception:
                pass

        # Prepare per-location day lists
        loc_day_vals: Dict[str, Dict[str, List[int]]] = {}
        days = []
        for i in range(0, 7):
            d = today - timedelta(days=i)
            days.append(d)
            rows = session.query(AttendanceSummary).filter(AttendanceSummary.date == d).all()
            # compute per-location counts for that day
            per_loc_counts: Dict[str, Dict[str, int]] = {}
            if rows:
                for r in rows:
                    try:
                        if (r.presence_count or 0) <= 0:
                            continue
                        partition = None
                        try:
                            if r.derived and isinstance(r.derived, dict):
                                partition = r.derived.get("partition")
                        except Exception:
                            partition = None
                        loc = partition or "Unknown"
                        if not isinstance(loc, str) or not loc.strip():
                            loc = "Unknown"
                        if loc not in per_loc_counts:
                            per_loc_counts[loc] = {"employee": 0, "contractor": 0, "total": 0}
                        # classify row
                        key = _normalize_employee_key(r.employee_id)
                        cls = "contractor"
                        if key and key in emp_id_set:
                            cls = "employee"
                        elif key and key in contr_id_set:
                            cls = "contractor"
                        else:
                            # try derived card number
                            try:
                                card = (r.derived.get("card_number") if (r.derived and isinstance(r.derived, dict)) else None)
                            except Exception:
                                card = None
                            cnorm = _normalize_card_like(card)
                            if cnorm and cnorm in card_to_emp and card_to_emp.get(cnorm) in emp_id_set:
                                cls = "employee"
                            elif cnorm and cnorm in card_to_emp and card_to_emp.get(cnorm) in contr_id_set:
                                cls = "contractor"
                            else:
                                # fallback: try to classify by looking at presence of explicit PersonnelType in derived/raw (rare for AttendanceSummary)
                                cls = "contractor"
                        per_loc_counts[loc][cls] += 1
                        per_loc_counts[loc]["total"] += 1
                    except Exception:
                        continue
            # for each location seen on that day, append day's counts
            for loc, counts in per_loc_counts.items():
                if loc not in loc_day_vals:
                    loc_day_vals[loc] = {"employee": [], "contractor": [], "total": []}
                loc_day_vals[loc]["employee"].append(counts.get("employee", 0))
                loc_day_vals[loc]["contractor"].append(counts.get("contractor", 0))
                loc_day_vals[loc]["total"].append(counts.get("total", 0))

        # compute per-location averages
        for loc, lists in loc_day_vals.items():
            emp_list = lists.get("employee", [])
            con_list = lists.get("contractor", [])
            tot_list = lists.get("total", [])
            days_counted = len(tot_list)
            avg_emp = round(sum(emp_list) / float(days_counted), 2) if days_counted and sum(emp_list) is not None else 0.0
            avg_con = round(sum(con_list) / float(days_counted), 2) if days_counted and sum(con_list) is not None else 0.0
            avg_tot = round(sum(tot_list) / float(days_counted), 2) if days_counted and sum(tot_list) is not None else 0.0
            avg_by_location_last_7_days[loc] = {
                "history_days_counted": int(days_counted),
                "avg_employee_last_7_days": _sanitize_for_json(avg_emp),
                "avg_contractor_last_7_days": _sanitize_for_json(avg_con),
                "avg_overall_last_7_days": _sanitize_for_json(avg_tot)
            }

        # compute DB overall avg_headcount_last_7_days (previous behavior)
        days_totals = []
        for d in days:
            rows = session.query(AttendanceSummary).filter(AttendanceSummary.date == d).all()
            day_total = 0
            if rows:
                for r in rows:
                    if (r.presence_count or 0) > 0:
                        day_total += 1
            days_totals.append(day_total)
        if days_totals:
            avg_headcount_last_7_days = round(sum(days_totals) / float(len(days_totals)), 2)
            if sites_queried and sites_queried > 0:
                avg_headcount_per_site_last_7_days = round((sum(days_totals) / float(len(days_totals))) / float(sites_queried), 2)

        session.close()
    except Exception:
        logger.exception("Error computing averages from AttendanceSummary")
        notes.append("Failed to compute historical averages from AttendanceSummary; partial results only.")

    # --- HISTORY AVERAGES: use region_clients history endpoints (new)
    history_emp_avg = None
    history_contractor_avg = None
    history_overall_avg = None
    history_days = 0
    # per-partition history averages (new)
    history_avg_by_location_last_7_days: Dict[str, Dict[str, Any]] = {}

    try:
        import region_clients
        if hasattr(region_clients, "fetch_all_history"):
            entries = region_clients.fetch_all_history(timeout=timeout) or []
            # aggregate by date across regions
            agg_by_date = {}  # date_str -> {"employee": int, "contractor": int, "total": int}
            # Also aggregate partitions per date
            agg_partitions_by_date: Dict[str, Dict[str, Dict[str, int]]] = {}  # date -> partition -> {employee, contractor, total}
            for e in entries:
                try:
                    dstr = e.get("date")
                    if not dstr:
                        continue
                    region_obj = e.get("region") if isinstance(e.get("region"), dict) else None
                    emp = None
                    con = None
                    tot = None
                    if region_obj and isinstance(region_obj, dict):
                        emp = _safe_int(region_obj.get("Employee"))
                        con = _safe_int(region_obj.get("Contractor"))
                        tot = _safe_int(region_obj.get("total")) or ((emp or 0) + (con or 0))
                    else:
                        emp = _safe_int(e.get("Employee") or (e.get("region") and e.get("region").get("Employee") if isinstance(e.get("region"), dict) else None))
                        con = _safe_int(e.get("Contractor") or (e.get("region") and e.get("region").get("Contractor") if isinstance(e.get("region"), dict) else None))
                        tot = _safe_int(e.get("total") or ((emp or 0) + (con or 0)))
                    if emp is None and con is None and tot is None:
                        try:
                            robj = e.get("region") or {}
                            if isinstance(robj, dict):
                                emp = _safe_int(robj.get("Employee"))
                                con = _safe_int(robj.get("Contractor"))
                                tot = _safe_int(robj.get("total"))
                        except Exception:
                            pass
                    if emp is None and con is None:
                        continue
                    if tot is None:
                        tot = (emp or 0) + (con or 0)
                    if dstr not in agg_by_date:
                        agg_by_date[dstr] = {"employee": 0, "contractor": 0, "total": 0, "counted_regions": 0}
                    agg_by_date[dstr]["employee"] += (emp or 0)
                    agg_by_date[dstr]["contractor"] += (con or 0)
                    agg_by_date[dstr]["total"] += (tot or 0)
                    agg_by_date[dstr]["counted_regions"] += 1

                    # partitions
                    parts = e.get("partitions") if isinstance(e.get("partitions"), dict) else {}
                    if dstr not in agg_partitions_by_date:
                        agg_partitions_by_date[dstr] = {}
                    for pname, pstat in parts.items():
                        try:
                            p_emp = _safe_int(pstat.get("Employee"))
                            p_con = _safe_int(pstat.get("Contractor"))
                            p_tot = _safe_int(pstat.get("total")) or ((p_emp or 0) + (p_con or 0))
                            if pname not in agg_partitions_by_date[dstr]:
                                agg_partitions_by_date[dstr][pname] = {"employee": 0, "contractor": 0, "total": 0}
                            agg_partitions_by_date[dstr][pname]["employee"] += (p_emp or 0)
                            agg_partitions_by_date[dstr][pname]["contractor"] += (p_con or 0)
                            agg_partitions_by_date[dstr][pname]["total"] += (p_tot or 0)
                        except Exception:
                            continue
                except Exception:
                    continue

            # Now compute per-date lists for last 7 days
            day_vals_emp = []
            day_vals_con = []
            day_vals_tot = []
            for i in range(0, 7):
                d_iso = (today - timedelta(days=i)).isoformat()
                entry = agg_by_date.get(d_iso)
                if entry:
                    day_vals_emp.append(entry.get("employee", 0))
                    day_vals_con.append(entry.get("contractor", 0))
                    day_vals_tot.append(entry.get("total", 0))
            if day_vals_emp:
                history_emp_avg = round(sum(day_vals_emp) / float(len(day_vals_emp)), 2)
            if day_vals_con:
                history_contractor_avg = round(sum(day_vals_con) / float(len(day_vals_con)), 2)
            if day_vals_tot:
                history_overall_avg = round(sum(day_vals_tot) / float(len(day_vals_tot)), 2)
            history_days = len(day_vals_tot)
            if history_days == 0:
                notes.append("History endpoints returned no usable last-7-day rows; history averages not available.")

            # Compute per-partition averages across last 7 days
            # Build partition -> lists
            partition_day_values: Dict[str, Dict[str, List[int]]] = {}
            for i in range(0, 7):
                d_iso = (today - timedelta(days=i)).isoformat()
                per_parts = agg_partitions_by_date.get(d_iso, {})
                for pname, pvals in per_parts.items():
                    if pname not in partition_day_values:
                        partition_day_values[pname] = {"employee": [], "contractor": [], "total": []}
                    partition_day_values[pname]["employee"].append(pvals.get("employee", 0))
                    partition_day_values[pname]["contractor"].append(pvals.get("contractor", 0))
                    partition_day_values[pname]["total"].append(pvals.get("total", 0))
            # finalize per-partition averages
            for pname, lists in partition_day_values.items():
                emp_list = lists.get("employee", [])
                con_list = lists.get("contractor", [])
                tot_list = lists.get("total", [])
                days_counted = len(tot_list)
                if days_counted == 0:
                    continue
                avg_emp = round(sum(emp_list) / float(days_counted), 2)
                avg_con = round(sum(con_list) / float(days_counted), 2)
                avg_tot = round(sum(tot_list) / float(days_counted), 2)
                history_avg_by_location_last_7_days[pname] = {
                    "history_days_counted": int(days_counted),
                    "avg_employee_last_7_days": _sanitize_for_json(avg_emp),
                    "avg_contractor_last_7_days": _sanitize_for_json(avg_con),
                    "avg_overall_last_7_days": _sanitize_for_json(avg_tot)
                }

    except Exception:
        logger.exception("Error fetching/processing history endpoints")
        notes.append("Failed to compute history averages from region history endpoints; partial results.")

    # ---------- NEW: if DB-based 7-day avg empty, fallback to history_overall_avg ----------
    if (not avg_headcount_last_7_days or avg_headcount_last_7_days == 0) and history_overall_avg:
        try:
            avg_headcount_last_7_days = history_overall_avg
            avg_headcount_per_site_last_7_days = round(history_overall_avg / float(sites_queried), 2) if sites_queried and sites_queried > 0 else None
            notes.append("avg_headcount_last_7_days derived from region history endpoints due to missing AttendanceSummary historical data.")
        except Exception:
            pass

    # --- compute percentages (head/live vs CCURE reported)
    def safe_pct(n, denom):
        try:
            if n is None or denom is None:
                return None
            d = float(denom)
            if d == 0.0:
                return None
            return round((float(n) / d) * 100.0, 2)
        except Exception:
            return None

    cc_emp_denom = reported_active_emps
    cc_con_denom = reported_active_contractors
    cc_total_denom = None
    if isinstance(cc_emp_denom, int) and isinstance(cc_con_denom, int):
        cc_total_denom = cc_emp_denom + cc_con_denom

    head_emp_total = sum(v.get("employee", 0) for v in head_per_location.values())
    head_con_total = sum(v.get("contractor", 0) for v in head_per_location.values())
    live_emp_total = sum(v.get("employee", 0) for v in live_per_location.values())
    live_con_total = sum(v.get("contractor", 0) for v in live_per_location.values())

    # percent of CCURE employees/contractors present today (headcount basis)
    head_emp_pct_vs_ccure_today = _sanitize_for_json(safe_pct(head_emp_total, cc_emp_denom))
    head_con_pct_vs_ccure_today = _sanitize_for_json(safe_pct(head_con_total, cc_con_denom))
    head_overall_pct_vs_ccure_today = _sanitize_for_json(safe_pct(head_total, cc_total_denom))

    live_emp_pct_vs_ccure_today = _sanitize_for_json(safe_pct(live_emp_total, cc_emp_denom))
    live_con_pct_vs_ccure_today = _sanitize_for_json(safe_pct(live_con_total, cc_con_denom))
    live_overall_pct_vs_ccure_today = _sanitize_for_json(safe_pct(live_total, cc_total_denom))

    # history percentages vs CCURE (if denominators exist)
    history_emp_pct_vs_ccure = _sanitize_for_json(safe_pct(history_emp_avg, cc_emp_denom))
    history_con_pct_vs_ccure = _sanitize_for_json(safe_pct(history_contractor_avg, cc_con_denom))
    history_overall_pct_vs_ccure = _sanitize_for_json(safe_pct(history_overall_avg, cc_total_denom))

    result = {
        "date": today.isoformat(),
        "headcount": {
            "total_visited_today": int(head_total),
            "employee": int(head_emp_total),
            "contractor": int(head_con_total),
            "by_location": { loc: {"total": int(stats.get("total", 0)), "employee": int(stats.get("employee", 0)), "contractor": int(stats.get("contractor", 0))} for loc, stats in head_per_location.items() }
        },
        "live_headcount": {
            "currently_present_total": int(live_total),
            "employee": int(live_emp_total),
            "contractor": int(live_con_total),
            "by_location": { loc: {"total": int(stats.get("total", 0)), "employee": int(stats.get("employee", 0)), "contractor": int(stats.get("contractor", 0))} for loc, stats in live_per_location.items() }
        },
        "ccure_active": {
            "ccure_active_employees_reported": _safe_int(reported_active_emps),
            "ccure_active_contractors_reported": _safe_int(reported_active_contractors)
        },
        "averages": {
            # existing AttendanceSummary averages
            "head_emp_pct_vs_ccure_today": head_emp_pct_vs_ccure_today,
            "head_contractor_pct_vs_ccure_today": head_contractor_pct_vs_ccure_today,
            "headcount_overall_pct_vs_ccure_today": head_overall_pct_vs_ccure_today,
            "live_employee_pct_vs_ccure": live_emp_pct_vs_ccure_today,
            "live_contractor_pct_vs_ccure": live_con_pct_vs_ccure_today if False else live_con_pct_vs_ccure_today if 'live_con_pct_vs_ccure_today' in locals() else _sanitize_for_json(safe_pct(live_con_total, cc_con_denom)),
            "live_overall_pct_vs_ccure": live_overall_pct_vs_ccure_today,
            "avg_headcount_last_7_days": _sanitize_for_json(avg_headcount_last_7_days),
            "avg_headcount_per_site_last_7_days": _sanitize_for_json(avg_headcount_per_site_last_7_days),
            "avg_live_per_site": _sanitize_for_json(round(live_total / sites_queried, 2) if sites_queried and sites_queried > 0 else None),

            # NEW: history endpoint averages (region-provided)
            "history_avg_employee_last_7_days": _sanitize_for_json(history_emp_avg),
            "history_avg_contractor_last_7_days": _sanitize_for_json(history_contractor_avg),
            "history_avg_overall_last_7_days": _sanitize_for_json(history_overall_avg),
            "history_days_counted": int(history_days) if history_days is not None else None,
            "history_employee_pct_vs_ccure": history_emp_pct_vs_ccure,
            "history_contractor_pct_vs_ccure": history_con_pct_vs_ccure,
            "history_overall_pct_vs_ccure": history_overall_pct_vs_ccure,

            # NEW per-location aggregates:
            "avg_by_location_last_7_days": _sanitize_for_json(avg_by_location_last_7_days),
            "history_avg_by_location_last_7_days": _sanitize_for_json(history_avg_by_location_last_7_days)
        },
        "compliance": _sanitize_for_json(compliance),
        "sites_queried": int(sites_queried),
        "notes": " | ".join(notes) if notes else None
    }

    # sanitize and return
    return _sanitize_for_json(result)





